<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.80.0" />


<title>Common statistical tests are linear models - A Hugo website</title>
<meta property="og:title" content="Common statistical tests are linear models - A Hugo website">


  <link href='../../../../favicon.ico' rel='icon' type='image/x-icon'/>



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="../../../../css/fonts.css" media="all">
<link rel="stylesheet" href="../../../../css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="../../../../" class="nav-logo">
    <img src="../../../../images/logo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="../../../../about/">about</a></li>
    
    <li><a href="../../../../vitae/">CV</a></li>
    
    <li><a href="https://github.com/danli349">GitHub</a></li>
    
    <li><a href="https://scholar.google.com/citations?user=mNjLK8EAAAAJ&amp;hl=en">Googlr Scholar</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">99 min read</span>
    

    <h1 class="article-title">Common statistical tests are linear models</h1>

    
    <span class="article-date">2023-09-24</span>
    

    <div class="article-content">
      
<script src="../../../../2023/09/24/common-statistical-tests-are-linear-models-or-how-to-teach-stats/index_files/htmlwidgets/htmlwidgets.js"></script>
<link href="../../../../2023/09/24/common-statistical-tests-are-linear-models-or-how-to-teach-stats/index_files/datatables-css/datatables-crosstalk.css" rel="stylesheet" />
<script src="../../../../2023/09/24/common-statistical-tests-are-linear-models-or-how-to-teach-stats/index_files/datatables-binding/datatables.js"></script>
<script src="../../../../2023/09/24/common-statistical-tests-are-linear-models-or-how-to-teach-stats/index_files/jquery/jquery-3.6.0.min.js"></script>
<link href="../../../../2023/09/24/common-statistical-tests-are-linear-models-or-how-to-teach-stats/index_files/dt-core/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="../../../../2023/09/24/common-statistical-tests-are-linear-models-or-how-to-teach-stats/index_files/dt-core/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="../../../../2023/09/24/common-statistical-tests-are-linear-models-or-how-to-teach-stats/index_files/dt-core/js/jquery.dataTables.min.js"></script>
<link href="../../../../2023/09/24/common-statistical-tests-are-linear-models-or-how-to-teach-stats/index_files/crosstalk/css/crosstalk.min.css" rel="stylesheet" />
<script src="../../../../2023/09/24/common-statistical-tests-are-linear-models-or-how-to-teach-stats/index_files/crosstalk/js/crosstalk.min.js"></script>

<div id="TOC">
<ul>
<li><a href="#interpretation-of-rs-lm-output" id="toc-interpretation-of-rs-lm-output">Interpretation of R’s <code>lm()</code> output</a>
<ul>
<li><a href="#five-point-summary" id="toc-five-point-summary">Five point summary</a></li>
<li><a href="#coefficients-and-hatbeta_is" id="toc-coefficients-and-hatbeta_is">Coefficients and <span class="math inline">\(\hat{\beta_i}s\)</span></a></li>
<li><a href="#t-statistics" id="toc-t-statistics"><span class="math inline">\(t\)</span>-statistics</a></li>
<li><a href="#residual-standard-error" id="toc-residual-standard-error">Residual standard error</a></li>
<li><a href="#adjusted-r2" id="toc-adjusted-r2">Adjusted <span class="math inline">\(R^2\)</span></a></li>
<li><a href="#f-statistic" id="toc-f-statistic"><span class="math inline">\(F\)</span>-statistic</a></li>
</ul></li>
<li><a href="#the-simplicity-underlying-common-tests" id="toc-the-simplicity-underlying-common-tests">The simplicity underlying common tests</a></li>
<li><a href="#settings-and-toy-data" id="toc-settings-and-toy-data">Settings and toy data</a></li>
<li><a href="#correlation" id="toc-correlation">Pearson and Spearman correlation</a>
<ul>
<li><a href="#theory-as-linear-models" id="toc-theory-as-linear-models">Theory: As linear models</a></li>
<li><a href="#rank" id="toc-rank">Theory: rank-transformation</a></li>
<li><a href="#r-code-pearson-correlation" id="toc-r-code-pearson-correlation">R code: Pearson correlation</a></li>
<li><a href="#r-code-spearman-correlation" id="toc-r-code-spearman-correlation">R code: Spearman correlation</a></li>
</ul></li>
<li><a href="#one-mean" id="toc-one-mean">One mean</a>
<ul>
<li><a href="#t1" id="toc-t1">One sample t-test and Wilcoxon signed-rank</a>
<ul>
<li><a href="#theory-as-linear-models-1" id="toc-theory-as-linear-models-1">Theory: As linear models</a></li>
<li><a href="#r-code-one-sample-t-test" id="toc-r-code-one-sample-t-test">R code: One-sample t-test</a></li>
<li><a href="#r-code-wilcoxon-signed-rank-test" id="toc-r-code-wilcoxon-signed-rank-test">R code: Wilcoxon signed-rank test</a></li>
</ul></li>
<li><a href="#tpair" id="toc-tpair">Paired samples t-test and Wilcoxon matched pairs</a>
<ul>
<li><a href="#theory-as-linear-models-2" id="toc-theory-as-linear-models-2">Theory: As linear models</a></li>
<li><a href="#r-code-paired-sample-t-test" id="toc-r-code-paired-sample-t-test">R code: Paired sample t-test</a></li>
<li><a href="#r-code-wilcoxon-matched-pairs" id="toc-r-code-wilcoxon-matched-pairs">R code: Wilcoxon matched pairs</a></li>
</ul></li>
</ul></li>
<li><a href="#two-means" id="toc-two-means">Two means</a>
<ul>
<li><a href="#t2" id="toc-t2">Independent t-test and Mann-Whitney U</a>
<ul>
<li><a href="#theory-as-linear-models-3" id="toc-theory-as-linear-models-3">Theory: As linear models</a></li>
<li><a href="#dummy" id="toc-dummy">Theory: Dummy coding</a></li>
<li><a href="#dummy2" id="toc-dummy2">Theory: Dummy coding (continued)</a></li>
<li><a href="#r-code-independent-t-test" id="toc-r-code-independent-t-test">R code: independent t-test</a></li>
<li><a href="#r-code-mann-whitney-u" id="toc-r-code-mann-whitney-u">R code: Mann-Whitney U</a></li>
</ul></li>
<li><a href="#welch" id="toc-welch">Welch’s t-test</a></li>
</ul></li>
<li><a href="#three-or-more-means" id="toc-three-or-more-means">Three or more means</a>
<ul>
<li><a href="#anova1" id="toc-anova1">One-way ANOVA and Kruskal-Wallis</a>
<ul>
<li><a href="#theory-as-linear-models-4" id="toc-theory-as-linear-models-4">Theory: As linear models</a></li>
<li><a href="#example-data" id="toc-example-data">Example data</a></li>
<li><a href="#r-code-one-way-anova" id="toc-r-code-one-way-anova">R code: one-way ANOVA</a></li>
<li><a href="#r-code-kruskal-wallis" id="toc-r-code-kruskal-wallis">R code: Kruskal-Wallis</a></li>
</ul></li>
<li><a href="#two-way-anova" id="toc-two-way-anova">Two-way ANOVA</a>
<ul>
<li><a href="#theory-as-linear-models-5" id="toc-theory-as-linear-models-5">Theory: As linear models</a></li>
<li><a href="#r-code-two-way-anova" id="toc-r-code-two-way-anova">R code: Two-way ANOVA</a></li>
</ul></li>
<li><a href="#ancova" id="toc-ancova">ANCOVA</a></li>
</ul></li>
<li><a href="#proportions-chi-square-is-a-log-linear-model" id="toc-proportions-chi-square-is-a-log-linear-model">Proportions: Chi-square is a log-linear model</a>
<ul>
<li><a href="#goodness" id="toc-goodness">Goodness of fit</a>
<ul>
<li><a href="#theory-as-log-linear-model" id="toc-theory-as-log-linear-model">Theory: As log-linear model</a></li>
<li><a href="#example-data-1" id="toc-example-data-1">Example data</a></li>
<li><a href="#r-code-goodness-of-fit" id="toc-r-code-goodness-of-fit">R code: Goodness of fit</a></li>
</ul></li>
<li><a href="#contingency" id="toc-contingency">Contingency tables</a>
<ul>
<li><a href="#theory-as-log-linear-model-1" id="toc-theory-as-log-linear-model-1">Theory: As log-linear model</a></li>
<li><a href="#example-data-2" id="toc-example-data-2">Example data</a></li>
<li><a href="#r-code-chi-square-test" id="toc-r-code-chi-square-test">R code: Chi-square test</a></li>
</ul></li>
</ul></li>
<li><a href="#links" id="toc-links">Sources and further equivalences</a></li>
<li><a href="#explicit-glmm-equivalents-for-standard-tests" id="toc-explicit-glmm-equivalents-for-standard-tests">Explicit GLM(M) Equivalents for Standard Tests</a>
<ul>
<li><a href="#explicit-glm-test-poisson" id="toc-explicit-glm-test-poisson">Explicit GLM Test: Poisson</a></li>
<li><a href="#binomial-test-logistic-regression" id="toc-binomial-test-logistic-regression">Binomial Test: Logistic Regression</a>
<ul>
<li><a href="#classical-test-exact-binomial-test" id="toc-classical-test-exact-binomial-test">Classical Test: Exact Binomial Test</a></li>
<li><a href="#explicit-glm-logit-or-probit" id="toc-explicit-glm-logit-or-probit">Explicit GLM: Logit (or Probit)</a></li>
<li><a href="#probability-density-function-of-logistic-distribution" id="toc-probability-density-function-of-logistic-distribution">Probability density function of Logistic distribution</a></li>
</ul></li>
<li><a href="#proportion-test-multinomial-logistic-or-poisson-model" id="toc-proportion-test-multinomial-logistic-or-poisson-model">Proportion Test: (Multinomial) Logistic or Poisson Model</a>
<ul>
<li><a href="#classical-test-test-for-equality-of-proportions" id="toc-classical-test-test-for-equality-of-proportions">Classical Test: Test for Equality of Proportions</a></li>
<li><a href="#explicit-glm-logit" id="toc-explicit-glm-logit">Explicit GLM: Logit</a></li>
<li><a href="#explicit-glm-poisson" id="toc-explicit-glm-poisson">Explicit GLM: Poisson</a></li>
<li><a href="#classical-test-poisson-test" id="toc-classical-test-poisson-test">Classical Test: Poisson Test</a></li>
</ul></li>
</ul></li>
<li><a href="#references" id="toc-references">References</a></li>
</ul>
</div>

<!-- Social sharing. From simplesharebuttons.com -->
<style type="text/css">
  #share-buttons img {
    width: 40px;
    padding-right: 15px;
    border: 0;
    box-shadow: 0;
    display: inline;
    vertical-align: top;
  }
</style>
<pre class="r"><code># Options for building this document
knitr::opts_chunk$set(
  fig.height = 4,
  fig.width = 6,
  fig.align = &#39;center&#39;,
  message = FALSE,
  warning = FALSE
)

#devtools::install_github(&quot;jumpingrivers/headR&quot;)

# To show tables.
print_df = function(D,
                    decimals = 4,
                    navigate = FALSE) {
  DT::datatable(
    mutate_if(D, is.numeric, round, decimals),
    rownames = FALSE,
    options = list(
      searching = FALSE,
      lengthChange = FALSE,
      ordering = FALSE,
      autoWidth = TRUE,
      bPaginate = navigate,
      bInfo = navigate,
      paging = navigate
    )
  )
}</code></pre>
<div id="interpretation-of-rs-lm-output" class="section level1">
<h1>Interpretation of R’s <code>lm()</code> output</h1>
<p>The help pages in R assume I know what those numbers mean, but I don’t.
I’m trying to really intuitively understand every number here. I will just post the output and comment on what I found out. There might (will) be mistakes, as I’ll just write what I assume. Mainly I’d like to know what the t-value in the coefficients mean, and why they print the residual standard error.</p>
<pre class="r"><code>summary(lm(formula = iris$Sepal.Width ~ iris$Petal.Width))</code></pre>
<pre><code>## 
## Call:
## lm(formula = iris$Sepal.Width ~ iris$Petal.Width)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.09907 -0.23626 -0.01064  0.23345  1.17532 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)       3.30843    0.06210  53.278  &lt; 2e-16 ***
## iris$Petal.Width -0.20936    0.04374  -4.786 4.07e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.407 on 148 degrees of freedom
## Multiple R-squared:  0.134,	Adjusted R-squared:  0.1282 
## F-statistic: 22.91 on 1 and 148 DF,  p-value: 4.073e-06</code></pre>
<pre class="r"><code>pf(22.91, df1=1, df2=148, lower.tail = FALSE)</code></pre>
<pre><code>## [1] 4.073605e-06</code></pre>
<p>The gist is that the <span class="math inline">\(F\)</span>-test is asking if one model is better than another. If that is the case, then you seem “significant” the parameters in the larger model but not in the smaller model. If you do a two-sided test, you are considering that the larger model is worse than the smaller model, which makes no sense from the standpoint of trying to show that a predictor impacts the response variable.</p>
<p>In a bit more detail, the <span class="math inline">\(F\)</span>-test compares two models on squared differences between predicted values and observed values (square loss), mathematically expressed as <span class="math inline">\((y_i - \hat y_i)^2\)</span>. The models are nested, meaning that the larger one has all of the parameters that the smaller one has, plus some extra ones (maybe just one, <a href="http://en.wikipedia.org/wiki/Ordinary_least_squares">maybe a bunch</a>). The test then asks if the reduction square loss is enough to convince us that the additional parameters are not zero (reject the null hypothesis). If those parameters are not zero, then the variables to which they correspond can be considered contributors to the values of <span class="math inline">\(y\)</span>.</p>
<p>This is why we only care about the one-sided test. If the evidence is that the larger model provides a <em>worse</em> fit than the smaller model, then that does not help us show that the additional parameters are non-zero.</p>
<pre><code>Call:
lm(formula = iris$Sepal.Width ~ iris$Petal.Width)

Residuals:
     Min       1Q   Median       3Q      Max 
-1.09907 -0.23626 -0.01064  0.23345  1.17532 </code></pre>
<p>This is a 5-point-summary of the residuals (their Median is always 0, right?). The numbers can be used (I’m guessing here) to quickly see if there are any big outliers. Also you can already see it here if the residuals are far from normally distributed (they should be normally distributed).</p>
<pre><code>Coefficients:
                 Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)       3.30843    0.06210  53.278  &lt; 2e-16 ***
iris$Petal.Width -0.20936    0.04374  -4.786 4.07e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 </code></pre>
<p>Estimates <span class="math inline">\(\hat{\beta_i}\)</span>, computed by least squares regression. Also, the standard error is <span class="math inline">\(\sigma_{\beta_i}\)</span>. I’d like to know how this is calculated. I have no idea where the t-value and the corresponding p-value come from. I know <span class="math inline">\(\hat{\beta}\)</span> should be normal distributed, but how is the t-value calculated?</p>
<pre><code>Residual standard error: 0.407 on 148 degrees of freedom</code></pre>
<p><span class="math inline">\(\sqrt{ \frac{1}{n-p} \epsilon^T\epsilon }\)</span>, I guess. But why do we calculate that, and what does it tell us?</p>
<pre><code>Multiple R-squared: 0.134,	Adjusted R-squared: 0.1282 </code></pre>
<p><span class="math display">\[R^2 = \frac{s_\hat{y}^2}{s_y^2}\]</span>, which is <span class="math inline">\(\frac{\sum_{i=1}^n (\hat{y_i}-\bar{y})^2}{\sum_{i=1}^n (y_i-\bar{y})^2}\)</span>. The ratio is close to 1 if the points lie on a straight line, and 0 if they are random. What is the adjusted R-squared?</p>
<pre><code>F-statistic: 22.91 on 1 and 148 DF,  p-value: 4.073e-06 </code></pre>
<p>F and p for the <strong>whole</strong> model, not only for single <span class="math inline">\(\beta_i\)</span>s as previous. The F value is
<span class="math inline">\(\frac{s^2_{\hat{y}}}{\sum\epsilon_i}\)</span>. The bigger it grows, the more unlikely it is that the <span class="math inline">\(\beta\)</span>’s do not have any effect at all.</p>
<div id="five-point-summary" class="section level2">
<h2>Five point summary</h2>
<p>yes, the idea is to give a quick summary of the distribution. It should be roughly symmetrical about mean, the median should be close to 0, the 1Q and 3Q values should ideally be roughly similar values.</p>
</div>
<div id="coefficients-and-hatbeta_is" class="section level2">
<h2>Coefficients and <span class="math inline">\(\hat{\beta_i}s\)</span></h2>
<p>Each coefficient in the model is a Gaussian (Normal) random variable. The <span class="math inline">\(\hat{\beta_i}\)</span> is the estimate of the mean of the distribution of that random variable, and the standard error is the square root of the variance of that distribution. It is a measure of the uncertainty in the estimate of the <span class="math inline">\(\hat{\beta_i}\)</span>.</p>
<p>You can look at how these are computed (well the mathematical formulae used) on <a href="http://en.wikipedia.org/wiki/Ordinary_least_squares">Wikipedia</a>. Note that any self-respecting stats program will <strong>not</strong> use the standard mathematical equations to compute the <span class="math inline">\(\hat{\beta_i}\)</span> because doing them on a computer can lead to a large loss of precision in the computations.</p>
</div>
<div id="t-statistics" class="section level2">
<h2><span class="math inline">\(t\)</span>-statistics</h2>
<p>The <span class="math inline">\(t\)</span> statistics are the estimates (<span class="math inline">\(\hat{\beta_i}\)</span>) divided by their standard errors (<span class="math inline">\(\hat{\sigma_i}\)</span>), e.g. 
<span class="math display">\[t_i = \frac{\hat{\beta_i}}{\hat{\sigma_i}}\]</span>. Assuming you have the same model in object <code>mod</code>as your Q:</p>
<pre class="r"><code>mod &lt;- lm(Sepal.Width ~ Petal.Width, data = iris)
summary(mod)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Sepal.Width ~ Petal.Width, data = iris)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.09907 -0.23626 -0.01064  0.23345  1.17532 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  3.30843    0.06210  53.278  &lt; 2e-16 ***
## Petal.Width -0.20936    0.04374  -4.786 4.07e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.407 on 148 degrees of freedom
## Multiple R-squared:  0.134,	Adjusted R-squared:  0.1282 
## F-statistic: 22.91 on 1 and 148 DF,  p-value: 4.073e-06</code></pre>
<pre class="r"><code>mod2 &lt;- glm(Sepal.Width ~ Petal.Width, data = iris, family=gaussian)
summary(mod2)</code></pre>
<pre><code>## 
## Call:
## glm(formula = Sepal.Width ~ Petal.Width, family = gaussian, data = iris)
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  3.30843    0.06210  53.278  &lt; 2e-16 ***
## Petal.Width -0.20936    0.04374  -4.786 4.07e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 0.1656246)
## 
##     Null deviance: 28.307  on 149  degrees of freedom
## Residual deviance: 24.512  on 148  degrees of freedom
## AIC: 159.96
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<p>then the <span class="math inline">\(t\)</span> values R reports are computed as:</p>
<pre class="r"><code>tstats &lt;- coef(mod) / sqrt(diag(vcov(mod)))
tstats</code></pre>
<pre><code>## (Intercept) Petal.Width 
##   53.277950   -4.786461</code></pre>
<p>Where <code>coef(mod)</code> are the <span class="math inline">\(\hat{\beta_i}\)</span>, and <code>sqrt(diag(vcov(mod)))</code> gives the square roots of the diagonal elements of the covariance matrix of the model parameters, which are the standard errors of the parameters (<span class="math inline">\(\hat{\sigma_i}\)</span>).</p>
<p>The p-value is the probability of achieving a <span class="math inline">\(|t|\)</span> as large as or larger than the observed absolute t value if the null hypothesis (<span class="math inline">\(H_0\)</span>) was true, where <span class="math inline">\(H_0\)</span> is <span class="math inline">\(\beta_i = 0\)</span>. They are computed as (using <code>tstats</code> from above):</p>
<pre class="r"><code>df.residual(mod)</code></pre>
<pre><code>## [1] 148</code></pre>
<pre class="r"><code>2 * pt(abs(tstats), df = df.residual(mod), lower.tail = FALSE)</code></pre>
<pre><code>##  (Intercept)  Petal.Width 
## 1.835999e-98 4.073229e-06</code></pre>
<pre><code>&gt; 2 * pt(abs(tstats), df = df.residual(mod), lower.tail = FALSE)
 (Intercept)  Petal.Width 
1.835999e-98 4.073229e-06</code></pre>
<p>So we compute the upper tail probability of achieving the <span class="math inline">\(t\)</span> values we did from a <span class="math inline">\(t\)</span> distribution with degrees of freedom equal to the residual degrees of freedom of the model. This represents the probability of achieving a <span class="math inline">\(t\)</span> value greater than the absolute values of the observed <span class="math inline">\(t\)</span>s. It is multiplied by 2, because of course <span class="math inline">\(t\)</span> can be large in the negative direction too.</p>
</div>
<div id="residual-standard-error" class="section level2">
<h2>Residual standard error</h2>
<p>The residual standard error is an estimate of the parameter <span class="math inline">\(\sigma\)</span>. The assumption in ordinary least squares is that the residuals are individually described by a Gaussian (normal) distribution with mean 0 and standard deviation <span class="math inline">\(\sigma\)</span>. The <span class="math inline">\(\sigma\)</span> relates to the constant variance assumption; each residual has the same variance and that variance is equal to <span class="math inline">\(\sigma^2\)</span>.</p>
</div>
<div id="adjusted-r2" class="section level2">
<h2>Adjusted <span class="math inline">\(R^2\)</span></h2>
<p>The <strong>residual standard error</strong> is <span class="math inline">\(\sqrt{MSE}\)</span>. The <span class="math inline">\(MSE\)</span> is an unbiased estimator of <span class="math inline">\(\sigma^2\)</span>, where <span class="math inline">\(\sigma^2 = Var(y|x)\)</span>.</p>
<p>To make it more clear of the answer by <span class="citation">@Silverfish</span> and <span class="citation">@Waldir</span> Leoncio.<br />
A summary of all definitions was shown below. Always got confused by these terms, put it here instead of making it as a comment for better formatting.</p>
<p><strong>Anova table of <em>SLR/Simple Linear Regression</em> (DF is different for multiple regression):</strong></p>
<table style="width:100%;">
<colgroup>
<col width="15%" />
<col width="13%" />
<col width="15%" />
<col width="45%" />
<col width="9%" />
</colgroup>
<thead>
<tr class="header">
<th>Source</th>
<th>DF</th>
<th>Sum Sq</th>
<th>Mean Sq</th>
<th>F value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Regression</td>
<td><span class="math inline">\(1\)</span></td>
<td><span class="math inline">\(SSR\)</span></td>
<td><span class="math inline">\(MSR = \frac{SSR}{1}\)</span></td>
<td><span class="math inline">\(\frac{MSR}{MSE}\)</span></td>
</tr>
<tr class="even">
<td>Residual</td>
<td><span class="math inline">\(n - 2\)</span></td>
<td><span class="math inline">\(SSE\)</span></td>
<td><span class="math inline">\(MSE = \frac{SSE}{n - 2}\)</span></td>
<td></td>
</tr>
<tr class="odd">
<td>Total</td>
<td><span class="math inline">\(n - 1\)</span></td>
<td><span class="math inline">\(SST\)</span></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>where <span class="math inline">\(n\)</span> is the sample size of <span class="math inline">\(x_i\)</span>, <span class="math inline">\(SST = SSE + SSR\)</span>, <span class="math inline">\(SST = S_{YY} = \sum_{i = 1}^{n}{(y_i - \bar{y})^2}\)</span>, <span class="math inline">\(SSE = \sum_{i = 1}^{n}{(y_i - \hat{y_i})^2}\)</span>, <span class="math inline">\(SSR = \sum_{i = 1}^{n}{(\hat{y_i} - \bar{y})^2}\)</span>.</p>
<p>The <span class="math inline">\(SSR\)</span> is the part of variance of <span class="math inline">\(y_i\)</span> which can be explained by <span class="math inline">\(\hat{y_i}\)</span>, the greater the better.</p>
<p>Also for <strong>SLR</strong>, <span class="math inline">\(se(\beta_1) = \sqrt{MSE}/\sqrt{S_{xx}}\)</span>, where <span class="math inline">\(S_{XX}\)</span> is defined similarly as <span class="math inline">\(S_{YY}\)</span>.</p>
<p>Say we have the following ANOVA table (adapted from R’s <code>example(aov)</code> command):</p>
<pre class="r"><code>anova(mod)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Response: Sepal.Width
##              Df  Sum Sq Mean Sq F value    Pr(&gt;F)    
## Petal.Width   1  3.7945  3.7945   22.91 4.073e-06 ***
## Residuals   148 24.5124  0.1656                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>#SSR sum square of regression
anova(mod)$`Sum Sq`[1]</code></pre>
<pre><code>## [1] 3.794493</code></pre>
<pre class="r"><code>sum((mod$fitted.values-mean(iris$Sepal.Width))^2)</code></pre>
<pre><code>## [1] 3.794493</code></pre>
<pre class="r"><code>#SSE sum square of error (or Residuals)
anova(mod)$`Sum Sq`[2]</code></pre>
<pre><code>## [1] 24.51244</code></pre>
<pre class="r"><code>sum((iris$Sepal.Width-mod$fitted.values)^2)</code></pre>
<pre><code>## [1] 24.51244</code></pre>
<pre class="r"><code>#SST sum square of total 
sum(anova(mod)$`Sum Sq`)</code></pre>
<pre><code>## [1] 28.30693</code></pre>
<pre class="r"><code>sum((iris$Sepal.Width-mean(iris$Sepal.Width))^2)</code></pre>
<pre><code>## [1] 28.30693</code></pre>
<p>If you divide the sum of squares from any source of variation (model or residuals) by its respective degrees of freedom, you get the mean square. Particularly for the residuals:</p>
<pre class="r"><code>24.5124/148</code></pre>
<pre><code>## [1] 0.1656243</code></pre>
<p><span class="math display">\[
\frac{24.5124}{148} \approx 0.1656
\]</span></p>
<p>So 0.1656 is the mean square of the residuals, i.e., the amount of residual (after applying the model) variation on your response variable.</p>
<p>The <strong>residual standard error</strong> is nothing more than the <strong>positive square root of the mean square error</strong>. In my example, the residual standard error would be equal to <span class="math inline">\(\sqrt{0.1656}\)</span>, or approximately 0.407. R would output this information as “0.407 on 148 degrees of freedom”.</p>
<pre class="r"><code>sqrt(24.5124/148)</code></pre>
<pre><code>## [1] 0.4069697</code></pre>
<pre class="r"><code>summary(mod)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Sepal.Width ~ Petal.Width, data = iris)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.09907 -0.23626 -0.01064  0.23345  1.17532 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  3.30843    0.06210  53.278  &lt; 2e-16 ***
## Petal.Width -0.20936    0.04374  -4.786 4.07e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.407 on 148 degrees of freedom
## Multiple R-squared:  0.134,	Adjusted R-squared:  0.1282 
## F-statistic: 22.91 on 1 and 148 DF,  p-value: 4.073e-06</code></pre>
<p>Typically you will have a regression model looks like this:
<span class="math display">\[
Y = \beta_{0} + \beta_{1}X + \epsilon
\]</span>
where $ $ is an error term independent of $ X $.</p>
<p>If $ <em>{0} $ and $ </em>{1} $ are known, we still cannot perfectly predict Y using X due to $ $. Therefore, we use RSE as a judgement value of the Standard Deviation of $ $.</p>
<p>RSE is s just an estimate of the Standard Deviation of $ $, i.e. the residual. It’s also known as the residual standard deviation (RSD), and it can be defined as <span class="math inline">\(RSE=\sqrt{\frac{RSS}{(n−2)}}\)</span></p>
<p>The R squared value ranges between 0 to 1 and is represented by the below formula:</p>
<p><span class="math display">\[R2= 1- SSres / SStot\]</span></p>
<p>Here,</p>
<p>SSres: The sum of squares of the residual errors.
SStot: It represents the total sum of the errors.</p>
<p>So, here we have</p>
<pre class="r"><code>anova(mod)$`Sum Sq`</code></pre>
<pre><code>## [1]  3.794493 24.512440</code></pre>
<pre class="r"><code>1-anova(mod)$`Sum Sq`[2]/(sum(anova(mod)$`Sum Sq`))</code></pre>
<pre><code>## [1] 0.1340482</code></pre>
<pre class="r"><code>summary(mod)$r.squared</code></pre>
<pre><code>## [1] 0.1340482</code></pre>
<p>Adjusted <span class="math inline">\(R^2\)</span> is computed as:</p>
<p><span class="math display">\[1 - (1 - R^2) \frac{n - 1}{n - p - 1}\]</span></p>
<pre class="r"><code>summary(mod)$adj.r.squared</code></pre>
<pre><code>## [1] 0.1281972</code></pre>
<pre class="r"><code>n &lt;- length(iris$Sepal.Width)
p &lt;- 1
r2 &lt;- summary(mod)$r.squared
1-(1-r2)*(n-1)/(n-p-1)</code></pre>
<pre><code>## [1] 0.1281972</code></pre>
<p>The adjusted <span class="math inline">\(R^2\)</span> is the same thing as <span class="math inline">\(R^2\)</span>, but adjusted for the complexity (i.e. the number of parameters) of the model. Given a model with a single parameter, with a certain <span class="math inline">\(R^2\)</span>, if we add another parameter to this model, the <span class="math inline">\(R^2\)</span> of the new model has to increase, <em>even if</em> the added parameter has no statistical power. The adjusted <span class="math inline">\(R^2\)</span> accounts for this by including the number of parameters in the model.</p>
</div>
<div id="f-statistic" class="section level2">
<h2><span class="math inline">\(F\)</span>-statistic</h2>
<p>The <span class="math inline">\(F\)</span> is the ratio of two variances (<span class="math inline">\(SSR/SSE\)</span>), the variance explained by the parameters in the model (sum of squares of regression, SSR) and the residual or unexplained variance (sum of squares of error, SSE). You can see this better if we get the ANOVA table for the model via <code>anova()</code>:</p>
<pre class="r"><code>anova(mod)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Response: Sepal.Width
##              Df  Sum Sq Mean Sq F value    Pr(&gt;F)    
## Petal.Width   1  3.7945  3.7945   22.91 4.073e-06 ***
## Residuals   148 24.5124  0.1656                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>anova(mod)$`F value`[1]</code></pre>
<pre><code>## [1] 22.91021</code></pre>
<pre class="r"><code>anova(mod)$`Mean Sq`[1]/anova(mod)$`Mean Sq`[2]</code></pre>
<pre><code>## [1] 22.91021</code></pre>
<p>The <span class="math inline">\(F\)</span>s are the same in the ANOVA output and the <code>summary(mod)</code> output. The <code>Mean Sq</code> column contains the two variances and <span class="math inline">\(3.7945 / 0.1656 = 22.91\)</span>. We can compute the probability of achieving an <span class="math inline">\(F\)</span> that large under the null hypothesis of no effect, from an <span class="math inline">\(F\)</span>-distribution with 1 and 148 degrees of freedom. This is what is reported in the final column of the ANOVA table. In the simple case of a single, continuous predictor (as per your example), <span class="math inline">\(F = t_{\mathrm{Petal.Width}}^2\)</span>, which is why the p-values are the same. This equivalence only holds in this simple case.</p>
<p>This document is summarised in the table below. It shows the linear models underlying common parametric and “non-parametric” tests. Formulating all the tests in the same language highlights the many similarities between them. Get it <a href="linear_tests_cheat_sheet.png">as an image</a> or <a href="linear_tests_cheat_sheet.pdf">as a PDF</a>.</p>
<hr />
<p><a href="linear_tests_cheat_sheet.pdf"><img src="linear_tests_cheat_sheet.png" /></a></p>
<hr />
</div>
</div>
<div id="the-simplicity-underlying-common-tests" class="section level1">
<h1>The simplicity underlying common tests</h1>
<p>Most of the common statistical models (t-test, correlation, ANOVA; chi-square, etc.) are special cases of linear models or a very close approximation. This beautiful simplicity means that there is less to learn. In particular, it all comes down to <span class="math inline">\(y = a \cdot x + b\)</span> which most students know from highschool. Unfortunately, stats intro courses are usually taught as if each test is an independent tool, needlessly making life more complicated for students and teachers alike.</p>
<p>This needless complexity multiplies when students try to rote learn the parametric assumptions underlying each test separately rather than deducing them from the linear model.</p>
<p>For this reason, I think that teaching linear models first and foremost and <em>then</em> name-dropping the special cases along the way makes for an excellent teaching strategy, emphasizing <em>understanding</em> over rote learning. Since linear models are the same across frequentist, Bayesian, and permutation-based inferences, I’d argue that it’s better to start with modeling than p-values, type-1 errors, Bayes factors, or other inferences.</p>
<p>Concerning the teaching of <em>“non-parametric”</em> tests in intro-courses, I think that we can justify <a href="https://en.wikipedia.org/wiki/Lie-to-children">lying-to-children</a> and teach “non-parametric”” tests as if they are merely ranked versions of the corresponding parametric tests. It is much better for students to think “ranks!” than to believe that you can magically throw away assumptions. Indeed, the Bayesian equivalents of “non-parametric”” tests implemented in <a href="https://jasp-stats.org">JASP</a> <a href="https://arxiv.org/abs/1712.06941">literally just do (latent) ranking</a> and that’s it. For the frequentist “non-parametric”” tests considered here, this approach is highly accurate for N &gt; 15.</p>
<center>
<img src="https://www.picsellmedia.com/wp-content/uploads/2017/01/shutterstock_336913772.jpg" />
</center>
<p><br /></p>
<p>Use the menu to jump to your favourite section. There are links to lots of similar (though more scattered) stuff under <a href="#links">sources</a> and <a href="#course">teaching materials</a>. I hope that you will join in suggesting improvements or submitting improvements yourself in <a href="https://github.com/lindeloev/tests-as-linear">the Github repo to this page</a>. Let’s make it awesome!</p>
</div>
<div id="settings-and-toy-data" class="section level1">
<h1>Settings and toy data</h1>
Unfold this if you want to see functions and other settings for this notebook:
<div class='fold s'>

<pre class="r"><code># Load packages for data handling and plotting
library(tidyverse)
library(patchwork)
library(broom)

# Reproducible &quot;random&quot; results
set.seed(40)

# Generate normal data with known parameters
rnorm_fixed = function(N, mu = 0, sd = 1)
  scale(rnorm(N)) * sd + mu

# Plot style.
theme_axis = function(P,
                      jitter = FALSE,
                      xlim = c(-0.5, 2),
                      ylim = c(-0.5, 2),
                      legend.position = NULL) {
  P = P + theme_bw(15) +
    geom_segment(
      x = -1000, xend = 1000,
      y = 0, yend = 0,
      lty = 2, color = &#39;dark gray&#39;, lwd = 0.5
    ) +
    geom_segment(
      x = 0, xend = 0,
      y = -1000, yend = 1000,
      lty = 2, color = &#39;dark gray&#39;, lwd = 0.5
    ) +
    coord_cartesian(xlim = xlim, ylim = ylim) +
    theme(
      axis.title = element_blank(),
      axis.text = element_blank(),
      axis.ticks = element_blank(),
      panel.border = element_blank(),
      panel.grid = element_blank(),
      legend.position = legend.position
    )
  
  # Return jittered or non-jittered plot?
  if (jitter) {
    P + geom_jitter(width = 0.1, size = 2)
  }
  else {
    P + geom_point(size = 2)
  }
}</code></pre>
<p>For a start, we’ll keep it simple and play with three standard normals in wide (<code>a</code>, <code>b</code>, <code>c</code>) and long format (<code>value</code>, <code>group</code>):</p>
<pre class="r"><code>rnorm(15)</code></pre>
<pre><code>##  [1]  0.47773904  0.49618282 -0.85958430 -0.82905996 -0.32157308 -1.30377040
##  [7] -1.42148660  1.74491495 -0.28827936 -1.30886572 -0.06945219 -1.22492668
## [13]  0.80899626 -0.49215034  0.45269393</code></pre>
<pre class="r"><code>exp(rnorm(15))</code></pre>
<pre><code>##  [1] 2.7172847 1.5952486 1.4565229 5.4930901 0.3550625 3.7739496 0.5519559
##  [8] 5.0092419 0.3286790 0.2321938 2.0795593 0.1998198 1.3938467 2.1401077
## [15] 0.1566612</code></pre>
<pre class="r"><code>runif(20, min = -3, max = 0)  </code></pre>
<pre><code>##  [1] -0.6432833 -2.1694417 -2.7000994 -1.4465571 -2.3468054 -1.4680747
##  [7] -0.2255054 -2.1287277 -1.7784885 -0.3228574 -0.8106110 -0.6170659
## [13] -2.7829337 -0.9272402 -1.2122765 -0.6369051 -1.8735809 -2.4847702
## [19] -0.5852019 -0.9449704</code></pre>
<pre class="r"><code># Wide format (sort of)
#y = rnorm_fixed(50, mu=0.3, sd=2)  # Almost zero mean.
y = c(rnorm(15), exp(rnorm(15)), runif(20, min = -3, max = 0))  # Almost zero mean, not normal
x = rnorm_fixed(50, mu = 0, sd = 1)  # Used in correlation where this is on x-axis
y2 = rnorm_fixed(50, mu = 0.5, sd = 1.5)  # Used in two means

# Long format data with indicator
value = c(y, y2)
group = rep(c(&#39;y1&#39;, &#39;y2&#39;), each = 50)
value</code></pre>
<pre><code>##   [1]  1.344155071  0.315557196  2.045444858 -0.182470534 -1.483938235
##   [6]  0.397165634  1.569657554  1.270232962 -0.871443345  0.360883261
##  [11]  0.915887532  0.574518132 -0.485404025  0.015742672  1.014214682
##  [16]  1.059873176  9.662916213  2.031253698  4.818577620  2.428326404
##  [21]  0.243736114  2.233958509  0.575578075  1.530720131  0.462793355
##  [26]  0.533344982  0.981778410  0.516864708  0.600238224  1.908600833
##  [31] -2.038146279 -2.653129577 -0.253483178 -0.903758054 -0.346609408
##  [36] -2.586676906 -2.193484671 -2.603475586 -2.551755410 -1.151738176
##  [41] -1.034232551 -0.342944997 -1.238128181 -2.469581956 -1.036729235
##  [46] -1.321768353 -1.467654067 -1.393584104 -0.325763606 -2.176596497
##  [51]  0.483920767  3.306909348  0.802282966  1.240246688 -0.464334362
##  [56]  1.345909965 -1.623820863  4.415378224  0.656090287 -1.469010382
##  [61]  1.045811348  0.174267671  1.313981677  1.247098312  1.684222912
##  [66]  2.046754745  1.521126780  0.072680006 -0.178586619 -0.770538113
##  [71]  0.322923756 -1.312263390  0.009354966  0.508404502  1.727756023
##  [76]  0.003921556 -0.626886964 -0.086264441 -1.187847059  2.286785001
##  [81] -0.890249459 -0.893011965  4.621396653  1.024113354 -0.466419705
##  [86]  1.897737876 -1.738333346  1.639722306 -1.672539218  0.924650792
##  [91]  0.546730643  0.688774173  0.877414401 -2.138468637 -0.516606707
##  [96]  0.208472291  3.451198253 -0.078514821 -0.773308920 -0.209033271</code></pre>
<pre class="r"><code>plot(value)</code></pre>
<p><img src="../../../../2023/09/24/common-statistical-tests-are-linear-models-or-how-to-teach-stats/index_files/figure-html/unnamed-chunk-22-1.svg" width="576" style="display: block; margin: auto;" /></p>
</div>
<div id="correlation" class="section level1">
<h1>Pearson and Spearman correlation</h1>
<div id="theory-as-linear-models" class="section level3">
<h3>Theory: As linear models</h3>
<p>Model: the recipe for <span class="math inline">\(y\)</span> is a slope (<span class="math inline">\(\beta_1\)</span>) times <span class="math inline">\(x\)</span> plus an intercept (<span class="math inline">\(\beta_0\)</span>, aka a straight line).</p>
<p><span class="math display">\[y = \beta_0 + \beta_1 x \qquad \mathcal{H}_0: \beta_1 = 0\]</span></p>
<p>… which is a math-y way of writing the good old <span class="math inline">\(y = ax + b\)</span> (here ordered as <span class="math inline">\(y = b + ax\)</span>). In R we are lazy and write <code>y ~ 1 + x</code> which R reads like <code>y = 1*number + x*othernumber</code> and the task of t-tests, lm, etc., is simply to find the numbers that best predict <span class="math inline">\(y\)</span>.</p>
<p>Either way you write it, it’s an intercept (<span class="math inline">\(\beta_0\)</span>) and a slope (<span class="math inline">\(\beta_1\)</span>) yielding a straight line:</p>
<pre class="r"><code>matrix(c(1, 0.8, 1, 0.8), ncol = 2)</code></pre>
<pre><code>##      [,1] [,2]
## [1,]  1.0  1.0
## [2,]  0.8  0.8</code></pre>
<pre class="r"><code>matrix(c(10,3,3,2),2,2)</code></pre>
<pre><code>##      [,1] [,2]
## [1,]   10    3
## [2,]    3    2</code></pre>
<pre class="r"><code>data.frame(MASS::mvrnorm(30, mu = c(0.9, 0.9), Sigma = matrix(c(1, 0.8, 1, 0.8), ncol = 2), empirical = TRUE))  # Correlated data</code></pre>
<pre><code>##             X1           X2
## 1   2.45600484  2.540950290
## 2   2.26124006  2.919492489
## 3   0.42684789 -0.086736504
## 4   0.76554517  0.261209857
## 5   1.38979062  1.082800880
## 6  -0.68705006  0.139495735
## 7   1.98775389  2.101443922
## 8  -1.20151292 -0.993196677
## 9   1.41092548  1.566501475
## 10  1.40939014  0.453190835
## 11 -0.36424016 -0.069808522
## 12 -0.84949145  0.033873520
## 13  1.14047983  0.940798253
## 14  1.54307691  1.239969890
## 15 -0.25177318  0.003715194
## 16  2.34857533  1.893354294
## 17  1.75790184  1.425004385
## 18  0.14287975  0.400994980
## 19  1.13035767  1.316340759
## 20  1.39972793  0.797433749
## 21  0.62882408  0.730267672
## 22  1.64168401  1.843714523
## 23  1.91233838  1.388068578
## 24  1.60766921  1.466846855
## 25  0.44118797 -0.186642420
## 26 -0.32701477 -0.117693078
## 27  0.35278987  0.786427827
## 28 -0.06385019  0.412086493
## 29  1.16836323  1.134952011
## 30  1.42157862  1.575142734</code></pre>
<pre class="r"><code>D_correlation = data.frame(MASS::mvrnorm(30, mu = c(0.9, 0.9), Sigma = matrix(c(1, 0.8, 1, 0.8), ncol = 2), empirical = TRUE))  # Correlated data
colMeans(D_correlation)</code></pre>
<pre><code>##  X1  X2 
## 0.9 0.9</code></pre>
<pre class="r"><code>cov(D_correlation)</code></pre>
<pre><code>##     X1  X2
## X1 1.0 0.8
## X2 0.8 0.8</code></pre>
<pre class="r"><code># Fixed correlation
D_correlation = data.frame(MASS::mvrnorm(30, mu = c(0.9, 0.9), Sigma = matrix(c(1, 0.8, 1, 0.8), ncol = 2), empirical = TRUE))  # Correlated data

# Add labels (for next plot)
D_correlation$label_num = sprintf(&#39;(%.1f,%.1f)&#39;, D_correlation$X1, D_correlation$X2)
D_correlation$label_rank = sprintf(&#39;(%i,%i)&#39;, rank(D_correlation$X1), rank(D_correlation$X2))
D_correlation</code></pre>
<pre><code>##            X1          X2   label_num label_rank
## 1   2.1302518  1.89616689   (2.1,1.9)    (28,25)
## 2   1.2057786  1.63552097   (1.2,1.6)    (21,24)
## 3   0.1689564  0.08544956   (0.2,0.1)      (7,7)
## 4   1.8724590  2.10272571   (1.9,2.1)    (26,28)
## 5  -0.7351348 -0.60739840 (-0.7,-0.6)      (3,1)
## 6   0.8890323  1.33246669   (0.9,1.3)    (14,19)
## 7   1.8528334  1.55062142   (1.9,1.6)    (25,22)
## 8   0.8187449  0.41262053   (0.8,0.4)    (13,11)
## 9   1.0417000  1.30042952   (1.0,1.3)    (19,18)
## 10 -0.7405273 -0.12954818 (-0.7,-0.1)      (2,6)
## 11  0.9036606  0.38211089   (0.9,0.4)    (15,10)
## 12  1.0252168  1.48080025   (1.0,1.5)    (18,21)
## 13 -0.3332069 -0.24655685 (-0.3,-0.2)      (5,4)
## 14  0.4956308  0.64278685   (0.5,0.6)    (10,14)
## 15  1.3866276  1.08298169   (1.4,1.1)    (22,16)
## 16 -0.4144748 -0.56308080 (-0.4,-0.6)      (4,2)
## 17  2.8613446  2.34954847   (2.9,2.3)    (29,30)
## 18  3.0283524  2.09315046   (3.0,2.1)    (30,27)
## 19 -0.1301395  0.14355983  (-0.1,0.1)      (6,8)
## 20  1.7544009  0.96668263   (1.8,1.0)    (24,15)
## 21  0.9378148  0.53298530   (0.9,0.5)    (16,12)
## 22  0.8165806  0.57247354   (0.8,0.6)    (12,13)
## 23  0.3210004  0.18773006   (0.3,0.2)      (9,9)
## 24  1.4266704  2.07551851   (1.4,2.1)    (23,26)
## 25  0.8009172  1.58381271   (0.8,1.6)    (11,23)
## 26  0.2560323 -0.24942169  (0.3,-0.2)      (8,3)
## 27  2.0907237  2.14275659   (2.1,2.1)    (27,29)
## 28  0.9688419  1.33876453   (1.0,1.3)    (17,20)
## 29  1.1957502  1.12164183   (1.2,1.1)    (20,17)
## 30 -0.8958382 -0.21729950 (-0.9,-0.2)      (1,5)</code></pre>
<pre class="r"><code>D_correlation$X2 * 0.5 + 0.4</code></pre>
<pre><code>##  [1] 1.3480834 1.2177605 0.4427248 1.4513629 0.0963008 1.0662333 1.1753107
##  [8] 0.6063103 1.0502148 0.3352259 0.5910554 1.1404001 0.2767216 0.7213934
## [15] 0.9414908 0.1184596 1.5747742 1.4465752 0.4717799 0.8833413 0.6664927
## [22] 0.6862368 0.4938650 1.4377593 1.1919064 0.2752892 1.4713783 1.0693823
## [29] 0.9608209 0.2913502</code></pre>
<pre class="r"><code>I(D_correlation$X2 * 0.5 + 0.4)</code></pre>
<pre><code>##  [1] 1.3480834 1.2177605 0.4427248 1.4513629 0.0963008 1.0662333 1.1753107
##  [8] 0.6063103 1.0502148 0.3352259 0.5910554 1.1404001 0.2767216 0.7213934
## [15] 0.9414908 0.1184596 1.5747742 1.4465752 0.4717799 0.8833413 0.6664927
## [22] 0.6862368 0.4938650 1.4377593 1.1919064 0.2752892 1.4713783 1.0693823
## [29] 0.9608209 0.2913502</code></pre>
<pre class="r"><code># Plot it
fit = lm(I(X2 * 0.5 + 0.4) ~ I(X1 * 0.5 + 0.2), D_correlation)
coefficients(fit)</code></pre>
<pre><code>##       (Intercept) I(X1 * 0.5 + 0.2) 
##              0.33              0.80</code></pre>
<pre class="r"><code># pearson intercept
intercept_pearson = coefficients(fit)[1]


P_pearson = ggplot(D_correlation, aes(x=X1*0.5+0.2, y=X2*0.5+0.4)) +
  geom_smooth(method=lm, se=FALSE, lwd=2, aes(colour=&#39;beta_1&#39;)) + 
  geom_segment(x=-100, xend=100, 
               y=intercept_pearson, yend=intercept_pearson, 
               lwd=2, aes(color=&quot;beta_0&quot;)) + 
  scale_color_manual(name=NULL, values=c(&quot;blue&quot;, &quot;red&quot;), labels=c(bquote(beta[0]*&quot; (intercept)&quot;), bquote(beta[1]*&quot; (slope)&quot;)))
  
theme_axis(P_pearson, legend.position = c(0.4, 0.9))</code></pre>
<p><img src="../../../../2023/09/24/common-statistical-tests-are-linear-models-or-how-to-teach-stats/index_files/figure-html/unnamed-chunk-28-1.svg" width="576" style="display: block; margin: auto;" /></p>
<p>This is often simply called a <strong>regression</strong> model which can be extended to <strong>multiple regression</strong> where there are several <span class="math inline">\(\beta\)</span>s and on the right-hand side multiplied with the predictors. Everything below, from <a href="#t1">one-sample t-test</a> to <a href="#anova2">two-way ANOVA</a> are just special cases of this system. Nothing more, nothing less.</p>
<p>As the name implies, the <strong>Spearman rank correlation</strong> is a <strong>Pearson correlation</strong> on rank-transformed <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>:</p>
<p><span class="math display">\[rank(y) = \beta_0 + \beta_1 \cdot rank(x) \qquad \mathcal{H}_0: \beta_1 = 0\]</span></p>
<p>I’ll introduce <a href="#rank">ranks</a> in a minute. For now, notice that the correlation coefficient of the linear model is identical to a “real” Pearson correlation, but p-values are an approximation which is is <a href="simulations/simulate_spearman.html">appropriate for samples greater than N=10 and almost perfect when N &gt; 20</a>.</p>
<p>Such a nice and non-mysterious equivalence that many students are left unaware of! Visualizing them side by side including data labels, we see this rank-transformation in action:</p>
<pre class="r"><code>rank(D_correlation$X1)</code></pre>
<pre><code>##  [1] 28 21  7 26  3 14 25 13 19  2 15 18  5 10 22  4 29 30  6 24 16 12  9 23 11
## [26]  8 27 17 20  1</code></pre>
<pre class="r"><code>rank(D_correlation$X2)</code></pre>
<pre><code>##  [1] 25 24  7 28  1 19 22 11 18  6 10 21  4 14 16  2 30 27  8 15 12 13  9 26 23
## [26]  3 29 20 17  5</code></pre>
<pre class="r"><code># Spearman intercept
coefficients(lm(rank(X2) ~ rank(X1), D_correlation))</code></pre>
<pre><code>## (Intercept)    rank(X1) 
##   1.7241379   0.8887653</code></pre>
<pre class="r"><code># Spearman intercept
intercept_spearman = coefficients(lm(rank(X2) ~ rank(X1), D_correlation))[1]

# Spearman plot
P_spearman = ggplot(D_correlation, aes(x=rank(X1), y=rank(X2))) +
  geom_smooth(method=lm, se=FALSE, lwd=2, aes(color=&#39;beta_1&#39;)) + 
  geom_text(aes(label=label_rank), nudge_y=1, size=3, color=&#39;dark gray&#39;) + 
  geom_segment(x=-100, xend=100, 
               y=intercept_spearman, yend=intercept_spearman, 
               lwd=2, aes(color=&#39;beta_0&#39;)) + 
  scale_color_manual(name=NULL, values=c(&quot;blue&quot;, &quot;red&quot;), labels=c(bquote(beta[0]*&quot; (intercept)&quot;), bquote(beta[1]*&quot; (slope)&quot;)))

# Stich together using patchwork
(theme_axis(P_pearson, legend.position=c(0.5, 0.1)) + geom_text(aes(label=label_num), nudge_y=0.1, size=3, color=&#39;dark gray&#39;) + labs(title=&#39;         Pearson&#39;)) + (theme_axis(P_spearman, xlim=c(-7.5, 30), ylim=c(-7.5, 30), legend.position=c(0.5, 0.1)) + labs(title=&#39;         Spearman&#39;))</code></pre>
<p><img src="../../../../2023/09/24/common-statistical-tests-are-linear-models-or-how-to-teach-stats/index_files/figure-html/unnamed-chunk-31-1.svg" width="768" style="display: block; margin: auto;" /></p>
</div>
<div id="rank" class="section level3">
<h3>Theory: rank-transformation</h3>
<p><code>rank</code> simply takes a list of numbers and “replace” them with the integers of their rank (1st smallest, 2nd smallest, 3rd smallest, etc.). So the result of the rank-transformation <code>rank(c(3.6, 3.4, -5.0, 8.2))</code> is <code>3, 2, 1, 4</code>. See that in the figure above?</p>
<p>A <em>signed</em> rank is the same, just where we rank according to absolute size first and then add in the sign second. So the signed rank here would be <code>2, 1, -3, 4</code>. Or in code:</p>
<pre class="r"><code>signed_rank = function(x) sign(x) * rank(abs(x))</code></pre>
<p>I hope I don’t offend anyone when I say that ranks are easy; yet it’s all you need to do to convert most parametric tests into their “non-parametric” counterparts! One interesting implication is that <em>many “non-parametric tests” are about as parametric as their parametric counterparts with means, standard deviations, homogeneity of variance, etc. - just on rank-transformed data</em>. That’s why I put “non-parametric” in quotation marks.</p>
</div>
<div id="r-code-pearson-correlation" class="section level3">
<h3>R code: Pearson correlation</h3>
<p>It couldn’t be much simpler to run these models in R. They yield identical <code>p</code> and <code>t</code>, but there’s a catch: <code>lm</code> gives you the <em>slope</em> and even though that is usually much more interpretable and informative than the <em>correlation coefficient</em> <em>r</em>, you may still want <em>r</em>. Luckily, the slope becomes <code>r</code> if <code>x</code> and <code>y</code> have identical standard deviations. For now, we will use <code>scale(x)</code> to make <span class="math inline">\(SD(x) = 1.0\)</span> and <span class="math inline">\(SD(y) = 1.0\)</span>:</p>
<pre class="r"><code>a = cor.test(y, x, method = &quot;pearson&quot;) # Built-in
b = lm(y ~ 1 + x) # Equivalent linear model: y = Beta0*1 + Beta1*x
c = lm(scale(y) ~ 1 + scale(x))  # On scaled vars to recover r</code></pre>
<p>Results:</p>
<pre class="r"><code>at = tidy(a)
bt = tidy(b)[2,]  # Only slope
bt$conf.low = confint(b)[2, 1]
bt$conf.high = confint(b)[2, 2]

ct = tidy(c)[2,]  # Only slope
ct$conf.low = confint(c)[2, 1]
ct$conf.high = confint(c)[2, 2]

# Merge and print nicely
df = bind_rows(at, ct, bt) %&gt;%
  mutate(model = c(&#39;cor.test&#39;, &#39;lm scaled&#39;, &#39;lm&#39;)) %&gt;%
  rename(t = statistic,
         r = estimate) %&gt;%
  select(model, p.value, t, r, conf.low, conf.high)

print_df(df)</code></pre>
<div class="datatables html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-1" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-1">{"x":{"filter":"none","vertical":false,"data":[["cor.test","lm scaled","lm"],[0.7126,0.7126,0.7126],[-0.3705,-0.3705,-0.3705],[-0.0534,-0.0534,-0.1119],[-0.3269,-0.3432,-0.7192],[0.2283,0.2364,0.4954]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>model<\/th>\n      <th>p.value<\/th>\n      <th>t<\/th>\n      <th>r<\/th>\n      <th>conf.low<\/th>\n      <th>conf.high<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"lengthChange":false,"ordering":false,"autoWidth":true,"bPaginate":false,"bInfo":false,"paging":false,"columnDefs":[{"className":"dt-right","targets":[1,2,3,4,5]}],"order":[],"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>a</code></pre>
<pre><code>## 
## 	Pearson&#39;s product-moment correlation
## 
## data:  y and x
## t = -0.3705, df = 48, p-value = 0.7126
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.3268890  0.2283417
## sample estimates:
##         cor 
## -0.05340008</code></pre>
<pre class="r"><code>summary(b)</code></pre>
<pre><code>## 
## Call:
## lm(formula = y ~ 1 + x)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.7805 -1.3769 -0.1222  0.8402  9.4128 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)   0.1260     0.2990   0.421    0.675
## x            -0.1119     0.3020  -0.370    0.713
## 
## Residual standard error: 2.114 on 48 degrees of freedom
## Multiple R-squared:  0.002852,	Adjusted R-squared:  -0.01792 
## F-statistic: 0.1373 on 1 and 48 DF,  p-value: 0.7126</code></pre>
<pre class="r"><code>summary(c)</code></pre>
<pre><code>## 
## Call:
## lm(formula = scale(y) ~ 1 + scale(x))
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.3268 -0.6571 -0.0583  0.4010  4.4918 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) -4.192e-19  1.427e-01    0.00    1.000
## scale(x)    -5.340e-02  1.441e-01   -0.37    0.713
## 
## Residual standard error: 1.009 on 48 degrees of freedom
## Multiple R-squared:  0.002852,	Adjusted R-squared:  -0.01792 
## F-statistic: 0.1373 on 1 and 48 DF,  p-value: 0.7126</code></pre>
<p>The CIs are not exactly identical, but very close.</p>
</div>
<div id="r-code-spearman-correlation" class="section level3">
<h3>R code: Spearman correlation</h3>
<p>Note that we can interpret the slope which is the number of ranks <span class="math inline">\(y\)</span> change for each rank on <span class="math inline">\(x\)</span>. I think that this is a pretty interesting number. However, the intercept is less interpretable since it lies at <span class="math inline">\(rank(x) = 0\)</span> which is impossible since x starts at 1.</p>
<p>See the identical <code>r</code> (now “rho”) and <code>p</code>:</p>
<pre class="r"><code># Spearman correlation
a = cor.test(y, x, method = &quot;spearman&quot;) # Built-in
b = lm(rank(y) ~ 1 + rank(x)) # Equivalent linear model</code></pre>
<p>Let’s look at the results:</p>
<pre class="r"><code>df = data.frame(
  model = c(&#39;cor.test&#39;, &#39;lm&#39;),
  p.value = c(a$p.value, tidy(b)$p.value[2]),
  rho = c(a$estimate, b$coefficients[2])
)

print_df(df)</code></pre>
<div class="datatables html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-2" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-2">{"x":{"filter":"none","vertical":false,"data":[["cor.test","lm"],[0.7996,0.8001],[0.0367,0.0367]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>model<\/th>\n      <th>p.value<\/th>\n      <th>rho<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"lengthChange":false,"ordering":false,"autoWidth":true,"bPaginate":false,"bInfo":false,"paging":false,"columnDefs":[{"className":"dt-right","targets":[1,2]}],"order":[],"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>a</code></pre>
<pre><code>## 
## 	Spearman&#39;s rank correlation rho
## 
## data:  y and x
## S = 20060, p-value = 0.7996
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##        rho 
## 0.03673469</code></pre>
<pre class="r"><code>summary(b)</code></pre>
<pre><code>## 
## Call:
## lm(formula = rank(y) ~ 1 + rank(x))
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -25.3633 -11.5520   0.4592  12.5592  25.1796 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 24.56327    4.22626   5.812 4.85e-07 ***
## rank(x)      0.03673    0.14424   0.255      0.8    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 14.72 on 48 degrees of freedom
## Multiple R-squared:  0.001349,	Adjusted R-squared:  -0.01946 
## F-statistic: 0.06486 on 1 and 48 DF,  p-value: 0.8001</code></pre>
</div>
</div>
<div id="one-mean" class="section level1">
<h1>One mean</h1>
<div id="t1" class="section level2">
<h2>One sample t-test and Wilcoxon signed-rank</h2>
<div id="theory-as-linear-models-1" class="section level3">
<h3>Theory: As linear models</h3>
<p><strong>t-test</strong> model: A single number predicts <span class="math inline">\(y\)</span>.</p>
<p><span class="math display">\[y = \beta_0 \qquad \mathcal{H}_0: \beta_0 = 0\]</span></p>
<p>In other words, it’s our good old <span class="math inline">\(y = \beta_0 + \beta_1*x\)</span> where the last term is gone since there is no <span class="math inline">\(x\)</span> (essentially <span class="math inline">\(x=0\)</span>, see left figure below).</p>
<p>The same is to a very close approximately true for <strong>Wilcoxon signed-rank test</strong>, just with the <a href="#rank">signed ranks</a> of <span class="math inline">\(y\)</span> instead of <span class="math inline">\(y\)</span> itself (see right panel below).</p>
<p><span class="math display">\[signed\_rank(y) = \beta_0\]</span></p>
<p><a href="simulations/simulate_wilcoxon.html">This approximation is good enough when the sample size is larger than 14 and almost perfect if the sample size is larger than 50</a>.</p>
<pre class="r"><code>library(ggplot2)
D_t1 = data.frame(y = rnorm_fixed(20, 0.5, 0.6),
                  x = runif(20, 0.93, 1.07))  # Fix mean and SD

ggplot(D_t1, aes(y = y, x = x)) + geom_point()</code></pre>
<p><img src="../../../../2023/09/24/common-statistical-tests-are-linear-models-or-how-to-teach-stats/index_files/figure-html/unnamed-chunk-39-1.svg" width="576" style="display: block; margin: auto;" /></p>
<pre class="r"><code>D_t1_rank = data.frame(y = signed_rank(D_t1$y))
P_t1_rank &lt;- ggplot(D_t1_rank, aes(y = y, x = 0)) + geom_point() + 
  geom_text(aes(label = y), nudge_x = 0.1, size = 3, color = &#39;dark gray&#39;) +
  geom_text(aes(label = signif(D_t1$y, digits = 2)), nudge_x = -0.1, size = 3, color = &#39;dark gray&#39;)
theme_axis(P_t1_rank, ylim = NULL,  legend.position = c(0.6, 0.1))</code></pre>
<p><img src="../../../../2023/09/24/common-statistical-tests-are-linear-models-or-how-to-teach-stats/index_files/figure-html/unnamed-chunk-40-1.svg" width="576" style="display: block; margin: auto;" /></p>
<pre class="r"><code># T-test
D_t1 = data.frame(y = rnorm_fixed(20, 0.5, 0.6),
                  x = runif(20, 0.93, 1.07))  # Fix mean and SD

P_t1 = ggplot(D_t1, aes(y = y, x = 0)) + 
  stat_summary(fun=mean, geom = &quot;errorbar&quot;, aes(ymax = ..y.., ymin = ..y.., color=&#39;beta_0&#39;), lwd=2) +
  scale_color_manual(name = NULL, values = c(&quot;blue&quot;), labels = c(bquote(beta[0] * &quot; (intercept)&quot;))) +
  
  geom_text(aes(label = round(y, 1)), nudge_x = 0.2, size = 3, color = &#39;dark gray&#39;) + 
  labs(title=&#39;         T-test&#39;)

# Wilcoxon
D_t1_rank = data.frame(y = signed_rank(D_t1$y))

P_t1_rank = ggplot(D_t1_rank, aes(y = y, x = 0)) + 
  stat_summary(fun = mean, geom = &quot;errorbar&quot;, aes(ymax = ..y.., ymin = ..y..,  color = &#39;beta_0&#39;), lwd = 2) +
  scale_color_manual(name = NULL, values = c(&quot;blue&quot;), labels = c(bquote(beta[0] * &quot; (intercept)&quot;))) +

  geom_text(aes(label = y), nudge_x = 0.2, size = 3, color = &#39;dark gray&#39;) + 
  labs(title=&#39;         Wilcoxon&#39;)


# Stich together using patchwork
theme_axis(P_t1, ylim = c(-1, 2), legend.position = c(0.6, 0.1)) + 
  theme_axis(P_t1_rank, ylim = NULL,  legend.position = c(0.6, 0.1))</code></pre>
<p><img src="../../../../2023/09/24/common-statistical-tests-are-linear-models-or-how-to-teach-stats/index_files/figure-html/unnamed-chunk-41-1.svg" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="r-code-one-sample-t-test" class="section level3">
<h3>R code: One-sample t-test</h3>
<p>Try running the R code below and see that the linear model (<code>lm</code>) produces the same <span class="math inline">\(t\)</span>, <span class="math inline">\(p\)</span>, and <span class="math inline">\(r\)</span> as the built-in <code>t.test</code>. The confidence interval is not presented in the output of <code>lm</code> but is also identical if you use <code>confint(lm(...))</code>:</p>
<p>As an example, in the one-sample t-test</p>
<p><span class="math display">\[{\displaystyle t={\frac {Z}{s}}={\frac {{\bar {X}}-\mu }{{\widehat {\sigma }}/{\sqrt {n}}}}}\]</span>
where <span class="math inline">\(\bar{X}\)</span> is the sample mean from a sample <span class="math inline">\(X_1, X_2, \cdots, X_n\)</span>, of size <span class="math inline">\(n\)</span>, <span class="math inline">\(s\)</span> is the standard error of the mean, <span class="math display">\[{\textstyle {\widehat {\sigma }}}\]</span> is the estimate of the standard deviation of the population, and <span class="math inline">\(\mu\)</span> is the population mean.</p>
<pre class="r"><code>y</code></pre>
<pre><code>##  [1]  1.34415507  0.31555720  2.04544486 -0.18247053 -1.48393823  0.39716563
##  [7]  1.56965755  1.27023296 -0.87144335  0.36088326  0.91588753  0.57451813
## [13] -0.48540403  0.01574267  1.01421468  1.05987318  9.66291621  2.03125370
## [19]  4.81857762  2.42832640  0.24373611  2.23395851  0.57557808  1.53072013
## [25]  0.46279335  0.53334498  0.98177841  0.51686471  0.60023822  1.90860083
## [31] -2.03814628 -2.65312958 -0.25348318 -0.90375805 -0.34660941 -2.58667691
## [37] -2.19348467 -2.60347559 -2.55175541 -1.15173818 -1.03423255 -0.34294500
## [43] -1.23812818 -2.46958196 -1.03672924 -1.32176835 -1.46765407 -1.39358410
## [49] -0.32576361 -2.17659650</code></pre>
<pre class="r"><code>(mean(y)-0)/(sd(y)/sqrt(length(y))) # t</code></pre>
<pre><code>## [1] 0.4251309</code></pre>
<pre class="r"><code>sd(y)</code></pre>
<pre><code>## [1] 2.09556</code></pre>
<pre class="r"><code>sqrt(sum((y-mean(y))^2)/(length(y)-1))</code></pre>
<pre><code>## [1] 2.09556</code></pre>
<pre class="r"><code>length(y)</code></pre>
<pre><code>## [1] 50</code></pre>
<pre class="r"><code>mean(y)</code></pre>
<pre><code>## [1] 0.1259905</code></pre>
<pre class="r"><code>1-pt((mean(y)-0)/(sd(y)/sqrt(length(y))), df=length(y)-1)</code></pre>
<pre><code>## [1] 0.3363012</code></pre>
<pre class="r"><code>pt(0, df=49)</code></pre>
<pre><code>## [1] 0.5</code></pre>
<pre class="r"><code>2*(1-pt(0.4251309, df=49)) # two tails </code></pre>
<pre><code>## [1] 0.6726025</code></pre>
<pre class="r"><code># Built-in t-test
a = t.test(y)

# Equivalent linear model: intercept-only
b = lm(y ~ 1)</code></pre>
<p>Results:</p>
<pre class="r"><code>df = data.frame(
  model = c(&#39;t.test&#39;, &#39;lm&#39;),
  mean = c(a$estimate, b$coefficients),
  p.value = c(a$p.value, tidy(b)$p.value),
  t = c(a$statistic, tidy(b)$statistic),
  df = c(a$parameter, b$df.residual),
  conf.low = c(a$conf.int[1], confint(b)[1]),
  conf.high = c(a$conf.int[2], confint(b)[2])
)
print_df(df)</code></pre>
<div class="datatables html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-3" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-3">{"x":{"filter":"none","vertical":false,"data":[["t.test","lm"],[0.126,0.126],[0.6726,0.6726],[0.4251,0.4251],[49,49],[-0.4696,-0.4696],[0.7215,0.7215]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>model<\/th>\n      <th>mean<\/th>\n      <th>p.value<\/th>\n      <th>t<\/th>\n      <th>df<\/th>\n      <th>conf.low<\/th>\n      <th>conf.high<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"lengthChange":false,"ordering":false,"autoWidth":true,"bPaginate":false,"bInfo":false,"paging":false,"columnDefs":[{"className":"dt-right","targets":[1,2,3,4,5,6]}],"order":[],"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>2*pt(0.42513, df=49, lower=FALSE) #Use pt and make it two-tailed.</code></pre>
<pre><code>## [1] 0.6726031</code></pre>
<pre class="r"><code>a</code></pre>
<pre><code>## 
## 	One Sample t-test
## 
## data:  y
## t = 0.42513, df = 49, p-value = 0.6726
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  -0.4695610  0.7215419
## sample estimates:
## mean of x 
## 0.1259905</code></pre>
<pre class="r"><code>summary(b)</code></pre>
<pre><code>## 
## Call:
## lm(formula = y ~ 1)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.7791 -1.3425  0.0037  0.8801  9.5369 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)   0.1260     0.2964   0.425    0.673
## 
## Residual standard error: 2.096 on 49 degrees of freedom</code></pre>
</div>
<div id="r-code-wilcoxon-signed-rank-test" class="section level3">
<h3>R code: Wilcoxon signed-rank test</h3>
<p>In addition to matching <code>p</code>-values, <code>lm</code> also gives us the mean signed rank, which I find to be an informative number.</p>
<pre class="r"><code># Built-in
a = wilcox.test(y)

# Equivalent linear model
b = lm(signed_rank(y) ~ 1)  # See? Same model as above, just on signed ranks

# Bonus: of course also works for one-sample t-test
c = t.test(signed_rank(y))</code></pre>
<p>Results:</p>
<pre class="r"><code>df = data.frame(
  model = c(&#39;wilcox.test&#39;, &#39;lm&#39;, &#39;t.test&#39;),
  p.value = c(a$p.value, tidy(b)$p.value, c$p.value),
  mean_rank = c(NA, tidy(b)$estimate, c$estimate)
)
print_df(df)</code></pre>
<div class="datatables html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-4" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-4">{"x":{"filter":"none","vertical":false,"data":[["wilcox.test","lm","t.test"],[0.9078000000000001,0.9054,0.9054],[null,-0.5,-0.5]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>model<\/th>\n      <th>p.value<\/th>\n      <th>mean_rank<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"lengthChange":false,"ordering":false,"autoWidth":true,"bPaginate":false,"bInfo":false,"paging":false,"columnDefs":[{"className":"dt-right","targets":[1,2]}],"order":[],"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>a</code></pre>
<pre><code>## 
## 	Wilcoxon signed rank test with continuity correction
## 
## data:  y
## V = 625, p-value = 0.9078
## alternative hypothesis: true location is not equal to 0</code></pre>
<pre class="r"><code>summary(b)</code></pre>
<pre><code>## 
## Call:
## lm(formula = signed_rank(y) ~ 1)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -47.50 -26.25   2.50  22.25  50.50 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)   -0.500      4.185  -0.119    0.905
## 
## Residual standard error: 29.59 on 49 degrees of freedom</code></pre>
<pre class="r"><code>c</code></pre>
<pre><code>## 
## 	One Sample t-test
## 
## data:  signed_rank(y)
## t = -0.11947, df = 49, p-value = 0.9054
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  -8.910332  7.910332
## sample estimates:
## mean of x 
##      -0.5</code></pre>
</div>
</div>
<div id="tpair" class="section level2">
<h2>Paired samples t-test and Wilcoxon matched pairs</h2>
<div id="theory-as-linear-models-2" class="section level3">
<h3>Theory: As linear models</h3>
<p><strong>t-test</strong> model: a single number (intercept) predicts the pairwise differences.</p>
<p><span class="math display">\[y_2-y_1 = \beta_0 \qquad \mathcal{H}_0: \beta_0 = 0\]</span></p>
<p>This means that there is just one <span class="math inline">\(y = y_2 - y_1\)</span> to predict and it becomes a <a href="#t1">one-sample t-test</a> on the pairwise differences. The visualization is therefore also the same as for the one-sample t-test. At the risk of overcomplicating a simple substraction, you can think of these pairwise differences as slopes (see left panel of the figure), which we can represent as y-offsets (see right panel of the figure):</p>
<pre class="r"><code># Data for plot
N = nrow(D_t1)
start = rnorm_fixed(N, 0.2, 0.3)
D_tpaired = data.frame(
  x = rep(c(0, 1), each = N),
  y = c(start, start + D_t1$y),
  id = 1:N
)

# Plot
P_tpaired = ggplot(D_tpaired, aes(x = x, y = y)) +
  geom_line(aes(group = id)) +
  labs(title = &#39;          Pairs&#39;)

# Use patchwork to put them side-by-side
theme_axis(P_tpaired) + theme_axis(P_t1, legend.position = c(0.6, 0.1))</code></pre>
<p><img src="../../../../2023/09/24/common-statistical-tests-are-linear-models-or-how-to-teach-stats/index_files/figure-html/unnamed-chunk-53-1.svg" width="672" style="display: block; margin: auto;" /></p>
<p>Similarly, the <strong>Wilcoxon matched pairs</strong> only differ from <strong>Wilcoxon signed-rank</strong> in that it’s testing the signed ranks of the pairwise <span class="math inline">\(y-x\)</span> differences.</p>
<p><span class="math display">\[signed\_rank(y_2-y_1) = \beta_0 \qquad \mathcal{H}_0: \beta_0 = 0\]</span></p>
</div>
<div id="r-code-paired-sample-t-test" class="section level3">
<h3>R code: Paired sample t-test</h3>
<pre class="r"><code>a = t.test(y, y2, paired = TRUE) # Built-in paired t-test
b = lm(y - y2 ~ 1) # Equivalent linear model</code></pre>
<p>Results:</p>
<pre class="r"><code>df = data.frame(
  model = c(&#39;t.test&#39;, &#39;lm&#39;),
  mean = c(a$estimate, b$coefficients),
  p.value = c(a$p.value, tidy(b)$p.value),
  df = c(a$parameter, b$df.residual),
  t = c(a$statistic, tidy(b)$statistic),
  conf.low = c(a$conf.int[1], confint(b)[1]),
  conf.high = c(a$conf.int[2], confint(b)[2])
)

print_df(df)</code></pre>
<div class="datatables html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-5" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-5">{"x":{"filter":"none","vertical":false,"data":[["t.test","lm"],[-0.374,-0.374],[0.2772,0.2772],[49,49],[-1.0988,-1.0988],[-1.058,-1.058],[0.31,0.31]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>model<\/th>\n      <th>mean<\/th>\n      <th>p.value<\/th>\n      <th>df<\/th>\n      <th>t<\/th>\n      <th>conf.low<\/th>\n      <th>conf.high<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"lengthChange":false,"ordering":false,"autoWidth":true,"bPaginate":false,"bInfo":false,"paging":false,"columnDefs":[{"className":"dt-right","targets":[1,2,3,4,5,6]}],"order":[],"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>a</code></pre>
<pre><code>## 
## 	Paired t-test
## 
## data:  y and y2
## t = -1.0988, df = 49, p-value = 0.2772
## alternative hypothesis: true mean difference is not equal to 0
## 95 percent confidence interval:
##  -1.0580285  0.3100095
## sample estimates:
## mean difference 
##      -0.3740095</code></pre>
<pre class="r"><code>summary(b)</code></pre>
<pre><code>## 
## Call:
## lm(formula = y - y2 ~ 1)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -4.5448 -1.1943 -0.4006  0.9679  8.5158 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)  -0.3740     0.3404  -1.099    0.277
## 
## Residual standard error: 2.407 on 49 degrees of freedom</code></pre>
</div>
<div id="r-code-wilcoxon-matched-pairs" class="section level3">
<h3>R code: Wilcoxon matched pairs</h3>
<p>Again, we do the signed-ranks trick. This is still an approximation, but a close one:</p>
<pre class="r"><code># Built-in Wilcoxon matched pairs
a = wilcox.test(y, y2, paired = TRUE)

# Equivalent linear model:
b = lm(signed_rank(y - y2) ~ 1)

# Bonus: identical to one-sample t-test ong signed ranks
c = t.test(signed_rank(y - y2))</code></pre>
<p>Results:</p>
<pre class="r"><code># Print nicely
df = data.frame(
  model = c(&#39;wilcox.test&#39;, &#39;lm&#39;, &#39;t.test&#39;),
  p.value = c(a$p.value, tidy(b)$p.value, c$p.value),
  mean_rank_diff = c(NA, b$coefficients, c$estimate)
)

print_df(df)</code></pre>
<div class="datatables html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-6" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-6">{"x":{"filter":"none","vertical":false,"data":[["wilcox.test","lm","t.test"],[0.0949,0.09420000000000001,0.09420000000000001],[null,-6.94,-6.94]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>model<\/th>\n      <th>p.value<\/th>\n      <th>mean_rank_diff<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"lengthChange":false,"ordering":false,"autoWidth":true,"bPaginate":false,"bInfo":false,"paging":false,"columnDefs":[{"className":"dt-right","targets":[1,2]}],"order":[],"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>a</code></pre>
<pre><code>## 
## 	Wilcoxon signed rank test with continuity correction
## 
## data:  y and y2
## V = 464, p-value = 0.09492
## alternative hypothesis: true location shift is not equal to 0</code></pre>
<pre class="r"><code>summary(b)</code></pre>
<pre><code>## 
## Call:
## lm(formula = signed_rank(y - y2) ~ 1)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -41.06 -21.81  -7.06  18.69  56.94 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)   -6.940      4.067  -1.707   0.0942 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 28.76 on 49 degrees of freedom</code></pre>
<pre class="r"><code>c</code></pre>
<pre><code>## 
## 	One Sample t-test
## 
## data:  signed_rank(y - y2)
## t = -1.7066, df = 49, p-value = 0.09423
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  -15.112198   1.232198
## sample estimates:
## mean of x 
##     -6.94</code></pre>
<p>For large sample sizes (N &gt;&gt; 100), this approaches the <strong>sign test</strong> to a reasonable degree, but this approximation is too inaccurate to flesh out here.</p>
</div>
</div>
</div>
<div id="two-means" class="section level1">
<h1>Two means</h1>
<div id="t2" class="section level2">
<h2>Independent t-test and Mann-Whitney U</h2>
<div id="theory-as-linear-models-3" class="section level3">
<h3>Theory: As linear models</h3>
<p>Independent t-test model: two means predict <span class="math inline">\(y\)</span>.</p>
<p><span class="math display">\[y_i = \beta_0 + \beta_1 x_i \qquad \mathcal{H}_0: \beta_1 = 0\]</span></p>
<p>where <span class="math inline">\(x_i\)</span> is an indicator (0 or 1) saying whether data point <span class="math inline">\(i\)</span> was sampled from one or the other group. <a href="https://en.wikipedia.org/wiki/Dummy_variable_(statistics)">Indicator variables (also called “dummy coding”)</a> underly a lot of linear models and we’ll take an aside to see how it works in a minute.</p>
<p><strong>Mann-Whitney U</strong> (also known as <strong>Wilcoxon rank-sum test</strong> for two independent groups; no <em>signed</em> rank this time) is the same model to a very close approximation, just on the ranks of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> instead of the actual values:</p>
<p><span class="math display">\[rank(y_i) = \beta_0 + \beta_1 x_i \qquad \mathcal{H}_0: \beta_1 = 0\]</span></p>
<p>To me, equivalences like this make “non-parametric” statistics much easier to understand. The approximation is appropriate <a href="simulations/simulate_mannwhitney.html">when the sample size is larger than 11 in each group and virtually perfect when N &gt; 30 in each group</a>.</p>
</div>
<div id="dummy" class="section level3">
<h3>Theory: Dummy coding</h3>
<p>Dummy coding can be understood visually. The indicator is on the x-axis so data points from the first group are located at <span class="math inline">\(x = 0\)</span> and data points from the second group is located at <span class="math inline">\(x = 1\)</span>. Then <span class="math inline">\(\beta_0\)</span> is the intercept (blue line) and <span class="math inline">\(\beta_1\)</span> is the slope between the two means (red line). Why? Because when <span class="math inline">\(\Delta x = 1\)</span> the slope equals the difference because:</p>
<p><span class="math display">\[slope = \Delta y / \Delta x = \Delta y / 1 = \Delta y = difference\]</span></p>
<p>Magic! Even categorical differences can be modelled using linear models! It’s a true Swizz army knife.</p>
<pre class="r"><code># Data
N = 20  # Number of data points per group
D_t2 = data.frame(
  x = rep(c(0, 1), each=N),
  y = c(rnorm_fixed(N, 0.3, 0.3), rnorm_fixed(N, 1.3, 0.3))
)

# Plot
P_t2 = ggplot(D_t2, aes(x=x, y=y)) + 
  stat_summary(fun = mean, geom = &quot;errorbar&quot;, aes(ymax = ..y.., ymin = ..y..,  color = &#39;something&#39;), lwd = 2) +
  geom_segment(x = -10, xend = 10, y = 0.3, yend = 0.3, lwd = 2, aes(color = &#39;beta_0&#39;)) + 
  geom_segment(x = 0, xend = 1, y = 0.3, yend = 1.3, lwd = 2, aes(color = &#39;beta_1&#39;)) + 
  
  scale_color_manual(name = NULL, values = c(&quot;blue&quot;, &quot;red&quot;, &quot;green&quot;), labels=c(bquote(beta[0]*&quot; (group 1 mean)&quot;), bquote(beta[1]*&quot; (slope = difference)&quot;), bquote(beta[0]+beta[1]%.%1*&quot; (group 2 mean)&quot;)))
  #scale_x_discrete(breaks=c(0.5, 1.5), labels=c(&#39;1&#39;, &#39;2&#39;))

theme_axis(P_t2, jitter = TRUE, xlim = c(-0.3, 2), legend.position = c(0.53, 0.08))</code></pre>
<p><img src="../../../../2023/09/24/common-statistical-tests-are-linear-models-or-how-to-teach-stats/index_files/figure-html/unnamed-chunk-60-1.svg" width="576" style="display: block; margin: auto;" /></p>
</div>
<div id="dummy2" class="section level3">
<h3>Theory: Dummy coding (continued)</h3>
<p>If you feel like you get dummy coding now, just skip ahead to the next section. Here is a more elaborate explanation of dummy coding:</p>
<p>If a data point was sampled from the first group, i.e., when <span class="math inline">\(x_i = 0\)</span>, the model simply becomes <span class="math inline">\(y = \beta_0 + \beta_1 \cdot 0 = \beta_0\)</span>. In other words, the model predicts that that data point is <span class="math inline">\(beta_0\)</span>. It turns out that the <span class="math inline">\(\beta\)</span> which best predicts a set of data points is the <em>mean</em> of those data points, so <span class="math inline">\(\beta_0\)</span> is the mean of group 1.</p>
<p>On the other hand, data points sampled from the second group would have <span class="math inline">\(x_i = 1\)</span> so the model becomes <span class="math display">\[y_i = \beta_0 + \beta_1\cdot 1 = \beta_0 + \beta_1\]</span>. In other words, we add <span class="math inline">\(\beta_1\)</span> to “shift” from the mean of the first group to the mean of the second group. Thus <span class="math inline">\(\beta_1\)</span> becomes the <em>mean difference</em> between the groups.</p>
<p>As an example, say group 1 is 25 years old (<span class="math inline">\(\beta_0 = 25\)</span>) and group 2 is 28 years old (<span class="math inline">\(\beta_1 = 3\)</span>), then the model for a person in group 1 is <span class="math inline">\(y = 25 + 3 \cdot 0 = 25\)</span> and the model for a person in group 2 is <span class="math inline">\(y = 25 + 3 \cdot 1 = 28\)</span>.</p>
<p>Hooray, it works! For first-timers it takes a few moments to understand dummy coding, but you only need to know addition and multiplication to get there!</p>
</div>
<div id="r-code-independent-t-test" class="section level3">
<h3>R code: independent t-test</h3>
<p>As a reminder, when we write <code>y ~ 1 + x</code> in R, it is shorthand for <span class="math inline">\(y = \beta_0 \cdot 1 + \beta_1 \cdot x\)</span> and R goes on computing the <span class="math inline">\(\beta\)</span>s for you. Thus <code>y ~ 1 + x</code> is the R-way of writing <span class="math inline">\(y = a \cdot x + b\)</span>.</p>
<p>Notice the identical <code>t</code>, <code>df</code>, <code>p</code>, and estimates. We can get the confidence interval by running <code>confint(lm(...))</code>.</p>
<pre class="r"><code># Built-in independent t-test on wide data
a = t.test(y, y2, var.equal = TRUE)

# Be explicit about the underlying linear model by hand-dummy-coding:
group_y2 = ifelse(group == &#39;y2&#39;, 1, 0)  # 1 if group == y2, 0 otherwise
b = lm(value ~ 1 + group_y2) # Using our hand-made dummy regressor

# Note: We could also do the dummy-coding in the model
# specification itself. Same result.
c = lm(value ~ 1 + I(group == &#39;y2&#39;))</code></pre>
<p>Results:</p>
<pre class="r"><code>mean(y) #mean-y</code></pre>
<pre><code>## [1] 0.1259905</code></pre>
<pre class="r"><code>mean(y2) #mean-y2</code></pre>
<pre><code>## [1] 0.5</code></pre>
<p>The formula for a confidence interval of 1 sample t-test with confidence coefficient <span class="math inline">\(1−\alpha\)</span> is:</p>
<p><span class="math display">\[(\bar{x}+t_{n−1,\alpha/2}\cdot \frac{s}{\sqrt n}, \;\;\;\bar{x}+t_{n−1,1-\alpha/2}\cdot \frac{s}{\sqrt n})\]</span>
t statistic <span class="math display">\[t=\frac{\bar x -\mu}{s/\sqrt{n}}\]</span></p>
<p>The formula for a confidence interval of 2 independent sample t-test with confidence coefficient <span class="math inline">\(1−\alpha\)</span> is:
<span class="math display">\[(\bar x_1 - \bar x_2) + t_{n_1+n_2−2,\alpha/2} s_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}, \;\;\; (\bar x_1 - \bar x_2) + t_{n_1+n_2−2,1-\alpha/2} s_p\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}\]</span>
where <span class="math display">\[s_p=\sqrt{\frac{(n_1-1)s_1^2+(n_2-1)s_2^2}{n_1+n_2-2}}\]</span></p>
<pre class="r"><code>length(y)</code></pre>
<pre><code>## [1] 50</code></pre>
<pre class="r"><code>length(y2)</code></pre>
<pre><code>## [1] 50</code></pre>
<pre class="r"><code>alpha=0.05
difference = mean(y)-mean(y2)
sp=sqrt((49*sd(y)^2+49*sd(y2)^2)/98)
difference+qt(alpha/2, df=98)*sp*sqrt(2/50)</code></pre>
<pre><code>## [1] -1.097258</code></pre>
<pre class="r"><code>difference+qt(1-alpha/2, df=98)*sp*sqrt(2/50)</code></pre>
<pre><code>## [1] 0.3492394</code></pre>
<pre class="r"><code>a$estimate</code></pre>
<pre><code>## mean of x mean of y 
## 0.1259905 0.5000000</code></pre>
<pre class="r"><code>a$p.value</code></pre>
<pre><code>## [1] 0.3073161</code></pre>
<pre class="r"><code>a$parameter</code></pre>
<pre><code>## df 
## 98</code></pre>
<pre class="r"><code>a$conf.int</code></pre>
<pre><code>## [1] -1.0972585  0.3492394
## attr(,&quot;conf.level&quot;)
## [1] 0.95</code></pre>
<pre class="r"><code>summary(b)</code></pre>
<pre><code>## 
## Call:
## lm(formula = value ~ 1 + group_y2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.7791 -1.1897 -0.0632  0.8484  9.5369 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)   0.1260     0.2577   0.489    0.626
## group_y2      0.3740     0.3645   1.026    0.307
## 
## Residual standard error: 1.822 on 98 degrees of freedom
## Multiple R-squared:  0.01063,	Adjusted R-squared:  0.0005363 
## F-statistic: 1.053 on 1 and 98 DF,  p-value: 0.3073</code></pre>
<pre class="r"><code>summary(b)$df[2]</code></pre>
<pre><code>## [1] 98</code></pre>
<pre class="r"><code>a$conf.int</code></pre>
<pre><code>## [1] -1.0972585  0.3492394
## attr(,&quot;conf.level&quot;)
## [1] 0.95</code></pre>
<pre class="r"><code>confint(b)</code></pre>
<pre><code>##                  2.5 %    97.5 %
## (Intercept) -0.3854238 0.6374047
## group_y2    -0.3492394 1.0972585</code></pre>
<pre class="r"><code>confint(b)[2,1]</code></pre>
<pre><code>## [1] -0.3492394</code></pre>
<pre class="r"><code># Put it together. Note that the signs are inversed for t.test.
df = data.frame(
  model = c(&#39;t.test&#39;, &#39;lm&#39;),
  mean_y = c(a$estimate[1], summary(b)$coefficients[1,1]),
  mean_y2 = c(a$estimate[2], sum(summary(b)$coefficients[,1])),
  difference = c(a$estimate[2] - a$estimate[1], summary(b)$coefficients[2,1]),
  p.value = c(a$p.value, summary(b)$coefficients[2,4]),
  df = c(a$parameter, summary(b)$df[2]),
  
  conf.low = c(a$conf.int[1], confint(b)[2,1]),
  conf.high = c(a$conf.int[2], confint(b)[2,2])
)

# Print it nicely
print_df(df)</code></pre>
<div class="datatables html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-7" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-7">{"x":{"filter":"none","vertical":false,"data":[["t.test","lm"],[0.126,0.126],[0.5,0.5],[0.374,0.374],[0.3073,0.3073],[98,98],[-1.0973,-0.3492],[0.3492,1.0973]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>model<\/th>\n      <th>mean_y<\/th>\n      <th>mean_y2<\/th>\n      <th>difference<\/th>\n      <th>p.value<\/th>\n      <th>df<\/th>\n      <th>conf.low<\/th>\n      <th>conf.high<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"lengthChange":false,"ordering":false,"autoWidth":true,"bPaginate":false,"bInfo":false,"paging":false,"columnDefs":[{"className":"dt-right","targets":[1,2,3,4,5,6,7]}],"order":[],"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>a</code></pre>
<pre><code>## 
## 	Two Sample t-test
## 
## data:  y and y2
## t = -1.0262, df = 98, p-value = 0.3073
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -1.0972585  0.3492394
## sample estimates:
## mean of x mean of y 
## 0.1259905 0.5000000</code></pre>
<pre class="r"><code>summary(b)</code></pre>
<pre><code>## 
## Call:
## lm(formula = value ~ 1 + group_y2)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.7791 -1.1897 -0.0632  0.8484  9.5369 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)   0.1260     0.2577   0.489    0.626
## group_y2      0.3740     0.3645   1.026    0.307
## 
## Residual standard error: 1.822 on 98 degrees of freedom
## Multiple R-squared:  0.01063,	Adjusted R-squared:  0.0005363 
## F-statistic: 1.053 on 1 and 98 DF,  p-value: 0.3073</code></pre>
<pre class="r"><code>summary(c)</code></pre>
<pre><code>## 
## Call:
## lm(formula = value ~ 1 + I(group == &quot;y2&quot;))
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.7791 -1.1897 -0.0632  0.8484  9.5369 
## 
## Coefficients:
##                      Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)            0.1260     0.2577   0.489    0.626
## I(group == &quot;y2&quot;)TRUE   0.3740     0.3645   1.026    0.307
## 
## Residual standard error: 1.822 on 98 degrees of freedom
## Multiple R-squared:  0.01063,	Adjusted R-squared:  0.0005363 
## F-statistic: 1.053 on 1 and 98 DF,  p-value: 0.3073</code></pre>
</div>
<div id="r-code-mann-whitney-u" class="section level3">
<h3>R code: Mann-Whitney U</h3>
<pre class="r"><code># Wilcoxon / Mann-Whitney U
a = wilcox.test(y, y2)

# As linear model with our dummy-coded group_y2:
b = lm(rank(value) ~ 1 + group_y2)  # compare to linear model above</code></pre>
<pre class="r"><code>df = data.frame(
  model = c(&#39;wilcox.test&#39;, &#39;lm&#39;),
  p.value = c(a$p.value, tidy(b)$p.value[2]),
  rank_diff = c(NA, b$coefficients[2])
)
print_df(df)</code></pre>
<div class="datatables html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-8" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-8">{"x":{"filter":"none","vertical":false,"data":[["wilcox.test","lm"],[0.1586,0.1586],[null,8.199999999999999]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>model<\/th>\n      <th>p.value<\/th>\n      <th>rank_diff<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"lengthChange":false,"ordering":false,"autoWidth":true,"bPaginate":false,"bInfo":false,"paging":false,"columnDefs":[{"className":"dt-right","targets":[1,2]}],"order":[],"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>a</code></pre>
<pre><code>## 
## 	Wilcoxon rank sum test with continuity correction
## 
## data:  y and y2
## W = 1045, p-value = 0.1586
## alternative hypothesis: true location shift is not equal to 0</code></pre>
<pre class="r"><code>summary(b)</code></pre>
<pre><code>## 
## Call:
## lm(formula = rank(value) ~ 1 + group_y2)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -46.60 -24.80   0.50  23.85  53.60 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   46.400      4.082   11.37   &lt;2e-16 ***
## group_y2       8.200      5.773    1.42    0.159    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 28.86 on 98 degrees of freedom
## Multiple R-squared:  0.02017,	Adjusted R-squared:  0.01018 
## F-statistic: 2.018 on 1 and 98 DF,  p-value: 0.1586</code></pre>
</div>
</div>
<div id="welch" class="section level2">
<h2>Welch’s t-test</h2>
<p>This is identical to the (Student’s) <a href="#t2">independent t-test</a> above except that Student’s assumes identical variances and <strong>Welch’s t-test</strong> does not. So the linear model is the same but we model one variance per group. We can do this using the <code>nlme</code> package (<a href="https://stats.stackexchange.com/questions/142685/equivalent-to-welchs-t-test-in-gls-framework">see more details here</a>):</p>
<pre class="r"><code># Built-in
a = t.test(y, y2, var.equal=FALSE)

# As linear model with per-group variances
b = nlme::gls(value ~ 1 + group_y2, weights = nlme::varIdent(form=~1|group), method=&quot;ML&quot;)</code></pre>
<p>Results:</p>
<pre class="r"><code>df = data.frame(
  model = c(&#39;t.test&#39;, &#39;gls&#39;),
  mean_y = c(a$estimate[1], b$coefficients[1]),
  mean_diff = c(a$estimate[2] - a$estimate[1], b$coefficients[2]),
  p.value = c(a$p.value, coef(summary(b))[2, 4]),
  t = c(a$statistic, -coef(summary(b))[2, 3]),
  conf.low = c(-a$conf.int[2], confint(b)[2, 1]),
  conf.high = c(-a$conf.int[1], confint(b)[2, 2])
)
print_df(df)</code></pre>
<div class="datatables html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-9" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-9">{"x":{"filter":"none","vertical":false,"data":[["t.test","gls"],[0.126,0.126],[0.374,0.374],[0.3076,0.3073],[-1.0262,-1.0262],[-0.3502,-0.3403],[1.0982,1.0883]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>model<\/th>\n      <th>mean_y<\/th>\n      <th>mean_diff<\/th>\n      <th>p.value<\/th>\n      <th>t<\/th>\n      <th>conf.low<\/th>\n      <th>conf.high<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"lengthChange":false,"ordering":false,"autoWidth":true,"bPaginate":false,"bInfo":false,"paging":false,"columnDefs":[{"className":"dt-right","targets":[1,2,3,4,5,6]}],"order":[],"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>a</code></pre>
<pre><code>## 
## 	Welch Two Sample t-test
## 
## data:  y and y2
## t = -1.0262, df = 88.771, p-value = 0.3076
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -1.0981994  0.3501804
## sample estimates:
## mean of x mean of y 
## 0.1259905 0.5000000</code></pre>
<pre class="r"><code>summary(b)</code></pre>
<pre><code>## Generalized least squares fit by maximum likelihood
##   Model: value ~ 1 + group_y2 
##   Data: NULL 
##       AIC      BIC   logLik
##   404.296 414.7167 -198.148
## 
## Variance function:
##  Structure: Different standard deviations per stratum
##  Formula: ~1 | group 
##  Parameter estimates:
##        y1        y2 
## 1.0000000 0.7157993 
## 
## Coefficients:
##                 Value Std.Error   t-value p-value
## (Intercept) 0.1259905 0.2963569 0.4251309  0.6717
## group_y2    0.3740095 0.3644549 1.0262161  0.3073
## 
##  Correlation: 
##          (Intr)
## group_y2 -0.813
## 
## Standardized residuals:
##         Min          Q1         Med          Q3         Max 
## -1.77683721 -0.66432885 -0.03198632  0.49966158  4.59722062 
## 
## Residual standard error: 2.074498 
## Degrees of freedom: 100 total; 98 residual</code></pre>
</div>
</div>
<div id="three-or-more-means" class="section level1">
<h1>Three or more means</h1>
<p>ANOVAs are linear models with (only) categorical predictors so they simply extend everything we did above, relying heavily on dummy coding. Do make sure to read <a href="#dummy">the section on dummy coding</a> if you haven’t already.</p>
<div id="anova1" class="section level2">
<h2>One-way ANOVA and Kruskal-Wallis</h2>
<div id="theory-as-linear-models-4" class="section level3">
<h3>Theory: As linear models</h3>
<p>Model: One mean for each group predicts <span class="math inline">\(y\)</span>.</p>
<p><span class="math display">\[y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 +... \qquad \mathcal{H}_0: y = \beta_0\]</span></p>
<p>where <span class="math inline">\(x_i\)</span> are indicators (<span class="math inline">\(x=0\)</span> or <span class="math inline">\(x=1\)</span>) where at most one <span class="math inline">\(x_i=1\)</span> while all others are <span class="math inline">\(x_i=0\)</span>.</p>
<p>Notice how this is just “more of the same” of what we already did in other models above. When there are only two groups, this model is <span class="math inline">\(y = \beta_0 + \beta_1*x\)</span>, i.e. the <a href="#t2">independent t-test</a>. If there is only one group, it is <span class="math inline">\(y = \beta_0\)</span>, i.e. the <a href="#t1">one-sample t-test</a>. This is easy to see in the visualization below - just cover up a few groups and see that it matches the other visualizations above.</p>
<pre class="r"><code># Figure
N = 15
D_anova1 = data.frame(
  y = c(
    rnorm_fixed(N, 0.5, 0.3),
    rnorm_fixed(N, 0, 0.3),
    rnorm_fixed(N, 1, 0.3),
    rnorm_fixed(N, 0.8, 0.3)
  ),
  x = rep(0:3, each = 15)
)
ymeans = aggregate(y~x, D_anova1, mean)$y
P_anova1 = ggplot(D_anova1, aes(x=x, y=y)) + 
  stat_summary(fun=mean, geom = &quot;errorbar&quot;, aes(ymax = ..y.., ymin = ..y.., color=&#39;intercepts&#39;), lwd=2) + 
  geom_segment(x = -10, xend = 100, y = 0.5, yend = 0.5, lwd = 2, aes(color = &#39;beta_0&#39;)) +
  geom_segment(x = 0, xend = 1, y = ymeans[1], yend = ymeans[2], lwd = 2, aes(color = &#39;betas&#39;)) +
  geom_segment(x = 1, xend = 2, y = ymeans[1], yend = ymeans[3], lwd = 2, aes(color = &#39;betas&#39;)) +
  geom_segment(x = 2, xend = 3, y = ymeans[1], yend = ymeans[4], lwd = 2, aes(color = &#39;betas&#39;)) +
  
  scale_color_manual(
    name = NULL, values = c(&quot;blue&quot;, &quot;red&quot;, &quot;green&quot;), 
    labels=c(
      bquote(beta[0]*&quot; (group 1 mean)&quot;), 
      bquote(beta[1]*&quot;, &quot;*beta[2]*&quot;,  etc. (slopes/differences to &quot;*beta[0]*&quot;)&quot;),
      bquote(beta[0]*&quot;+&quot;*beta[1]*&quot;, &quot;*beta[0]*&quot;+&quot;*beta[2]*&quot;, etc. (group 2, 3, ... means)&quot;)
    )
  )
  

theme_axis(P_anova1, xlim = c(-0.5, 4), legend.position = c(0.7, 0.1))</code></pre>
<p><img src="../../../../2023/09/24/common-statistical-tests-are-linear-models-or-how-to-teach-stats/index_files/figure-html/unnamed-chunk-77-1.svg" width="576" style="display: block; margin: auto;" /></p>
<p>A one-way ANOVA has a log-linear counterpart called <a href="#goodness">goodness-of-fit</a> test which we’ll return to. By the way, since we now regress on more than one <span class="math inline">\(x\)</span>, the one-way ANOVA is a <strong>multiple regression</strong> model.</p>
<p>The <strong>Kruskal-Wallis</strong> test is simply a <strong>one-way ANOVA</strong> on the rank-transformed <span class="math inline">\(y\)</span> (<code>value</code>):</p>
<p><span class="math display">\[rank(y) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 +...\]</span></p>
<p>This approximation is <a href="simulations/simulate_kruskall.html">good enough for 12 or more data points</a>. Again, if you do this for just one or two groups, we’re already acquainted with those equations, i.e. the <a href="#t1">Wilcoxon signed-rank test</a> or the <a href="#t2">Mann-Whitney U test</a> respectively.</p>
</div>
<div id="example-data" class="section level3">
<h3>Example data</h3>
<p>We make a three-level factor with the levels <code>a</code>, <code>b</code>, and <code>c</code> so that the <strong>one-way ANOVA</strong> basically becomes a “three-sample t-test”. Then we manually do the <a href="#dummy">dummy coding</a> of the groups.</p>
<pre class="r"><code># Three variables in &quot;long&quot; format
N = 20  # Number of samples per group
D = data.frame(
  value = c(rnorm_fixed(N, 0), rnorm_fixed(N, 1), rnorm_fixed(N, 0.5)),
  group = rep(c(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;), each = N),
  
  # Explicitly add indicator/dummy variables
  # Could also be done using model.matrix(~D$group)
  #group_a = rep(c(1, 0, 0), each=N),  # This is the intercept. No need to code
  group_b = rep(c(0, 1, 0), each = N),
  group_c = rep(c(0, 0, 1), each = N)
)  # N of each level</code></pre>
<pre class="r"><code>print_df(D, navigate=TRUE)</code></pre>
<div class="datatables html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-10" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-10">{"x":{"filter":"none","vertical":false,"data":[[-0.9999,-0.081,0.3332,-0.1102,-0.4488,0.4641,0.5154,-0.2836,-0.7425,-1.6591,1.1126,1.6475,1.8672,0.8578,-0.2465,-2.186,-0.5212,-0.2852,0.1149,0.6512,0.5409,0.3513,0.5486,-0.2161,1.2966,-0.6798999999999999,-0.2963,1.1239,2.3541,1.6241,0.2862,0.6813,3.83,1.3513,1.2598,1.1645,0.5002,1.0979,1.7659,1.4155,0.4464,-0.4189,2.0676,1.7144,-0.4727,-0.9947,-1.5458,0.3576,0.5487,0.7709,0.6107,-0.7869,0.7499,1.7448,0.9844000000000001,0.3121,1.6151,0.5251,-0.0274,1.7987],["a","a","a","a","a","a","a","a","a","a","a","a","a","a","a","a","a","a","a","a","b","b","b","b","b","b","b","b","b","b","b","b","b","b","b","b","b","b","b","b","c","c","c","c","c","c","c","c","c","c","c","c","c","c","c","c","c","c","c","c"],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>value<\/th>\n      <th>group<\/th>\n      <th>group_b<\/th>\n      <th>group_c<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"lengthChange":false,"ordering":false,"autoWidth":true,"bPaginate":true,"bInfo":true,"paging":true,"columnDefs":[{"className":"dt-right","targets":[0,2,3]}],"order":[],"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>D$value</code></pre>
<pre><code>##  [1] -0.99986550 -0.08102959  0.33317532 -0.11018630 -0.44884149  0.46412376
##  [7]  0.51543519 -0.28355654 -0.74246374 -1.65909364  1.11255118  1.64754056
## [13]  1.86717990  0.85784150 -0.24647087 -2.18596427 -0.52118124 -0.28520725
## [19]  0.11486156  0.65115145  0.54087656  0.35127066  0.54862249 -0.21614680
## [25]  1.29661540 -0.67987039 -0.29630811  1.12389525  2.35414725  1.62414002
## [31]  0.28624992  0.68134431  3.83003044  1.35130913  1.25981287  1.16452665
## [37]  0.50022156  1.09787477  1.76588838  1.41549964  0.44639469 -0.41887179
## [43]  2.06761817  1.71439785 -0.47271912 -0.99468994 -1.54581633  0.35763787
## [49]  0.54872043  0.77089526  0.61074337 -0.78686708  0.74987913  1.74475505
## [55]  0.98439060  0.31211917  1.61505788  0.52506482 -0.02743684  1.79872681</code></pre>
<p>With group a’s intercept omni-present, see how exactly one other parameter is added to predict <code>value</code> for group b and c in a given row (scroll to he end). Thus data points in group b never affect the estimates in group c.</p>
</div>
<div id="r-code-one-way-anova" class="section level3">
<h3>R code: one-way ANOVA</h3>
<p>OK, let’s see the identity between a dedicated <strong>ANOVA</strong> function (<code>car::Anova</code>) and the dummy-coded in-your-face linear model in <code>lm</code>.</p>
<pre class="r"><code># Compare built-in and linear model
a = car::Anova(aov(value ~ group, D))  # Dedicated ANOVA function
b = lm(value ~ 1 + group_b + group_c, data = D)  # As in-your-face linear model</code></pre>
<pre class="r"><code>a</code></pre>
<pre><code>## Anova Table (Type II tests)
## 
## Response: value
##           Sum Sq Df F value   Pr(&gt;F)   
## group         10  2       5 0.009984 **
## Residuals     57 57                    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(b)</code></pre>
<pre><code>## 
## Call:
## lm(formula = value ~ 1 + group_b + group_c, data = D)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.18596 -0.52275  0.03689  0.49215  2.83003 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept) 1.147e-16  2.236e-01   0.000  1.00000   
## group_b     1.000e+00  3.162e-01   3.162  0.00251 **
## group_c     5.000e-01  3.162e-01   1.581  0.11938   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1 on 57 degrees of freedom
## Multiple R-squared:  0.1493,	Adjusted R-squared:  0.1194 
## F-statistic:     5 on 2 and 57 DF,  p-value: 0.009984</code></pre>
<pre class="r"><code>glance(b)</code></pre>
<pre><code>## # A tibble: 1 × 12
##   r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC
##       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1     0.149         0.119     1         5 0.00998     2  -83.6  175.  184.
## # ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;</code></pre>
<pre class="r"><code>a$Df</code></pre>
<pre><code>## [1]  2 57</code></pre>
<pre class="r"><code>b$df.residual</code></pre>
<pre><code>## [1] 57</code></pre>
<pre class="r"><code>a$`F value`</code></pre>
<pre><code>## [1]  5 NA</code></pre>
<pre class="r"><code>glance(b)$statistic</code></pre>
<pre><code>## value 
##     5</code></pre>
<pre class="r"><code>a$`Pr(&gt;F)`</code></pre>
<pre><code>## [1] 0.00998393         NA</code></pre>
<p>Results:</p>
<pre class="r"><code>df = data.frame(
  model = c(&#39;Anova&#39;, &#39;lm&#39;),
  df = c(a$Df[1], glance(b)$df),  # -1? https://github.com/tidymodels/broom/issues/273
  df.residual = c(a$Df[2], b$df.residual),
  F = c(a$`F value`[1], glance(b)$statistic),
  p.value = c(a$`Pr(&gt;F)`[1], glance(b)$p.value)
)
print_df(df, 5)</code></pre>
<div class="datatables html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-11" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-11">{"x":{"filter":"none","vertical":false,"data":[["Anova","lm"],[2,2],[57,57],[5,5],[0.009979999999999999,0.009979999999999999]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>model<\/th>\n      <th>df<\/th>\n      <th>df.residual<\/th>\n      <th>F<\/th>\n      <th>p.value<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"lengthChange":false,"ordering":false,"autoWidth":true,"bPaginate":false,"bInfo":false,"paging":false,"columnDefs":[{"className":"dt-right","targets":[1,2,3,4]}],"order":[],"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<p>Actually, <code>car::Anova</code> and <code>aov</code> are wrappers around <code>lm</code> so the identity comes as no surprise. It only shows that the dummy-coded formula, which had a direct interpretation as a linear model, is the one that underlies the shorthand notation syntax <code>y ~ factor</code>. Indeed, the only real reason to use aov and <code>car::Anova</code> rather than <code>lm</code> is to get a nicely formatted ANOVA table.</p>
<p>The default output of <code>lm</code> returns parameter estimates as well (bonus!), which you can see if you unfold the R output above. However, because this IS the ANOVA model, you can also get parameter estimates out into the open by calling <code>coefficients(aov(...))</code>.</p>
<p>Note that I do not use the <code>aov</code> function because it computes type-I sum of squares, which is widely discouraged. There is a BIG polarized debate about whether to use type-II (as <code>car::Anova</code> does by default) or type-III sum of squares (set <code>car::Anova(..., type=3)</code>), but let’s skip that for now.</p>
</div>
<div id="r-code-kruskal-wallis" class="section level3">
<h3>R code: Kruskal-Wallis</h3>
<pre class="r"><code>a = kruskal.test(value ~ group, D)  # Built-in
b = lm(rank(value) ~ 1 + group_b + group_c, D)  # As linear model
c = car::Anova(aov(rank(value) ~ group, D))  # The same model, using a dedicated ANOVA function. It just wraps lm.</code></pre>
<p>Results:</p>
<pre class="r"><code>df = data.frame(
  model = c(&#39;kruskal.test&#39;, &#39;lm&#39;),
  df = c(a$parameter, glance(b)$df - 1),  # -1? https://github.com/tidymodels/broom/issues/273
  p.value = c(a$p.value, glance(b)$p.value)
)
print_df(df)</code></pre>
<div class="datatables html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-12" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-12">{"x":{"filter":"none","vertical":false,"data":[["kruskal.test","lm"],[2,1],[0.0169,0.0144]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>model<\/th>\n      <th>df<\/th>\n      <th>p.value<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"lengthChange":false,"ordering":false,"autoWidth":true,"bPaginate":false,"bInfo":false,"paging":false,"columnDefs":[{"className":"dt-right","targets":[1,2]}],"order":[],"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>a</code></pre>
<pre><code>## 
## 	Kruskal-Wallis rank sum test
## 
## data:  value by group
## Kruskal-Wallis chi-squared = 8.163, df = 2, p-value = 0.01688</code></pre>
<pre class="r"><code>summary(b)</code></pre>
<pre><code>## 
## Call:
## lm(formula = rank(value) ~ 1 + group_b + group_c, data = D)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -30.100 -11.787  -0.575  10.188  34.650 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   22.350      3.688   6.060 1.15e-07 ***
## group_b       15.750      5.216   3.020  0.00378 ** 
## group_c        8.700      5.216   1.668  0.10079    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 16.49 on 57 degrees of freedom
## Multiple R-squared:  0.1384,	Adjusted R-squared:  0.1081 
## F-statistic: 4.576 on 2 and 57 DF,  p-value: 0.01435</code></pre>
<pre class="r"><code>c</code></pre>
<pre><code>## Anova Table (Type II tests)
## 
## Response: rank(value)
##            Sum Sq Df F value  Pr(&gt;F)  
## group      2489.7  2  4.5763 0.01435 *
## Residuals 15505.3 57                  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
</div>
<div id="two-way-anova" class="section level2">
<h2>Two-way ANOVA</h2>
<div id="theory-as-linear-models-5" class="section level3">
<h3>Theory: As linear models</h3>
<p>Model: one mean per group (main effects) plus these means multiplied across factors (interaction effects). The main effects are the <a href="#anova1">one-way ANOVA</a>s above, though in the context of a larger model. The interaction effect is harder to explain in the abstract even though it’s just a few numbers multiplied with each other. I will leave that to the teachers to keep focus on equivalences here :-)</p>
<p>Switching to matrix notation:</p>
<p><span class="math display">\[y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_1 X_2 \qquad \mathcal{H}_0: \beta_3 = 0\]</span></p>
<p>Here <span class="math inline">\(\beta_i\)</span> are vectors of betas of which only one is selected by the indicator vector <span class="math inline">\(X_i\)</span>. The <span class="math inline">\(\mathcal{H}_0\)</span> shown here is the interaction effect. Note that the intercept <span class="math inline">\(\beta_0\)</span>, to which all other <span class="math inline">\(\beta\)</span>s are relative, is now the mean for the first level of all factors.</p>
<p>Continuing with the dataset from the one-way ANOVA above, let’s add a crossing factor <code>mood</code> so that we can test the <code>group:mood</code> interaction (a 3x2 ANOVA). We also do the <a href="#dummy">dummy coding</a> of this factor needed for the linear model.</p>
<pre class="r"><code># Crossing factor
D$mood = c(&#39;happy&#39;, &#39;sad&#39;)

# Dummy coding
D$mood_happy = ifelse(D$mood == &#39;happy&#39;, 1, 0)  # 1 if mood==happy. 0 otherwise.
#D$mood_sad = ifelse(D$mood == &#39;sad&#39;, 1, 0)  # Same, but we won&#39;t be needing this</code></pre>
<pre class="r"><code>print_df(D, navigate=TRUE)</code></pre>
<div class="datatables html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-13" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-13">{"x":{"filter":"none","vertical":false,"data":[[-0.9999,-0.081,0.3332,-0.1102,-0.4488,0.4641,0.5154,-0.2836,-0.7425,-1.6591,1.1126,1.6475,1.8672,0.8578,-0.2465,-2.186,-0.5212,-0.2852,0.1149,0.6512,0.5409,0.3513,0.5486,-0.2161,1.2966,-0.6798999999999999,-0.2963,1.1239,2.3541,1.6241,0.2862,0.6813,3.83,1.3513,1.2598,1.1645,0.5002,1.0979,1.7659,1.4155,0.4464,-0.4189,2.0676,1.7144,-0.4727,-0.9947,-1.5458,0.3576,0.5487,0.7709,0.6107,-0.7869,0.7499,1.7448,0.9844000000000001,0.3121,1.6151,0.5251,-0.0274,1.7987],["a","a","a","a","a","a","a","a","a","a","a","a","a","a","a","a","a","a","a","a","b","b","b","b","b","b","b","b","b","b","b","b","b","b","b","b","b","b","b","b","c","c","c","c","c","c","c","c","c","c","c","c","c","c","c","c","c","c","c","c"],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],["happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad"],[1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>value<\/th>\n      <th>group<\/th>\n      <th>group_b<\/th>\n      <th>group_c<\/th>\n      <th>mood<\/th>\n      <th>mood_happy<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"lengthChange":false,"ordering":false,"autoWidth":true,"bPaginate":true,"bInfo":true,"paging":true,"columnDefs":[{"className":"dt-right","targets":[0,2,3,5]}],"order":[],"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code># Three variables in &quot;long&quot; format
N = 20  # Number of samples per group
D = data.frame(
  value = c(rnorm_fixed(N, 0), rnorm_fixed(N, 1), rnorm_fixed(N, 0.5)),
  group = rep(c(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;), each = N),
  
  # Explicitly add indicator/dummy variables
  # Could also be done using model.matrix(~D$group)
  #group_a = rep(c(1, 0, 0), each=N),  # This is the intercept. No need to code
  group_b = rep(c(0, 1, 0), each = N),
  group_c = rep(c(0, 0, 1), each = N)
)  # N of each level

# Crossing factor
D$mood = c(&#39;happy&#39;, &#39;sad&#39;)

# Dummy coding
D$mood_happy = ifelse(D$mood == &#39;happy&#39;, 1, 0)  # 1 if mood==happy. 0 otherwise.
#D$mood_sad = ifelse(D$mood == &#39;sad&#39;, 1, 0)  # Same, but we won&#39;t be needing this
print_df(D, navigate=TRUE)</code></pre>
<div class="datatables html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-14" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-14">{"x":{"filter":"none","vertical":false,"data":[[-1.3514,-1.3732,1.4558,-1.2695,1.3852,1.3663,-0.8431,-0.279,0.4832,-0.1416,-0.0036,1.4348,-1.3927,1.0542,0.5653,0.6015,-0.4283,-0.0867,-0.7541,-0.4232,1.143,0.885,1.9739,-1.3219,1.3195,-0.8818,1.1357,1.1159,1.5234,0.4643,0.5107,1.3,0.4657,2.8329,0.0497,2.2724,0.2477,1.6821,1.7846,1.4972,0.2227,0.034,0.4197,-0.3644,0.5704,1.7518,1.3276,1.7336,-0.2753,0.8789,2.0163,2.2672,-1.2429,-0.1594,1.2521,-0.364,-0.7339,-0.7345,0.9186,0.4814],["a","a","a","a","a","a","a","a","a","a","a","a","a","a","a","a","a","a","a","a","b","b","b","b","b","b","b","b","b","b","b","b","b","b","b","b","b","b","b","b","c","c","c","c","c","c","c","c","c","c","c","c","c","c","c","c","c","c","c","c"],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],["happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad","happy","sad"],[1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0,1,0]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>value<\/th>\n      <th>group<\/th>\n      <th>group_b<\/th>\n      <th>group_c<\/th>\n      <th>mood<\/th>\n      <th>mood_happy<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"lengthChange":false,"ordering":false,"autoWidth":true,"bPaginate":true,"bInfo":true,"paging":true,"columnDefs":[{"className":"dt-right","targets":[0,2,3,5]}],"order":[],"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<p><span class="math inline">\(\beta_0\)</span> is now the happy guys from group a!</p>
<pre class="r"><code># Add intercept line
# Add cross...
# Use other data?

means = lm(value ~ mood * group, D)$coefficients

P_anova2 = ggplot(D, aes(x=group, y=value, color=mood)) + 
  geom_segment(x = -10, xend = 100, y = means[1], yend = 0.5, col = &#39;blue&#39;, lwd = 2) +
  stat_summary(fun.y = mean, geom = &quot;errorbar&quot;, aes(ymax = ..y.., ymin = ..y..),  lwd = 2)
theme_axis(P_anova2, xlim = c(-0.5, 3.5)) + theme(axis.text.x = element_text())</code></pre>
<p><img src="../../../../2023/09/24/common-statistical-tests-are-linear-models-or-how-to-teach-stats/index_files/figure-html/unnamed-chunk-92-1.svg" width="576" style="display: block; margin: auto;" /></p>
</div>
<div id="r-code-two-way-anova" class="section level3">
<h3>R code: Two-way ANOVA</h3>
<p>Now let’s turn to the actual modeling in R. We compare a dedicated ANOVA function (<code>car::Anova</code>; see <a href="#anova1">One-Way ANOVA</a> why) to the linear model (<code>lm</code>). Notice that in ANOVA, we are testing a full factor interaction all at once which involves many parameters (two in this case), so we can’t look at the overall model fit nor any particular parameter for the result. Therefore, I use a <a href="https://en.wikipedia.org/wiki/Likelihood-ratio_test">likelihood-ratio test</a> to compare a full two-way ANOVA model (“saturated”) to one without the interaction effect(s). The <code>anova</code> function does this test. Even though that looks like cheating, it’s just computing likelihoods, p-values, etc. on the models that were already fitted, so it’s legit!</p>
<pre class="r"><code># Dedicated two-way ANOVA functions
a = car::Anova(aov(value ~ mood * group, D), type=&#39;II&#39;)  # Normal notation. &quot;*&quot; both multiplies and adds main effects
b = car::Anova(aov(value ~ mood + group + mood:group, D))  # Identical but more verbose about main effects and interaction

# Testing the interaction terms as linear model.
full = lm(value ~ 1 + group_b + group_c + mood_happy + group_b:mood_happy + group_c:mood_happy, D)  # Full model
null = lm(value ~ 1 + group_b + group_c + mood_happy, D)  # Without interaction
c = anova(null, full)  # whoop whoop, same F, p, and Dfs</code></pre>
<pre class="r"><code>a</code></pre>
<pre><code>## Anova Table (Type II tests)
## 
## Response: value
##            Sum Sq Df F value  Pr(&gt;F)  
## mood        0.105  1  0.0997 0.75335  
## group      10.000  2  4.7549 0.01253 *
## mood:group  0.111  2  0.0528 0.94862  
## Residuals  56.784 54                  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>tidy(a)</code></pre>
<pre><code>## # A tibble: 4 × 5
##   term        sumsq    df statistic p.value
##   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1 mood        0.105     1    0.0997  0.753 
## 2 group      10.0       2    4.75    0.0125
## 3 mood:group  0.111     2    0.0528  0.949 
## 4 Residuals  56.8      54   NA      NA</code></pre>
<pre class="r"><code>tidy(b)</code></pre>
<pre><code>## # A tibble: 4 × 5
##   term        sumsq    df statistic p.value
##   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1 mood        0.105     1    0.0997  0.753 
## 2 group      10.0       2    4.75    0.0125
## 3 mood:group  0.111     2    0.0528  0.949 
## 4 Residuals  56.8      54   NA      NA</code></pre>
<p>Results:</p>
<pre class="r"><code>tidy(a)[3:4, ]</code></pre>
<pre><code>## # A tibble: 2 × 5
##   term        sumsq    df statistic p.value
##   &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1 mood:group  0.111     2    0.0528   0.949
## 2 Residuals  56.8      54   NA       NA</code></pre>
<pre class="r"><code>(tidy(a)[3,]$`sumsq`/tidy(a)[3,]$df)/(tidy(a)[4,]$`sumsq`/tidy(a)[4,]$df) #F statistic is MSR/MSE</code></pre>
<pre><code>## [1] 0.05279774</code></pre>
<pre class="r"><code>pf((tidy(a)[3,]$`sumsq`/tidy(a)[3,]$df)/(tidy(a)[4,]$`sumsq`/tidy(a)[4,]$df), #P value of F 
   df1=tidy(a)[3,]$df,
   df2=tidy(a)[4,]$df,
   lower.tail = FALSE)</code></pre>
<pre><code>## [1] 0.9486208</code></pre>
<pre class="r"><code>summary(full)</code></pre>
<pre><code>## 
## Call:
## lm(formula = value ~ 1 + group_b + group_c + mood_happy + group_b:mood_happy + 
##     group_c:mood_happy, data = D)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.30652 -0.71462  0.02849  0.71542  1.84829 
## 
## Coefficients:
##                    Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept)         0.08836    0.32428   0.272   0.7863  
## group_b             0.89625    0.45860   1.954   0.0558 .
## group_c             0.46410    0.45860   1.012   0.3161  
## mood_happy         -0.17672    0.45860  -0.385   0.7015  
## group_b:mood_happy  0.20750    0.64855   0.320   0.7503  
## group_c:mood_happy  0.07180    0.64855   0.111   0.9123  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.025 on 54 degrees of freedom
## Multiple R-squared:  0.1525,	Adjusted R-squared:  0.074 
## F-statistic: 1.943 on 5 and 54 DF,  p-value: 0.1023</code></pre>
<pre class="r"><code>anova(full)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Response: value
##                    Df Sum Sq Mean Sq F value   Pr(&gt;F)   
## group_b             1  7.500  7.5000  7.1323 0.009983 **
## group_c             1  2.500  2.5000  2.3774 0.128940   
## mood_happy          1  0.105  0.1049  0.0997 0.753352   
## group_b:mood_happy  1  0.098  0.0982  0.0933 0.761148   
## group_c:mood_happy  1  0.013  0.0129  0.0123 0.912262   
## Residuals          54 56.784  1.0516                    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>summary(null)</code></pre>
<pre><code>## 
## Call:
## lm(formula = value ~ 1 + group_b + group_c + mood_happy, data = D)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.36372 -0.71093 -0.00011  0.67869  1.79109 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)  0.04181    0.26025   0.161  0.87294   
## group_b      1.00000    0.31875   3.137  0.00272 **
## group_c      0.50000    0.31875   1.569  0.12236   
## mood_happy  -0.08362    0.26025  -0.321  0.74917   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.008 on 56 degrees of freedom
## Multiple R-squared:  0.1508,	Adjusted R-squared:  0.1053 
## F-statistic: 3.315 on 3 and 56 DF,  p-value: 0.02632</code></pre>
<pre class="r"><code>anova(null)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Response: value
##            Df Sum Sq Mean Sq F value   Pr(&gt;F)   
## group_b     1  7.500  7.5000  7.3820 0.008749 **
## group_c     1  2.500  2.5000  2.4607 0.122363   
## mood_happy  1  0.105  0.1049  0.1032 0.749173   
## Residuals  56 56.895  1.0160                    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>c</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: value ~ 1 + group_b + group_c + mood_happy
## Model 2: value ~ 1 + group_b + group_c + mood_happy + group_b:mood_happy + 
##     group_c:mood_happy
##   Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)
## 1     56 56.895                           
## 2     54 56.784  2   0.11104 0.0528 0.9486</code></pre>
<pre class="r"><code>tidy(c)</code></pre>
<pre><code>## # A tibble: 2 × 7
##   term                          df.residual   rss    df  sumsq statistic p.value
##   &lt;chr&gt;                               &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1 value ~ 1 + group_b + group_…          56  56.9    NA NA       NA       NA    
## 2 value ~ 1 + group_b + group_…          54  56.8     2  0.111    0.0528   0.949</code></pre>
<pre class="r"><code>(tidy(c)[2,]$`sumsq`/tidy(c)[2,]$df)/(tidy(c)[2,]$`rss`/tidy(c)[2,]$`df.residual`) #F statistic is MSR/MSE</code></pre>
<pre><code>## [1] 0.05279774</code></pre>
<pre class="r"><code>at = tidy(a)[3, ]
at$res.df = tidy(a)[4,]$df
at$rss = tidy(a)[4,]$sumsq
ct = tidy(c)[2, ]

df = bind_rows(at, ct) %&gt;%
  mutate(model = c(&#39;Anova mood:group&#39;, &#39;lm LRT&#39;)) %&gt;%
  rename(F = statistic,
         res.sumsq = rss) %&gt;%
  select(model, F, df, p.value, sumsq, res.sumsq)
print_df(df)</code></pre>
<div class="datatables html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-15" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-15">{"x":{"filter":"none","vertical":false,"data":[["Anova mood:group","lm LRT"],[0.0528,0.0528],[2,2],[0.9486,0.9486],[0.111,0.111],[56.7841,56.7841]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>model<\/th>\n      <th>F<\/th>\n      <th>df<\/th>\n      <th>p.value<\/th>\n      <th>sumsq<\/th>\n      <th>res.sumsq<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"lengthChange":false,"ordering":false,"autoWidth":true,"bPaginate":false,"bInfo":false,"paging":false,"columnDefs":[{"className":"dt-right","targets":[1,2,3,4,5]}],"order":[],"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>a</code></pre>
<pre><code>## Anova Table (Type II tests)
## 
## Response: value
##            Sum Sq Df F value  Pr(&gt;F)  
## mood        0.105  1  0.0997 0.75335  
## group      10.000  2  4.7549 0.01253 *
## mood:group  0.111  2  0.0528 0.94862  
## Residuals  56.784 54                  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>c</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: value ~ 1 + group_b + group_c + mood_happy
## Model 2: value ~ 1 + group_b + group_c + mood_happy + group_b:mood_happy + 
##     group_c:mood_happy
##   Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)
## 1     56 56.895                           
## 2     54 56.784  2   0.11104 0.0528 0.9486</code></pre>
<p>Below, I present approximate main effect models, though exact calculation of ANOVA main effects <a href="https://stats.idre.ucla.edu/stata/faq/how-can-i-get-anova-simple-main-effects-with-dummy-coding/">is more involved</a> if it is to be accurate and furthermore depend on whether type-II or type-III sum of squares are used for inference.</p>
<p>Look at the model summary statistics to find values comparable to the <code>Anova</code>-estimated main effects above.</p>
<pre class="r"><code># Main effect of group.
e = lm(value ~ 1 + group_b + group_c, D)

# Main effect of mood.
f = lm(value ~ 1 + mood_happy, D)</code></pre>
<pre class="r"><code>et = glance(e)
et$df = et$df - 1 # see https://github.com/tidymodels/broom/issues/273
ft = glance(f)
ft$df = ft$df - 1 # see https://github.com/tidymodels/broom/issues/273
at = tidy(a)[1:2, ]

df = bind_rows(et, ft, at) %&gt;%
  mutate(
    model = c(&#39;lm&#39;, &#39;lm&#39;, &#39;Anova&#39;, &#39;Anova&#39;),
    term = c(&#39;group&#39;, &#39;mood&#39;, &#39;mood&#39;, &#39;group&#39;)
  ) %&gt;%
  rename(F = statistic) %&gt;%
  select(term, model, df, F, p.value) %&gt;%
  arrange(term, model)
print_df(df, 5)</code></pre>
<div class="datatables html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-16" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-16">{"x":{"filter":"none","vertical":false,"data":[["group","group","mood","mood"],["Anova","lm","Anova","lm"],[2,1,1,0],[4.75485,5,0.09975000000000001,0.09093999999999999],[0.01253,0.009979999999999999,0.75335,0.76406]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>term<\/th>\n      <th>model<\/th>\n      <th>df<\/th>\n      <th>F<\/th>\n      <th>p.value<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"lengthChange":false,"ordering":false,"autoWidth":true,"bPaginate":false,"bInfo":false,"paging":false,"columnDefs":[{"className":"dt-right","targets":[2,3,4]}],"order":[],"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>summary(e)</code></pre>
<pre><code>## 
## Call:
## lm(formula = value ~ 1 + group_b + group_c, data = D)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -2.32191 -0.75274 -0.01108  0.69960  1.83290 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept) 2.293e-16  2.236e-01   0.000  1.00000   
## group_b     1.000e+00  3.162e-01   3.162  0.00251 **
## group_c     5.000e-01  3.162e-01   1.581  0.11938   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1 on 57 degrees of freedom
## Multiple R-squared:  0.1493,	Adjusted R-squared:  0.1194 
## F-statistic:     5 on 2 and 57 DF,  p-value: 0.009984</code></pre>
<pre class="r"><code>summary(f)</code></pre>
<pre><code>## 
## Call:
## lm(formula = value ~ 1 + mood_happy, data = D)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.91504 -0.83722  0.03875  0.86335  2.29109 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)  0.54181    0.19608   2.763  0.00766 **
## mood_happy  -0.08362    0.27729  -0.302  0.76406   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 1.074 on 58 degrees of freedom
## Multiple R-squared:  0.001566,	Adjusted R-squared:  -0.01565 
## F-statistic: 0.09094 on 1 and 58 DF,  p-value: 0.7641</code></pre>
</div>
</div>
<div id="ancova" class="section level2">
<h2>ANCOVA</h2>
<p>This is simply ANOVA with a continuous regressor added so that it now contains continuous and (dummy-coded) categorical predictors. For example, if we continue with the <a href="#anova1">one-way ANOVA</a> example, we can add <code>age</code> and it is now called a <strong>one-way ANCOVA</strong>:</p>
<p><span class="math display">\[y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_3 age\]</span></p>
<p>… where <span class="math inline">\(x_i\)</span> are our usual dummy-coded indicator variables. <span class="math inline">\(\beta_0\)</span> is now the mean for the first group at <span class="math inline">\(age=0\)</span>. You can turn all ANOVAs into ANCOVAs this way, e.g. by adding <span class="math inline">\(\beta_N \cdot age\)</span> to our <strong>two-way ANOVA</strong> in the previous section. But let us go ahead with our one-way ANCOVA, starting by adding <span class="math inline">\(age\)</span> to our dataset:</p>
<pre class="r"><code>D</code></pre>
<pre><code>##           value group group_b group_c  mood mood_happy
## 1  -1.351387612     a       0       0 happy          1
## 2  -1.373227623     a       0       0   sad          0
## 3   1.455799673     a       0       0 happy          1
## 4  -1.269454417     a       0       0   sad          0
## 5   1.385205392     a       0       0 happy          1
## 6   1.366253481     a       0       0   sad          0
## 7  -0.843083252     a       0       0 happy          1
## 8  -0.278988443     a       0       0   sad          0
## 9   0.483213416     a       0       0 happy          1
## 10 -0.141556320     a       0       0   sad          0
## 11 -0.003587294     a       0       0 happy          1
## 12  1.434767265     a       0       0   sad          0
## 13 -1.392672920     a       0       0 happy          1
## 14  1.054200684     a       0       0   sad          0
## 15  0.565283008     a       0       0 happy          1
## 16  0.601531344     a       0       0   sad          0
## 17 -0.428312886     a       0       0 happy          1
## 18 -0.086688261     a       0       0   sad          0
## 19 -0.754055855     a       0       0 happy          1
## 20 -0.423239381     a       0       0   sad          0
## 21  1.142965432     b       1       0 happy          1
## 22  0.884986296     b       1       0   sad          0
## 23  1.973887747     b       1       0 happy          1
## 24 -1.321912166     b       1       0   sad          0
## 25  1.319526554     b       1       0 happy          1
## 26 -0.881763131     b       1       0   sad          0
## 27  1.135739419     b       1       0 happy          1
## 28  1.115869346     b       1       0   sad          0
## 29  1.523397694     b       1       0 happy          1
## 30  0.464313447     b       1       0   sad          0
## 31  0.510657926     b       1       0 happy          1
## 32  1.300006873     b       1       0   sad          0
## 33  0.465655671     b       1       0 happy          1
## 34  2.832899449     b       1       0   sad          0
## 35  0.049714455     b       1       0 happy          1
## 36  2.272449898     b       1       0   sad          0
## 37  0.247702501     b       1       0 happy          1
## 38  1.682094352     b       1       0   sad          0
## 39  1.784635899     b       1       0 happy          1
## 40  1.497172336     b       1       0   sad          0
## 41  0.222672380     c       0       1 happy          1
## 42  0.033992783     c       0       1   sad          0
## 43  0.419742661     c       0       1 happy          1
## 44 -0.364360978     c       0       1   sad          0
## 45  0.570367796     c       0       1 happy          1
## 46  1.751820641     c       0       1   sad          0
## 47  1.327580716     c       0       1 happy          1
## 48  1.733607128     c       0       1   sad          0
## 49 -0.275314235     c       0       1 happy          1
## 50  0.878910401     c       0       1   sad          0
## 51  2.016340712     c       0       1 happy          1
## 52  2.267185958     c       0       1   sad          0
## 53 -1.242889759     c       0       1 happy          1
## 54 -0.159415943     c       0       1   sad          0
## 55  1.252114637     c       0       1 happy          1
## 56 -0.364041061     c       0       1   sad          0
## 57 -0.733858093     c       0       1 happy          1
## 58 -0.734512470     c       0       1   sad          0
## 59  0.918631853     c       0       1 happy          1
## 60  0.481424873     c       0       1   sad          0</code></pre>
<pre class="r"><code>nrow(D)</code></pre>
<pre><code>## [1] 60</code></pre>
<pre class="r"><code>rnorm_fixed(nrow(D), sd = 3)</code></pre>
<pre><code>##              [,1]
##  [1,]  0.08915962
##  [2,]  0.94910164
##  [3,] -3.82568438
##  [4,] -0.62858973
##  [5,]  7.92800847
##  [6,]  1.39845988
##  [7,] -1.79942547
##  [8,] -1.25298164
##  [9,]  1.01056525
## [10,]  3.80594472
## [11,]  2.78456252
## [12,] -7.13985523
## [13,] -3.51446735
## [14,]  2.06513177
## [15,]  0.20324444
## [16,]  0.96473965
## [17,] -1.18023006
## [18,]  2.90228521
## [19,]  2.43330741
## [20,] -2.40464509
## [21,]  1.90912797
## [22,] -1.13791569
## [23,]  0.57918976
## [24,] -0.52302230
## [25,]  1.42020175
## [26,] -0.83451575
## [27,]  2.94604496
## [28,] -3.16202627
## [29,]  0.87431089
## [30,] -3.95958089
## [31,]  0.09943368
## [32,]  3.01096508
## [33,]  4.89221372
## [34,]  2.27201969
## [35,]  0.66176877
## [36,]  1.14917217
## [37,]  0.75566450
## [38,] -3.67861385
## [39,]  4.81344377
## [40,]  2.55241506
## [41,] -3.25170953
## [42,]  0.05352314
## [43,]  1.37062592
## [44,] -2.00024035
## [45,]  2.57644784
## [46,] -7.07458409
## [47,]  5.33877219
## [48,] -1.23944603
## [49,] -6.61729709
## [50,]  1.21069025
## [51,]  0.24701188
## [52,]  1.31596239
## [53,]  0.85349866
## [54,]  0.72477884
## [55,] -0.47091624
## [56,] -3.47241185
## [57,]  0.05124527
## [58,] -5.07978008
## [59,] -3.92771118
## [60,] -0.03738856
## attr(,&quot;scaled:center&quot;)
## [1] 0.05281647
## attr(,&quot;scaled:scale&quot;)
## [1] 0.7798746</code></pre>
<pre class="r"><code>D$value</code></pre>
<pre><code>##  [1] -1.351387612 -1.373227623  1.455799673 -1.269454417  1.385205392
##  [6]  1.366253481 -0.843083252 -0.278988443  0.483213416 -0.141556320
## [11] -0.003587294  1.434767265 -1.392672920  1.054200684  0.565283008
## [16]  0.601531344 -0.428312886 -0.086688261 -0.754055855 -0.423239381
## [21]  1.142965432  0.884986296  1.973887747 -1.321912166  1.319526554
## [26] -0.881763131  1.135739419  1.115869346  1.523397694  0.464313447
## [31]  0.510657926  1.300006873  0.465655671  2.832899449  0.049714455
## [36]  2.272449898  0.247702501  1.682094352  1.784635899  1.497172336
## [41]  0.222672380  0.033992783  0.419742661 -0.364360978  0.570367796
## [46]  1.751820641  1.327580716  1.733607128 -0.275314235  0.878910401
## [51]  2.016340712  2.267185958 -1.242889759 -0.159415943  1.252114637
## [56] -0.364041061 -0.733858093 -0.734512470  0.918631853  0.481424873</code></pre>
<pre class="r"><code># Update data with a continuous covariate
D$age = D$value + rnorm_fixed(nrow(D), sd = 3)  # Correlated to value</code></pre>
<p>This is best visualized using colors for groups instead of x-position. The <span class="math inline">\(\beta\)</span>s are still the average <span class="math inline">\(y\)</span>-offset of the data points, only now we model each group using a slope instead of an intercept. In other words, the one-way ANOVA is sort of <a href="#t1">one-sample t-tests</a> model for each group (<span class="math inline">\(y = \beta_0\)</span>) while the <strong>one-way ANCOVA</strong> is sort of <a href="#correlation">Pearson correlation</a> model for each group (<span class="math inline">\(y_i = \beta_0 + \beta_i + \beta_1 \cdot age\)</span>):</p>
<pre class="r"><code># For linear model plot
D$pred = predict(lm(value ~ age + group, D))

# Plot
P_ancova = ggplot(D, aes(x=age, y=value, color=group, shape=group)) + 
  geom_line(aes(y=pred), lwd=2)

# Theme it
theme_axis(P_ancova, xlim=NULL, ylim=NULL, legend.position=c(0.8, 0.2)) + theme(axis.title=element_text())</code></pre>
<p><img src="../../../../2023/09/24/common-statistical-tests-are-linear-models-or-how-to-teach-stats/index_files/figure-html/unnamed-chunk-111-1.svg" width="576" style="display: block; margin: auto;" /></p>
<p>And now some R code to run the one-way ANCOVA as a linear model:</p>
<pre class="r"><code># Dedicated ANCOVA functions. The order of factors matter in pure-aov (type-I variance).
# Use type-II (default for car::Anova) or type-III (set type=3),
a = car::Anova(aov(value ~ group + age, D))
#a = aov(value ~ group + age, D)  # Predictor order matters. Not nice!

# As dummy-coded linear model.
full = lm(value ~ 1 + group_b + group_c + age, D)

# Testing main effect of age using Likelihood-ratio test
null_age = lm(value ~ 1 + group_b + group_c, D)  # Full without age. One-way ANOVA!
result_age = anova(null_age, full)

# Testing main effect of groupusing Likelihood-ratio test
null_group = lm(value ~ 1 + age, D)  # Full without group. Pearson correlation!
result_group = anova(null_group, full)</code></pre>
<p>Results:</p>
<pre class="r"><code>at = tidy(a)[1:2,]
at$rss = a$`Sum Sq`[3]
at$res.df = a$Df[3]
groupt = tidy(result_group)[2, ]
aget = tidy(result_age)[2,]

df = bind_rows(at, groupt, aget) %&gt;%
  mutate(
    model=rep(c(&#39;Anova&#39;, &#39;lm&#39;), each=2),
    term = c(&#39;group&#39;, &#39;age&#39;, &#39;group&#39;, &#39;age&#39;)
  ) %&gt;%
  rename(
    F = statistic,
    res.sumsq = rss
  ) %&gt;%
  select(term, model, F, df, p.value, sumsq, everything()) %&gt;%
  arrange(term)
print_df(df)</code></pre>
<div class="datatables html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-17" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-17">{"x":{"filter":"none","vertical":false,"data":[["age","age","group","group"],["Anova","lm","Anova","lm"],[1.2087,1.2087,4.8555,4.8555],[1,1,2,2],[0.2763,0.2763,0.0114,0.0114],[1.2043,1.2043,9.675599999999999,9.675599999999999],[55.7957,55.7957,55.7957,55.7957],[56,null,56,null],[null,56,null,56]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>term<\/th>\n      <th>model<\/th>\n      <th>F<\/th>\n      <th>df<\/th>\n      <th>p.value<\/th>\n      <th>sumsq<\/th>\n      <th>res.sumsq<\/th>\n      <th>res.df<\/th>\n      <th>df.residual<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"lengthChange":false,"ordering":false,"autoWidth":true,"bPaginate":false,"bInfo":false,"paging":false,"columnDefs":[{"className":"dt-right","targets":[2,3,4,5,6,7,8]}],"order":[],"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>a</code></pre>
<pre><code>## Anova Table (Type II tests)
## 
## Response: value
##           Sum Sq Df F value  Pr(&gt;F)  
## group      9.676  2  4.8555 0.01136 *
## age        1.204  1  1.2087 0.27628  
## Residuals 55.796 56                  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>result_age</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: value ~ 1 + group_b + group_c
## Model 2: value ~ 1 + group_b + group_c + age
##   Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)
## 1     57 57.000                           
## 2     56 55.796  1    1.2043 1.2087 0.2763</code></pre>
<pre class="r"><code>result_group</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: value ~ 1 + age
## Model 2: value ~ 1 + group_b + group_c + age
##   Res.Df    RSS Df Sum of Sq      F  Pr(&gt;F)  
## 1     58 65.471                              
## 2     56 55.796  2    9.6756 4.8555 0.01136 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Is there a well-known “non-parametric” ANCOVA? No, but now that we understand it as a mix of a <strong>Pearson correlation</strong> and <strong>t-tests</strong>, you can get creative and make one up. If we rank the <span class="math inline">\(y\)</span> and the <span class="math inline">\(x\)</span> we get a <strong>Spearman correlation</strong> (<span class="math inline">\(rank(y) ~ \beta_0 + rank(x)\)</span>) and at the same time the <strong>Wilcoxon</strong> ($rank(y) ~ 1):</p>
<p><span class="math display">\[rank(y) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_3 rank(age)\]</span></p>
<p>As I noted earlier, this does not match up perfectly with the true “non-parametric” model (if that exists), but it can be very close!</p>
<pre class="r"><code>full = lm(rank(value) ~ group + rank(age), D)
null = lm(rank(value) ~ rank(age), D)
anova(null, full)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: rank(value) ~ rank(age)
## Model 2: rank(value) ~ group + rank(age)
##   Res.Df   RSS Df Sum of Sq      F  Pr(&gt;F)  
## 1     58 17663                              
## 2     56 15164  2    2499.1 4.6146 0.01396 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>#sm::sm.ancova(x=D$age, y=D$value, group=D$group, display=&#39;none&#39;, model=&#39;equal&#39;)</code></pre>
</div>
</div>
<div id="proportions-chi-square-is-a-log-linear-model" class="section level1">
<h1>Proportions: Chi-square is a log-linear model</h1>
<p>Recall that when you take the logarithm, you can easily make statements about <em>proportions</em>, i.e., that for every increase in <span class="math inline">\(x\)</span>, <span class="math inline">\(y\)</span> increases a certain percentage. This turns out to be one of the simplest (and therefore best!) ways to make count data and contingency tables intelligible.</p>
<div id="goodness" class="section level2">
<h2>Goodness of fit</h2>
<div id="theory-as-log-linear-model" class="section level3">
<h3>Theory: As log-linear model</h3>
<p>Model: a single intercept predicts <span class="math inline">\(log(y)\)</span>.</p>
<p>I’ll refer you to take a look at <a href="#contingency">the section on contingency tables</a> which is basically a “two-way goodness of fit”.</p>
<p>Before log-transforming, this is a one-way ANOVA:</p>
<p><span class="math display">\[y = \beta_1*x_1 + \beta_2*x_2 + \beta_3*x_3 +... \qquad \mathcal{H}_0: y = \beta_1\]</span></p>
<p>We should think of these as proportions of <span class="math inline">\(sum(y)\)</span> for reasons that will be clearer in <a href="#contingency">the section on contingency tables</a>:</p>
<p><span class="math display">\[y = N\beta_1*x_1/N + N\beta_2*x_2/N + N\beta_3*x_3/N + ...\]</span></p>
<p>But we fit parameters on the log_transformed model (ignoring the proportion-notation for now):</p>
<p><span class="math display">\[log(y) = log(\beta_1*x_1 + \beta_2*x_2 + \beta_3*x_3 +...) \qquad \mathcal{H}_0: log(y) = log(\beta_1)\]</span></p>
<p><span class="math display">\[log(y) = log(N\beta_1*x_1/N + N)\]</span></p>
</div>
<div id="example-data-1" class="section level3">
<h3>Example data</h3>
<p>For this, we need some wide count data:</p>
<pre class="r"><code># Data in long format
D = data.frame(mood = c(&#39;happy&#39;, &#39;sad&#39;, &#39;meh&#39;),
               counts = c(60, 90, 70))

# Dummy coding for the linear model
D$mood_happy = ifelse(D$mood == &#39;happy&#39;, 1, 0)
D$mood_sad = ifelse(D$mood == &#39;sad&#39;, 1, 0)

print_df(D)</code></pre>
<div class="datatables html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-18" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-18">{"x":{"filter":"none","vertical":false,"data":[["happy","sad","meh"],[60,90,70],[1,0,0],[0,1,0]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>mood<\/th>\n      <th>counts<\/th>\n      <th>mood_happy<\/th>\n      <th>mood_sad<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"lengthChange":false,"ordering":false,"autoWidth":true,"bPaginate":false,"bInfo":false,"paging":false,"columnDefs":[{"className":"dt-right","targets":[1,2,3]}],"order":[],"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
</div>
<div id="r-code-goodness-of-fit" class="section level3">
<h3>R code: Goodness of fit</h3>
<p>Now let’s see that the Goodness of fit is just a log-linear equivalent to a one-way ANOVA. We set <code>family = poisson()</code> which defaults to setting a logarithmic <a href="https://en.wikipedia.org/wiki/Generalized_linear_model#Link_function">link function</a> (<code>family = poisson(link='log')</code>).</p>
<pre class="r"><code># Built-in test
a = chisq.test(D$counts)

# As log-linear model, comparing to an intercept-only model
full = glm(counts ~ 1 + mood_happy + mood_sad, data = D, family = poisson())
null = glm(counts ~ 1, data = D, family = poisson())
b = anova(null, full, test = &#39;Rao&#39;)

# Note: glm can also do the dummy coding for you:
c = glm(counts ~ mood, data = D, family = poisson())</code></pre>
<pre class="r"><code>a</code></pre>
<pre><code>## 
## 	Chi-squared test for given probabilities
## 
## data:  D$counts
## X-squared = 6.3636, df = 2, p-value = 0.04151</code></pre>
<pre class="r"><code>b</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: counts ~ 1
## Model 2: counts ~ 1 + mood_happy + mood_sad
##   Resid. Df Resid. Dev Df Deviance    Rao Pr(&gt;Chi)  
## 1         2     6.2697                              
## 2         0     0.0000  2   6.2697 6.3636  0.04151 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>c</code></pre>
<pre><code>## 
## Call:  glm(formula = counts ~ mood, family = poisson(), data = D)
## 
## Coefficients:
## (Intercept)      moodmeh      moodsad  
##      4.0943       0.1542       0.4055  
## 
## Degrees of Freedom: 2 Total (i.e. Null);  0 Residual
## Null Deviance:	    6.27 
## Residual Deviance: -2.22e-15 	AIC: 24.36</code></pre>
<pre class="r"><code>full</code></pre>
<pre><code>## 
## Call:  glm(formula = counts ~ 1 + mood_happy + mood_sad, family = poisson(), 
##     data = D)
## 
## Coefficients:
## (Intercept)   mood_happy     mood_sad  
##      4.2485      -0.1542       0.2513  
## 
## Degrees of Freedom: 2 Total (i.e. Null);  0 Residual
## Null Deviance:	    6.27 
## Residual Deviance: -1.066e-14 	AIC: 24.36</code></pre>
<pre class="r"><code>summary(full)</code></pre>
<pre><code>## 
## Call:
## glm(formula = counts ~ 1 + mood_happy + mood_sad, family = poisson(), 
##     data = D)
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)   4.2485     0.1195  35.545   &lt;2e-16 ***
## mood_happy   -0.1542     0.1759  -0.876    0.381    
## mood_sad      0.2513     0.1594   1.577    0.115    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance:  6.2697e+00  on 2  degrees of freedom
## Residual deviance: -1.0658e-14  on 0  degrees of freedom
## AIC: 24.363
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<pre class="r"><code>null</code></pre>
<pre><code>## 
## Call:  glm(formula = counts ~ 1, family = poisson(), data = D)
## 
## Coefficients:
## (Intercept)  
##       4.295  
## 
## Degrees of Freedom: 2 Total (i.e. Null);  2 Residual
## Null Deviance:	    6.27 
## Residual Deviance: 6.27 	AIC: 26.63</code></pre>
<pre class="r"><code>summary(null)</code></pre>
<pre><code>## 
## Call:
## glm(formula = counts ~ 1, family = poisson(), data = D)
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  4.29502    0.06742    63.7   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 6.2697  on 2  degrees of freedom
## Residual deviance: 6.2697  on 2  degrees of freedom
## AIC: 26.633
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<p>Let’s look at the results:</p>
<pre class="r"><code>df = data.frame(
  model = c(&#39;chisq.test&#39;, &#39;glm LRT&#39;),
  Chisq = c(a$statistic, b$Rao[2]),
  df = c(a$parameter, b$Df[2]),
  p.value = c(a$p.value, b$`Pr(&gt;Chi)`[2])
)
print_df(df)</code></pre>
<div class="datatables html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-19" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-19">{"x":{"filter":"none","vertical":false,"data":[["chisq.test","glm LRT"],[6.3636,6.3636],[2,2],[0.0415,0.0415]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>model<\/th>\n      <th>Chisq<\/th>\n      <th>df<\/th>\n      <th>p.value<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"lengthChange":false,"ordering":false,"autoWidth":true,"bPaginate":false,"bInfo":false,"paging":false,"columnDefs":[{"className":"dt-right","targets":[1,2,3]}],"order":[],"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>a</code></pre>
<pre><code>## 
## 	Chi-squared test for given probabilities
## 
## data:  D$counts
## X-squared = 6.3636, df = 2, p-value = 0.04151</code></pre>
<pre class="r"><code>b</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: counts ~ 1
## Model 2: counts ~ 1 + mood_happy + mood_sad
##   Resid. Df Resid. Dev Df Deviance    Rao Pr(&gt;Chi)  
## 1         2     6.2697                              
## 2         0     0.0000  2   6.2697 6.3636  0.04151 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Note the strange <code>anova(..., test='Rao')</code> which merely states that p-values should be computed using the (Rao) <a href="https://en.wikipedia.org/wiki/Score_test">score test</a>. We could also have jotted in <code>test='Chisq'</code> or <code>test='LRT'</code> which would have yielded approximate p-values. You may think that we’re cheating here, sneaking in some sort of Chi-Square model post-hoc. However, <code>anova</code> only specifies how p-values are calculated whereas all the log-linear modeling happened in <code>glm</code>.</p>
<p>By the way, if there are only two counts and a large sample size (N &gt; 100), this model begins to approximate the <strong>binomial test</strong>, <code>binom.test</code>, to a reasonable degree. But this sample size is larger than most use cases, so I won’t raise to a rule-of-thumb and won’t dig deeper into it here.</p>
</div>
</div>
<div id="contingency" class="section level2">
<h2>Contingency tables</h2>
<div id="theory-as-log-linear-model-1" class="section level3">
<h3>Theory: As log-linear model</h3>
<p>The theory here will be a bit more convoluted, and I mainly write it up so that you can get the <em>feeling</em> that it really is just a log-linear <a href="#anova2">two-way ANOVA model</a>. Let’s get started…</p>
<p>For a two-way contingency table, the model of the count variable <span class="math inline">\(y\)</span> is a modeled using the marginal proportions of a contingency table. Why this makes sense, is too involved to go into here, but <a href="https://www.uni-tuebingen.de/fileadmin/Uni_Tuebingen/SFB/SFB_833/A_Bereich/A1/Christoph_Scheepers_-_Statistikworkshop.pdf">see the relevant slides by Christoph Scheepers here</a> for an excellent exposition. The model is composed of a lot of counts and the regression coefficients <span class="math inline">\(A_i\)</span> and <span class="math inline">\(B_i\)</span>:</p>
<p><span class="math display">\[y_i = N \cdot x_i(A_i/N) \cdot z_j(B_j/N) \cdot x_{ij}/((A_i x_i)/(B_j z_j)/N)\]</span></p>
<p>What a mess!!! Here, <span class="math inline">\(i\)</span> is the row index, <span class="math inline">\(j\)</span> is the column index, <span class="math inline">\(x_{something}\)</span> is the sum of that row and/or column, <span class="math inline">\(N = sum(y)\)</span>. Remember that <span class="math inline">\(y\)</span> is a count variable, so <span class="math inline">\(N\)</span> is just the total count.</p>
<p>We can simplify the notation by defining the <em>proportions</em>: <span class="math inline">\(\alpha_i = x_i(A_i/N)\)</span>, <span class="math inline">\(\beta_i = x_j(B_i/N)\)</span> and <span class="math inline">\(\alpha_i\beta_j = x_{ij}/(A_i x_i)/(B_j z_j)/N\)</span>. Let’s write the model again:</p>
<p><span class="math display">\[y_i = N \cdot \alpha_i \cdot \beta_j \cdot \alpha_i\beta_j\]</span></p>
<p>Ah, much prettier. However, there is still lot’s of multiplication which makes it hard to get an intuition about how the actual numbers interact. We can make it much more intelligible when we remember that <span class="math inline">\(log(A \cdot B) = log(A) + log(B)\)</span>. Doing logarithms on both sides, we get:</p>
<p><span class="math display">\[log(y_i) = log(N) + log(\alpha_i) + log(\beta_j) + log(\alpha_i\beta_j)\]</span></p>
<p>Snuggly! Now we can get a better grasp on how the regression coefficients (which are proportions) independently contribute to <span class="math inline">\(y\)</span>. This is why logarithms are so nice for proportions. Note that this is just <a href="#anova2">the two-way ANOVA model</a> with some logarithms added, so we are back to our good old linear models - only the interpretation of the regression coefficients have changed! And we cannot use <code>lm</code> anymore in R.</p>
</div>
<div id="example-data-2" class="section level3">
<h3>Example data</h3>
<p>Here we need some long data and we need it in table format for <code>chisq.test</code>:</p>
<pre class="r"><code># Contingency data in long format for linear model
D = data.frame(
  mood = c(&#39;happy&#39;, &#39;happy&#39;, &#39;meh&#39;, &#39;meh&#39;, &#39;sad&#39;, &#39;sad&#39;),
  sex = c(&#39;male&#39;, &#39;female&#39;, &#39;male&#39;, &#39;female&#39;, &#39;male&#39;, &#39;female&#39;),
  Freq = c(100, 70, 30, 32, 110, 120)
)

# ... and as table for chisq.test
D_table = D %&gt;%
  spread(key = mood, value = Freq) %&gt;%  # Mood to columns
  select(-sex) %&gt;%  # Remove sex column
  as.matrix()

# Dummy coding of D for linear model (skipping mood==&quot;sad&quot; and gender==&quot;female&quot;)
# We could also use model.matrix(D$Freq~D$mood*D$sex)
D$mood_happy = ifelse(D$mood == &#39;happy&#39;, 1, 0)
D$mood_meh = ifelse(D$mood == &#39;meh&#39;, 1, 0)
D$sex_male = ifelse(D$sex == &#39;male&#39;, 1, 0)</code></pre>
<pre class="r"><code>print_df(D)</code></pre>
<div class="datatables html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-20" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-20">{"x":{"filter":"none","vertical":false,"data":[["happy","happy","meh","meh","sad","sad"],["male","female","male","female","male","female"],[100,70,30,32,110,120],[1,1,0,0,0,0],[0,0,1,1,0,0],[1,0,1,0,1,0]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>mood<\/th>\n      <th>sex<\/th>\n      <th>Freq<\/th>\n      <th>mood_happy<\/th>\n      <th>mood_meh<\/th>\n      <th>sex_male<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"lengthChange":false,"ordering":false,"autoWidth":true,"bPaginate":false,"bInfo":false,"paging":false,"columnDefs":[{"className":"dt-right","targets":[2,3,4,5]}],"order":[],"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
</div>
<div id="r-code-chi-square-test" class="section level3">
<h3>R code: Chi-square test</h3>
<p>Now let’s show the equivalence between a chi-square model and a log-linear model. This is very similar to our <a href="#anova2">two-way ANOVA</a> above:</p>
<pre class="r"><code># Built-in chi-square. It requires matrix format.
a = chisq.test(D_table)

# Using glm to do a log-linear model, we get identical results when testing the interaction term:
full = glm(Freq ~ 1 + mood_happy + mood_meh + sex_male + mood_happy*sex_male + mood_meh*sex_male, data = D, family = poisson())
null = glm(Freq ~ 1 + mood_happy + mood_meh + sex_male, data = D, family = poisson())
b = anova(null, full, test = &#39;Rao&#39;)  # Could also use test=&#39;LRT&#39; or test=&#39;Chisq&#39;

# Note: let glm do the dummy coding for you
full = glm(Freq ~ mood * sex, family = poisson(), data = D)
c = anova(full, test = &#39;Rao&#39;)

# Note: even simpler syntax using MASS:loglm (&quot;log-linear model&quot;)
d = MASS::loglm(Freq ~ mood + sex, D)</code></pre>
<pre class="r"><code>df = data.frame(
  model = c(&#39;chisq.test&#39;, &#39;glm&#39;, &#39;loglm&#39;),
  Chisq = c(a$statistic, b$Rao[2], d$pearson),
  df = c(a$parameter, b$Df[2], d$df),
  p.value = c(a$p.value, b$`Pr(&gt;Chi)`[2], summary(d)$tests[2, 3])
)
print_df(df)</code></pre>
<div class="datatables html-widget html-fill-item-overflow-hidden html-fill-item" id="htmlwidget-21" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-21">{"x":{"filter":"none","vertical":false,"data":[["chisq.test","glm","loglm"],[5.0999,5.0999,5.0999],[2,2,2],[0.0781,0.0781,0.0781]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>model<\/th>\n      <th>Chisq<\/th>\n      <th>df<\/th>\n      <th>p.value<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"searching":false,"lengthChange":false,"ordering":false,"autoWidth":true,"bPaginate":false,"bInfo":false,"paging":false,"columnDefs":[{"className":"dt-right","targets":[1,2,3]}],"order":[],"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
<pre class="r"><code>a</code></pre>
<pre><code>## 
## 	Pearson&#39;s Chi-squared test
## 
## data:  D_table
## X-squared = 5.0999, df = 2, p-value = 0.07809</code></pre>
<pre class="r"><code>b</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: Freq ~ 1 + mood_happy + mood_meh + sex_male
## Model 2: Freq ~ 1 + mood_happy + mood_meh + sex_male + mood_happy * sex_male + 
##     mood_meh * sex_male
##   Resid. Df Resid. Dev Df Deviance    Rao Pr(&gt;Chi)  
## 1         2     5.1199                              
## 2         0     0.0000  2   5.1199 5.0999  0.07809 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>c</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model: poisson, link: log
## 
## Response: Freq
## 
## Terms added sequentially (first to last)
## 
## 
##          Df Deviance Resid. Df Resid. Dev    Rao Pr(&gt;Chi)    
## NULL                         5    111.130                    
## mood      2  105.308         3      5.821 94.132  &lt; 2e-16 ***
## sex       1    0.701         2      5.120  0.701  0.40235    
## mood:sex  2    5.120         0      0.000  5.100  0.07809 .  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>d</code></pre>
<pre><code>## Call:
## MASS::loglm(formula = Freq ~ mood + sex, data = D)
## 
## Statistics:
##                       X^2 df   P(&gt; X^2)
## Likelihood Ratio 5.119915  2 0.07730804
## Pearson          5.099859  2 0.07808717</code></pre>
<pre class="r"><code>summary(full)</code></pre>
<pre><code>## 
## Call:
## glm(formula = Freq ~ mood * sex, family = poisson(), data = D)
## 
## Coefficients:
##                 Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)       4.2485     0.1195  35.545  &lt; 2e-16 ***
## moodmeh          -0.7828     0.2134  -3.668 0.000244 ***
## moodsad           0.5390     0.1504   3.584 0.000339 ***
## sexmale           0.3567     0.1558   2.289 0.022094 *  
## moodmeh:sexmale  -0.4212     0.2981  -1.413 0.157670    
## moodsad:sexmale  -0.4437     0.2042  -2.172 0.029819 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 1.1113e+02  on 5  degrees of freedom
## Residual deviance: 3.9968e-15  on 0  degrees of freedom
## AIC: 48.254
## 
## Number of Fisher Scoring iterations: 3</code></pre>
<pre class="r"><code>pchisq(5.0999, df = 2, lower.tail = FALSE)</code></pre>
<pre><code>## [1] 0.07808557</code></pre>
<p>If you unfold the raw R output, I’ve included <code>summary(full)</code> so that you can see the raw regression coefficients. Being a log-linear model, these are the <em>percentage increase</em>in <span class="math inline">\(y\)</span> over and above the intercept if that category obtains.</p>
</div>
</div>
</div>
<div id="links" class="section level1">
<h1>Sources and further equivalences</h1>
<p>Here are links to other sources who have exposed bits and pieces of this puzzle, including many further equivalences not covered here:</p>
<ul>
<li><a href="https://stats.stackexchange.com/questions/303269/common-statistical-tests-as-linear-models">My original exposition of the idea</a> at Cross Validated</li>
<li><a href="https://stats.stackexchange.com/questions/210529/are-parametric-tests-on-rank-transformed-data-equivalent-to-non-parametric-test?noredirect=1#comment399981_210529">An earlier question by me</a> about non-parametric tests and a helpful answer.</li>
<li><a href="https://stats.stackexchange.com/questions/59047/how-are-regression-the-t-test-and-the-anova-all-versions-of-the-general-linear">This question and replies</a> on t-tests and ANOVA at StackOverflow</li>
<li><a href="https://www.uni-tuebingen.de/fileadmin/Uni_Tuebingen/SFB/SFB_833/A_Bereich/A1/Christoph_Scheepers_-_Statistikworkshop.pdf">These slides by Christoph Scheepers</a> on Chi-Square as log-linear models.</li>
<li><a href="https://rpubs.com/palday/glm-test">This notebook by Philip M. Alday</a> on Chi-square, binomial, multinomial, and poisson tests as log-linear and logistic models. These “equivalences” are less exact than what I presented above, and were therefore not included here. They are still great for a conceptual understanding of these tests, though!</li>
<li><a href="https://rpsychologist.com/r-guide-longitudinal-lme-lmer">This article by Kristoffer Magnusson</a> on RM-ANOVA and growth models using <code>lme4::lmer</code> mixed models.</li>
<li><a href="https://seriousstats.wordpress.com/2012/02/14/friedman/">This post by Thom Baguley</a> on the Friedman test. That post was actually the one that inititated my exploration of linear equivalences to “non-parametric”” tests which ultimately pushed me over the edge to write up the present article.</li>
</ul>
<ol style="list-style-type: decimal">
<li><p><strong>Fundamentals of regression:</strong></p>
<ol style="list-style-type: decimal">
<li><p>Recall from high-school: <span class="math inline">\(y = a \cdot x + b\)</span>, and getting a really good intuition about slopes and intercepts. Understanding that this can be written using all variable names, e.g., <code>money = profit * time + starting_money</code> or <span class="math inline">\(y = \beta_1x + \beta_2*1\)</span> or, suppressing the coefficients, as <code>y ~ x + 1</code>. If the audience is receptive, convey the idea of these models <a href="https://magesblog.com/post/modelling-change">as a solution to differential equations</a>, specifying how <span class="math inline">\(y\)</span> <em>changes</em> with <span class="math inline">\(x\)</span>.</p></li>
<li><p>Extend to a few multiple regression as models. Make sure to include plenty of real-life examples and exercises at this point to make all of this really intuitive. Marvel at how briefly these models allow us to represent large datasets.</p></li>
<li><p>Introduce the idea of rank-transforming non-metric data and try it out.</p></li>
<li><p>Teach the three assumptions: independence of data points, normality of residuals, and homoscedasticity.</p></li>
<li><p>Confidence/credible intervals on the parameters. Stress that the Maximum-Likelihood estimate is extremely unlikely, so intervals are more important.</p></li>
<li><p>Briefly introduce <span class="math inline">\(R^2\)</span> for the simple regression models above. Mention in passing that this is called <a href="#correlation">the Pearson and Spearman correlation coefficients</a>.</p></li>
</ol></li>
<li><p><strong>Special case #1: One or two means (t-tests, Wilcoxon, Mann-Whitney):</strong></p>
<ol style="list-style-type: decimal">
<li><p><strong>One mean:</strong> When there is only one x-value, the regression model simplifies to <span class="math inline">\(y = b\)</span>. If <span class="math inline">\(y\)</span> is non-metric, you can rank-transform it. Apply the assumptions (homoscedasticity doesn’t apply since there is only one <span class="math inline">\(x\)</span>). Mention in passing that these intercept-only models are called <a href="#t1">one-sample t-test and Wilcoxon Signed Rank test respectively</a>.</p></li>
<li><p><strong>Two means:</strong> If we put two variables 1 apart on the x-axis, the difference between the means is the slope. Great! It is accessible to our swizz army knife called linear modeling. Apply the assumption checks to see that homoscedasticity reduces to equal variance between groups. This is called an <a href="#t2">independent t-test</a>. Do a few worked examples and exercises, maybe adding Welch’s test, and do the rank-transformed version, called Mann-Whitney U.</p></li>
<li><p><em>Paired samples:</em> Violates the independence assumption. After computing pairwise differences, this is equivalent to 2.1 (one intercept), though it is called the <a href="#tpair">paired t-test and Wilcoxon’s matched pairs</a>.</p></li>
</ol></li>
<li><p><strong>Special case #2: Three or more means (ANOVAs)</strong></p>
<ol style="list-style-type: decimal">
<li><p><em><a href="#dummy">Dummy coding</a> of categories:</em> How one regression coefficient for each level of a factor models an intercept for each level when multiplied by a binary indicator. This is just extending what we did in 2.1. to make this data accessible to linear modeling.</p></li>
<li><p><em>Means of one variable:</em> <a href="#anova1">One-way ANOVA</a>.</p></li>
<li><p><em>Means of two variables:</em> <a href="#anova2">Two-way ANOVA</a>.</p></li>
</ol></li>
<li><p><strong>Special case #3: Three or more proportions (Chi-Square)</strong></p>
<ol style="list-style-type: decimal">
<li><p><em>Logarithmic transformation:</em> Making multiplicative models linear using logarithms, thus modeling proportions. See <a href="https://www.uni-tuebingen.de/fileadmin/Uni_Tuebingen/SFB/SFB_833/A_Bereich/A1/Christoph_Scheepers_-_Statistikworkshop.pdf">this excellent introduction</a> to the equivalence of log-linear models and Chi-Square tests as models of proportions. Also needs to introduce (log-)odds ratios. When the multiplicative model is made summative using logarithms, we just add the dummy-coding trick from 3.1, and see that the models are identical to the ANOVA models in 3.2 and 3.3, only the interpretation of the coefficients have changed.</p></li>
<li><p><em>Proportions of one variable:</em> <a href="#goodness">Goodness of fit</a>.</p></li>
<li><p><em>Proportions of two variables:</em> <a href="#contingency">Contingency tables</a>.</p></li>
</ol></li>
<li><p><strong>Hypothesis testing:</strong></p>
<ol style="list-style-type: decimal">
<li><p><em>Hypothesis testing as model comparisons:</em> Hypothesis testing is the act of choosing between a full model and one where a parameter is fixed to a particular value (often zero, i.e., effectively excluded from the model) instead of being estimated. For example, when fixing one of the two means to zero in the <a href="#t2">t-test</a>, we study how well a single mean (a <a href="#t1">one-sample t-test</a>) explains all the data from both groups. If it does a good job, we prefer this model over the two-mean model because it is simpler. So hypothesis testing is just comparing linear models to make more qualitative statements than the truly quantitative statements which were covered in bullets 1-4 above. As tests of single parameters, hypothesis testing is therefore less informative However, when testing multiple parameters at the same time (e.g., a factor in ANOVA), model comparison becomes invaluable.</p></li>
<li><p><em>Likelihood ratios:</em> Likelihood ratios are the swizz army knife which will do model comparison all the way from the one-sample t-test to GLMMs. BIC penalizes model complexity. Moreover, add priors and you’ve got Bayes Factors. One tool, and you’re done. I’ve used LRTs in the ANOVAs above.</p></li>
</ol></li>
</ol>
<pre class="r"><code># Plot style for icons in table
theme_icon = function(P, jitter=FALSE, xlim=c(-0.5, 2), ylim=c(-0.5, 2)) {
  P = P + theme_bw(15) + 
  coord_cartesian(xlim=xlim, ylim=ylim) +
  theme(axis.title = element_blank(), 
        axis.text = element_blank(),
        axis.ticks = element_blank(),
        title = element_blank(),
        text = element_blank(),
        panel.border = element_blank(),
        panel.grid = element_blank(),
        legend.position = &#39;none&#39;,
        legend.key=element_blank())
  
    # Return jittered or non-jittered plot?
  if(jitter) {
    P + geom_jitter(width=0.1, size=2)
  }
  else {
    P + geom_point(size=2)
  }
}

P_t1_icon = ggplot(D_t1, aes(y=y, x=0)) + 
  stat_summary(fun.y=mean, geom = &quot;errorbar&quot;, color=&#39;blue&#39;, aes(ymax = ..y.., ymin = ..y..), lwd=2)

theme_icon(P_t1_icon, jitter=TRUE)</code></pre>
<p><img src="../../../../2023/09/24/common-statistical-tests-are-linear-models-or-how-to-teach-stats/index_files/figure-html/unnamed-chunk-128-1.svg" width="192" style="display: block; margin: auto;" /></p>
<pre class="r"><code>theme_icon(P_pearson)</code></pre>
<p><img src="../../../../2023/09/24/common-statistical-tests-are-linear-models-or-how-to-teach-stats/index_files/figure-html/unnamed-chunk-128-2.svg" width="192" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#theme_icon(P_t1)
theme_icon(P_tpaired)</code></pre>
<p><img src="../../../../2023/09/24/common-statistical-tests-are-linear-models-or-how-to-teach-stats/index_files/figure-html/unnamed-chunk-128-3.svg" width="192" style="display: block; margin: auto;" /></p>
<pre class="r"><code>theme_icon(P_t2, jitter=TRUE)</code></pre>
<p><img src="../../../../2023/09/24/common-statistical-tests-are-linear-models-or-how-to-teach-stats/index_files/figure-html/unnamed-chunk-128-4.svg" width="192" style="display: block; margin: auto;" /></p>
<pre class="r"><code>theme_icon(P_anova1, xlim=c(-0.5, 4), jitter=TRUE)</code></pre>
<p><img src="../../../../2023/09/24/common-statistical-tests-are-linear-models-or-how-to-teach-stats/index_files/figure-html/unnamed-chunk-128-5.svg" width="192" style="display: block; margin: auto;" /></p>
<pre class="r"><code>theme_icon(P_ancova, xlim=NULL, ylim=NULL)</code></pre>
<p><img src="../../../../2023/09/24/common-statistical-tests-are-linear-models-or-how-to-teach-stats/index_files/figure-html/unnamed-chunk-128-6.svg" width="192" style="display: block; margin: auto;" /></p>
</div>
<div id="explicit-glmm-equivalents-for-standard-tests" class="section level1">
<h1>Explicit GLM(M) Equivalents for Standard Tests</h1>
<p><a href="https://rpubs.com/palday/glm-test">https://rpubs.com/palday/glm-test</a></p>
<ul>
<li>the relationship between ANOVA and the t-test</li>
<li>the relationship betweenthe t-test and simple linear regression<br />
</li>
<li>repeated-measures ANOVA is just a special case of the mixed model with certain assumptions about the random effects (sphericity and only one variance component).</li>
</ul>
<p>For the other models and tests, it makes sense to start with the fixed-effects (i.e. not mixed) models until we’re used to dealing with them. The mixed-effects models are a relatively straightforward extension, so we’ll just leave them alone for now. A lot of the frequenstist examples here were inspired by Bayesian examples from Rasmus Bååth and his Bayesian First Aid package. It’s good work, but I would prefer estimation to testing, so I have mixed feelings about displaying the models as tests.</p>
<p>Beyond the “estimating is better than testing” perspective and the difficulties of finding repeated-measures equivalents for a lot of these tests, there is anohter advantage: the explicit GLM-based modeling strategy allows for continuous predictors, while many classical tests do not.</p>
<p>For a lot of the examples today, we’ll be using the survey data from the MASS package.</p>
<pre class="r"><code>library(MASS)
library(car)
# use ANOVA-style contrasts
options(contrasts=c(&quot;contr.Sum&quot;, &quot;contr.poly&quot;))
library(tidyverse)</code></pre>
<p><span class="math inline">\(\chi^2\)</span>-Test : Poisson Model</p>
<p>Classical Test: <span class="math inline">\(\chi^2\)</span>-Test of Independence</p>
<pre class="r"><code>smoke_exercise &lt;- table(Smoke=survey$Smoke, Exer=survey$Exer)
smoke_exercise</code></pre>
<pre><code>##        Exer
## Smoke   Freq None Some
##   Heavy    7    1    3
##   Never   87   18   84
##   Occas   12    3    4
##   Regul    9    1    7</code></pre>
<pre class="r"><code>smoke_exercise.chisq &lt;- chisq.test(smoke_exercise, correct=FALSE)
print(smoke_exercise.chisq)</code></pre>
<pre><code>## 
## 	Pearson&#39;s Chi-squared test
## 
## data:  smoke_exercise
## X-squared = 5.4885, df = 6, p-value = 0.4828</code></pre>
<p>the <span class="math inline">\(\chi^2\)</span> is the sum of squared residuals:</p>
<pre class="r"><code>sum(smoke_exercise.chisq$residuals^2)</code></pre>
<pre><code>## [1] 5.488546</code></pre>
<p>We are unable to reject the null hypothesis. But that doesn’t tell us much. The chisq.test actually gives a lot more information than most people realize.</p>
<p>The observed data:</p>
<pre class="r"><code>smoke_exercise.chisq$observed</code></pre>
<pre><code>##        Exer
## Smoke   Freq None Some
##   Heavy    7    1    3
##   Never   87   18   84
##   Occas   12    3    4
##   Regul    9    1    7</code></pre>
<p>The expected results based on the null model:</p>
<p><span class="math display">\[expected_{i.j}=\frac{rowsum_i}{N}\frac{colsum_j}{N}*N\]</span></p>
<pre class="r"><code>sum(smoke_exercise.chisq$observed)</code></pre>
<pre><code>## [1] 236</code></pre>
<pre class="r"><code>sum(smoke_exercise.chisq$observed[1,])</code></pre>
<pre><code>## [1] 11</code></pre>
<pre class="r"><code>sum(smoke_exercise.chisq$observed[,1])</code></pre>
<pre><code>## [1] 115</code></pre>
<pre class="r"><code>(sum(smoke_exercise.chisq$observed[1,])/sum(smoke_exercise.chisq$observed))*(sum(smoke_exercise.chisq$observed[,1])/sum(smoke_exercise.chisq$observed)*sum(smoke_exercise.chisq$observed))</code></pre>
<pre><code>## [1] 5.360169</code></pre>
<pre class="r"><code>smoke_exercise.chisq$expected</code></pre>
<pre><code>##        Exer
## Smoke        Freq      None      Some
##   Heavy  5.360169  1.072034  4.567797
##   Never 92.097458 18.419492 78.483051
##   Occas  9.258475  1.851695  7.889831
##   Regul  8.283898  1.656780  7.059322</code></pre>
<p>And the Pearson residuals ( (observed - expected) / sqrt(expected) )</p>
<pre class="r"><code>expected &lt;- (sum(smoke_exercise.chisq$observed[1,])/sum(smoke_exercise.chisq$observed))*(sum(smoke_exercise.chisq$observed[,1])/sum(smoke_exercise.chisq$observed)*sum(smoke_exercise.chisq$observed))
observed &lt;- smoke_exercise.chisq$observed[1,1]
(observed - expected) / sqrt(expected)</code></pre>
<pre><code>## [1] 0.7082877</code></pre>
<pre class="r"><code>smoke_exercise.chisq$residuals</code></pre>
<pre><code>##        Exer
## Smoke          Freq        None        Some
##   Heavy  0.70828770 -0.06957171 -0.73356118
##   Never -0.53116543 -0.09774271  0.62274614
##   Occas  0.90099537  0.84386422 -1.38483121
##   Regul  0.24880398 -0.51025506 -0.02232721</code></pre>
<pre class="r"><code>smoke_exercise.chisq$observed - smoke_exercise.chisq$expected</code></pre>
<pre><code>##        Exer
## Smoke          Freq        None        Some
##   Heavy  1.63983051 -0.07203390 -1.56779661
##   Never -5.09745763 -0.41949153  5.51694915
##   Occas  2.74152542  1.14830508 -3.88983051
##   Regul  0.71610169 -0.65677966 -0.05932203</code></pre>
<p>Looking at the differences and the standardized residuals (which are somewhat analogous to z
-scores), it’s no surprise that we can’t reject the null hypothesis.</p>
<div id="explicit-glm-test-poisson" class="section level2">
<h2>Explicit GLM Test: Poisson</h2>
<p>But I’ve always found the <span class="math inline">\(\chi^2\)</span>-test confusing for anything but the simplest designs – a significant result suggest that there’s a difference somewhere, but where? I find it much easier to reason in terms of which things actually make a difference and what that difference looks like. We can do that by using the GLM explicitly.</p>
<p>The Poisson distribution is often used for modelling count data. There are some issues with Poisson models for data with too many zeros (so-called Zero-Inflated Poissons or ZIP) or for data where the variance is too (overdispersion), but we’ll leave those issues alone for today.</p>
<p>The basic Poisson model for our data is easy to compute, but first we need to get our data in the right format:</p>
<pre class="r"><code>smoke_exercise</code></pre>
<pre><code>##        Exer
## Smoke   Freq None Some
##   Heavy    7    1    3
##   Never   87   18   84
##   Occas   12    3    4
##   Regul    9    1    7</code></pre>
<pre class="r"><code>dat &lt;- as.data.frame(smoke_exercise)
dat</code></pre>
<pre><code>##    Smoke Exer Freq
## 1  Heavy Freq    7
## 2  Never Freq   87
## 3  Occas Freq   12
## 4  Regul Freq    9
## 5  Heavy None    1
## 6  Never None   18
## 7  Occas None    3
## 8  Regul None    1
## 9  Heavy Some    3
## 10 Never Some   84
## 11 Occas Some    4
## 12 Regul Some    7</code></pre>
<pre class="r"><code>dat[dat$Smoke == &#39;Heavy&#39;,]</code></pre>
<pre><code>##   Smoke Exer Freq
## 1 Heavy Freq    7
## 5 Heavy None    1
## 9 Heavy Some    3</code></pre>
<p>Note that the the <span class="math inline">\(Freq\)</span> column refers to the number of “matches” for a particular combination of smoker type Smoke and excercise regularity <span class="math inline">\(Exer\)</span> and is not to be confused with the entry <span class="math inline">\(Freq\)</span> in the <span class="math inline">\(Exer\)</span> column, which refers to frequent exercise.</p>
<p>The model itself is for predicting how often we observe a particular combination of <span class="math inline">\(Smoke\)</span> and <span class="math inline">\(Exer\)</span>, so they form our predictors and <span class="math inline">\(Freq\)</span> forms our prediction. We use the “over-parameterized” version of the model without an intercept so that each category is explicit and no category is “hidden” in the intercept.</p>
<pre class="r"><code>smoke_exercise.glm &lt;- glm(Freq ~ 0 + Smoke * Exer, data=dat, family=poisson())
summary(smoke_exercise.glm)</code></pre>
<pre><code>## 
## Call:
## glm(formula = Freq ~ 0 + Smoke * Exer, family = poisson(), data = dat)
## 
## Coefficients:
##                             Estimate Std. Error z value Pr(&gt;|z|)    
## SmokeHeavy                   1.01484    0.40499   2.506 0.012217 *  
## SmokeNever                   3.92903    0.09366  41.949  &lt; 2e-16 ***
## SmokeOccas                   1.65660    0.27217   6.087 1.15e-09 ***
## SmokeRegul                   1.38104    0.37327   3.700 0.000216 ***
## Exer[S.Freq]                 0.77811    0.17721   4.391 1.13e-05 ***
## Exer[S.None]                -0.99813    0.27186  -3.672 0.000241 ***
## Smoke[S.Heavy]:Exer[S.Freq]  0.15296    0.37044   0.413 0.679662    
## Smoke[S.Never]:Exer[S.Freq] -0.24123    0.19418  -1.242 0.214124    
## Smoke[S.Occas]:Exer[S.Freq]  0.05020    0.28693   0.175 0.861128    
## Smoke[S.Heavy]:Exer[S.None] -0.01671    0.56796  -0.029 0.976534    
## Smoke[S.Never]:Exer[S.None] -0.04053    0.29589  -0.137 0.891060    
## Smoke[S.Occas]:Exer[S.None]  0.44014    0.40804   1.079 0.280735    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 1.3554e+03  on 12  degrees of freedom
## Residual deviance: 8.8818e-15  on  0  degrees of freedom
## AIC: 70.569
## 
## Number of Fisher Scoring iterations: 3</code></pre>
<p>We also compute a null model. The relevant null here is “no interaction” (it is after all the <span class="math inline">\(\chi^2\)</span>
test for independence, i.e. not-interacting).</p>
<pre class="r"><code>summary(smoke_exercise.glm)$coefficients</code></pre>
<pre><code>##                                Estimate Std. Error     z value     Pr(&gt;|z|)
## SmokeHeavy                   1.01484081 0.40499393  2.50581733 1.221687e-02
## SmokeNever                   3.92903223 0.09366285 41.94867120 0.000000e+00
## SmokeOccas                   1.65660443 0.27216552  6.08675362 1.152231e-09
## SmokeRegul                   1.38104491 0.37326764  3.69987848 2.157027e-04
## Exer[S.Freq]                 0.77810678 0.17721119  4.39084450 1.129113e-05
## Exer[S.None]                -0.99813458 0.27185537 -3.67156476 2.410700e-04
## Smoke[S.Heavy]:Exer[S.Freq]  0.15296256 0.37043673  0.41292492 6.796616e-01
## Smoke[S.Never]:Exer[S.Freq] -0.24123089 0.19418002 -1.24230540 2.141239e-01
## Smoke[S.Occas]:Exer[S.Freq]  0.05019544 0.28693157  0.17493870 8.611278e-01
## Smoke[S.Heavy]:Exer[S.None] -0.01670623 0.56796165 -0.02941436 9.765341e-01
## Smoke[S.Never]:Exer[S.None] -0.04052588 0.29589012 -0.13696261 8.910603e-01
## Smoke[S.Occas]:Exer[S.None]  0.44014244 0.40804157  1.07867059 2.807346e-01</code></pre>
<pre class="r"><code>summary(smoke_exercise.glm)$coefficients[1,3]</code></pre>
<pre><code>## [1] 2.505817</code></pre>
<pre class="r"><code>2*pnorm(summary(smoke_exercise.glm)$coefficients[1,3], lower.tail = FALSE)</code></pre>
<pre><code>## [1] 0.01221687</code></pre>
<pre class="r"><code>smoke_exercise.null &lt;- glm(Freq ~ 0 + Smoke + Exer, data=dat, family=poisson)
summary(smoke_exercise.null)</code></pre>
<pre><code>## 
## Call:
## glm(formula = Freq ~ 0 + Smoke + Exer, family = poisson, data = dat)
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## SmokeHeavy    1.08919    0.30595   3.560 0.000371 ***
## SmokeNever    3.93305    0.08936  44.015  &lt; 2e-16 ***
## SmokeOccas    1.63574    0.23521   6.954 3.54e-12 ***
## SmokeRegul    1.52451    0.24803   6.147 7.92e-10 ***
## Exer[S.Freq]  0.58980    0.09914   5.949 2.70e-09 ***
## Exer[S.None] -1.01964    0.14637  -6.966 3.25e-12 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 1355.4456  on 12  degrees of freedom
## Residual deviance:    5.8015  on  6  degrees of freedom
## AIC: 64.37
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<pre class="r"><code>coef(smoke_exercise.null)</code></pre>
<pre><code>##   SmokeHeavy   SmokeNever   SmokeOccas   SmokeRegul Exer[S.Freq] Exer[S.None] 
##    1.0891947    3.9330465    1.6357384    1.5245128    0.5898009   -1.0196371</code></pre>
<pre class="r"><code>exp(coef(smoke_exercise.null))</code></pre>
<pre><code>##   SmokeHeavy   SmokeNever   SmokeOccas   SmokeRegul Exer[S.Freq] Exer[S.None] 
##    2.9718800   51.0623015    5.1332472    4.5929054    1.8036292    0.3607258</code></pre>
<pre class="r"><code>exp(coef(smoke_exercise.null))/(exp(coef(smoke_exercise.null))+1)</code></pre>
<pre><code>##   SmokeHeavy   SmokeNever   SmokeOccas   SmokeRegul Exer[S.Freq] Exer[S.None] 
##    0.7482301    0.9807922    0.8369542    0.8212021    0.6433195    0.2650981</code></pre>
<pre class="r"><code>smoke_exercise.null2 &lt;- glm(Freq ~ 0 + Smoke + Exer, data=dat, family=gaussian)
summary(smoke_exercise.null2)</code></pre>
<pre><code>## 
## Call:
## glm(formula = Freq ~ 0 + Smoke + Exer, family = gaussian, data = dat)
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## SmokeHeavy      3.667     10.397   0.353 0.736402    
## SmokeNever     63.000     10.397   6.059 0.000916 ***
## SmokeOccas      6.333     10.397   0.609 0.564769    
## SmokeRegul      5.667     10.397   0.545 0.605392    
## Exer[S.Freq]    9.083      7.352   1.236 0.262822    
## Exer[S.None]  -13.917      7.352  -1.893 0.107216    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for gaussian family taken to be 324.3056)
## 
##     Null deviance: 15308.0  on 12  degrees of freedom
## Residual deviance:  1945.8  on  6  degrees of freedom
## AIC: 109.12
## 
## Number of Fisher Scoring iterations: 2</code></pre>
<p>The <span class="math inline">\(\chi^2\)</span> for independence is then equal to the likelihood test for whether the interaction model fits the data better than the null model:</p>
<pre class="r"><code>anova(smoke_exercise.null, smoke_exercise.glm, test=&quot;LRT&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: Freq ~ 0 + Smoke + Exer
## Model 2: Freq ~ 0 + Smoke * Exer
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)
## 1         6     5.8015                     
## 2         0     0.0000  6   5.8015   0.4458</code></pre>
<p>The <span class="math inline">\(p\)</span>-values here aren’t identical to ones above, but they’re very close. (The deviance differs slightly.) And it’s no coincendence that the <span class="math inline">\(\chi^2\)</span> statistic occurs in both the likelihood-ratio test and the test of (marginal) independence!</p>
<p>The <code>car</code> package provides a convenience function for computing this type of model.</p>
<pre class="r"><code>Anova(smoke_exercise.glm, test.statistic=&quot;LR&quot;, type = 2)</code></pre>
<pre><code>## Analysis of Deviance Table (Type II tests)
## 
## Response: Freq
##            LR Chisq Df Pr(&gt;Chisq)    
## Smoke        643.05  4     &lt;2e-16 ***
## Exer          73.84  2     &lt;2e-16 ***
## Smoke:Exer     5.80  6     0.4458    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>We can also predict from the null model:</p>
<pre class="r"><code>dat$h0 &lt;- predict(smoke_exercise.null, dat, type=&quot;response&quot;)
xtabs(h0 ~ Smoke + Exer, dat)</code></pre>
<pre><code>##        Exer
## Smoke        Freq      None      Some
##   Heavy  5.360169  1.072034  4.567797
##   Never 92.097458 18.419492 78.483051
##   Occas  9.258475  1.851695  7.889831
##   Regul  8.283898  1.656780  7.059322</code></pre>
<p>And from the full model:</p>
<pre class="r"><code>dat$h1 &lt;- predict(smoke_exercise.glm, dat, type=&quot;response&quot;)
xtabs(h1 ~ Smoke + Exer, dat)</code></pre>
<pre><code>##        Exer
## Smoke   Freq None Some
##   Heavy    7    1    3
##   Never   87   18   84
##   Occas   12    3    4
##   Regul    9    1    7</code></pre>
<p>This model nails our original data nearly perfectly. Now the reason why this isn’t significantly better becomes apparent when we look at the standard errors:</p>
<pre class="r"><code>dat$h1.se &lt;- predict(smoke_exercise.glm, dat, type=&quot;response&quot;, se.fit = TRUE)$se.fit
xtabs(h1.se ~ Smoke + Exer, dat)</code></pre>
<pre><code>##        Exer
## Smoke        Freq      None      Some
##   Heavy 2.6457513 0.9999952 1.7320507
##   Never 9.3273791 4.2426407 9.1651514
##   Occas 3.4641016 1.7320507 2.0000000
##   Regul 3.0000000 0.9999952 2.6457513</code></pre>
<p>By the way, we can see that our null model is indeed similar to the classical test’s null model:</p>
<pre class="r"><code>xtabs(h0 ~ Smoke + Exer, dat) - smoke_exercise.chisq$expected</code></pre>
<pre><code>##        Exer
## Smoke            Freq          None          Some
##   Heavy  1.145750e-12  2.722267e-13  1.397993e-12
##   Never -3.780087e-12 -7.105427e-15  4.050094e-12
##   Occas  5.824585e-10  1.165665e-10  4.970877e-10
##   Regul -3.321787e-13  2.220446e-16  3.668177e-13</code></pre>
<p>And the same holds for the standard errors:</p>
<pre class="r"><code>dat$h0.se &lt;- predict(smoke_exercise.glm, dat, type=&quot;response&quot;, se.fit = TRUE)$se.fit
xtabs(h0.se ~ Smoke + Exer, dat) - smoke_exercise.chisq$stdres</code></pre>
<pre><code>##        Exer
## Smoke         Freq       None       Some
##   Heavy  1.6326853  1.0749956  2.7145167
##   Never 10.9896438  4.4731867  7.3402703
##   Occas  2.1518654  0.8057224  3.8885976
##   Regul  2.6392930  1.5575498  2.6760612</code></pre>
<p>And of course, we can visualize all of this:</p>
<pre class="r"><code>ggplot(dat, 
       aes(x=Smoke,color=Exer,y=h1,ymin=h1-2*h1.se,ymax=h1+2*h1.se)) + 
    geom_point(aes(y=Freq, shape=&quot;Data&quot;)) + 
    geom_point(aes(y=h1, shape=&quot;Model&quot;)) + 
    geom_errorbar() +
    geom_line(aes(group=Exer)) + 
    labs(x=&quot;Smoking habits&quot;, y=&quot;Number of Respondents&quot;, color=&quot;Exercise habits&quot;,
         shape=&quot;Point estimate&quot;,
         title=&quot;Poisson model investigating the independence of smoking and exercise habits&quot;,
         subtitle=&quot;Error bars represent 95% Wald prediction intervals&quot;) + 
    theme_light()</code></pre>
<p><img src="../../../../2023/09/24/common-statistical-tests-are-linear-models-or-how-to-teach-stats/index_files/figure-html/unnamed-chunk-155-1.svg" width="576" style="display: block; margin: auto;" /></p>
</div>
<div id="binomial-test-logistic-regression" class="section level2">
<h2>Binomial Test: Logistic Regression</h2>
<div id="classical-test-exact-binomial-test" class="section level3">
<h3>Classical Test: Exact Binomial Test</h3>
<p>The binomial test is often used for comparing the number of “succeses” (hits, ‘yes’ answers, etc.) to “failures”, where the null hypothesis that the probability of success is 0.5 (by default; you can change this manually). In R, it can be computed as number of success and total number:</p>
<pre class="r"><code>binom.test(50, 100)</code></pre>
<pre><code>## 
## 	Exact binomial test
## 
## data:  50 and 100
## number of successes = 50, number of trials = 100, p-value = 1
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.3983211 0.6016789
## sample estimates:
## probability of success 
##                    0.5</code></pre>
<p>Or as number of success vs. number of failures:</p>
<pre class="r"><code>binom.test(c(50,50))</code></pre>
<pre><code>## 
## 	Exact binomial test
## 
## data:  c(50, 50)
## number of successes = 50, number of trials = 100, p-value = 1
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.3983211 0.6016789
## sample estimates:
## probability of success 
##                    0.5</code></pre>
<p>Note the very subtle difference in the input!</p>
<p>For a more complex example, we can examine handedness.</p>
<pre class="r"><code>summary(survey$W.Hnd)</code></pre>
<pre><code>##  Left Right  NA&#39;s 
##    18   218     1</code></pre>
<p>to be more interesting, let’s set our null hypothesis to “probability of being right-handed is 99%” – i.e. that lefties are exceptionally rare. The classical test gives us:</p>
<pre class="r"><code>hand.binom &lt;- binom.test(c(218,18),p=.99)
hand.binom</code></pre>
<pre><code>## 
## 	Exact binomial test
## 
## data:  c(218, 18)
## number of successes = 218, number of trials = 236, p-value = 5.234e-11
## alternative hypothesis: true probability of success is not equal to 0.99
## 95 percent confidence interval:
##  0.8821360 0.9541722
## sample estimates:
## probability of success 
##              0.9237288</code></pre>
</div>
<div id="explicit-glm-logit-or-probit" class="section level3">
<h3>Explicit GLM: Logit (or Probit)</h3>
<p>For the exact equivalent to the classical binomial test, we only care what the probability of the Bernoulli trial is and whether it differs from our null hypothesis. This corresponds to an intercept only binomial model. We’ll use the logit link function, but this method can be easily adapted for probit regression.</p>
<pre class="r"><code>hand.glm &lt;- glm(W.Hnd ~ 1, data=survey, family=binomial(link=&quot;logit&quot;))
summary(hand.glm)</code></pre>
<pre><code>## 
## Call:
## glm(formula = W.Hnd ~ 1, family = binomial(link = &quot;logit&quot;), data = survey)
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)   2.4941     0.2452   10.17   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 127.24  on 235  degrees of freedom
## Residual deviance: 127.24  on 235  degrees of freedom
##   (1 observation deleted due to missingness)
## AIC: 129.24
## 
## Number of Fisher Scoring iterations: 5</code></pre>
</div>
<div id="probability-density-function-of-logistic-distribution" class="section level3">
<h3>Probability density function of Logistic distribution</h3>
<p>When the location parameter <span class="math inline">\(μ\)</span> is <span class="math inline">\(0\)</span> and the scale parameter <span class="math inline">\(s\)</span> is <span class="math inline">\(1\)</span>, then the probability density function of the logistic distribution is given by</p>
<p><span class="math display">\[{\displaystyle {\begin{aligned}f(x;0,1)&amp;={\frac {e^{-x}}{(1+e^{-x})^{2}}}\\[4pt]&amp;={\frac {1}{(e^{x/2}+e^{-x/2})^{2}}}\\[5pt]&amp;={\frac {1}{4}}\operatorname {sech} ^{2}\left({\frac {x}{2}}\right).\end{aligned}}}\]</span>
Thus in general the density is:</p>
<p><span class="math display">\[{\displaystyle {\begin{aligned}f(x;\mu ,s)&amp;={\frac {e^{-(x-\mu )/s}}{s\left(1+e^{-(x-\mu )/s}\right)^{2}}}\\[4pt]&amp;={\frac {1}{s\left(e^{(x-\mu )/(2s)}+e^{-(x-\mu )/(2s)}\right)^{2}}}\\[4pt]&amp;={\frac {1}{4s}}\operatorname {sech} ^{2}\left({\frac {x-\mu }{2s}}\right).\end{aligned}}}\]</span></p>
<p>umulative distribution function
The logistic distribution receives its name from its cumulative distribution function, which is an instance of the family of logistic functions. The cumulative distribution function of the logistic distribution is also a scaled version of the hyperbolic tangent.</p>
<p><span class="math display">\[{\displaystyle F(x;\mu ,s)={\frac {1}{1+e^{-(x-\mu )/s}}}={\frac {1}{2}}+{\frac {1}{2}}\operatorname {tanh} \left({\frac {x-\mu }{2s}}\right).}\]</span>
In this equation <span class="math inline">\(μ\)</span> is the mean, and <span class="math inline">\(s\)</span> is a scale parameter proportional to the standard deviation.</p>
<p>We can convert logistic coefficients to probabilities with the plogis function:</p>
<pre class="r"><code>coef(hand.glm)</code></pre>
<pre><code>## (Intercept) 
##    2.494123</code></pre>
<pre class="r"><code>plogis(coef(hand.glm))</code></pre>
<pre><code>## (Intercept) 
##   0.9237288</code></pre>
<pre class="r"><code>1/2+1/2*tanh(coef(hand.glm)/2)</code></pre>
<pre><code>## (Intercept) 
##   0.9237288</code></pre>
<p>(If we just want odds-ratios, then simple exponentiation would suffice.)</p>
<p>This matched our estimate via the classical test. But how do we test against our null hypothesis of 99% probability? First we convert probability to log-odds:</p>
<pre class="r"><code>logit.null &lt;- qlogis(.99)
logit.null</code></pre>
<pre><code>## [1] 4.59512</code></pre>
<pre class="r"><code>1/2+1/2*tanh(logit.null/2)</code></pre>
<pre><code>## [1] 0.99</code></pre>
<p>Next, we use Wald confidence intevals to see if that value is included. confint()</p>
<pre class="r"><code>confint(hand.glm)</code></pre>
<pre><code>##    2.5 %   97.5 % 
## 2.043428 3.010507</code></pre>
<p>It’s not! We can actually see that the previous p-value is the point where the null would be included (confidence intervals can after alll beformed by inverting tests):</p>
<pre class="r"><code>confint(hand.glm,level=1-hand.binom$p.value)</code></pre>
<pre><code>##      0 %    100 % 
## 1.162023 4.600165</code></pre>
<p>(Some of the decimal digits are off here because it’s a finite sample.)</p>
</div>
</div>
<div id="proportion-test-multinomial-logistic-or-poisson-model" class="section level2">
<h2>Proportion Test: (Multinomial) Logistic or Poisson Model</h2>
<div id="classical-test-test-for-equality-of-proportions" class="section level3">
<h3>Classical Test: Test for Equality of Proportions</h3>
<p>A generalization of the binomial test is the test of proportions. For the simplest case, it’s simply a different way of expressing the binomial test:</p>
<pre class="r"><code>prop.test(218,n=236,p=.99,correct=FALSE)</code></pre>
<pre><code>## 
## 	1-sample proportions test without continuity correction
## 
## data:  218 out of 236, null probability 0.99
## X-squared = 104.7, df = 1, p-value &lt; 2.2e-16
## alternative hypothesis: true p is not equal to 0.99
## 95 percent confidence interval:
##  0.8826712 0.9512130
## sample estimates:
##         p 
## 0.9237288</code></pre>
<p>(We should probably use Yates’ correction here, but our sample size isn’t that small and the various small sample size corrections hide the asymptotic equivance of the tests. Nonetheless, the p
-values differ here because proportion test is an asymptotic/approximate test, while the binomial test is an exact test. )</p>
<p>With prop.test, we can also express various proportions within multiple categories and compare them. For example, we can see if the proportion of lefties differs between the sexes:</p>
<pre class="r"><code>hand.sex &lt;- xtabs(~Sex + W.Hnd,data=survey)
hand.sex</code></pre>
<pre><code>##         W.Hnd
## Sex      Left Right
##   Female    7   110
##   Male     10   108</code></pre>
<pre class="r"><code># swap the order so that &quot;righties&quot; are in the &quot;success&quot; column on the left
prop.test(hand.sex[, c(&quot;Right&quot;,&quot;Left&quot;)])</code></pre>
<pre><code>## 
## 	2-sample test for equality of proportions with continuity correction
## 
## data:  hand.sex[, c(&quot;Right&quot;, &quot;Left&quot;)]
## X-squared = 0.23563, df = 1, p-value = 0.6274
## alternative hypothesis: two.sided
## 95 percent confidence interval:
##  -0.04971453  0.09954794
## sample estimates:
##    prop 1    prop 2 
## 0.9401709 0.9152542</code></pre>
<pre class="r"><code>prop.test(c(110,108),n=c(117,118))</code></pre>
<pre><code>## 
## 	2-sample test for equality of proportions with continuity correction
## 
## data:  c(110, 108) out of c(117, 118)
## X-squared = 0.23563, df = 1, p-value = 0.6274
## alternative hypothesis: two.sided
## 95 percent confidence interval:
##  -0.04971453  0.09954794
## sample estimates:
##    prop 1    prop 2 
## 0.9401709 0.9152542</code></pre>
<p>So now, we have by-sex estimates of the proportions as well as an estimate of the difference. (The point estimate of the difference is implicit in the sample estimates and the 95% confidence interval of the difference.) Note that prop.test doesn’t allow you to specify what the proportion is for multiple groups – prop.test only tests for the equality of proportions between groups.</p>
<p>prop.test will even allow you to have an arbitrary number of categories as rows in your table. For example, we could consider the relationship of handedness to smoking:</p>
<pre class="r"><code>hand.smoke &lt;- xtabs(~Smoke + W.Hnd,data=survey)
print(hand.smoke)</code></pre>
<pre><code>##        W.Hnd
## Smoke   Left Right
##   Heavy    1    10
##   Never   13   175
##   Occas    3    16
##   Regul    1    16</code></pre>
<pre class="r"><code>prop.test(hand.smoke)</code></pre>
<pre><code>## 
## 	4-sample test for equality of proportions without continuity correction
## 
## data:  hand.smoke
## X-squared = 2.0307, df = 3, p-value = 0.5661
## alternative hypothesis: two.sided
## sample estimates:
##     prop 1     prop 2     prop 3     prop 4 
## 0.09090909 0.06914894 0.15789474 0.05882353</code></pre>
<p>However, for more than two-groups, prop.test doesn’t provide an estimate of the difference because there are multiple estimated differences.</p>
</div>
<div id="explicit-glm-logit" class="section level3">
<h3>Explicit GLM: Logit</h3>
<p>Now, all this success and failure language suggest that we can express these models as binomial GLMs, and we can. For sex, we have:</p>
<pre class="r"><code>hand.sex.binom &lt;-  glm(W.Hnd ~ 0 + Sex, data=na.omit(survey), family=binomial(link=&quot;logit&quot;),
                       contrasts = list(Sex=&quot;contr.Sum&quot;))
hand.sex.binom.null &lt;-  glm(W.Hnd ~ 1, data=na.omit(survey), family=binomial(link=&quot;logit&quot;))
print(summary(hand.sex.binom))</code></pre>
<pre><code>## 
## Call:
## glm(formula = W.Hnd ~ 0 + Sex, family = binomial(link = &quot;logit&quot;), 
##     data = na.omit(survey), contrasts = list(Sex = &quot;contr.Sum&quot;))
## 
## Coefficients:
##           Estimate Std. Error z value Pr(&gt;|z|)    
## SexFemale   2.7600     0.4611   5.985 2.16e-09 ***
## SexMale     2.3979     0.3948   6.074 1.25e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 232.897  on 168  degrees of freedom
## Residual deviance:  86.099  on 166  degrees of freedom
## AIC: 90.099
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<pre class="r"><code>print(plogis(coef(hand.sex.binom)))</code></pre>
<pre><code>## SexFemale   SexMale 
## 0.9404762 0.9166667</code></pre>
<pre class="r"><code># non-overlap of83% CIs corresponds to 95% CI of diff not crossing zero:
# https://rpubs.com/bbolker/overlapCI
print(plogis(confint(hand.sex.binom,level=0.83)))</code></pre>
<pre><code>##               8.5 %    91.5 %
## SexFemale 0.8984303 0.9694946
## SexMale   0.8691164 0.9518829</code></pre>
<pre class="r"><code>anova(hand.sex.binom.null, hand.sex.binom, test=&quot;Chisq&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: W.Hnd ~ 1
## Model 2: W.Hnd ~ 0 + Sex
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)
## 1       167     86.459                     
## 2       166     86.099  1  0.36054   0.5482</code></pre>
<pre class="r"><code>print(prop.test(hand.sex[ , c(2,1)], correct=FALSE))</code></pre>
<pre><code>## 
## 	2-sample test for equality of proportions without continuity correction
## 
## data:  hand.sex[, c(2, 1)]
## X-squared = 0.54351, df = 1, p-value = 0.461
## alternative hypothesis: two.sided
## 95 percent confidence interval:
##  -0.04120374  0.09103715
## sample estimates:
##    prop 1    prop 2 
## 0.9401709 0.9152542</code></pre>
<pre class="r"><code>print(prop.test(hand.sex[ , c(2,1)], correct=TRUE))</code></pre>
<pre><code>## 
## 	2-sample test for equality of proportions with continuity correction
## 
## data:  hand.sex[, c(2, 1)]
## X-squared = 0.23563, df = 1, p-value = 0.6274
## alternative hypothesis: two.sided
## 95 percent confidence interval:
##  -0.04971453  0.09954794
## sample estimates:
##    prop 1    prop 2 
## 0.9401709 0.9152542</code></pre>
<p>This suggests that our test is doing something right – it’s not quite as conservative as Yates correction, but because it’s an explicit GLM, it’s generative and so we can plot and make predictions and all that.</p>
</div>
<div id="explicit-glm-poisson" class="section level3">
<h3>Explicit GLM: Poisson</h3>
<p>Now, some of you might have noticed that the multi-condition proportion test can be viewed as having “occurrences [out of total events]” instead of “successes” and “failures”</p>
<p>If you were paying attention earlier, this should make you think of the Poisson model. Let’s try to reformulate this as a Poisson model. First, let’s convert our data from single Bernoulli trials to observed occurences in a given time unit (here: everything).</p>
<pre class="r"><code>hand.sex.poisson &lt;- glm(Freq ~ 1 + Sex * W.Hnd, data=as.data.frame(hand.sex), family=poisson(),
                        contrasts = list(Sex=&quot;contr.Sum&quot;))
hand.sex.poisson.null &lt;- glm(Freq ~ 1 + Sex + W.Hnd, data=as.data.frame(hand.sex), family=poisson(),
                        contrasts = list(Sex=&quot;contr.Sum&quot;))
print(summary(hand.sex.poisson))</code></pre>
<pre><code>## 
## Call:
## glm(formula = Freq ~ 1 + Sex * W.Hnd, family = poisson(), data = as.data.frame(hand.sex), 
##     contrasts = list(Sex = &quot;contr.Sum&quot;))
## 
## Coefficients:
##                             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)                  3.40778    0.12777  26.671   &lt;2e-16 ***
## Sex[S.Female]               -0.08458    0.12777  -0.662    0.508    
## W.Hnd[S.Left]               -1.28353    0.12777 -10.046   &lt;2e-16 ***
## Sex[S.Female]:W.Hnd[S.Left] -0.09376    0.12777  -0.734    0.463    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance:  2.0429e+02  on 3  degrees of freedom
## Residual deviance: -1.1102e-15  on 0  degrees of freedom
## AIC: 29.026
## 
## Number of Fisher Scoring iterations: 3</code></pre>
<pre class="r"><code>anova(hand.sex.poisson.null, hand.sex.poisson, test=&quot;Chisq&quot;)</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: Freq ~ 1 + Sex + W.Hnd
## Model 2: Freq ~ 1 + Sex * W.Hnd
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)
## 1         1    0.54629                     
## 2         0    0.00000  1  0.54629   0.4598</code></pre>
<p>The <span class="math inline">\(p\)</span>-values for the likelihood-ratio and for the interaction term lie on either side of the p
-value of uncorrected test of proportions. The LRTs are known to be more conservative than the Wald (coefficient) tests, so this is not surprising within the Poisson model and suggests moreover that the Poisson model largely agrees with the uncorrected test for equality of proportions.</p>
</div>
<div id="classical-test-poisson-test" class="section level3">
<h3>Classical Test: Poisson Test</h3>
<p>Now, you’ve seen that the proportion test is effectively just a generalization of the binomial test. And you’ve seen that we can model the proportion test with a Poisson model. So the following facts from R’s documentation for poisson.test should not surprise you:</p>
<ul>
<li>The one-sample case is effectively the binomial test with a very large n. The two sample case is converted to a binomial test by conditioning on the total event count, and the rate ratio is directly related to the odds in that binomial distribution.</li>
</ul>
<p>Let’s take this bit by bit:</p>
<ul>
<li>The one-sample case is effectively the binomial test with a very large n. </li>
</ul>
<pre class="r"><code>print(summary(survey$W.Hnd))</code></pre>
<pre><code>##  Left Right  NA&#39;s 
##    18   218     1</code></pre>
<pre class="r"><code>print(binom.test(218,n=236))</code></pre>
<pre><code>## 
## 	Exact binomial test
## 
## data:  218 and 236
## number of successes = 218, number of trials = 236, p-value &lt; 2.2e-16
## alternative hypothesis: true probability of success is not equal to 0.5
## 95 percent confidence interval:
##  0.8821360 0.9541722
## sample estimates:
## probability of success 
##              0.9237288</code></pre>
<pre class="r"><code>print(prop.test(218,n=236))</code></pre>
<pre><code>## 
## 	1-sample proportions test with continuity correction
## 
## data:  218 out of 236, null probability 0.5
## X-squared = 167.8, df = 1, p-value &lt; 2.2e-16
## alternative hypothesis: true p is not equal to 0.5
## 95 percent confidence interval:
##  0.8801771 0.9528813
## sample estimates:
##         p 
## 0.9237288</code></pre>
<pre class="r"><code>print(poisson.test(218,236))</code></pre>
<pre><code>## 
## 	Exact Poisson test
## 
## data:  218 time base: 236
## number of events = 218, time base = 236, p-value = 0.2545
## alternative hypothesis: true event rate is not equal to 1
## 95 percent confidence interval:
##  0.8051693 1.0548307
## sample estimates:
## event rate 
##  0.9237288</code></pre>
<p>Oh wow, those do all line up. The Poisson terminology of “rate” per unit “time” sounds weird, but we can also think of “events” being the same as “sucesses” and “rate” being the same as “probability” and then “unit time” being the same as “observation”.</p>
<ul>
<li>The two sample case is converted to a binomial test by conditioning on the total event count, and the rate ratio is directly related to the odds in that binomial distribution.</li>
</ul>
<pre class="r"><code>hand.sex &lt;- xtabs(~Sex + W.Hnd,data=survey)
print(hand.sex)</code></pre>
<pre><code>##         W.Hnd
## Sex      Left Right
##   Female    7   110
##   Male     10   108</code></pre>
<pre class="r"><code># reverse the column order so that right-handedness is &quot;sucess&quot;
hand.sex &lt;- hand.sex[, c(&quot;Right&quot;,&quot;Left&quot;)]
binom.female &lt;- binom.test(hand.sex[&quot;Female&quot;,])
binom.male &lt;- binom.test(hand.sex[&quot;Male&quot;,])
print(sprintf(&quot;Ratio of conditional binomial probabilities: %f&quot;, binom.female$estimate / binom.male$estimate))</code></pre>
<pre><code>## [1] &quot;Ratio of conditional binomial probabilities: 1.027224&quot;</code></pre>
<pre class="r"><code>total_righties &lt;- sum(hand.sex[,&quot;Right&quot;])
total_females &lt;- sum(hand.sex[&quot;Female&quot;,])
total_males &lt;- sum(hand.sex[&quot;Male&quot;,])
total_all &lt;- sum(hand.sex)

binom.test(hand.sex[,&quot;Right&quot;], total_righties, total_females / total_all)</code></pre>
<pre><code>## 
## 	Exact binomial test
## 
## data:  hand.sex[, &quot;Right&quot;]
## number of successes = 110, number of trials = 218, p-value = 0.8923
## alternative hypothesis: true probability of success is not equal to 0.4978723
## 95 percent confidence interval:
##  0.4362578 0.5727901
## sample estimates:
## probability of success 
##              0.5045872</code></pre>
<pre class="r"><code>prop &lt;- prop.test(hand.sex)
print(prop)</code></pre>
<pre><code>## 
## 	2-sample test for equality of proportions with continuity correction
## 
## data:  hand.sex
## X-squared = 0.23563, df = 1, p-value = 0.6274
## alternative hypothesis: two.sided
## 95 percent confidence interval:
##  -0.04971453  0.09954794
## sample estimates:
##    prop 1    prop 2 
## 0.9401709 0.9152542</code></pre>
<pre class="r"><code>print(sprintf(&quot;Ratio of proportions: %f&quot;, prop$estimate[1]/prop$estimate[2]))</code></pre>
<pre><code>## [1] &quot;Ratio of proportions: 1.027224&quot;</code></pre>
<pre class="r"><code>print(poisson.test(hand.sex[,&quot;Right&quot;],c(total_females, total_males)))</code></pre>
<pre><code>## 
## 	Comparison of Poisson rates
## 
## data:  hand.sex[, &quot;Right&quot;] time base: c(total_females, total_males)
## count1.Female = 110, expected count1 = 108.54, p-value = 0.8923
## alternative hypothesis: true rate ratio is not equal to 1
## 95 percent confidence interval:
##  0.7804746 1.3522292
## sample estimates:
## rate ratio.Female 
##          1.027224</code></pre>
<p>Huh. The p-values from the binomial test and Poisson test line up perfectly, and ratio of proportions identical across all tests.</p>
</div>
</div>
</div>
<div id="references" class="section level1">
<h1>References</h1>
<p><a href="https://lindeloev.github.io/tests-as-linear/">https://lindeloev.github.io/tests-as-linear/</a></p>
</div>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
          </li>
          <li>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="../../../../js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

