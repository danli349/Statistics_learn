<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Inference on A Hugo website</title>
    <link>/tags/inference/</link>
    <description>Recent content in Inference on A Hugo website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 07 Oct 2020 00:00:00 +0000</lastBuildDate><atom:link href="/tags/inference/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Principal Component Analysis</title>
      <link>/2020/10/07/principal-component-analysis/</link>
      <pubDate>Wed, 07 Oct 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/10/07/principal-component-analysis/</guid>
      <description>Let the random vector \(\mathbf X^T=[X_1,X_2,\cdots,X_p]\) have the covariance matrix \(\boldsymbol\Sigma\) with eigenvalues \(\lambda_1\ge\lambda_2\ge\cdots\ge\lambda_p\ge0\), the linear combinations \(Y_i=\mathbf a_i^T\mathbf X=a_{i1}X_1+a_{i2}X_2+\cdots+a_{ip}X_p, \quad (i=1,2,\cdots,p)\) has \(Var(Y_i)=Var(\mathbf a_i^T\mathbf X)=\mathbf a_i^TCov(\mathbf X)\mathbf a_i=\mathbf a_i^T\boldsymbol\Sigma\mathbf a_i\) and \(Cov(Y_i,Y_k)=Cov(\mathbf a_i^T\mathbf X, \mathbf a_k^T\mathbf X)=\mathbf a_i^T\boldsymbol\Sigma\mathbf a_k \quad i,k=1,2,\cdots,p\). The principal components are those uncorrelated linear combinations of \([X_1,X_2,\cdots,X_p]\), \(Y_1,Y_2,\cdots,Y_p\) whose variances \(Var(Y_i)=\mathbf a_i^T\boldsymbol\Sigma\mathbf a_i\) are as large as possible, subject to \(\mathbf a_i^T\mathbf a_i=1\). These linear combinations represent the selection of a new coordinate system obtained by rotating the original system with \(Y_1,Y_2,\cdots,Y_p\) as the new coordinate axes.</description>
    </item>
    
    <item>
      <title>Comparisons of several means</title>
      <link>/2020/09/29/comparisons-of-several-means/</link>
      <pubDate>Tue, 29 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/09/29/comparisons-of-several-means/</guid>
      <description>Paired Comparisons:
If there are \(2\) treatments over multivariate \(\mathbf x_p\), the difference between treatment \(1\) and treatment \(2\) is \(\mathbf d_j=\mathbf x_{j1}-\mathbf x_{j2},\quad j=1,2,\cdots,n\) if \(\mathbf d_j\) are independent \(N_p(\boldsymbol\delta, \mathbf\Sigma_d)\) random vectors, inferencesabout the vector of mean differences \(\boldsymbol\delta\) can be based upon a \(T^2\)-statistic: \(T^2=n(\overline{\mathbf d}-\boldsymbol\delta)^T\mathbf S_d^{-1}(\overline{\mathbf d}-\boldsymbol\delta)\) is distributed as an \(\frac{(n-1)p}{n-p}F_{p,n-p}\) random variable, where \(\overline{\mathbf d}=\displaystyle\frac{1}{n}\displaystyle\sum_{j=1}^{n}\mathbf d_j\) and \(\mathbf S_d=\displaystyle\frac{1}{n-1}\displaystyle\sum_{j=1}^{n}(\mathbf d_j-\overline{\mathbf d})(\mathbf d_j-\overline{\mathbf d})^T\), then an \(\alpha\)-level hypothesis test of \(H_0:\boldsymbol\delta=\mathbf 0\) versus \(H_1:\boldsymbol\delta\ne\mathbf 0\), rejects \(H_0\) if the observed \(T^2=n\overline{\mathbf d}^T\mathbf S_d^{-1}\overline{\mathbf d}&amp;gt;\frac{(n-1)p}{n-p}F_{p,n-p}(\alpha)\).</description>
    </item>
    
    <item>
      <title>Inferences about the mean</title>
      <link>/2020/09/25/inferences-about-the-mean/</link>
      <pubDate>Fri, 25 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/09/25/inferences-about-the-mean/</guid>
      <description>The hypothesis testing about the mean is a test of the competing hypotheses: \(H_0:\mu=\mu_0\) and \(H_1:\mu\ne\mu_0\). If \(X_1,X_2,\cdots,X_n\) denote a random sample from a normal population, the appropriate test statistic is \(t=\frac{(\overline X-\mu_0)}{s/\sqrt{n}}\) with \(s^2=\frac{1}{(n-1)}\displaystyle\sum_{i=1}^{n}(X_i-\overline X)^2\). Rejecting \(H_0\) when \(|t|\) is large is equivalent to rejecting \(H_0\) when \(t^2=\frac{(\overline X-\mu_0)^2}{s^2/n}=n(\overline X-\mu_0)(s^2)^{-1}(\overline X-\mu_0)\) is large. Then the test becomes reject \(H_0\) in favor of \(H_1\) at significance level \(\alpha\) if \(n(\overline X-\mu_0)(s^2)^{-1}(\overline X-\mu_0)&amp;gt;t_{n-1}^2(\alpha/2)\), its multivariate analog is \(T^2=(\overline {\mathbf X}-\boldsymbol\mu_0)^T(\frac{1}{n}\mathbf S)^{-1}(\overline {\mathbf X}-\boldsymbol\mu_0)=n(\overline {\mathbf X}-\boldsymbol\mu_0)^T\mathbf S^{-1}(\overline {\mathbf X}-\boldsymbol\mu_0)\), where \(\overline {\mathbf X}=\frac{1}{n}\displaystyle\sum_{j=1}^{n}\mathbf X_j\), \(\underset{(p\times p)}{\mathbf S}=\frac{1}{n-1}\displaystyle\sum_{j=1}^{n}(\underset{(p\times 1)}{\mathbf X_j}-\underset{(p\times 1)}{\overline {\mathbf X}})(\underset{(p\times 1)}{\mathbf X_j}-\underset{(p\times 1)}{\overline {\mathbf X}})^T\)</description>
    </item>
    
    <item>
      <title>Randomized block design</title>
      <link>/2020/09/09/randomized-block-design/</link>
      <pubDate>Wed, 09 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/09/09/randomized-block-design/</guid>
      <description>In the Randomized block design, all of the sample sizes are the same \(b\), which is the blocks, the mathematical model associated with \(Y_{ij}\) is :\(Y_{ij}=\mu_j+\beta_i+\epsilon_{ij}\), the term \(\beta_i\) represents the effect of the \(i^{th}\) block.\[\begin{array}{|cc|cccc ccc|}\hline&amp;amp;&amp;amp;&amp;amp;\text{treatment}&amp;amp;\text{levels}&amp;amp; &amp;amp; &amp;amp; Block&amp;amp;Block&amp;amp; Block\\&amp;amp; &amp;amp; 1 &amp;amp; 2 &amp;amp; \cdots &amp;amp; k &amp;amp;&amp;amp; Totals &amp;amp; Means &amp;amp; Effects \\\hline&amp;amp;1&amp;amp; Y_{11} &amp;amp; Y_{12} &amp;amp; \cdots &amp;amp; Y_{1k} &amp;amp;&amp;amp; T_{1.</description>
    </item>
    
    <item>
      <title>Testing Subhypotheses with Contrasts</title>
      <link>/2020/09/07/testing-subhypotheses-with-contrasts/</link>
      <pubDate>Mon, 07 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/09/07/testing-subhypotheses-with-contrasts/</guid>
      <description>A linear combination of the true means of \(k\) factor levels \(\mu_1,\mu_2,\cdots,\mu_k\) of the randomized-one-factor-design \(C=\displaystyle\sum_{j=1}^{k}c_j\mu_j\) is said to be a contrast if the sum of its coefficients \(\displaystyle\sum_{j=1}^{k}c_j=0\). Because \(\overline Y_{.j}\) is always an unbiased estimator for \(\mu_j\), we can use it to estimate C \(\hat C=\displaystyle\sum_{j=1}^{k}c_j\overline Y_{.j}\). Because \(Y_{ij}\) are normal, so \(\hat C\) is also normal.Then, \(E(\hat C)=\displaystyle\sum_{j=1}^{k}c_jE(\overline Y_{.j})=\displaystyle\sum_{j=1}^{k}c_j\mu_j=C\) and \(Var(\hat C)=\displaystyle\sum_{j=1}^{k}c_j^2Var(\overline Y_{.j})=\displaystyle\sum_{j=1}^{k}c_j^2\frac{\sigma^2}{n_j}=\sigma^2\displaystyle\sum_{j=1}^{k}\frac{c_j^2}{n_j}\). Replacing \(\sigma^2\) by its estimate \(MSE\) gives a formula for the estimated variance \(S_{\hat C}^2=MSE\displaystyle\sum_{j=1}^{k}\frac{c_j^2}{n_j}\).</description>
    </item>
    
    <item>
      <title>Randomized one-factor design and the analysis of variance (ANOVA)</title>
      <link>/2020/09/06/randomized-one-factor-design-and-the-analysis-of-variance-anova/</link>
      <pubDate>Sun, 06 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/09/06/randomized-one-factor-design-and-the-analysis-of-variance-anova/</guid>
      <description>If we want to compare the average effects elicited by \(k\) different levels of some given factor, there will be \(k\) independent random samples of sizes \(n_j\quad (j=1,2,...,k)\), the total sample size is \(n=\displaystyle\sum_{j=1}^{k}n_j\). Let \(Y_{ij}\) represent the \(i^{th}\) observation recorded for the \(j^{th}\) level.\[\begin{array}{|c|cccc|}\hline&amp;amp;&amp;amp;\text{treatment}&amp;amp;\text{levels}&amp;amp;\\\hline&amp;amp; 1 &amp;amp; 2 &amp;amp; \cdots &amp;amp; k \\\hline&amp;amp; Y_{11} &amp;amp; Y_{12} &amp;amp; \cdots &amp;amp; Y_{1k} \\&amp;amp; Y_{21} &amp;amp; Y_{22} &amp;amp; \cdots &amp;amp; Y_{2k} \\&amp;amp;\vdots &amp;amp;\vdots &amp;amp;\cdots&amp;amp;\vdots \\&amp;amp;Y_{n_11} &amp;amp;Y_{n_22} &amp;amp;\cdots&amp;amp;Y_{n_kk} \\\text{Sample sizes:}&amp;amp;n_1&amp;amp;n_2&amp;amp;\cdots&amp;amp;n_k\\\text{Sample totals:}&amp;amp;T_{.</description>
    </item>
    
  </channel>
</rss>
