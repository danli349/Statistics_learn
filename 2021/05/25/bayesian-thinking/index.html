<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.80.0" />


<title>Bayesian Thinking - A Hugo website</title>
<meta property="og:title" content="Bayesian Thinking - A Hugo website">


  <link href='../../../../favicon.ico' rel='icon' type='image/x-icon'/>



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="../../../../css/fonts.css" media="all">
<link rel="stylesheet" href="../../../../css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="../../../../" class="nav-logo">
    <img src="../../../../images/logo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="../../../../about/">about</a></li>
    
    <li><a href="../../../../vitae/">CV</a></li>
    
    <li><a href="https://github.com/danli349">GitHub</a></li>
    
    <li><a href="https://scholar.google.com/citations?user=mNjLK8EAAAAJ&amp;hl=en">Googlr Scholar</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">271 min read</span>
    

    <h1 class="article-title">Bayesian Thinking</h1>

    
    <span class="article-date">2021-05-25</span>
    

    <div class="article-content">
      
<script src="../../../../2021/05/25/bayesian-thinking/index_files/header-attrs/header-attrs.js"></script>

<div id="TOC">
<ul>
<li><a href="#the-basics-of-bayesian-statistics">1 The Basics of Bayesian Statistics</a>
<ul>
<li><a href="#bayes-rule">Bayes’ Rule</a>
<ul>
<li><a href="#sec:bayes-rule">Conditional Probabilities &amp; Bayes’ Rule</a></li>
<li><a href="#sec:diagnostic-testing">Bayes’ Rule and Diagnostic Testing</a></li>
<li><a href="#bayes-updating">Bayes Updating</a></li>
<li><a href="#bayesian-vs.-frequentist-definitions-of-probability">Bayesian vs. Frequentist Definitions of Probability</a></li>
<li><a href="#inference-for-a-proportion-frequentist-approach">Inference for a Proportion: Frequentist Approach</a></li>
<li><a href="#inference-for-a-proportion-bayesian-approach">Inference for a Proportion: Bayesian Approach</a></li>
<li><a href="#effect-of-sample-size-on-the-posterior">Effect of Sample Size on the Posterior</a></li>
<li><a href="#frequentist-vs.-bayesian-inference">Frequentist vs. Bayesian Inference</a></li>
</ul></li>
</ul></li>
<li><a href="#bayesian-inference">2 Bayesian Inference</a>
<ul>
<li><a href="#continuous-variables-and-eliciting-probability-distributions">Continuous Variables and Eliciting Probability Distributions</a>
<ul>
<li><a href="#from-the-discrete-to-the-continuous">From the Discrete to the Continuous</a></li>
<li><a href="#elicitation">Elicitation</a></li>
<li><a href="#conjugacy">Conjugacy</a></li>
<li><a href="#inference-on-a-binomial-proportion">Inference on a Binomial Proportion</a></li>
<li><a href="#the-gamma-poisson-conjugate-families">The Gamma-Poisson Conjugate Families</a></li>
<li><a href="#sec:normal-normal">The Normal-Normal Conjugate Families</a></li>
<li><a href="#non-conjugate-priors">Non-Conjugate Priors</a></li>
<li><a href="#credible-intervals">Credible Intervals</a></li>
<li><a href="#predictive-inference">Predictive Inference</a></li>
</ul></li>
</ul></li>
<li><a href="#losses-and-decision-making">3 Losses and Decision Making</a>
<ul>
<li><a href="#bayesian-decision-making">Bayesian Decision Making</a></li>
<li><a href="#sec:bayes-factors">Posterior Probabilities of Hypotheses and Bayes Factors</a></li>
</ul></li>
<li><a href="#inference-and-decision-making-with-multiple-parameters">4 Inference and Decision-Making with Multiple Parameters</a>
<ul>
<li><a href="#conjugate-prior-for-mu-and-sigma2">Conjugate Prior for <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span></a></li>
<li><a href="#conjugate-posterior-distribution">Conjugate Posterior Distribution</a></li>
<li><a href="#marginal-distribution-for-mu-student-t">Marginal Distribution for <span class="math inline">\(\mu\)</span>: Student <span class="math inline">\(t\)</span></a></li>
<li><a href="#credible-intervals-for-mu">Credible Intervals for <span class="math inline">\(\mu\)</span></a></li>
<li><a href="#sec:tapwater">Example: TTHM in Tapwater</a></li>
<li><a href="#section-summary">Section Summary</a></li>
<li><a href="#optional-derivations">(Optional) Derivations</a></li>
<li><a href="#sec:NG-MC">Monte Carlo Inference</a>
<ul>
<li><a href="#monte-carlo-sampling">Monte Carlo Sampling</a></li>
<li><a href="#monte-carlo-inference-tap-water-example">Monte Carlo Inference: Tap Water Example</a></li>
<li><a href="#monte-carlo-inference-for-functions-of-parameters">Monte Carlo Inference for Functions of Parameters</a></li>
<li><a href="#summary">Summary</a></li>
<li><a href="#prior-predictive-distribution">Prior Predictive Distribution</a></li>
<li><a href="#tap-water-example-continued">Tap Water Example (continued)</a></li>
<li><a href="#sampling-from-the-prior-predictive-in-r">Sampling from the Prior Predictive in <code>R</code></a></li>
<li><a href="#posterior-predictive">Posterior Predictive</a></li>
<li><a href="#summary-1">Summary</a></li>
</ul></li>
<li><a href="#sec:NG-MCMC">Markov Chain Monte Carlo (MCMC)</a></li>
</ul></li>
<li><a href="#hypothesis-testing-with-normal-populations">5 Hypothesis Testing with Normal Populations</a>
<ul>
<li><a href="#bayes-factors-for-testing-a-normal-mean-variance-known">Bayes Factors for Testing a Normal Mean: variance known</a></li>
<li><a href="#comparing-two-paired-means-using-bayes-factors">Comparing Two Paired Means using Bayes Factors</a></li>
<li><a href="#sec:indep-means">Comparing Independent Means: Hypothesis Testing</a></li>
<li><a href="#inference-after-testing">Inference after Testing</a></li>
</ul></li>
<li><a href="#introduction-to-bayesian-regression">6 Introduction to Bayesian Regression</a>
<ul>
<li><a href="#sec:simple-linear">Bayesian Simple Linear Regression</a>
<ul>
<li><a href="#frequentist-ordinary-least-square-ols-simple-linear-regression">Frequentist Ordinary Least Square (OLS) Simple Linear Regression</a></li>
<li><a href="#bayesian-simple-linear-regression-using-the-reference-prior">Bayesian Simple Linear Regression Using the Reference Prior</a></li>
<li><a href="#sec:informative-prior">Informative Priors</a></li>
<li><a href="#sec:derivations">(Optional) Derivations of Marginal Posterior Distributions of <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>, <span class="math inline">\(\sigma^2\)</span></a></li>
<li><a href="#marginal-posterior-distribution-of-beta">Marginal Posterior Distribution of <span class="math inline">\(\beta\)</span></a></li>
<li><a href="#marginal-posterior-distribution-of-alpha">Marginal Posterior Distribution of <span class="math inline">\(\alpha\)</span></a></li>
<li><a href="#marginal-posterior-distribution-of-sigma2">Marginal Posterior Distribution of <span class="math inline">\(\sigma^2\)</span></a></li>
<li><a href="#joint-normal-gamma-posterior-distributions">Joint Normal-Gamma Posterior Distributions</a></li>
<li><a href="#posterior-distribution-of-epsilon_j-conditioning-on-sigma2">Posterior Distribution of <span class="math inline">\(\epsilon_j\)</span> Conditioning On <span class="math inline">\(\sigma^2\)</span></a></li>
<li><a href="#implementation-using-bas-package">Implementation Using <code>BAS</code> Package</a></li>
</ul></li>
<li><a href="#sec:Bayes-multiple-regression">Bayesian Multiple Linear Regression</a>
<ul>
<li><a href="#the-model">The Model</a></li>
<li><a href="#data-pre-processing">Data Pre-processing</a></li>
<li><a href="#specify-bayesian-prior-distributions">Specify Bayesian Prior Distributions</a></li>
<li><a href="#fitting-the-bayesian-model">Fitting the Bayesian Model</a></li>
<li><a href="#posterior-means-and-posterior-standard-deviations">Posterior Means and Posterior Standard Deviations</a></li>
</ul></li>
<li><a href="#credible-intervals-summary">Credible Intervals Summary</a></li>
<li><a href="#summary-2">Summary</a></li>
</ul></li>
<li><a href="#bayesian-model-choice">7 Bayesian Model Choice</a>
<ul>
<li><a href="#definition-of-bic">Definition of BIC</a></li>
<li><a href="#backward-elimination-with-bic">Backward Elimination with BIC</a></li>
<li><a href="#coefficient-estimates-under-reference-prior-for-best-bic-model">Coefficient Estimates Under Reference Prior for Best BIC Model</a></li>
<li><a href="#other-criteria">Other Criteria</a></li>
<li><a href="#model-uncertainty">Model Uncertainty</a></li>
<li><a href="#calculating-posterior-probability-in-r">Calculating Posterior Probability in R</a></li>
<li><a href="#bayesian-model-averaging">Bayesian Model Averaging</a>
<ul>
<li><a href="#visualizing-model-uncertainty">Visualizing Model Uncertainty</a></li>
<li><a href="#bayesian-model-averaging-using-posterior-probability">Bayesian Model Averaging Using Posterior Probability</a></li>
<li><a href="#coefficient-summary-under-bma">Coefficient Summary under BMA</a></li>
</ul></li>
<li><a href="#summary-3">Summary</a></li>
</ul></li>
<li><a href="#stochastic-explorations-using-mcmc">8 Stochastic Explorations Using MCMC</a>
<ul>
<li><a href="#markov-chain-monte-carlo-exploration">Markov Chain Monte Carlo Exploration</a></li>
<li><a href="#other-priors-for-bayesian-model-uncertainty">Other Priors for Bayesian Model Uncertainty</a>
<ul>
<li><a href="#zellners-g-prior">Zellner’s <span class="math inline">\(g\)</span>-Prior</a></li>
<li><a href="#bayes-factor-of-zellners-g-prior">Bayes Factor of Zellner’s <span class="math inline">\(g\)</span>-Prior</a></li>
<li><a href="#kids-cognitive-score-example">Kid’s Cognitive Score Example</a></li>
<li><a href="#the-uscrime-data-set-and-data-processing">The <code>UScrime</code> Data Set and Data Processing</a></li>
<li><a href="#bayesian-models-and-diagnostics">Bayesian Models and Diagnostics</a></li>
<li><a href="#posterior-uncertainty-in-coefficients">Posterior Uncertainty in Coefficients</a></li>
<li><a href="#prediction">Prediction</a></li>
<li><a href="#model-choice">Model Choice</a></li>
<li><a href="#prediction-with-new-data">Prediction with New Data</a></li>
</ul></li>
<li><a href="#summary-4">Summary</a></li>
</ul></li>
<li><a href="#references">References</a></li>
</ul>
</div>

<div id="the-basics-of-bayesian-statistics" class="section level1">
<h1>1 The Basics of Bayesian Statistics</h1>
<p>Bayesian statistics mostly involves <strong>conditional probability</strong>, which is the the probability of an event A <strong>given</strong> event B, and it can be calculated using the Bayes rule. The concept of conditional probability is widely used in medical testing, in which false positives and false negatives may occur. A false positive can be defined as a positive outcome on a medical test when the patient does not actually have the disease they are being tested for. In other words, it’s the probability of testing positive given no disease. Similarly, a false negative can be defined as a negative outcome on a medical test when the patient does have the disease. In other words, testing negative given disease. Both indicators are critical for any medical decisions.</p>
<p>For how the Bayes’ rule is applied, we can set up a prior, then calculate posterior probabilities based on a prior and likelihood. That is to say, the prior probabilities are updated through an iterative process of data collection.</p>
<div id="bayes-rule" class="section level2">
<h2>Bayes’ Rule</h2>
<p>This section introduces how the Bayes’ rule is applied to calculating
conditional probability, and several real-life examples are
demonstrated. Finally, we compare the Bayesian and frequentist
definition of probability.</p>
<div id="sec:bayes-rule" class="section level3">
<h3>Conditional Probabilities &amp; Bayes’ Rule</h3>
<p>Consider Table <a href="#tab:2015gallupDating"><strong>??</strong></a>. It shows the results of a
poll among 1,738 adult Americans. This table allows us to calculate
probabilities.</p>
<pre class="r"><code>temp &lt;- matrix(c(60, 86, 58, 21, 225, 255, 426, 450, 382, 1513, 315, 512, 508, 403, 1738), nrow = 3, byrow = TRUE)
rownames(temp) &lt;- c(&#39;Used online dating site&#39;, &#39;Did not use online dating site&#39;, &#39;Total&#39;)
colnames(temp) &lt;- c(&#39;18-29&#39;, &#39;30-49&#39;, &#39;50-64&#39;, &#39;65+&#39;, &#39;Total&#39;)

knitr::kable(
  x = temp,
  booktabs = TRUE,
  caption = &#39;Results from a 2015 Gallup poll on the use of online dating sites by age group&#39;
)</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-1">Table 1: </span>Results from a 2015 Gallup poll on the use of online dating sites by age group</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">18-29</th>
<th align="right">30-49</th>
<th align="right">50-64</th>
<th align="right">65+</th>
<th align="right">Total</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Used online dating site</td>
<td align="right">60</td>
<td align="right">86</td>
<td align="right">58</td>
<td align="right">21</td>
<td align="right">225</td>
</tr>
<tr class="even">
<td align="left">Did not use online dating site</td>
<td align="right">255</td>
<td align="right">426</td>
<td align="right">450</td>
<td align="right">382</td>
<td align="right">1513</td>
</tr>
<tr class="odd">
<td align="left">Total</td>
<td align="right">315</td>
<td align="right">512</td>
<td align="right">508</td>
<td align="right">403</td>
<td align="right">1738</td>
</tr>
</tbody>
</table>
<p>For instance, the probability of an adult American using an online
dating site can be calculated as
<span class="math display">\[\begin{multline*}
    P(\text{using an online dating site}) = \\
    \frac{\text{Number that indicated they used an online dating site}}{\text{Total number of people in the poll}}
    = \frac{225}{1738} \approx 13\%.
\end{multline*}\]</span> This is the overall probability of using an online
dating site. Say, we are now interested in the probability of using an
online dating site if one falls in the age group 30-49. Similar to the
above, we have <span class="math display">\[\begin{multline*}
    P(\text{using an online dating site} \mid \text{in age group 30-49}) = \\
    \frac{\text{Number in age group 30-49 that indicated they used an online dating site}}{\text{Total number in age group 30-49}}
    = \frac{86}{512} \approx 17\%.
\end{multline*}\]</span>
Here, the pipe symbol `|’ means <strong>conditional on</strong>.
This is a <strong>conditional probability</strong> as one can consider it the
probability of using an online dating site conditional on being in age
group 30-49.</p>
<p>We can rewrite this conditional probability in terms of ‘regular’
probabilities by dividing both numerator and the denominator by the
total number of people in the poll. That is, <span class="math display">\[\begin{multline*}
    P(\text{using an online dating site} \mid \text{in age group 30-49}) \\
\begin{split}
    &amp;= \frac{\text{Number in age group 30-49 that indicated they used an online dating site}}{\text{Total number in age group 30-49}} \\
    &amp;= \frac{\frac{\text{Number in age group 30-49 that indicated they used an online dating site}}{\text{Total number of people in the poll}}}{\frac{\text{Total number in age group 30-49}}{\text{Total number of people in the poll}}} \\
    &amp;= \frac{P(\text{using an online dating site \&amp; falling in age group 30-49})}{P(\text{Falling in age group 30-49})}.
\end{split}
\end{multline*}\]</span> It turns out this relationship holds true for any
conditional probability and is known as Bayes’ rule:</p>

<div class="definition">
<p><span id="def:unnamed-chunk-2" class="definition"><strong>Definition 1  (Bayes’ Rule)  </strong></span>The conditional probability of the event <span class="math inline">\(A\)</span> conditional on the event <span class="math inline">\(B\)</span> is given by</p>
<span class="math display">\[
  P(A \mid B) = \frac{P(A \,\&amp;\, B)}{P(B)}.
\]</span>
</div>

<div class="example">
<p><span id="exm:unnamed-chunk-3" class="example"><strong>Example 1  </strong></span>What is the probability that an 18-29 year old from Table <a href="#tab:2015gallupDating"><strong>??</strong></a> uses online dating sites?</p>
<p>Note that the question asks a question about 18-29 year olds. Therefore, it conditions on being 18-29 years old.
Bayes’ rule provides a way to compute this conditional probability:</p>
<span class="math display">\[\begin{multline*}
    P(\text{using an online dating site} \mid \text{in age group 18-29}) \\
\begin{split}
    &amp;= \frac{P(\text{using an online dating site \&amp; falling in age group 18-29})}{P(\text{Falling in age group 18-29})} \\
    &amp;= \frac{\frac{\text{Number in age group 18-29 that indicated they used an online dating site}}{\text{Total number of people in the poll}}}{\frac{\text{Total number in age group 18-29}}{\text{Total number of people in the poll}}} \\
    &amp;= \frac{\text{Number in age group 18-29 that indicated they used an online dating site}}{\text{Total number in age group 18-29}} = \frac{60}{315} \approx 19\%.
\end{split}
\end{multline*}\]</span>
</div>
</div>
<div id="sec:diagnostic-testing" class="section level3">
<h3>Bayes’ Rule and Diagnostic Testing</h3>
<p>To better understand conditional probabilities and their importance, let
us consider an example involving the human immunodeficiency virus (HIV).
In the early 1980s, HIV had just been discovered and was rapidly
expanding. There was major concern with the safety of the blood supply.
Also, virtually no cure existed making an HIV diagnosis basically a
death sentence, in addition to the stigma that was attached to the
disease.</p>
<p>These made false positives and false negatives in HIV testing highly
undesirable. A <strong>false positive</strong> is when a test returns postive while
the truth is negative. That would for instance be that someone without
HIV is wrongly diagnosed with HIV, wrongly telling that person they are
going to die and casting the stigma on them. A <strong>false negative</strong> is
when a test returns negative while the truth is positive. That is when
someone with HIV undergoes an HIV test which wrongly comes back
negative. The latter poses a threat to the blood supply if that person
is about to donate blood.</p>
<p>The probability of a false positive if the truth is negative is called
the false positive rate. Similarly, the false negative rate is the
probability of a false negative if the truth is positive. Note that both
these rates are conditional probabilities: The false positive rate of an
HIV test is the probability of a positive result <strong>conditional on</strong> the
person tested having no HIV.</p>
<p>The HIV test we consider is an enzyme-linked immunosorbent assay,
commonly known as an ELISA. We would like to know the probability that
someone (in the early 1980s) has HIV if ELISA tests positive. For this,
we need the following information. ELISA’s true positive rate (one minus
the false negative rate), also referred to as sensitivity, recall, or
probability of detection, is estimated as <span class="math display">\[
  P(\text{ELISA is positive} \mid \text{Person tested has HIV}) = 93\% = 0.93.
\]</span> Its true negative rate (one minus the false positive rate), also
referred to as specificity, is estimated as <span class="math display">\[
  P(\text{ELISA is negative} \mid \text{Person tested has no HIV}) = 99\% = 0.99.
\]</span> Also relevant to our question is the prevalence of HIV in the overall
population, which is estimated to be 1.48 out of every 1000 American
adults. We therefore assume <span class="math display">\[\begin{equation}
  P(\text{Person tested has HIV}) = \frac{1.48}{1000} = 0.00148.
  (\#eq:HIVpositive)
\end{equation}\]</span> Note that the above numbers are estimates. For our
purposes, however, we will treat them as if they were exact.</p>
<p>Our goal is to compute the probability of HIV if ELISA is positive, that
is <span class="math inline">\(P(\text{Person tested has HIV} \mid \text{ELISA is positive})\)</span>. In
none of the above numbers did we condition on the outcome of ELISA.
Fortunately, Bayes’ rule allows is to use the above numbers to compute
the probability we seek. Bayes’ rule states that</p>
<span class="math display" id="eq:HIVconditional">\[\begin{equation}
  P(\text{Person tested has HIV}  \mid \text{ELISA is positive}) = \frac{P(\text{Person tested has HIV} \,\&amp;\, \text{ELISA is positive})}{P(\text{ELISA is positive})}.
   \tag{1}
\end{equation}\]</span>
<p>This can be derived as follows. For someone to test positive and be HIV
positive, that person first needs to be HIV positive and then secondly
test positive. The probability of the first thing happening is
<span class="math inline">\(P(\text{HIV positive}) = 0.00148\)</span>. The probability of then testing
positive is
<span class="math inline">\(P(\text{ELISA is positive} \mid \text{Person tested has HIV}) = 0.93\)</span>,
the true positive rate. This yields for the numerator</p>
<span class="math display" id="eq:HIVjoint">\[\begin{multline}
  P(\text{Person tested has HIV} \,\&amp;\, \text{ELISA is positive}) \\
  \begin{split}
  &amp;= P(\text{Person tested has HIV}) P(\text{ELISA is positive} \mid \text{Person tested has HIV}) \\
  &amp;= 0.00148 \cdot 0.93
  = 0.0013764.
  \end{split}
  \tag{2}
\end{multline}\]</span>
<p>The first step in the above equation is implied by Bayes’ rule: By
multiplying the left- and right-hand side of Bayes’ rule as presented in
Section <a href="#sec:bayes-rule"><strong>??</strong></a> by <span class="math inline">\(P(B)\)</span>, we obtain <span class="math display">\[
  P(A \mid B) P(B) = P(A \,\&amp;\, B).
\]</span></p>
<p>The denominator in <a href="#eq:HIVconditional">(1)</a> can be expanded as</p>
<span class="math display">\[\begin{multline*}
  P(\text{ELISA is positive}) \\
  \begin{split}
  &amp;= P(\text{Person tested has HIV} \,\&amp;\, \text{ELISA is positive}) + P(\text{Person tested has no HIV} \,\&amp;\, \text{ELISA is positive}) \\
  &amp;= 0.0013764 + 0.0099852 = 0.0113616
  \end{split}
\end{multline*}\]</span>
<p>where we used <a href="#eq:HIVjoint">(2)</a> and</p>
<span class="math display">\[\begin{multline*}
  P(\text{Person tested has no HIV} \,\&amp;\, \text{ELISA is positive}) \\
  \begin{split}
  &amp;= P(\text{Person tested has no HIV}) P(\text{ELISA is positive} \mid \text{Person tested has no HIV}) \\
  &amp;= \left(1 - P(\text{Person tested has HIV})\right) \cdot \left(1 - P(\text{ELISA is negative} \mid \text{Person tested has no HIV})\right) \\
  &amp;= \left(1 - 0.00148\right) \cdot \left(1 - 0.99\right) = 0.0099852.
  \end{split}
\end{multline*}\]</span>
<p>Putting this all together and inserting into <a href="#eq:HIVconditional">(1)</a>
reveals
<span class="math display">\[\begin{equation}
P(\\text{Person tested has HIV} \\mid \\text{ELISA is positive}) =
\\frac{0.0013764}{0.0113616} \\approx 0.12.
(\\\#eq:HIVresult)
\\end{equation}
\]</span> So even when the ELISA returns positive, the probability
of having HIV is only 12%. An important reason why this number is so low
is due to the prevalence of HIV. Before testing, one’s probability of
HIV was 0.148%, so the positive test changes that probability
dramatically, but it is still below 50%. That is, it is more likely that
one is HIV negative rather than positive after one positive ELISA test.</p>
<p>Questions like the one we just answered (What is the probability of a
disease if a test returns positive?) are crucial to make medical
diagnoses. As we saw, just the true positive and true negative rates of
a test do not tell the full story, but also a disease’s prevalence plays
a role. Bayes’ rule is a tool to synthesize such numbers into a more
useful probability of having a disease after a test result.</p>

<div class="example">
<span id="exm:unnamed-chunk-4" class="example"><strong>Example 2  </strong></span>What is the probability that someone who tests positive does not actually have HIV?
</div>
<p>We found in <a href="#eq:HIVresult">(<strong>??</strong>)</a> that someone who tests positive has a
<span class="math inline">\(0.12\)</span> probability of having HIV. That implies that the same person has
a <span class="math inline">\(1-0.12=0.88\)</span> probability of not having HIV, despite testing positive.</p>

<div class="example">
<span id="exm:unnamed-chunk-5" class="example"><strong>Example 3  </strong></span>If the individual is at a higher risk for having HIV than a randomly sampled person from the population considered, how, if at all, would you expect <span class="math inline">\(P(\text{Person tested has HIV} \mid \text{ELISA is positive})\)</span> to change?
</div>
<p>If the person has a priori a higher risk for HIV and tests positive,
then the probability of having HIV must be higher than for someone not
at increased risk who also tests positive. Therefore,
<span class="math inline">\(P(\text{Person tested has HIV} \mid \text{ELISA is positive}) &gt; 0.12\)</span>
where <span class="math inline">\(0.12\)</span> comes from <a href="#eq:HIVresult">(<strong>??</strong>)</a>.</p>
<p>One can derive this mathematically by plugging in a larger number in
<a href="#eq:HIVpositive">(<strong>??</strong>)</a> than 0.00148, as that number represents the prior
risk of HIV. Changing the calculations accordingly shows
<span class="math inline">\(P(\text{Person tested has HIV} \mid \text{ELISA is positive}) &gt; 0.12\)</span>.</p>

<div class="example">
<span id="exm:unnamed-chunk-6" class="example"><strong>Example 4  </strong></span>If the false positive rate of the test is higher than 1%, how, if at all, would you expect <span class="math inline">\(P(\text{Person tested has HIV} \mid \text{ELISA is positive})\)</span> to change?
</div>
<p>If the false positive rate increases, the probability of a wrong
positive result increases. That means that a positive test result is
more likely to be wrong and thus less indicative of HIV. Therefore, the
probability of HIV after a positive ELISA goes down such that
<span class="math inline">\(P(\text{Person tested has HIV} \mid \text{ELISA is positive}) &lt; 0.12\)</span>.</p>
</div>
<div id="bayes-updating" class="section level3">
<h3>Bayes Updating</h3>
<p>In the previous section, we saw that one positive ELISA test yields a
probability of having HIV of 12%. To obtain a more convincing
probability, one might want to do a second ELISA test after a first one
comes up positive. What is the probability of being HIV positive if also
the second ELISA test comes back positive?</p>
<p>To solve this problem, we will assume that the correctness of this
second test is not influenced by the first ELISA, that is, the tests are
independent from each other. This assumption probably does not hold true
as it is plausible that if the first test was a false positive, it is
more likely that the second one will be one as well. Nonetheless, we
stick with the independence assumption for simplicity.</p>
<p>In the last section, we used
<span class="math inline">\(P(\text{Person tested has HIV}) = 0.00148\)</span>, see <a href="#eq:HIVpositive">(<strong>??</strong>)</a>,
to compute the probability of HIV after one positive test. If we repeat
those steps but now with <span class="math inline">\(P(\text{Person tested has HIV}) = 0.12\)</span>, the
probability that a person with one positive test has HIV, we exactly
obtain the probability of HIV after two positive tests. Repeating the
maths from the previous section, involving Bayes’ rule, gives</p>
<span class="math display" id="eq:Bayes-updating">\[\begin{multline}
  P(\text{Person tested has HIV} \mid \text{Second ELISA is also positive}) \\
  \begin{split}
  &amp;= \frac{P(\text{Person tested has HIV}) P(\text{Second ELISA is positive} \mid \text{Person tested has HIV})}{P(\text{Second ELISA is also positive})} \\
  &amp;= \frac{0.12 \cdot 0.93}{
  \begin{split}
  &amp;P(\text{Person tested has HIV}) P(\text{Second ELISA is positive} \mid \text{Has HIV}) \\
  &amp;+ P(\text{Person tested has no HIV}) P(\text{Second ELISA is positive} \mid \text{Has no HIV})
  \end{split}
  } \\
  &amp;= \frac{0.1116}{0.12 \cdot 0.93 + (1 - 0.12)\cdot (1 - 0.99)} \approx 0.93.
  \end{split}
  \tag{3}
\end{multline}\]</span>
<p>Since we are considering the same ELISA test, we used the same true
positive and true negative rates as in Section
<a href="#sec:diagnostic-testing"><strong>??</strong></a>. We see that two positive tests makes it
much more probable for someone to have HIV than when only one test comes
up positive.</p>
<p>This process, of using Bayes’ rule to update a probability based on an
event affecting it, is called Bayes’ updating. More generally, the what
one tries to update can be considered ‘prior’ information, sometimes
simply called the <strong>prior</strong>. The event providing information about this
can also be data. Then, updating this prior using Bayes’ rule gives the
information conditional on the data, also known as the <strong>posterior</strong>, as
in the information <strong>after</strong> having seen the data. Going from the prior
to the posterior is Bayes updating.</p>
<p>The probability of HIV after one positive ELISA, 0.12, was the posterior
in the previous section as it was an update of the overall prevalence of
HIV, <a href="#eq:HIVpositive">(<strong>??</strong>)</a>. However, in this section we answered a
question where we used this posterior information as the prior. This
process of using a posterior as prior in a new problem is natural in the
Bayesian framework of updating knowledge based on the data.</p>

<div class="example">
<span id="exm:unnamed-chunk-7" class="example"><strong>Example 5  </strong></span>What is the probability that one actually has HIV after testing positive 3 times on the ELISA? Again, assume that all three ELISAs are independent.
</div>
<p>Analogous to what we did in this section, we can use Bayes’ updating for
this. However, now the prior is the probability of HIV after two
positive ELISAs, that is <span class="math inline">\(P(\text{Person tested has HIV}) = 0.93\)</span>.
Analogous to <a href="#eq:Bayes-updating">(3)</a>, the answer follows as</p>
<span class="math display">\[\begin{multline}
  P(\text{Person tested has HIV} \mid \text{Third ELISA is also positive}) \\
  \begin{split}
  &amp;= \frac{P(\text{Person tested has HIV}) P(\text{Third ELISA is positive} \mid \text{Person tested has HIV})}{P(\text{Third ELISA is also positive})} \\
  &amp;= \frac{0.93 \cdot 0.93}{\begin{split}
  &amp;P(\text{Person tested has HIV}) P(\text{Third ELISA is positive} \mid \text{Has HIV}) \\
  + &amp;P(\text{Person tested has no HIV}) P(\text{Third ELISA is positive} \mid \text{Has no HIV})
  \end{split}} \\
  &amp;= \frac{0.8649}{0.93 \cdot 0.93 + (1 - 0.93)\cdot (1 - 0.99)} \approx 0.999.
  \end{split}
\end{multline}\]</span>
</div>
<div id="bayesian-vs.-frequentist-definitions-of-probability" class="section level3">
<h3>Bayesian vs. Frequentist Definitions of Probability</h3>
<p>The frequentist definition of probability is based on observation of a
large number of trials. The probability for an event <span class="math inline">\(E\)</span> to occur is
<span class="math inline">\(P(E)\)</span>, and assume we get <span class="math inline">\(n_E\)</span> successes out of <span class="math inline">\(n\)</span> trials. Then we
have <span class="math display">\[\begin{equation}
P(E) = \lim_{n \rightarrow \infty} \dfrac{n_E}{n}.
\end{equation}\]</span></p>
<p>On the other hand, the Bayesian definition of probability <span class="math inline">\(P(E)\)</span>
reflects our prior beliefs, so <span class="math inline">\(P(E)\)</span> can be any probability
distribution, provided that it is consistent with all of our beliefs.
(For example, we cannot believe that the probability of a coin landing
heads is 0.7 and that the probability of getting tails is 0.8, because
they are inconsistent.)</p>
<p>The two definitions result in different methods of inference. Using the
frequentist approach, we describe the confidence level as the proportion
of random samples from the same population that produced confidence
intervals which contain the true population parameter. For example, if
we generated 100 random samples from the population, and 95 of the
samples contain the true parameter, then the confidence level is 95%.
Note that each sample either contains the true parameter or does not, so
the confidence level is NOT the probability that a given interval
includes the true population parameter.</p>

<div class="example">
<span id="exm:unnamed-chunk-8" class="example"><strong>Example 6  </strong></span>Based on a 2015 Pew Research poll on 1,500 adults: "We are 95% confident that 60% to 64% of Americans think the federal government does not do enough for middle class people.
</div>
<p>The correct interpretation is: 95% of random samples of 1,500 adults
will produce confidence intervals that contain the true proportion of
Americans who think the federal government does not do enough for middle
class people.</p>
<p>Here are two common misconceptions:</p>
<ul>
<li><p>There is a 95% chance that this confidence interval includes the
true population proportion.</p></li>
<li><p>The true population proportion is in this interval 95% of the time.</p></li>
</ul>
<p>The probability that a given confidence interval captures the true
parameter is either zero or one. To a frequentist, the problem is that
one never knows whether a specific interval contains the true value with
probability zero or one. So a frequentist says that “95% of similarly
constructed intervals contain the true value”.</p>
<p>The second (incorrect) statement sounds like the true proportion is a
value that moves around that is sometimes in the given interval and
sometimes not in it. Actually the true proportion is constant, it’s the
various intervals constructed based on new samples that are different.</p>
<p>The Bayesian alternative is the credible interval, which has a
definition that is easier to interpret. Since a Bayesian is allowed to
express uncertainty in terms of probability, a Bayesian credible
interval is a range for which the Bayesian thinks that the probability
of including the true value is, say, 0.95. Thus a Bayesian can say that
there is a 95% chance that the credible interval contains the true
parameter value.</p>

<div class="example">
<span id="exm:unnamed-chunk-9" class="example"><strong>Example 7  </strong></span>The posterior distribution yields a 95% credible interval of 60% to 64% for the proportion of Americans who think the federal government does not do enough for middle class people.
</div>
<p>We can say that there is a 95% probability that the proportion is
between 60% and 64% because this is a <strong>credible</strong> interval, and more
details will be introduced later in the course.
## Inference for a Proportion</p>
</div>
<div id="inference-for-a-proportion-frequentist-approach" class="section level3">
<h3>Inference for a Proportion: Frequentist Approach</h3>

<div class="example">
<p><span id="exm:RU-486" class="example"><strong>Example 8  </strong></span>RU-486 is claimed to be an effective “morning after” contraceptive pill, but is it really effective?</p>
<p>Data: A total of 40 women came to a health clinic asking for emergency contraception (usually to prevent pregnancy after unprotected sex). They were randomly assigned to RU-486 (treatment) or standard therapy (control), 20 in each group. In the treatment group, 4 out of 20 became pregnant. In the control group, the pregnancy rate is 16 out of 20.</p>
Question: How strongly do these data indicate that the treatment is more effective than the control?
</div>
<p>To simplify the framework, let’s make it a one proportion problem and just consider the 20 total pregnancies because the two groups have the same sample size. If the treatment and control are equally effective, then the probability that a pregnancy comes from the treatment group (<span class="math inline">\(p\)</span>) should be 0.5. If RU-486 is more effective, then the probability that a pregnancy comes from the treatment group (<span class="math inline">\(p\)</span>) should be less than 0.5.</p>
<p>Therefore, we can form the hypotheses as below:</p>
<ul>
<li><p><span class="math inline">\(p =\)</span> probability that a given pregnancy comes from the treatment group</p></li>
<li><p><span class="math inline">\(H_0: p = 0.5\)</span> (no difference, a pregnancy is equally likely to come from the treatment or control group)</p></li>
<li><p><span class="math inline">\(H_A: p &lt; 0.5\)</span> (treatment is more effective, a pregnancy is less likely to come from the treatment group)</p></li>
</ul>
<p>A p-value is needed to make an inference decision with the frequentist approach. The definition of p-value is the probability of observing something <strong>at least</strong> as extreme as the data, given that the null hypothesis (<span class="math inline">\(H_0\)</span>) is true. “More extreme” means in the direction of the alternative hypothesis (<span class="math inline">\(H_A\)</span>).</p>
<p>Since <span class="math inline">\(H_0\)</span> states that the probability of success (pregnancy) is 0.5, we can calculate the p-value from 20 independent Bernoulli trials where the probability of success is 0.5. The outcome of this experiment is 4 successes in 20 trials, so the goal is to obtain 4 or fewer successes in the 20 Bernoulli trials.</p>
<p>This probability can be calculated exactly from a binomial distribution with <span class="math inline">\(n=20\)</span> trials and success probability <span class="math inline">\(p=0.5\)</span>. Assume <span class="math inline">\(k\)</span> is the actual number of successes observed, the p-value is</p>
<p><span class="math display">\[P(k \leq 4) = P(k = 0) + P(k = 1) + P(k = 2) + P(k = 3) + P(k = 4)\]</span>.</p>
<pre class="r"><code>sum(dbinom(0:4, size = 20, p = 0.5))</code></pre>
<pre><code>## [1] 0.005908966</code></pre>
<p>According to <span class="math inline">\(\mathsf{R}\)</span>, the probability of getting 4 or fewer successes in 20 trials is 0.0059. Therefore, given that pregnancy is equally likely in the two groups, we get the chance of observing 4 or fewer preganancy in the treatment group is 0.0059. With such a small probability, we reject the null hypothesis and conclude that the data provide convincing evidence for the treatment being more effective than the control.</p>
</div>
<div id="inference-for-a-proportion-bayesian-approach" class="section level3">
<h3>Inference for a Proportion: Bayesian Approach</h3>
<p>This section uses the same example, but this time we make the inference for the proportion from a Bayesian approach. Recall that we still consider only the 20 total pregnancies, 4 of which come from the treatment group. The question we would like to answer is that how likely is for 4 pregnancies to occur in the treatment group. Also remember that if the treatment and control are equally effective, and the sample sizes for the two groups are the same, then the probability (<span class="math inline">\(p\)</span>) that the pregnancy comes from the treatment group is 0.5.</p>
<p>Within the Bayesian framework, we need to make some assumptions on the models which generated the data. First, <span class="math inline">\(p\)</span> is a probability, so it can take on any value between 0 and 1. However, let’s simplify by using discrete cases – assume <span class="math inline">\(p\)</span>, the chance of a pregnancy comes from the treatment group, can take on nine values, from 10%, 20%, 30%, up to 90%. For example, <span class="math inline">\(p = 20\%\)</span> means that among 10 pregnancies, it is expected that 2 of them will occur in the treatment group. Note that we consider all nine models, compared with the frequentist paradigm that whe consider only one model.</p>
<p>Table <a href="#tab:RU-486prior">2</a> specifies the prior probabilities that we want to assign to our assumption. There is no unique correct prior, but any prior probability should reflect our beliefs prior to the experiement. The prior probabilities should incorporate the information from all relevant research before we perform the current experiement.</p>
<pre class="r"><code>p &lt;- seq(from=0.1, to=0.9, by=0.1)
prior &lt;- c(rep(0.06, 4), 0.52, rep(0.06, 4))
likelihood &lt;- dbinom(4, size = 20, prob = p)

# posterior
numerator &lt;- prior * likelihood
denominator &lt;- sum(numerator)
posterior &lt;- numerator / denominator
# sum(posterior)

temp &lt;- matrix(c(p,
                 prior,
                 likelihood,
                 numerator,
                 posterior), 
               nrow = 5, byrow = TRUE)
rownames(temp) &lt;- c(&quot;Model (p)&quot;, &quot;Prior P(model)&quot;, 
                    &quot;Likelihood P(data|model)&quot;,
                    &quot;P(data|model) x P(model)&quot;,
                    &quot;Posterior P(model|data)&quot;)

knitr::kable(
  x = temp,
  booktabs = TRUE,
  caption = &#39;Prior, likelihood, and posterior probabilities for each of the 9 models&#39;,
  digits = 4,
  format.args = list(scientific = FALSE)
)</code></pre>
<table>
<caption><span id="tab:RU-486prior">Table 2: </span>Prior, likelihood, and posterior probabilities for each of the 9 models</caption>
<tbody>
<tr class="odd">
<td align="left">Model (p)</td>
<td align="right">0.1000</td>
<td align="right">0.2000</td>
<td align="right">0.3000</td>
<td align="right">0.4000</td>
<td align="right">0.5000</td>
<td align="right">0.6000</td>
<td align="right">0.70</td>
<td align="right">0.80</td>
<td align="right">0.90</td>
</tr>
<tr class="even">
<td align="left">Prior P(model)</td>
<td align="right">0.0600</td>
<td align="right">0.0600</td>
<td align="right">0.0600</td>
<td align="right">0.0600</td>
<td align="right">0.5200</td>
<td align="right">0.0600</td>
<td align="right">0.06</td>
<td align="right">0.06</td>
<td align="right">0.06</td>
</tr>
<tr class="odd">
<td align="left">Likelihood P(data|model)</td>
<td align="right">0.0898</td>
<td align="right">0.2182</td>
<td align="right">0.1304</td>
<td align="right">0.0350</td>
<td align="right">0.0046</td>
<td align="right">0.0003</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
</tr>
<tr class="even">
<td align="left">P(data|model) x P(model)</td>
<td align="right">0.0054</td>
<td align="right">0.0131</td>
<td align="right">0.0078</td>
<td align="right">0.0021</td>
<td align="right">0.0024</td>
<td align="right">0.0000</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
</tr>
<tr class="odd">
<td align="left">Posterior P(model|data)</td>
<td align="right">0.1748</td>
<td align="right">0.4248</td>
<td align="right">0.2539</td>
<td align="right">0.0681</td>
<td align="right">0.0780</td>
<td align="right">0.0005</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
<td align="right">0.00</td>
</tr>
</tbody>
</table>
<p>This prior incorporates two beliefs: the probability of <span class="math inline">\(p = 0.5\)</span> is highest, and the benefit of the treatment is symmetric. The second belief means that the treatment is equally likely to be better or worse than the standard treatment. Now it is natural to ask how I came up with this prior, and the specification will be discussed in detail later in the course.</p>
<p>Next, let’s calculate the likelihood – the probability of observed data for each model considered. In mathematical terms, we have</p>
<p><span class="math display">\[ P(\text{data}|\text{model}) = P(k = 4 | n = 20, p)\]</span></p>
<p>The likelihood can be computed as a binomial with 4 successes and 20 trials with <span class="math inline">\(p\)</span> is equal to the assumed value in each model. The values are listed in Table <a href="#tab:RU-486prior">2</a>.</p>
<p>After setting up the prior and computing the likelihood, we are ready to calculate the posterior using the Bayes’ rule, that is,</p>
<p><span class="math display">\[P(\text{model}|\text{data}) = \frac{P(\text{model})P(\text{data}|\text{model})}{P(\text{data})}\]</span></p>
<p>The posterior probability values are also listed in Table <a href="#tab:RU-486prior">2</a>, and the highest probability occurs at <span class="math inline">\(p=0.2\)</span>, which is 42.48%. Note that the priors and posteriors across all models both sum to 1.</p>
<p>In decision making, we choose the model with the highest posterior probability, which is <span class="math inline">\(p=0.2\)</span>. In comparison, the highest prior probability is at <span class="math inline">\(p=0.5\)</span> with 52%, and the posterior probability of <span class="math inline">\(p=0.5\)</span> drops to 7.8%. This demonstrates how we update our beliefs based on observed data. Note that the calculation of posterior, likelihood, and prior is unrelated to the frequentist concept (data “at least as extreme as observed”).</p>
<p>Here are the histograms of the prior, the likelihood, and the posterior probabilities:</p>
<pre class="r"><code>par(mfrow = c(1,3), bg = NA)
barplot(prior, names.arg = p, las = 2, main = &quot;Prior&quot;)
barplot(likelihood, names.arg = p, las = 2, main = &quot;Likelihood&quot;)
barplot(posterior, names.arg = p, las = 2, main = &quot;Posterior&quot;)</code></pre>
<div class="figure"><span id="fig:RU-486plot"></span>
<img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/RU-486plot-1.svg" alt="Original: sample size $n=20$ and number of successes $k=4$" width="960" />
<p class="caption">
Figure 1: Original: sample size <span class="math inline">\(n=20\)</span> and number of successes <span class="math inline">\(k=4\)</span>
</p>
</div>
<p>We started with the high prior at <span class="math inline">\(p=0.5\)</span>, but the data likelihood peaks at <span class="math inline">\(p=0.2\)</span>. And we updated our prior based on observed data to find the posterior. The Bayesian paradigm, unlike the frequentist approach, allows us to make direct probability statements about our models. For example, we can calculate the probability that RU-486, the treatment, is more effective than the control as the sum of the posteriors of the models where <span class="math inline">\(p&lt;0.5\)</span>. Adding up the relevant posterior probabilities in Table <a href="#tab:RU-486prior">2</a>, we get the chance that the treatment is more effective than the control is 92.16%.</p>
</div>
<div id="effect-of-sample-size-on-the-posterior" class="section level3">
<h3>Effect of Sample Size on the Posterior</h3>
<p>The RU-486 example is summarized in Figure <a href="#fig:RU-486plot">1</a>, and let’s look at what the posterior distribution would look like if we had more data.</p>
<pre class="r"><code># Use the same prior in this example

# more data: x2 -----------------------------------------------------
likelihood &lt;- dbinom(4*2, size = 20*2, prob = p)
numerator &lt;- prior * likelihood
denominator &lt;- sum(numerator)
posterior &lt;- numerator / denominator

par(mfrow = c(1,3), bg = NA)
barplot(prior, names.arg = p, las = 2, main = &quot;Prior&quot;)
barplot(likelihood, names.arg = p, las = 2, main = &quot;Likelihood&quot;)
barplot(posterior, names.arg = p, las = 2, main = &quot;Posterior&quot;)</code></pre>
<div class="figure"><span id="fig:RU-486plotX2"></span>
<img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/RU-486plotX2-1.svg" alt="More data: sample size $n=40$ and number of successes $k=8$" width="960" />
<p class="caption">
Figure 2: More data: sample size <span class="math inline">\(n=40\)</span> and number of successes <span class="math inline">\(k=8\)</span>
</p>
</div>
<p>Suppose our sample size was 40 instead of 20, and the number of successes was 8 instead of 4. Note that the ratio between the sample size and the number of successes is still 20%. We will start with the same prior distribution. Then calculate the likelihood of the data which is also centered at 0.20, but is less variable than the original likelihood we had with the smaller sample size. And finally put these two together to obtain the posterior distribution. The posterior also has a peak at p is equal to 0.20, but the peak is taller, as shown in Figure <a href="#fig:RU-486plotX2">2</a>. In other words, there is more mass on that model, and less on the others.</p>
<pre class="r"><code># Use the same prior in this example

# more data: x10 ----------------------------------------------------
likelihood &lt;- dbinom(4*10, size = 20*10, prob = p)
numerator &lt;- prior * likelihood
denominator &lt;- sum(numerator)
posterior &lt;- numerator / denominator

par(mfrow = c(1,3), bg = NA)
barplot(prior, names.arg = p, las = 2, main = &quot;Prior&quot;)
barplot(likelihood, names.arg = p, las = 2, main = &quot;Likelihood&quot;)
barplot(posterior, names.arg = p, las = 2, main = &quot;Posterior&quot;)</code></pre>
<div class="figure"><span id="fig:RU-486plotX10"></span>
<img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/RU-486plotX10-1.svg" alt="More data: sample size $n=200$ and number of successes $k=40$" width="960" />
<p class="caption">
Figure 3: More data: sample size <span class="math inline">\(n=200\)</span> and number of successes <span class="math inline">\(k=40\)</span>
</p>
</div>
<p>To illustrate the effect of the sample size even further, we are going to keep increasing our sample size, but still maintain the the 20% ratio between the sample size and the number of successes. So let’s consider a sample with 200 observations and 40 successes. Once again, we are going to use the same prior and the likelihood is again centered at 20% and almost all of the probability mass in the posterior is at p is equal to 0.20. The other models do not have zero probability mass, but they’re posterior probabilities are very close to zero.</p>
<p>Figure <a href="#fig:RU-486plotX10">3</a> demonstrates that <strong>as more data are collected, the likelihood ends up dominating the prior</strong>. This is why, while a good prior helps, a bad prior can be overcome with a large sample. However, it’s important to note that this will only work as long as we do not place a zero probability mass on any of the models in the prior.
## Frequentist vs. Bayesian Inference</p>
</div>
<div id="frequentist-vs.-bayesian-inference" class="section level3">
<h3>Frequentist vs. Bayesian Inference</h3>
<p>In this section, we will solve a simple inference problem using both frequentist and Bayesian approaches. Then we will compare our results based on decisions based on the two methods, to see whether we get the same answer or not. If we do not, we will discuss why that happens.</p>

<div class="example">
<p><span id="exm:MM" class="example"><strong>Example 9  </strong></span>We have a population of M&amp;M’s, and in this population the percentage of yellow M&amp;M’s is either 10% or 20%. You have been hired as a statistical consultant to decide whether the true percentage of yellow M&amp;M’s is 10% or 20%.</p>
<p>Payoffs/losses: You are being asked to make a decision, and there are associated payoff/losses that you should consider. If you make the correct decision, your boss gives you a bonus. On the other hand, if you make the wrong decision, you lose your job.</p>
<p>Data: You can “buy” a random sample from the population – You pay $200 for each M&amp;M, and you must buy in $1,000 increments (5 M&amp;Ms at a time). You have a total of $4,000 to spend, i.e., you may buy 5, 10, 15, or 20 M&amp;Ms.</p>
Remark: Remember that the cost of making a wrong decision is high, so you want to be fairly confident of your decision. At the same time, though, data collection is also costly, so you don’t want to pay for a sample larger than you need. If you believe that you could actually make a correct decision using a smaller sample size, you might choose to do so and save money and resources.
</div>
<p>Let’s start with the frequentist inference.</p>
<ul>
<li><p>Hypothesis: <span class="math inline">\(H_0\)</span> is 10% yellow M&amp;Ms, and <span class="math inline">\(H_A\)</span> is &gt;10% yellow M&amp;Ms.</p></li>
<li><p>Significance level: <span class="math inline">\(\alpha = 0.05\)</span>.</p></li>
<li><p>One sample: red, green, <strong>yellow</strong>, blue, orange</p></li>
<li><p>Observed data: <span class="math inline">\(k=1, n=5\)</span></p></li>
<li><p>P-value: <span class="math inline">\(P(k \geq 1 | n=5, p=0.10) = 1 - P(k=0 | n=5, p=0.10) = 1 - 0.90^5 \approx 0.41\)</span></p></li>
</ul>
<p>Note that the p-value is the probability of observed or more extreme outcome given that the null hypothesis is true.</p>
<p>Therefore, we fail to reject <span class="math inline">\(H_0\)</span> and conclude that the data do not provide convincing evidence that the proportion of yellow M&amp;M’s is greater than 10%. This means that if we had to pick between 10% and 20% for the proportion of M&amp;M’s, even though this hypothesis testing procedure does not actually confirm the null hypothesis, we would likely stick with 10% since we couldn’t find evidence that the proportion of yellow M&amp;M’s is greater than 10%.</p>
<p>The Bayesian inference works differently as below.</p>
<ul>
<li><p>Hypotheses: <span class="math inline">\(H_1\)</span> is 10% yellow M&amp;Ms, and <span class="math inline">\(H_2\)</span> is 20% yellow M&amp;Ms.</p></li>
<li><p>Prior: <span class="math inline">\(P(H_1) = P(H_2) = 0.5\)</span></p></li>
<li><p>Sample: red, green, <strong>yellow</strong>, blue, orange</p></li>
<li><p>Observed data: <span class="math inline">\(k=1, n=5\)</span></p></li>
<li><p>Likelihood:</p></li>
</ul>
<p><span class="math display">\[\begin{aligned}
P(k=1 | H_1) &amp;= \left( \begin{array}{c} 5 \\ 1 \end{array} \right) \times 0.10 \times 0.90^4 \approx 0.33 \\
P(k=1 | H_2) &amp;= \left( \begin{array}{c} 5 \\ 1 \end{array} \right) \times 0.20 \times 0.80^4 \approx 0.41
\end{aligned}\]</span></p>
<ul>
<li>Posterior</li>
</ul>
<p><span class="math display">\[\begin{aligned}
P(H_1 | k=1) &amp;= \frac{P(H_1)P(k=1 | H_1)}{P(k=1)} = \frac{0.5 \times 0.33}{0.5 \times 0.33 + 0.5 \times 0.41} \approx 0.45 \\
P(H_2 | k=1) &amp;= 1 - 0.45 = 0.55
\end{aligned}\]</span></p>
<p>The posterior probabilities of whether <span class="math inline">\(H_1\)</span> or <span class="math inline">\(H_2\)</span> is correct are close to each other. As a result, with equal priors and a low sample size, it is difficult to make a decision with a strong confidence, given the observed data. However, <span class="math inline">\(H_2\)</span> has a higher posterior probability than <span class="math inline">\(H_1\)</span>, so if we had to make a decision at this point, we should pick <span class="math inline">\(H_2\)</span>, i.e., the proportion of yellow M&amp;Ms is 20%. Note that this decision contradicts with the decision based on the frequentist approach.</p>
<p>Table <a href="#tab:freq-vs-bayes">3</a> summarizes what the results would look like if we had chosen larger sample sizes. Under each of these scenarios, the frequentist method yields a higher p-value than our significance level, so we would fail to reject the null hypothesis with any of these samples. On the other hand, the Bayesian method always yields a higher posterior for the second model where <span class="math inline">\(p\)</span> is equal to 0.20. So the decisions that we would make are contradictory to each other.</p>
<pre class="r"><code>temp &lt;- matrix(c(&quot;Observed Data&quot;,&quot;P(k or more | 10% yellow)&quot;, 
                 &quot;P(10% yellow | n, k)&quot;, &quot;P(20% yellow | n, k)&quot;,
                 &quot;n = 5, k = 1&quot;,  0.41, 0.45, 0.55,
                 &quot;n = 10, k = 2&quot;, 0.26, 0.39, 0.61,
                 &quot;n = 15, k = 3&quot;, 0.18, 0.34, 0.66,
                 &quot;n = 20, k = 4&quot;, 0.13, 0.29, 0.71), nrow=5, byrow=TRUE)

colnames(temp) &lt;- c(&quot;&quot;, &quot;Frequentist&quot;, &quot;Bayesian H_1&quot;, &quot;Bayesian H_2&quot;)


knitr::kable(
  x = temp, booktabs = TRUE,
  caption = &quot;Frequentist and Bayesian probabilities for larger sample sizes&quot;
)</code></pre>
<table>
<caption><span id="tab:freq-vs-bayes">Table 3: </span>Frequentist and Bayesian probabilities for larger sample sizes</caption>
<colgroup>
<col width="14%" />
<col width="31%" />
<col width="26%" />
<col width="26%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">Frequentist</th>
<th align="left">Bayesian H_1</th>
<th align="left">Bayesian H_2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Observed Data</td>
<td align="left">P(k or more | 10% yellow)</td>
<td align="left">P(10% yellow | n, k)</td>
<td align="left">P(20% yellow | n, k)</td>
</tr>
<tr class="even">
<td align="left">n = 5, k = 1</td>
<td align="left">0.41</td>
<td align="left">0.45</td>
<td align="left">0.55</td>
</tr>
<tr class="odd">
<td align="left">n = 10, k = 2</td>
<td align="left">0.26</td>
<td align="left">0.39</td>
<td align="left">0.61</td>
</tr>
<tr class="even">
<td align="left">n = 15, k = 3</td>
<td align="left">0.18</td>
<td align="left">0.34</td>
<td align="left">0.66</td>
</tr>
<tr class="odd">
<td align="left">n = 20, k = 4</td>
<td align="left">0.13</td>
<td align="left">0.29</td>
<td align="left">0.71</td>
</tr>
</tbody>
</table>
<p>However, if we had set up our framework differently in the frequentist method and set our null hypothesis to be <span class="math inline">\(p = 0.20\)</span> and our alternative to be <span class="math inline">\(p &lt; 0.20\)</span>, we would obtain different results. This shows that <strong>the frequentist method is highly sensitive to the null hypothesis</strong>, while in the Bayesian method, our results would be the same regardless of which order we evaluate our models.</p>
</div>
</div>
</div>
<div id="bayesian-inference" class="section level1">
<h1>2 Bayesian Inference</h1>
<p>This chapter is focused on the continuous version of Bayes’ rule and how to use it in a conjugate family. The RU-486 example will allow us to discuss Bayesian modeling in a concrete way. It also leads naturally to a Bayesian analysis without conjugacy. For the non-conjugate case, there is usually no simple mathematical expression, and one must resort to computation. Finally, we discuss credible intervals, i.e., the Bayesian analog of frequentist confidence intervals, and Bayesian estimation and prediction.</p>
<p>It is assumed that the readers have mastered the concept of conditional probability and the Bayes’ rule for discrete random variables. Calculus is not required for this chapter; however, for those who do, we shall briefly look at an integral.</p>
<pre class="r"><code>library(ggplot2)</code></pre>
<div id="continuous-variables-and-eliciting-probability-distributions" class="section level2">
<h2>Continuous Variables and Eliciting Probability Distributions</h2>
<p>We are going to introduce continuous variables and how to elicit probability distributions, from a prior belief to a posterior distribution using the Bayesian framework.</p>
<div id="from-the-discrete-to-the-continuous" class="section level3">
<h3>From the Discrete to the Continuous</h3>
<p>This section leads the reader from the discrete random variable to continuous random variables. Let’s start with the binomial random variable such as the number of heads in ten coin tosses, can only take a discrete number of values: 0, 1, 2, up to 10.</p>
<p>When the probability of a coin landing heads is <span class="math inline">\(p\)</span>, the chance of getting <span class="math inline">\(k\)</span> heads in <span class="math inline">\(n\)</span> tosses is</p>
<p><span class="math display">\[P(X = k) = \left( \begin{array}{c} n \\ k \end{array} \right) p^k (1-p)^{n-k}\]</span>.</p>
<p>This formula is called the <strong>probability mass function</strong> (pmf) for the binomial.</p>
<p>The probability mass function can be visualized as a histogram in Figure <a href="#fig:histogram">4</a>. The area under the histogram is one, and the area of each bar is the probability of seeing a binomial random variable, whose value is equal to the x-value at the center of the bars base.</p>
<pre class="r"><code>library(ggthemes)
data = data.frame(trials = c(0,1,1,1,2,2,2,3))

ggplot(data, aes(data$trials)) + 
  geom_histogram(aes(y=..count../sum(..count..))) +
  xlab(&quot;&quot;) + ylab(&quot;&quot;) + theme_tufte()</code></pre>
<div class="figure" style="text-align: center"><span id="fig:histogram"></span>
<img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/histogram-1.svg" alt="Histogram of binomial random variable" width="288" />
<p class="caption">
Figure 4: Histogram of binomial random variable
</p>
</div>
<p>In contrast, the normal distribution, a.k.a. Gaussian distribution or the bell-shaped curve, can take any numerical value in <span class="math inline">\((-\infty,+\infty)\)</span>. A random variable generated from a normal distribution because it can take a continuum of values.</p>
<p>In general, if the set of possible values a random variable can take are separated points, it is a discrete random variable. But if it can take any value in some (possibly infinite) interval, then it is a continuous random variable.</p>
<p>When the random variable is <strong>discrete</strong>, it has a <strong>probability mass function</strong> or pmf. That pmf tells us the probability that the random variable takes each of the possible values. But when the random variable is continuous, it has probability zero of taking any single value. (Hence probability zero does not equal to impossible, an event of probabilty zero can still happen.)</p>
<p>We can only talk about the probability of a continuous random variable lined within some interval. For example, suppose that heights are approximately normally distributed. The probability of finding someone who is exactly 6 feet and 0.0000 inches tall (for an infinite number of 0s after the decimal point) is 0. But we can easily calculate the probability of finding someone who is between 5’11" inches tall and 6’1" inches tall.</p>
<p>A <strong>continuous</strong> random variable has a <strong>probability density function</strong> or pdf, instead of probability mass functions. The probability of finding someone whose height lies between 5’11" (71 inches) and 6’1" (73 inches) is the area under the pdf curve for height between those two values, as shown in the blue area of Figure <a href="#fig:pdf-auc">5</a>.<!--^[Code reference: http://www.statmethods.net/advgraphs/probability.html]--></p>
<pre class="r"><code>library(ggplot2)
library(ggthemes)
# 5&#39;11&quot;=71 inches; 6&#39;1&quot;=73 inches

x = seq(from = 62, to = 82, by = 0.001)
hx = dnorm(x,mean = 72, sd = 2)

#plot(x,hx,type=&quot;n&quot;,xlab=&quot;Height (inches)&quot;,ylab=&quot;Density&quot;)
#lb=+71; ub=+73
#ii &lt;- x &gt;= lb &amp; x &lt;= ub
#lines(x, hx)
#polygon(c(lb,x[ii],ub), c(0,hx[ii],0), col=&quot;blue&quot;) 


# New code
mydata = data.frame(x = x, y = hx)
shade = rbind(c(71, 0), subset(mydata, x &gt; 71 &amp; x &lt; 73), 
                 c(73, 0))
ytop1 = dnorm(71, mean = 72, sd = 2)
ytop2 = dnorm(73, mean = 72, sd = 2)

p = qplot(x = mydata$x, y = mydata$y, geom = &quot;line&quot;, col = I(&quot;black&quot;))
p = p + geom_segment(aes(x = 71, y = 0, xend = 71, yend = ytop1), color = &quot;dodgerblue3&quot;) + 
  geom_segment(aes(x = 73, y = 0, xend = 73, yend = ytop2), color = &quot;dodgerblue3&quot;) +
  geom_polygon(data = shade, aes(x = x, y = y), fill = &quot;dodgerblue3&quot;) + 
  xlab(&quot;Height (inches)&quot;) + ylab(&quot;Probability Density&quot;) + theme_tufte() 
print(p)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:pdf-auc"></span>
<img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/pdf-auc-1.svg" alt="Area under curve for the probability density function" width="70%" />
<p class="caption">
Figure 5: Area under curve for the probability density function
</p>
</div>
<p>For example, a normal distribution with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span> (i.e., variance <span class="math inline">\(\sigma^2\)</span>) is defined as</p>
<p><span class="math display">\[f(x) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp[-\frac{1}{2\sigma^2}(x-\mu)^2],\]</span></p>
<p>where <span class="math inline">\(x\)</span> is any value the random variable <span class="math inline">\(X\)</span> can take. This is denoted as <span class="math inline">\(X \sim N(\mu,\sigma^2)\)</span>, where <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span> are the parameters of the normal distribution.</p>
<p>Recall that a probability mass function assigns the probability that a random variable takes a specific value for the discrete set of possible values. The sum of those probabilities over all possible values must equal one.</p>
<p>Similarly, a probability density function is any <span class="math inline">\(f(x)\)</span> that is non-negative and has area one underneath its curve. The pdf can be regarded as the limit of histograms made from its sample data. As the sample size becomes infinitely large, the bin width of the histogram shrinks to zero.</p>
<p>There are infinite number of pmf’s and an infinite number of pdf’s. Some distributions are so important that they have been given names:</p>
<ul>
<li><p>Continuous: normal, uniform, beta, gamma</p></li>
<li><p>Discrete: binomial, Poisson</p></li>
</ul>
<p>Here is a summary of the key ideas in this section:</p>
<ol style="list-style-type: decimal">
<li><p>Continuous random variables exist and they can take any value within some possibly infinite range.</p></li>
<li><p>The probability that a continuous random variable takes a specific value is zero.</p></li>
<li><p>Probabilities from a continuous random variable are determined by the density function with this non-negative and the area beneath it is one.</p></li>
<li><p>We can find the probability that a random variable lies between two values (<span class="math inline">\(c\)</span> and <span class="math inline">\(d\)</span>) as the area under the density function that lies between them.</p></li>
</ol>
</div>
<div id="elicitation" class="section level3">
<h3>Elicitation</h3>
<p>Next, we introduce the concept of prior elicitation in Bayesian statistics. Often, one has a belief about the distribution of one’s data. You may think that your data come from a binomial distribution and in that case you typically know the <span class="math inline">\(n\)</span>, the number of trials but you usually do not know <span class="math inline">\(p\)</span>, the probability of success. Or you may think that your data come from a normal distribution. But you do not know the mean <span class="math inline">\(\mu\)</span> or the standard deviation <span class="math inline">\(\sigma\)</span> of the normal. Beside to knowing the distribution of one’s data, you may also have beliefs about the unknown <span class="math inline">\(p\)</span> in the binomial or the unknown mean <span class="math inline">\(\mu\)</span> in the normal.</p>
<p>Bayesians express their belief in terms of personal probabilities. These personal probabilities encapsulate everything a Bayesian knows or believes about the problem. But these beliefs must obey the laws of probability, and be consistent with everything else the Bayesian knows.</p>

<div class="example">
<span id="exm:200percent" class="example"><strong>Example 10  </strong></span>You cannot say that your probability of passing this course is 200%, no matter how confident you are. A probability value must be between zero and one. (If you still think you have a probability of 200% to pass the course, you are definitely not going to pass it.)
</div>

<div class="example">
<span id="exm:binomial-data" class="example"><strong>Example 11  </strong></span>You may know nothing at all about the value of <span class="math inline">\(p\)</span> that generated some binomial data. In which case any value between zero and one is equally likely, you may want to make an inference on the proportion of people who would buy a new band of toothpaste. If you have industry experience, you may have a strong belief about the value of <span class="math inline">\(p\)</span>, but if you are new to the industry you would do nothing about <span class="math inline">\(p\)</span>. In any value between zero and one seems equally like a deal. This major personal probability is the uniform distribution whose probably density function is flat, denoted as <span class="math inline">\(\text{Unif}(0,1)\)</span>.
</div>

<div class="example">
<span id="exm:coin-toss" class="example"><strong>Example 12  </strong></span>If you were tossing a coin, most people believed that the probability of heads is pretty close to half. They know that some coins are biased and that some coins may have two heads or two tails. And they probably also know that coins are not perfectly balanced. Nonetheless, before they start to collect data by tossing the coin and counting the number of heads their belief is that values of <span class="math inline">\(p\)</span> near 0.5 are very likely, whereas values of <span class="math inline">\(p\)</span> near 0 or 1 are very unlikely.
</div>

<div class="example">
<span id="exm:marriage" class="example"><strong>Example 13  </strong></span>In real life, here are two ways to elicit a probability that you cousin will get married. A frequentist might go to the U.S. Census records and determine what proportion of people get married (or, better, what proportion of people of your cousin’s ethnicity, education level, religion, and age cohort are married). In contrast, a Bayesian might think “My cousin is brilliant, attractive, and fun. The probability that my cousin gets married is really high – probably around 0.97.”
</div>
<p>So a Bayesian will seek to express their belief about the value of <span class="math inline">\(p\)</span> through a probability distribution, and a very flexible family of distributions for this purpose is the <strong>beta family</strong>. A member of the beta family is specified by two parameters, <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>; we denote this as <span class="math inline">\(p \sim \text{beta}(\alpha, \beta)\)</span>. The probability density function is
<span class="math display" id="eq:beta">\[
\begin{equation}
f(p) = \frac{\text{Ga}mma(\alpha+\beta)}{\text{Ga}mma(\alpha)\text{Ga}mma(\beta)} p^{\alpha-1} (1-p)^{\beta-1},
\tag{4}
\end{equation}\]</span>
where <span class="math inline">\(0 \leq p \leq 1, \alpha&gt;0, \beta&gt;0\)</span>, and <span class="math inline">\(\text{Ga}mma\)</span> is a factorial:</p>
<p><span class="math display">\[\text{Ga}mma(n) = (n-1)! = (n-1) \times (n-2) \times \cdots \times 1\]</span></p>
<p>When <span class="math inline">\(\alpha=\beta=1\)</span>, the beta distribution becomes a uniform distribution, i.e. the probabilty density function is a flat line. In other words, the uniform distribution is a special case of the beta family.</p>
<p>The expected value of <span class="math inline">\(p\)</span> is <span class="math inline">\(\frac{\alpha}{\alpha+\beta}\)</span>, so <span class="math inline">\(\alpha\)</span> can be regarded as the prior number of successes, and <span class="math inline">\(\beta\)</span> the prior number of failures. When <span class="math inline">\(\alpha=\beta\)</span>, then one gets a symmetrical pdf around 0.5. For large but equal values of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>, the area under the beta probability density near 0.5 is very large. Figure <a href="#fig:beta">6</a> compares the beta distribution with different parameter values.</p>
<pre class="r"><code>library(ggthemes)
p.range = seq(from=0, to=1, by=0.01)
beta0 = dbeta(p.range, 1, 1)
beta1 = dbeta(p.range, 0.5, 0.5)
beta2 = dbeta(p.range, 5, 1)
beta3 = dbeta(p.range, 1, 3)
beta4 = dbeta(p.range, 2, 2)
beta5 = dbeta(p.range, 2, 5)


#texts = c(&quot;alpha=beta=1&quot;, &quot;alpha=beta=0.5&quot;, &quot;alpha=5, beta=1&quot;, 
#          &quot;alpha=1, beta=3&quot;, &quot;alpha=2, beta=2&quot;, &quot;alpha=2, beta=5&quot;)
colors = c(&quot;brown&quot;,&quot;red&quot;,&quot;green&quot;,&quot;blue&quot;,&quot;pink&quot;,&quot;black&quot;)

#plot(p.range,  beta1, type=&quot;l&quot;, col=colors[2],
#     xlab=&quot;p&quot;, ylab=&quot;probabilty density&quot;)
# lines(p.range, beta0, type=&quot;l&quot;, col=colors[1])
# lines(p.range, beta2, type=&quot;l&quot;, col=colors[3])
# lines(p.range, beta3, type=&quot;l&quot;, col=colors[4])
# lines(p.range, beta4, type=&quot;l&quot;, col=colors[5])
# lines(p.range, beta5, type=&quot;l&quot;, col=colors[6])
# legend(&quot;top&quot;, texts, lty=rep(c(1),6), col = colors)

# New code
my_beta = data.frame(x = p.range, beta0 = beta0, beta1 = beta1, beta2 = beta2, 
                     beta3 = beta3, beta4 = beta4, beta5 = beta5)

ggplot(data = my_beta) + geom_line(aes(x = x, y = beta0, col = &quot;a&quot;)) + 
  geom_line(aes(x = x, y = beta1, col = &quot;b&quot;)) +
  geom_line(aes(x = x, y = beta2, col = &quot;c&quot;)) + 
  geom_line(aes(x = x, y = beta3, col = &quot;d&quot;)) +
  geom_line(aes(x = x, y = beta4, col = &quot;e&quot;)) +
  geom_line(aes(x = x, y = beta5, col = &quot;f&quot;)) +
  scale_color_manual(values = colors,
                     labels = c(bquote(paste(alpha, &quot; = &quot;, 1, &quot;, &quot;, beta, &quot; = &quot;, 1)),
                                bquote(paste(alpha, &quot; = &quot;, 0.5, &quot;, &quot;, beta, &quot; = &quot;, 0.5)), 
                                bquote(paste(alpha, &quot; = &quot;, 5, &quot;, &quot;, beta, &quot; = &quot;, 1)),
                                bquote(paste(alpha, &quot; = &quot;, 1, &quot;, &quot;, beta, &quot; = &quot;, 3)),
                                bquote(paste(alpha, &quot; = &quot;, 2, &quot;, &quot;, beta, &quot; = &quot;, 2)),
                                bquote(paste(alpha, &quot; = &quot;, 2, &quot;, &quot;, beta, &quot; = &quot;, 5))),
                     name = &quot;Beta Distributions&quot;) + 
  ylab(&quot;Probability Density&quot;) + xlab(&quot;p&quot;) + theme_tufte() </code></pre>
<div class="figure" style="text-align: center"><span id="fig:beta"></span>
<img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/beta-1.svg" alt="Beta family" width="80%" />
<p class="caption">
Figure 6: Beta family
</p>
</div>
<pre class="r"><code>#+ theme(legend.position = c(1, 1), legend.justification = c(1.2, 1.1))</code></pre>
<p>These kinds of priors are probably appropriate if you want to infer the probability of getting heads in a coin toss. The beta family also includes skewed densities, which is appropriate if you think that <span class="math inline">\(p\)</span> the probability of success in ths binomial trial is close to zero or one.</p>
<p>Bayes’ rule is a machine to turn one’s prior beliefs into posterior beliefs. With binomial data you start with whatever beliefs you may have about <span class="math inline">\(p\)</span>, then you observe data in the form of the number of head, say 20 tosses of a coin with 15 heads.</p>
<p>Next, Bayes’ rule tells you how the data changes your opinion about <span class="math inline">\(p\)</span>. The same principle applies to all other inferences. You start with your prior probability distribution over some parameter, then you use data to update that distribution to become the posterior distribution that expresses your new belief.</p>
<p>These rules ensure that the change in distributions from prior to posterior is the uniquely rational solution. So, as long as you begin with the prior distribution that reflects your true opinion, you can hardly go wrong.</p>
<p>However, expressing that prior can be difficult. There are proofs and methods whereby a rational and coherent thinker can self-illicit their true prior distribution, but these are impractical and people are rarely rational and coherent.</p>
<p>The good news is that with the few simple conditions no matter what part distribution you choose. If enough data are observed, you will converge to an accurate posterior distribution. So, two bayesians, say the reference Thomas Bayes and the agnostic Ajay Good can start with different priors but, observe the same data. As the amount of data increases, they will converge to the same posterior distribution.</p>
<p>Here is a summary of the key ideas in this section:</p>
<ol style="list-style-type: decimal">
<li><p>Bayesians express their uncertainty through probability distributions.</p></li>
<li><p>One can think about the situation and self-elicit a probability distribution that approximately reflects his/her personal probability.</p></li>
<li><p>One’s personal probability should change according Bayes’ rule, as new data are observed.</p></li>
<li><p>The beta family of distribution can describe a wide range of prior beliefs.</p></li>
</ol>
</div>
<div id="conjugacy" class="section level3">
<h3>Conjugacy</h3>
<p>Next, let’s introduce the concept of conjugacy in Bayesian statistics.</p>
<p>Suppose we have the prior beliefs about the data as below:</p>
<ul>
<li><p>Binomial distribution <span class="math inline">\(\text{Bin}(n,p)\)</span> with <span class="math inline">\(n\)</span> known and <span class="math inline">\(p\)</span> unknown</p></li>
<li><p>Prior belief about <span class="math inline">\(p\)</span> is <span class="math inline">\(\text{beta}(\alpha,\beta)\)</span></p></li>
</ul>
<p>Then we observe <span class="math inline">\(x\)</span> success in <span class="math inline">\(n\)</span> trials, and it turns out the Bayes’ rule implies that our new belief about the probability density of <span class="math inline">\(p\)</span> is also the beta distribution, but with different parameters. In mathematical terms,</p>
<p><span class="math display" id="eq:beta-binomial">\[\begin{equation}
p|x \sim \text{beta}(\alpha+x, \beta+n-x).
\tag{5}
\end{equation}\]</span></p>
<p>This is an example of conjugacy. Conjugacy occurs when the <strong>posterior distribution</strong> is in the <strong>same family</strong> of probability density functions as the prior belief, but with <strong>new parameter values</strong>, which have been updated to reflect what we have learned from the data.</p>
<p>Why are the beta binomial families conjugate? Here is a mathematical explanation.</p>
<p>Recall the discrete form of the Bayes’ rule:</p>
<p><span class="math display">\[P(A_i|B) = \frac{P(B|A_i)P(A_i)}{\sum^n_{j=1}P(B|A_j)P(A_j)}\]</span></p>
<p>However, this formula does not apply to continuous random variables, such as the <span class="math inline">\(p\)</span> which follows a beta distribution, because the denominator sums over all possible values (must be finitely many) of the random variable.</p>
<p>But the good news is that the <span class="math inline">\(p\)</span> has a finite range – it can take any value <strong>only</strong> between 0 and 1. Hence we can perform integration, which is a generalization of the summation. The Bayes’ rule can also be written in continuous form as:</p>
<p><span class="math display">\[\pi^*(p|x) = \frac{P(x|p)\pi(p)}{\int^1_0 P(x|p)\pi(p) dp}.\]</span></p>
<p>This is analogus to the discrete form, since the integral in the denominator will also be equal to some constant, just like a summation. This constant ensures that the total area under the curve, i.e. the posterior density function, equals 1.</p>
<p>Note that in the numerator, the first term, <span class="math inline">\(P(x|p)\)</span>, is the data likelihood – the probability of observing the data given a specific value of <span class="math inline">\(p\)</span>. The second term, <span class="math inline">\(\pi(p)\)</span>, is the probability density function that reflects the prior belief about <span class="math inline">\(p\)</span>.</p>
<p>In the beta-binomial case, we have <span class="math inline">\(P(x|p)=\text{Bin}(n,p)\)</span> and <span class="math inline">\(\pi(p)=\text{beta}(\alpha,\beta)\)</span>.</p>
<p>Plugging in these distributions, we get</p>
<p><span class="math display">\[\begin{aligned}
\pi^*(p|x) &amp;= \frac{1}{\text{some number}} \times P(x|p)\pi(p) \\
&amp;= \frac{1}{\text{some number}} \left[\left( \begin{array}{c} n \\ x \end{array} \right) p^x (1-p)^{n-x}\right] \left[\frac{\text{Ga}mma(\alpha+\beta)}{\text{Ga}mma(\alpha)\text{Ga}mma(\beta)} p^{\alpha-1} (1-p)^{\beta-1}\right] \\
&amp;= \frac{\text{Ga}mma(\alpha+\beta+n)}{\text{Ga}mma(\alpha+x)\text{Ga}mma(\beta+n-x)} \times p^{\alpha+x-1} (1-p)^{\beta+n-x-1}
\end{aligned}\]</span></p>
<p>Let <span class="math inline">\(\alpha^* = \alpha + x\)</span> and <span class="math inline">\(\beta^* = \beta+n-x\)</span>, and we get</p>
<p><span class="math display">\[\pi^*(p|x) = \text{beta}(\alpha^*,\beta^*) = \text{beta}(\alpha+x, \beta+n-x),\]</span></p>
<p>same as the posterior formula in Equation <a href="#eq:beta-binomial">(5)</a>.</p>
<p>We can recognize the posterior distribution from the numerator <span class="math inline">\(p^{\alpha+x-1}\)</span> and <span class="math inline">\((1-p)^{\beta+n-x-1}\)</span>. Everything else are just constants, and they must take the unique value, which is needed to ensure that the area under the curve between 0 and 1 equals 1. So they have to take the values of the beta, which has parameters <span class="math inline">\(\alpha+x\)</span> and <span class="math inline">\(\beta+n-x\)</span>.</p>
<p>This is a cute trick. We can find the answer without doing the integral simply by looking at the form of the numerator.</p>
<p>Without conjugacy, one has to do the integral. Often, the integral is impossible to evaluate. That obstacle is the primary reason that most statistical theory in the 20th century was not Bayesian. The situation did not change until modern computing allowed researchers to compute integrals numerically.</p>
<p>In summary, some pairs of distributions are conjugate. If your prior is in one and your data comes from the other, then your posterior is in the same family as the prior, but with new parameters. We explored this in the context of the beta-binomial conjugate families. And we saw that conjugacy meant that we could apply the continuous version of Bayes’ rule without having to do any integration.
## Three Conjugate Families</p>
<p>In this section, the three conjugate families are beta-binomial, gamma-Poisson, and normal-normal pairs. Each of them has its own applications in everyday life.</p>
</div>
<div id="inference-on-a-binomial-proportion" class="section level3">
<h3>Inference on a Binomial Proportion</h3>

<div class="example">
<p><span id="exm:RU-486more" class="example"><strong>Example 14  </strong></span>Recall Example <a href="#exm:RU-486">8</a>, a simplified version of a real clinical trial taken in Scotland. It concerned RU-486, a morning after pill that was being studied to determine whether it was effective at preventing unwanted pregnancies. It had 800 women, each of whom had intercourse no more than 72 hours before reporting to a family planning clinic to seek contraception.</p>
Half of these women were randomly assigned to the standard contraceptive, a large dose of estrogen and progesterone. And half of the women were assigned RU-486. Among the RU-486 group, there were no pregnancies. Among those receiving the standard therapy, four became pregnant.
</div>
<p>Statistically, one can model these data as coming from a binomial distribution. Imagine a coin with two sides. One side is labeled standard therapy and the other is labeled RU-486. The coin was tossed four times, and each time it landed with the standard therapy side face up.</p>
<p>A frequentist would analyze the problem as below:</p>
<ul>
<li><p>The parameter <span class="math inline">\(p\)</span> is the probability of a preganancy comes from the standard treatment.</p></li>
<li><p><span class="math inline">\(H_0: p \geq 0.5\)</span> and <span class="math inline">\(H_A: p &lt; 0.5\)</span></p></li>
<li><p>The p-value is <span class="math inline">\(0.5^4 = 0.0625 &gt; 0.05\)</span></p></li>
</ul>
<p>Therefore, the frequentist fails to reject the null hypothesis, and will not conclude that RU-486 is superior to standard therapy.</p>
<p>Remark: The significance probability, or p-value, is the chance of observing
data that are as or more supportive of the alternative hypothesis than
the data that were collected, when the null hypothesis is true.</p>
<p>Now suppose a Bayesian performed the analysis. She may set her beliefs about the drug and decide that she has no prior knowledge about the efficacy of RU-486 at all. This would be reasonable if, for example, it were the first clinical trial of the drug. In that case, she would be using the uniform distribution on the interval from 0 to 1, which corresponds to the <span class="math inline">\(\text{beta}(1,1)\)</span> density. In mathematical terms,</p>
<p><span class="math display">\[p \sim \text{Unif}(0,1) = \text{beta}(1,1).\]</span></p>
<p>From conjugacy, we know that since there were four failures for RU-486 and no successes, that her posterior probability of an RU-486 child is</p>
<p><span class="math display">\[p|x \sim \text{beta}(1+0,1+4) = \text{beta}(1,5).\]</span></p>
<p>This is a beta that has much more area near <span class="math inline">\(p\)</span> equal to 0. The mean of <span class="math inline">\(\text{beta}(\alpha,\beta)\)</span> is <span class="math inline">\(\frac{\alpha}{\alpha+\beta}\)</span>. So this Bayesian now believes that the unknown <span class="math inline">\(p\)</span>, the probability of an RU-468 child, is about 1 over 6.</p>
<p>The standard deviation of a beta distribution with parameters in alpha and beta also has a closed form:</p>
<p><span class="math display">\[p \sim \text{beta}(\alpha,\beta) \Rightarrow \text{Standard deviation} = \sqrt{\frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}}\]</span></p>
<p>Before she saw the data, the Bayesian’s uncertainty expressed by her standard deviation was 0.71. After seeing the data, it was much reduced – her posterior standard deviation is just 0.13.</p>
<p>We promised not to do much calculus, so I hope you will trust me to tell you that this Bayesian now believes that her posterior probability that <span class="math inline">\(p &lt; 0.5\)</span> is 0.96875. She thought there was a 50-50 chance that RU-486 is better. But now she thinks there is about a 97% chance that RU-486 is better.</p>
<p>Suppose a fifth child were born, also to a mother who received standard chip therapy. Now the Bayesian’s prior is beta(1, 5) and the additional data point further updates her to a new posterior beta of 1 and 6. <strong>As data comes in, the Bayesian’s previous posterior becomes her new prior, so learning is self-consistent.</strong></p>
<p>This example has taught us several things:</p>
<ol style="list-style-type: decimal">
<li><p>We saw how to build a statistical model for an applied problem.</p></li>
<li><p>We could compare the frequentist and Bayesian approaches to inference and see large differences in the conclusions.</p></li>
<li><p>We saw how the data changed the Bayesian’s opinion with a new mean for p and less uncertainty.</p></li>
<li><p>We learned that Bayesian’s continually update as new data arrive. <strong>Yesterday’s posterior is today’s prior.</strong></p></li>
</ol>
</div>
<div id="the-gamma-poisson-conjugate-families" class="section level3">
<h3>The Gamma-Poisson Conjugate Families</h3>
<p>A second important case is the gamma-Poisson conjugate families. In this case the data come from a Poisson distribution, and the prior and posterior are both gamma distributions.</p>
<p>The Poisson random variable can take any <strong>non-negative integer value</strong> all the way up to infinity. It is used in describing <strong>count data</strong>, where one counts the number of independent events that occur in a fixed amount of time, a fixed area, or a fixed volume.</p>
<p>Moreover, the Poisson distribution has been used to describe the number of phone calls one receives in an hour. Or, the number of pediatric cancer cases in the city, for example, to see if pollution has elevated the cancer rate above that of in previous years or for similar cities. It is also used in medical screening for diseases, such as HIV, where one can count the number of T-cells in the tissue sample.</p>
<p>The Poisson distribution has a single parameter <span class="math inline">\(\lambda\)</span>, and it is denoted as <span class="math inline">\(X \sim \text{Pois}(\lambda)\)</span> with <span class="math inline">\(\lambda&gt;0\)</span>. The probability mass function is</p>
<p><span class="math display">\[P(X=k) = \frac{\lambda^k}{k!} e^{-\lambda} \text{ for } k=0,1,\cdots,\]</span></p>
<p>where <span class="math inline">\(k! = k \times (k-1) \times \cdots \times 1\)</span>. This gives the probability of observing a random variable equal to <span class="math inline">\(k\)</span>.</p>
<p>Note that <span class="math inline">\(\lambda\)</span> is both the mean and the variance of the Poisson random variable. It is obvious that <span class="math inline">\(\lambda\)</span> must be greater than zero, because it represents the mean number of counts, and the variance should be greater than zero (except for constants, which have zero variance).</p>

<div class="example">
<p><span id="exm:Poisson" class="example"><strong>Example 15  </strong></span>Famously, von Bortkiewicz used the Poisson distribution to study the number of Prussian cavalrymen who were kicked to death by a horse each year. This is count data over the course of a year, and the events are probably independent, so the Poisson model makes sense.</p>
<p>He had data on 15 cavalry units for the 20 years between 1875 and 1894, inclusive. The total number of cavalrymen who died by horse kick was 200.</p>
One can imagine that a Prussian general might want to estimate <span class="math inline">\(\lambda\)</span>. The average number per year, per unit. Perhaps in order to see whether some educational campaign about best practices for equine safety would make a difference.
</div>
<p>Suppose the Prussian general is a Bayesian. Introspective elicitation leads him to think that <span class="math inline">\(\lambda=0.75\)</span> and standard deviation 1.</p>
<p>Modern computing was unavailable at that time yet, so the Prussian general will need to express his prior as a member of a family conjugate to the Poisson. It turns out that this family consists of the gamma distributions. Gamma distributions describe continuous non-negative random variables. As we know, the value of <span class="math inline">\(\lambda\)</span> in the Poisson can take any non-negative value so this fits.</p>
<p>The gamma family is flexible, and Figure <a href="#fig:gamma">7</a> illustrates a wide range of gamma shapes.</p>
<pre class="r"><code>library(ggthemes)
library(ggplot2)
x = seq(from=0, to=20, by=0.005)

#texts = c(&quot;k=1.0, theta=2.0&quot;, &quot;k=2.0, theta=2.0&quot;, &quot;k=3.0, theta=2.0&quot;,
#          &quot;k=5.0, theta=1.0&quot;, &quot;k=9.0, theta=0.5&quot;, &quot;k=7.5, theta=1.0&quot;,
#          &quot;k=0.5, theta=1.0&quot;)
colors = c(&quot;red&quot;,&quot;orange&quot;,&quot;yellow&quot;,&quot;green&quot;,&quot;black&quot;,&quot;blue&quot;,&quot;purple&quot;)

ga1 = dgamma(x,shape=1.0,scale=2.0)
ga2 = dgamma(x,shape=2.0,scale=2.0)
ga3 = dgamma(x,shape=3.0,scale=2.0)
ga4 = dgamma(x,shape=5.0,scale=1.0)
ga5 = dgamma(x,shape=9.0,scale=0.5)
ga6 = dgamma(x,shape=7.5,scale=1.0)
ga7 = dgamma(x,shape=0.5,scale=1.0)

# plot(x,ga1,type=&quot;n&quot;,xlim=c(0,20),ylim=c(0,0.5))
# lines(x,ga1,type=&quot;l&quot;,col=color[1])
# lines(x,ga2,type=&quot;l&quot;,col=color[2])
# lines(x,ga3,type=&quot;l&quot;,col=color[3])
# lines(x,ga4,type=&quot;l&quot;,col=color[4])
# lines(x,ga5,type=&quot;l&quot;,col=color[5])
# lines(x,ga6,type=&quot;l&quot;,col=color[6])
# lines(x,ga7,type=&quot;l&quot;,col=color[7])
# legend(&quot;topright&quot;, texts, lty=rep(c(1),7), col = color)

# New code

my_gamma = data.frame(x = x, ga1 = ga1, ga2 = ga2, ga3 = ga3, ga4 = ga4, ga5 = ga5, ga6 = ga6, ga7 = ga7)

ggplot(data = my_gamma) + geom_line(aes(x = x, y = ga1, col = &quot;a&quot;)) + 
  geom_line(aes(x = x, y = ga2, col = &quot;b&quot;)) +
  geom_line(aes(x = x, y = ga3, col = &quot;c&quot;)) + 
  geom_line(aes(x = x, y = ga4, col = &quot;d&quot;)) +
  geom_line(aes(x = x, y = ga5, col = &quot;e&quot;)) +
  geom_line(aes(x = x, y = ga6, col = &quot;f&quot;)) +
  geom_line(aes(x = x, y = ga7, col = &quot;g&quot;)) +
  scale_color_manual(values = colors,
                     labels = c(bquote(paste(k, &quot; = &quot;, 1, &quot;, &quot;, theta, &quot; = &quot;, 2)),
                                bquote(paste(k, &quot; = &quot;, 2, &quot;, &quot;, theta, &quot; = &quot;, 2)), 
                                bquote(paste(k, &quot; = &quot;, 3, &quot;, &quot;, theta, &quot; = &quot;, 2)),
                                bquote(paste(k, &quot; = &quot;, 5, &quot;, &quot;, theta, &quot; = &quot;, 1)),
                                bquote(paste(k, &quot; = &quot;, 9, &quot;, &quot;, theta, &quot; = &quot;, 0.5)),
                                bquote(paste(k, &quot; = &quot;, 7.5, &quot;, &quot;, theta, &quot; = &quot;, 1)),
                                bquote(paste(k, &quot; = &quot;, 0.5, &quot;, &quot;, theta, &quot; = &quot;, 1))),
                     name = &quot;Gamma Distributions&quot;) + 
  xlim(0, 20) + ylim(0, 0.5) +
  ylab(&quot;Probability Density&quot;) + xlab(&quot;x&quot;) # + theme_tufte()</code></pre>
<div class="figure" style="text-align: center"><span id="fig:gamma"></span>
<img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/gamma-1.svg" alt="Gamma family" width="100%" />
<p class="caption">
Figure 7: Gamma family
</p>
</div>
<p>The probability density function for the gamma is indexed by shape <span class="math inline">\(k\)</span> and scale <span class="math inline">\(\theta\)</span>, denoted as <span class="math inline">\(\text{Gamma}(k,\theta)\)</span> with <span class="math inline">\(k,\theta &gt; 0\)</span>. The mathematical form of the density is
<span class="math display" id="eq:gamma">\[
\begin{equation}
f(x) = \dfrac{1}{\text{Ga}mma(k)\theta^k} x^{k-1} e^{-x/\theta}
\tag{6}
\end{equation}\]</span>
where</p>
<p><span class="math display" id="eq:gamma-function">\[\begin{equation}
\text{Ga}mma(z) = \int^{\infty}_0 x^{z-1} e^{-x} dx.
\tag{7}
\end{equation}\]</span>
<span class="math inline">\(\text{Ga}mma(z)\)</span>, the gamma function, is simply a constant that ensures the area under curve between 0 and 1 sums to 1, just like in the beta probability distribution case of Equation <a href="#eq:beta">(4)</a>. A special case is that <span class="math inline">\(\text{Ga}mma(n) = (n-1)!\)</span> when <span class="math inline">\(n\)</span> is a positive integer.</p>
<p>However, some books parameterize the gamma distribution in a slightly different way with shape <span class="math inline">\(\alpha = k\)</span> and rate (inverse scale) <span class="math inline">\(\beta=1/\theta\)</span>:</p>
<p><span class="math display">\[f(x) = \frac{\beta^{\alpha}}{\text{Ga}mma(\alpha)} x^{\alpha-1} e^{-\beta x}\]</span></p>
<p>For this example, we use the <span class="math inline">\(k\)</span>-<span class="math inline">\(\theta\)</span> parameterization, but you should always check which parameterization is being used. For example, <span class="math inline">\(\mathsf{R}\)</span> uses the <span class="math inline">\(\alpha\)</span>-<span class="math inline">\(\beta\)</span> parameterization by default.<br />
In the the later material we find that using the rate parameterization is more convenient.</p>
<p>For our parameterization, the mean of <span class="math inline">\(\text{Gamma}(k,\theta)\)</span> is <span class="math inline">\(k\theta\)</span>, and the variance is <span class="math inline">\(k\theta^2\)</span>. We can get the general’s prior as below:</p>
<p><span class="math display">\[\begin{aligned}
\text{Mean} &amp;= k\theta = 0.75 \\
\text{Standard deviation} &amp;= \theta\sqrt{k} = 1
\end{aligned}\]</span></p>
<p>Hence
<span class="math display">\[k = \frac{9}{16} \text{ and } \theta = \frac{4}{3}\]</span></p>
<p>For the gamma Poisson conjugate family, suppose we observed data <span class="math inline">\(x_1, x_2, \cdots, x_n\)</span> that follow a Poisson distribution.Then similar to the previous section, we would recognize the kernel of the gamma when using the gamma-Poisson family. The posterior <span class="math inline">\(\text{Gamma}(k^*, \theta^*)\)</span> has parameters</p>
<p><span class="math display">\[k^* = k + \sum^n_{i=1} x_i \text{ and } \theta^* = \frac{\theta}{(n\theta+1)}.\]</span></p>
<p>For this dataset, <span class="math inline">\(N = 15 \times 20 = 300\)</span> observations, and the number of casualities is 200. Therefore, the general now thinks that the average number of Prussian cavalry officers who die at the hoofs of their horses follows a gamma distribution with the parameters below:</p>
<p><span class="math display">\[\begin{aligned}
k^* &amp;= k + \sum^n_{i=1} x_i = \frac{9}{16} + 200 = 200.5625 \\
\theta^* = \frac{\theta}{(n\theta+1)} &amp;= \frac{4/3}{300\times(4/3)} = 0.0033
\end{aligned}\]</span></p>
<p>How the general has changed his mind is described in Table <a href="#tab:before-after">4</a>. After seeing the data, his uncertainty about lambda, expressed as a standard deviation, shrunk from 1 to 0.047.</p>
<pre class="r"><code>temp &lt;- matrix(c(0.75, 1, 0.67, 0.047), nrow = 2, byrow = TRUE)
rownames(temp) &lt;- c(&#39;Before&#39;, &#39;After&#39;)
colnames(temp) &lt;- c(&#39;lambda&#39;, &#39;Standard Deviation&#39;)

knitr::kable(
  x = temp,
  booktabs = TRUE,
  caption = &#39;Before and after seeing the data&#39;
)</code></pre>
<table>
<caption><span id="tab:before-after">Table 4: </span>Before and after seeing the data</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">lambda</th>
<th align="right">Standard Deviation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Before</td>
<td align="right">0.75</td>
<td align="right">1.000</td>
</tr>
<tr class="even">
<td align="left">After</td>
<td align="right">0.67</td>
<td align="right">0.047</td>
</tr>
</tbody>
</table>
<p>In summary, we learned about the Poisson and gamma distributions; we also knew that the gamma-Poisson families are conjugate. Moreover, we learned the updating fomula, and applied it to a classical dataset.</p>
</div>
<div id="sec:normal-normal" class="section level3">
<h3>The Normal-Normal Conjugate Families</h3>
<p>There are other conjugate families, and one is the normal-normal pair. If your data come from a normal distribution with known variance <span class="math inline">\(\sigma^2\)</span> but unknown mean <span class="math inline">\(\mu\)</span>, and if your prior on the mean <span class="math inline">\(\mu\)</span>, has a normal distribution with self-elicited mean <span class="math inline">\(\nu\)</span> and self-elicited variance <span class="math inline">\(\tau^2\)</span>, then your posterior density for the mean, after seeing a sample of size <span class="math inline">\(n\)</span> with sample mean <span class="math inline">\(\bar{x}\)</span>, is also normal. In mathematical notation, we have</p>
<p><span class="math display">\[\begin{aligned}
x|\mu &amp;\sim N(\mu,\sigma^2) \\
\mu &amp;\sim N(\nu, \tau^2)
\end{aligned}\]</span></p>
<p>As a practical matter, one often does not know <span class="math inline">\(\sigma^2\)</span>, the standard deviation of the normal from which the data come. In that case, you could use a more advanced conjugate family that we will describe in <a href="#sec:normal-gamma"><strong>??</strong></a>. But there are cases in which it is reasonable to treat the <span class="math inline">\(\sigma^2\)</span> as known.</p>

<div class="example">
<p><span id="exm:chemist" class="example"><strong>Example 16  </strong></span>An analytical chemist whose balance produces measurements that are normally distributed with mean equal to the true mass of the sample and standard deviation that has been estimated by the manufacturer balance and confirmed against calibration standards provided by the National Institute of Standards and Technology.</p>
<p>Note that this normal-normal assumption made by the anayltical chemist is technically wrong, but still reasonable.</p>
<ol style="list-style-type: decimal">
<li><p>The normal family puts some probability on all possible values between <span class="math inline">\((-\infty,+\infty)\)</span>. But the mass on the balance can <strong>never</strong> be negative. However, the normal prior on the unknown mass is usually so concentrated on positive values that the normal distribution is still a good approximation.</p></li>
<li><p>Even if the chemist has repeatedly calibrated her balance with standards from the National Institute of Standards and Technology, she still will not know its standard deviation precisely. However, if she has done it often and well, it is probably a sufficiently good approximation to assume that the standard deviation is known.</p></li>
</ol>
</div>
<p>For the normal-normal conjugate families, assume the prior on the unknown mean follows a normal distribution, i.e. <span class="math inline">\(\mu \sim N(\nu, \tau^2)\)</span>. We also assume that the data <span class="math inline">\(x_1,x_2,\cdots,x_n\)</span> are independent and come from a normal with variance <span class="math inline">\(\sigma^2\)</span>.</p>
<p>Then the posterior distribution of <span class="math inline">\(\mu\)</span> is also normal, with mean as a weighted average of the prior mean and the sample mean. We have</p>
<p><span class="math display">\[\mu|x_1,x_2,\cdots,x_n \sim N(\nu^*, \tau^{*2}),\]</span></p>
<p>where</p>
<p><span class="math display">\[\nu^* = \frac{\nu\sigma^2 + n\bar{x}\tau^2}{\sigma^2 + n\tau^2} \text{ and } \tau^* = \sqrt{\frac{\sigma^2\tau^2}{\sigma^2 + n\tau^2}}.\]</span></p>
<p>Let’s continue from Example <a href="#exm:chemist">16</a>, and suppose she wants to measure the mass of a sample of ammonium nitrate.</p>
<p>Her balance has a known standard deviation of 0.2 milligrams. By looking at the sample, she thinks this mass is about 10 milligrams and based on her previous experience in estimating masses, her guess has the standard deviation of 2. So she decides that her prior for the mass of the sample is a normal distribution with mean, 10 milligrams, and standard deviation, 2 milligrams.</p>
<p>Now she collects five measurements on the sample and finds that the average of those is 10.5. By conjugacy of the normal-normal family, our posterior belief about the mass of the sample has the normal distribution.</p>
<p>The new mean of that posterior normal is found by plugging into the formula:</p>
<p><span class="math display">\[\begin{aligned}
\mu &amp;\sim N(\nu=10, \tau^2=2^2) \\
\nu^*  &amp;= \frac{\nu\sigma^2 + n\bar{x}\tau^2}{\sigma^2 + n\tau^2} = \frac{10\times(0.2)^2+5\times10.5\times2^2}{(0.2)^2+5\times2^2} = 10.499\\
\tau^* &amp;= \sqrt{\frac{\sigma^2\tau^2}{\sigma^2 + n\tau^2}} = \sqrt{(0.2)^2\times2^2}{(0.2)^2+5\times2^2} = 0.089.
\end{aligned}\]</span></p>
<p>Before seeing the data, the Bayesian analytical chemist thinks the ammonium nitrate has mass 10 mg and uncertainty (standard deviation) 2 mg. After seeing the data, she thinks the mass is 10.499 mg and standard deviation 0.089 mg. Her posterior mean has shifted quite a bit and her uncertainty has dropped by a lot. That’s exactly what an analytical chemist wants.</p>
<p>This is the last of the three examples of conjugate families. There are many more, but they do not suffice for every situation one might have.</p>
<p>We learned several things in this lecture. First, we learned the new pair of conjugate families and the relevant updating formula. Also, we worked a realistic example problem that can arise in practical situations.
## Credible Intervals and Predictive Inference</p>
<p>In this part, we are going to quantify the uncertainty of the parameter by credible intervals after incorporating the data. Then we can use predictive inference to identify the posterior distribution for a new random variable.</p>
</div>
<div id="non-conjugate-priors" class="section level3">
<h3>Non-Conjugate Priors</h3>
<p>In many applications, a Bayesian may not be able to use a conjugate prior. Sometimes she may want to use a reference prior, which injects the minimum amount of personal belief into the analysis. But most often, a Bayesian will have a personal belief about the problem that cannot be expressed in terms of a convenient conjugate prior.</p>
<p>For example, we shall reconsider the RU-486 case from earlier in which four children were born to standard therapy mothers. But no children were born to RU-486 mothers. This time, the Bayesian believes that the probability p of an RU-486 baby is uniformly distributed between 0 and one-half, but has a point mass of 0.5 at one-half. That is, she believes there is a 50% chance that no difference exists between standard therapy and RU-486. But if a difference exists, she thinks that RU-486 is better, but she is completely unsure about how much better it would be.</p>
<p>In mathematical notation, the probability density function of <span class="math inline">\(p\)</span> is</p>
<p><span class="math display">\[\pi(p) = \left\{ \begin{array}{ccc}
1 &amp; \text{for} &amp; 0 \leq p &lt; 0.5 \\
0.5 &amp; \text{for} &amp; p = 0.5 \\
0 &amp; \text{for} &amp; p &lt; 0 \text{ or } p &gt; 0.5
\end{array}\right.\]</span></p>
<p>We can check that the area under the density curve, plus the amount of the point mass, equals 1.</p>
<p>The cumulative distribution function, <span class="math inline">\(P(p\leq x)\)</span> or <span class="math inline">\(F(x)\)</span>, is</p>
<p><span class="math display">\[P(p \leq x) = F(x) = \left\{ \begin{array}{ccc}
0 &amp; \text{for} &amp; x &lt; 0 \\
x &amp; \text{for} &amp; 0 \leq x &lt; 0.5  \\
1 &amp; \text{for} &amp; x \geq 0.5
\end{array}\right.\]</span></p>
<p>Why would this be a reasonable prior for an analyst to self-elicit? One reason is that in clinical trials, there is actually quite a lot of preceding research on the efficacy of the drug. This research might be based on animal studies or knowledge of the chemical activity of the molecule. So the Bayesian might feel sure that there is no possibility that RU-486 is worse than the standard treatment. And her interest is on whether the therapies are equivalent and if not, how much better RU-486 is than the standard therapy.</p>
<p>As previously mentioned, the posterior distribution <span class="math inline">\(\pi^*(p)\)</span> for <span class="math inline">\(p\)</span> has a complex mathematical form. That is why Bayesian inference languished for so many decades until computational power enabled numerical solutions. But now we have simulation tools to help us, and one of them is called <strong>JAGS (Just Another Gibbs Sampler)</strong>.</p>
<p>If we apply JAGS to the RU-486 data with this non-conjugate prior, we can find the posterior distribution <span class="math inline">\(\pi^*(p)\)</span>, as in Figure <a href="#fig:JAGS-screenshot"><strong>??</strong></a>. At a high level, this program is defining the binomial probability, that is the likelihood of seeing 0 RU-486 children, which is binomial. And then it defines the prior by using a few tricks to draw from either a uniform on the interval from 0 to one-half, or else draw from the point mass at one-half. Then it calls the JAGS model function, and draws 5,000 times from the posterior and creates a histogram of the results.</p>
<pre class="r"><code>library(rjags)


# Run JAGS model

str &lt;- &quot;model {
dummy ~ dunif(0, 1)  # this step should be fine
p = ifelse(dummy &gt; 0.5, 0.5, dummy)
y ~ dbin(p, 4)
}&quot;

set.seed(1234)

data_jags = list(y = 0)
params = c(&#39;dummy&#39;, &#39;p&#39;)
init = function(){
  init = list(&#39;dummy&#39; = 0.2)   # just a random number
}

mod = jags.model(textConnection(str), data = data_jags, inits = init)</code></pre>
<pre><code>## Compiling model graph
##    Resolving undeclared variables
##    Allocating nodes
## Graph information:
##    Observed stochastic nodes: 1
##    Unobserved stochastic nodes: 1
##    Total graph size: 8
## 
## Initializing model</code></pre>
<pre class="r"><code>mod_sim = coda.samples(model = mod, variable.names = params, n.iter = 10000)</code></pre>
<pre class="r"><code># Extract data for p

p &lt;- mod_sim[[1]][, 2]

# Split p into p != 0.5 and p == 0.5 for later density function

p.pointMass = p[p == 0.5]
p.notPointMass = p[p != 0.5]

# Plot the truncated density of p.notPointMass using logspline method
# Then add the line segment to represent p.pointMass
library(logspline)

fit = logspline(p.notPointMass)

# Set the margin of the graphic windwo
mar.default &lt;- c(5,4,4,2) + 0.1
par(mar = mar.default + c(0, 4, 0, 0))

# Plot. Shrink the range of &quot;x&quot; so that we won&#39;t see the sudden jump at the boundaries 
plot(fit, xlim = c(0.001, 0.495), ylim = c(0, 5.5), xlab = &quot;p&quot;, 
     ylab = expression(paste(&quot;posterior distribution, &quot;, pi, &quot;*&quot;, &quot;(p)&quot;)))
segments(0.5, 0, 0.5, length(p.pointMass) / length(p), col = &quot;black&quot;, lwd = 5)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:JAGS-plot"></span>
<img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/JAGS-plot-1.svg" alt="Posterior with JAGS" width="80%" />
<p class="caption">
Figure 8: Posterior with JAGS
</p>
</div>
<p>The posterior distribution is decreasing when <span class="math inline">\(p\)</span> is between 0 and 0.5, and has a point mass of probability at 0.5. But now the point mass has less weights than before. Also, note that the data have changed the posterior away from the original uniform prior when <span class="math inline">\(p\)</span> is between 0 and 0.5. The analyst sees a lot of probability under the curve near 0, which responds to the fact that no children were born to RU-486 mothers.</p>
<p>This section is mostly a look-ahead to future material. We have seen that a Bayesian might reasonably employ a non-conjugate prior in a practical application. But then she will need to employ some kind of numerical computation to approximate the posterior distribution. Additionally, we have used a computational tool, JAGS, to approximate the posterior for <span class="math inline">\(p\)</span>, and identified its three important elements, the probability of the data given <span class="math inline">\(p\)</span>, that is the likelihood, and the prior, and the call to the Gibbs sampler.</p>
</div>
<div id="credible-intervals" class="section level3">
<h3>Credible Intervals</h3>
<p>In this section, we introduce credible intervals, the Bayesian alternative to confidence intervals. Let’s start with the confidence intervals, which are the frequentist way to express uncertainty about an estimate of a population mean, a population proportion or some other parameter.</p>
<p>A confidence interval has the form of an upper and lower bound.</p>
<p><span class="math display">\[L, U = \text{pe} \pm \text{se} \times \text{cv}\]</span></p>
<p>where <span class="math inline">\(L\)</span>, <span class="math inline">\(U\)</span> are the lower bound and upper bound of the confidence interval respectively, <span class="math inline">\(\text{pe}\)</span> represents “point estimates”, <span class="math inline">\(\text{se}\)</span> is the standard error, and <span class="math inline">\(\text{cv}\)</span> is the critical value.</p>
<p>Most importantly, the interpretation of a 95% confidence interval on the mean is that <strong>“95% of similarly constructed intervals will contain the true mean”</strong>, not “the probability that true mean lies between <span class="math inline">\(L\)</span> and <span class="math inline">\(U\)</span> is 0.95”.</p>
<p>The reason for this frequentist wording is that a frequentist may not express his uncertainty as a probability. The true mean is either within the interval or not, so the probability is zero or one. The problem is that the frequentist does not know which is the case.</p>
<p>On the other hand, Bayesians have no such qualms. It is fine for us to say that <strong>“the probability that the true mean is contained within a given interval is 0.95”</strong>. To distinguish our intervals from confidence intervals, we call them <strong>credible intervals</strong>.</p>
<p>Recall the RU-486 example. When the analyst used the beta-binomial family, she took the prior as <span class="math inline">\(p \sim \text{beta}(1,1)\)</span>, the uniform distribution, where <span class="math inline">\(p\)</span> is the probability of a child having a mother who received RU-486.</p>
<p>After we observed four children born to mothers who received conventional therapy, her posterior is <span class="math inline">\(p|x \sim \text{beta}(1,5)\)</span>. In Figure <a href="#fig:posterior">9</a>, the posterior probability density for <span class="math inline">\(\text{beta}(1,5)\)</span> puts a lot of probability near zero and very little probability near one.</p>
<pre class="r"><code>library(ggthemes)
library(ggplot2)
x.vector = seq(from=0, to=1, by=0.001)
y.vector = dbeta(x.vector,1,5)

qplot(x = x.vector, y = y.vector, geom = &quot;line&quot;,  main=&quot;Beta(1,5)&quot;, xlab=&quot;p&quot;, ylab=&quot;Probability Density f(p)&quot;) + theme_tufte()</code></pre>
<div class="figure" style="text-align: center"><span id="fig:posterior"></span>
<img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/posterior-1.svg" alt="RU-486 Posterior" width="80%" />
<p class="caption">
Figure 9: RU-486 Posterior
</p>
</div>
<p>For the Bayesian, her 95% credible interval is just any <span class="math inline">\(L\)</span> and <span class="math inline">\(U\)</span> such that the posterior probability that <span class="math inline">\(L &lt; p &lt; U\)</span> is <span class="math inline">\(0.95\)</span>. The shortest such interval is obviously preferable.</p>
<p>To find this interval, the Bayesian looks at the area under the <span class="math inline">\(\text{beta}(1,5)\)</span> distribution, that lies to the left of a value x.</p>
<p>The density function of the <span class="math inline">\(\text{beta}(1,5)\)</span> is
<span class="math display">\[f(p) = 5 (1-p)^4 \text{ for } 0 \leq p \leq 1,\]</span></p>
<p>and the cumulative distribution function, which represents the area under the density function <span class="math inline">\(f(p)\)</span> between <span class="math inline">\(0\)</span> and <span class="math inline">\(x\)</span> is
<span class="math display">\[P(p\leq x)= F(x) = \int_0^x f(p)\, dp = 1 - (1-x)^5 ~\text{ for } 0 \leq p \leq 1.\]</span></p>
<p>The Bayesian can use this to find <span class="math inline">\(L, U\)</span> with area 0.95 under the density curve between them, i.e. <span class="math inline">\(F(U) - F(L) = 0.95\)</span>. Note that the Bayesian credible interval is asymmetric, unlike the symmetric confidence intervals that frequentists often obtain. It turns out that <span class="math inline">\(L = 0\)</span> and <span class="math inline">\(U = 0.45\)</span> is the shortest interval with probability 0.95 of containing <span class="math inline">\(p\)</span>.</p>
<p>What have we done? We have seen the difference in interpretations between the frequentist confidence interval and the Bayesian credible interval. Also, we have seen the general form of a credible interval. Finally, we have done a practical example constructing a 95% credible interval for the RU-486 data set.</p>
</div>
<div id="predictive-inference" class="section level3">
<h3>Predictive Inference</h3>
<p>Predictive inference arises when the goal is not to find a posterior distribution over some parameter, but rather to find a posterior distribution over some random variable depends on the parameter.</p>
<p>Specifically, we want to make an inference on a random variable <span class="math inline">\(X\)</span> with probability densifity function <span class="math inline">\(f(x|\theta)\)</span>, where you have some personal or prior probability distribution <span class="math inline">\(p(\theta)\)</span> for the parameter <span class="math inline">\(\theta\)</span>.</p>
<p>To solve this, one needs to integrate:
<span class="math display">\[P(X \leq x) = \int^{\infty}_{-\infty} P(X \leq x | \theta)\, p(\theta)d\theta = \int_{-\infty}^\infty \left(\int_{-\infty}^x f(s|\theta)\, ds\right)p(\theta)\, d\theta\]</span></p>
<p>The equation gives us the weighted average of the probabilities for <span class="math inline">\(X\)</span>, where the weights correspond to the personal probability on <span class="math inline">\(\theta\)</span>. Here we will not perform the integral case; instead, we will illustrate the thinking with a discrete example.</p>

<div class="example">
<p><span id="exm:unnamed-chunk-11" class="example"><strong>Example 17  </strong></span>Suppose you have two coins. One coin has probability 0.7 of coming up heads, and the other has probability 0.4 of coming up heads. You are playing a gambling game with a friend, and you draw one of those two coins at random from a bag.</p>
<p>Before you start the game, your prior belief is that the probability of choosing the 0.7 coin is 0.5. This is reasonable, because both coins were equally likely to be drawn. In this game, you win if the coin comes up heads.</p>
Suppose the game starts, you have tossed twice, and have obtained two heads. Then what is your new belief about <span class="math inline">\(p\)</span>, the probability that you are using the 0.7 coin?
</div>
<p>This is just a simple application of the discrete form of Bayes’ rule.</p>
<ul>
<li>Prior: <span class="math inline">\(p=0.5\)</span></li>
<li>Posterior:
<span class="math display">\[p^* = \frac{P(\text{2 heads}|0.7) \times 0.5}{P(\text{2 heads}|0.7) \times 0.5 + P(\text{2 heads}|0.4) \times 0.5} = 0.754.\]</span></li>
</ul>
<p>However, this does not answer the important question – What is the predictive probability that the next toss will come up heads? This is of interest because you are gambling on getting heads.</p>
<p>Fortunately, the predictive probability of getting heads is not difficult to calculate:</p>
<ul>
<li><span class="math inline">\(p^* \text{ of 0.7 coin } = 0.754\)</span></li>
<li><span class="math inline">\(p^* \text{ of 0.4 coin } = 1 − 0.754 = 0.246\)</span></li>
<li><span class="math inline">\(P(\text{heads}) = P(\text{heads} | 0.7) \times 0.754 + P(\text{heads} | 0.4) \times 0.246 = 0.626\)</span></li>
</ul>
<p>Therefore, the predictive probability that the next toss will come up heads is 0.626.</p>
<p>Note that most realistic predictive inference problems are more complicated and require one to use integrals. For example, one might want to know the chance that a fifth child born in the RU-486 clinical trial will have a mother who received RU-486. Or you might want to know the probability that your stock broker’s next recommendation will be profitable.</p>
<p>We have learned three things in this section. First, often the real goal is <strong>a prediction about the value of a future random variable</strong>, rather than making an estimate of a parameter. Second, these are deep waters, and often one needs to integrate. Finally, in certain simple cases where the parameter can only take discrete values, one can find a solution without integration. In our example, the parameter could only take two values to indicate which of the two coins was being used.</p>
</div>
</div>
</div>
<div id="losses-and-decision-making" class="section level1">
<h1>3 Losses and Decision Making</h1>
<p>In the previous chapter, we learned about continuous random variables. That enabled us to study conjugate families, such as the beta binomial, the Poisson gamma, and the normal normal. We also considered the difficulties of eliciting a personal prior, and of handling inference in nonconjugate cases. Finally, we introduced the credible interval and studied predictive inference.</p>
<p>In this new chapter, we will introduce loss functions and Bayesian decision making, minimizing expected loss for hypothesis testing, and define posterior probabilities of hypothesis and Bayes factors. We will then outline Bayesian testing for two proportions and two means, discuss how findings from credible intervals compare to those from our hypothesis test, and finally discuss when to reject, accept, or wait.</p>
<div id="bayesian-decision-making" class="section level2">
<h2>Bayesian Decision Making</h2>
<p>To a Bayesian, the posterior distribution is the basis of any inference, since it integrates both his/her prior opinions and knowledge and the new information provided by the data. It also contains everything she believes about the distribution of the unknown parameter of interest.</p>
<p>However, the posterior distribution on its own is not always sufficient. Sometimes the inference we want to express is a <strong>credible interval</strong>, because it indicates a range of likely values for the parameter. That would be helpful if you wanted to say that you are <strong>95% certain</strong> the probability of an RU-486 pregnancy lies between some number <span class="math inline">\(L\)</span> and some number <span class="math inline">\(U\)</span>. And on other occasions, one needs to make a single number guess about the value of the parameter. For example, you might want to declare the average payoff for an insurance claim or tell a patient how much longer he/she has to live.</p>
<p>Therefore, the Bayesian perspective leads directly to <strong>decision theory</strong>. And in decision theory, one seeks to minimize one’s expected loss.
## Loss Functions</p>
<p>Quantifying the loss can be tricky, and Table <a href="#tab:loss-functions">5</a> summarizes three different examples with three different loss functions.</p>
<p>If you’re declaring the average payoff for an insurance claim, and if you are <strong>linear</strong> in how you value money, that is, twice as much money is exactly twice as good, then one can prove that the optimal one-number estimate is the <strong>median</strong> of the posterior distribution. But in different situations, other measures of loss may apply.</p>
<p>If you are advising a patient on his/her life expectancy, it is easy to imagine that large errors are far more problematic than small ones. And perhaps the loss increases as the <strong>square</strong> of how far off your single number estimate is from the truth. For example, if she is told that her average life expectancy is two years, and it is actually ten, then her estate planning will be catastrophically bad, and she will die in poverty. In the case when the loss is proportional to the <strong>quadratic</strong> error, one can show that the optimal one-number estimate is the <strong>mean</strong> of the posterior distribution.</p>
<p>Finally, in some cases, the penalty is 0 if you are exactly correct, but constant if you’re at all wrong. This is the case with the old saying that close only counts with horseshoes and hand grenades; i.e., coming close but not succeeding is not good enough. And it would apply if you want a prize for correctly guessing the number of jelly beans in a jar. Here, of course, instead of minimizing expected losses, we want to <strong>maximize the expected gain</strong>. If a Bayesian is in such a situation, then his/her best one-number estimate is the <strong>mode</strong> of his/her posterior distribution, which is the most likely value.</p>
<p>There is a large literature on decision theory, and it is directly linked to risk analysis, which arises in many fields. Although it is possible for frequentists to employ a certain kind of decision theory, it is much more natural for Bayesians.</p>
<pre class="r"><code>temp &lt;- matrix(c(&quot;Linear&quot;,&quot;Median&quot;,
&quot;Quadratic&quot;,&quot;Mean&quot;,
&quot;0/1&quot;,&quot;Mode&quot;), nrow=3, byrow=TRUE)

colnames(temp) &lt;- c(&quot;Loss&quot;,&quot;Best Estimate&quot;)

knitr::kable(
x = temp, booktabs = TRUE,
caption = &quot;Loss Functions&quot;, align = &#39;c&#39;
)</code></pre>
<table>
<caption><span id="tab:loss-functions">Table 5: </span>Loss Functions</caption>
<thead>
<tr class="header">
<th align="center">Loss</th>
<th align="center">Best Estimate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Linear</td>
<td align="center">Median</td>
</tr>
<tr class="even">
<td align="center">Quadratic</td>
<td align="center">Mean</td>
</tr>
<tr class="odd">
<td align="center">0/1</td>
<td align="center">Mode</td>
</tr>
</tbody>
</table>
<p>When making point estimates of unknown parameters, we should make the choices that minimize the loss. Nevertheless, the best estimate depends on the kind of loss function we are using, and we will discuss in more depth how these best estimates are determined in the next section.
## Working with Loss Functions</p>
<p>Now we illustrate why certain estimates minimize certain loss functions.</p>

<div class="example">
<span id="exm:car" class="example"><strong>Example 18  </strong></span>You work at a car dealership. Your boss wants to know how many cars the dealership will sell per month. An analyst who has worked with past data from your company provided you a distribution that shows the probability of number of cars the dealership will sell per month. In Bayesian lingo, this is called the posterior distribution. A dot plot of that posterior is shown in Figure <a href="#fig:posterior-decision">10</a>. The mean, median and the mode of the distribution are also marked on the plot. Your boss does not know any Bayesian statistics though, so he/she wants you to report <strong>a single number</strong> for the number of cars the dealership will sell per month.
</div>
<pre class="r"><code># posterior ---------------------------------------------------------

posterior &lt;- c(47, 33, 35, 32, 19, 33, 34, 36, 47, 32, 35, 41, 32, 29, 35,
25, 32, 36, 20, 47, 37, 32, 35, 25, 37, 40, 36, 38, 40, 35, 49,
23, 33, 35, 38, 28, 36, 4, 28, 45, 37, 39, 34, 41, 28, 33, 27,
26, 30, 34, 23)

# length(posterior) # 51

# t(sort(posterior))

# mean(posterior) # 33.45098
# median(posterior) # 34
# table(posterior)[which.max(table(posterior))] # 35

# dotplot of posterior ----------------------------------------------

# pdf(&quot;posterior.pdf&quot;, width = 10, height = 3)
par(mar = c(2, 0, 0, 0), cex.axis = 1.5, cex = 1.5)
BHH2::dotPlot(posterior, pch = 19, xlim = c(0, 50), axes = FALSE)
axis(1, at = seq(from = 0, to = 50, by = 5))
abline(v = mean(posterior), col = &quot;orange&quot;, lwd = 4)
abline(v = median(posterior), col = &quot;turquoise4&quot;, lwd = 4)
abline(v = 35, col = &quot;pink&quot;, lwd = 4)
legend(&quot;topleft&quot;, col = c(&quot;orange&quot;, &quot;turquoise4&quot;, &quot;pink&quot;),
c(&quot;mean&quot;, &quot;median&quot;, &quot;mode&quot;), lty = 1, lwd = 4,
bty = &quot;n&quot;)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:posterior-decision"></span>
<img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/posterior-decision-1.svg" alt="Posterior" width="960" />
<p class="caption">
Figure 10: Posterior
</p>
</div>
<pre class="r"><code># dev.off()</code></pre>
<p>Suppose your single guess is 30, and we call this <span class="math inline">\(g\)</span> in the following calculations. If your loss function is <span class="math inline">\(L_0\)</span> (i.e., a 0/1 loss), then you lose a point for each value in your posterior that differs from your guess and do not lose any points for values that exactly equal your guess. The total loss is the sum of the losses from each value in the posterior.</p>
<p>In mathematical terms, we define <span class="math inline">\(L_0\)</span> (0/1 loss) as</p>
<p><span class="math display">\[L_{0,i}(0,g) = \left\{ \begin{array}{cc}
0 &amp; \text{if } g=x_i \\ 1 &amp; \text{otherwise}
\end{array}\right.\]</span></p>
<p>The total loss is <span class="math inline">\(L_0 = \sum_i L_{0,i}(0,g)\)</span>.</p>
<p>Let’s calculate what the total loss would be if your guess is 30. Table <a href="#tab:L0-table">6</a> summarizes the values in the posterior distribution sorted in descending order.</p>
<p>The first value is 4, which is not equal to your guess of 30, so the loss for that value is 1. The second value is 19, also not equal to your guess of 30, and the loss for that value is also 1. The third value is 20, also not equal to your guess of 30, and the loss for this value is also 1.</p>
<p>There is only one 30 in your posterior, and the loss for this value is 0 – since it’s equal to your guess (good news!). The remaining values in the posterior are all different than 30 hence, the loss for them are all ones as well.</p>
<p>To find the total loss, we simply sum over these individual losses in the posterior distribution with 51 observations where only one of them equals our guess and the remainder are different. Hence, the total loss is 50.</p>
<p>Figure <a href="#fig:L0-mode">11</a> is a visualization of the posterior distribution, along with the 0-1 loss calculated for a series of possible guesses within the range of the posterior distribution. To create this visualization of the loss function, we went through the process we described earlier for a guess of 30 for all guesses considered, and we recorded the total loss. We can see that the loss function has the lowest value when <span class="math inline">\(g\)</span>, our guess, is equal to <strong>the most frequent observation</strong> in the posterior. Hence, <span class="math inline">\(L_0\)</span> is minimized at the <strong>mode</strong> of the posterior, which means that if we use the 0/1 loss, the best point estimate is the mode of the posterior.</p>
<pre class="r"><code>i = c(1,2,3,&quot;&quot;,14,&quot;&quot;,50,51)
xi = c(4,19,20,&quot;...&quot;,30,&quot;...&quot;,47,49)
L0_loss = c(1,1,1,&quot;...&quot;,0,&quot;...&quot;,1,1)

temp &lt;- cbind(i,xi,L0_loss)
temp &lt;- rbind(temp, c(&quot;&quot;,&quot;Total&quot;,50))
temp &lt;- data.frame(temp)
names(temp) &lt;- c(&quot;i&quot;,&quot;x_i&quot;,&quot;L0: 0/1&quot;)

knitr::kable(
x = temp, booktabs = TRUE,
caption = &quot;L0: 0/1 loss for g = 30&quot;, align = &#39;c&#39;
)</code></pre>
<table>
<caption><span id="tab:L0-table">Table 6: </span>L0: 0/1 loss for g = 30</caption>
<thead>
<tr class="header">
<th align="center">i</th>
<th align="center">x_i</th>
<th align="center">L0: 0/1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">4</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">19</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center">20</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center"></td>
<td align="center">…</td>
<td align="center">…</td>
</tr>
<tr class="odd">
<td align="center">14</td>
<td align="center">30</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center"></td>
<td align="center">…</td>
<td align="center">…</td>
</tr>
<tr class="odd">
<td align="center">50</td>
<td align="center">47</td>
<td align="center">1</td>
</tr>
<tr class="even">
<td align="center">51</td>
<td align="center">49</td>
<td align="center">1</td>
</tr>
<tr class="odd">
<td align="center"></td>
<td align="center">Total</td>
<td align="center">50</td>
</tr>
</tbody>
</table>
<pre class="r"><code># g = 30 ------------------------------------------------------------

g = 30

# L0 for g ----------------------------------------------------------

# (abs(sort(posterior)-g) &gt; 1e-6)[c(1,2,3,12,13,14,50,51)]
# sum( abs(posterior-g) &gt; 1e-6 )

# L0 ----------------------------------------------------------------

# pdf(&quot;L0.pdf&quot;, width = 10, height = 5)
par(mfrow = c(2, 1), cex = 1.5, mar = c(2, 4, 0.5, 0), las = 1)
s = seq(0, 50, by = 0.01)
L0 = sapply(s, function(s) sum( abs(posterior - s) &gt; 1e-6 ))
plot(s, L0, ylab = &quot;L0&quot;, type = &quot;l&quot;, axes = FALSE, xlim = c(0, 50))
axis(2, at = c(44, 46, 48, 50))
#
BHH2::dotPlot(posterior, pch = 19, xlim = c(0, 50), axes = FALSE)
axis(1, at = seq(from = 0, to = 50, by = 5))
abline(v = mean(posterior), col = &quot;orange&quot;, lwd = 4)
abline(v = median(posterior), col = &quot;turquoise4&quot;, lwd = 4)
abline(v = 35, col = &quot;pink&quot;, lwd = 4)
legend(&quot;topleft&quot;, col = c(&quot;orange&quot;, &quot;turquoise4&quot;, &quot;pink&quot;),
c(&quot;mean&quot;, &quot;median&quot;, &quot;mode&quot;), lty = 1, lwd = 4,
bty = &quot;n&quot;)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:L0-mode"></span>
<img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/L0-mode-1.svg" alt="L0 is minimized at the mode of the posterior" width="960" />
<p class="caption">
Figure 11: L0 is minimized at the mode of the posterior
</p>
</div>
<pre class="r"><code># dev.off()</code></pre>
<p>Let’s consider another loss function. If your loss function is <span class="math inline">\(L_1\)</span> (i.e., linear loss), then the total loss for a guess is the sum of the <strong>absolute values</strong> of the difference between that guess and each value in the posterior. Note that the absolute value function is required, because overestimates and underestimates do not cancel out.</p>
<p>In mathematical terms, <span class="math inline">\(L_1\)</span> (linear loss) is calculated as <span class="math inline">\(L_1(g) = \sum_i |x_i - g|\)</span>.</p>
<p>We can once again calculate the total loss under <span class="math inline">\(L_1\)</span> if your guess is 30. Table <a href="#tab:L1-table">7</a> summarizes the values in the posterior distribution sorted in descending order.</p>
<p>The first value is 4, and the absolute value of the difference between 4 and 30 is 26. The second value is 19, and the absolute value of the difference between 19 and 30 is 11. The third value is 20 and the absolute value of the difference between 20 and 30 is 10.</p>
<p>There is only one 30 in your posterior, and the loss for this value is 0 since it is equal to your guess. The remaining value in the posterior are all different than 30 hence their losses are different than 0.</p>
<p>To find the total loss, we again simply sum over these individual losses, and the total is to 346.</p>
<p>Again, Figure <a href="#fig:L1-median">12</a> is a visualization of the posterior distribution, along with a linear loss function calculated for a series of possible guesses within the range of the posterior distribution. To create this visualization of the loss function, we went through the same process we described earlier for all of the guesses considered. This time, the function has the lowest value when <span class="math inline">\(g\)</span> is equal to the <strong>median</strong> of the posterior. Hence, <span class="math inline">\(L_1\)</span> is minimized at the <strong>median</strong> of the posterior one other loss function.</p>
<pre class="r"><code># i = c(1,2,3,&quot;&quot;,14,&quot;&quot;,50,51)
# xi = c(4,19,20,&quot;...&quot;,30,&quot;...&quot;,47,49)
L1_loss = c(26,11,10,&quot;...&quot;,0,&quot;...&quot;,17,19)

temp &lt;- cbind(i,xi,L1_loss)
temp &lt;- rbind(temp, c(&quot;&quot;,&quot;Total&quot;,346))
temp &lt;- data.frame(temp)
names(temp) &lt;- c(&quot;i&quot;,&quot;x_i&quot;,&quot;L1: |x_i-30|&quot;)

knitr::kable(
  x = temp, booktabs = TRUE,
  caption = &quot;L1: linear loss for g = 30&quot;, align = &#39;c&#39;
)</code></pre>
<table>
<caption><span id="tab:L1-table">Table 7: </span>L1: linear loss for g = 30</caption>
<thead>
<tr class="header">
<th align="center">i</th>
<th align="center">x_i</th>
<th align="center">L1: |x_i-30|</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">4</td>
<td align="center">26</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">19</td>
<td align="center">11</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center">20</td>
<td align="center">10</td>
</tr>
<tr class="even">
<td align="center"></td>
<td align="center">…</td>
<td align="center">…</td>
</tr>
<tr class="odd">
<td align="center">14</td>
<td align="center">30</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center"></td>
<td align="center">…</td>
<td align="center">…</td>
</tr>
<tr class="odd">
<td align="center">50</td>
<td align="center">47</td>
<td align="center">17</td>
</tr>
<tr class="even">
<td align="center">51</td>
<td align="center">49</td>
<td align="center">19</td>
</tr>
<tr class="odd">
<td align="center"></td>
<td align="center">Total</td>
<td align="center">346</td>
</tr>
</tbody>
</table>
<pre class="r"><code># L1 for g = 30 -----------------------------------------------------

# abs(sort(posterior) - g)[c(1,2,3,12,13,14,50,51)]
# sum(abs(sort(posterior) - g))

# L1 ----------------------------------------------------------------

# pdf(&quot;L1.pdf&quot;, width = 10, height = 5)
par(mfrow = c(2, 1), cex = 1.5, mar = c(2, 4, 0.5, 0), las = 1)
s = seq(0, 50, by = 0.01)
L1 = sapply(s,function(s) sum( abs(posterior - s) ))
plot(s, L1, ylab = &quot;L1&quot;, type = &quot;l&quot;, xlim = c(0, 50), axes = FALSE)
axis(2, at = seq(250, 1650, 350))
#
BHH2::dotPlot(posterior, pch = 19, xlim = c(0, 50), axes = FALSE)
axis(1, at = seq(from = 0, to = 50, by = 5))
abline(v = mean(posterior), col = &quot;orange&quot;, lwd = 4)
abline(v = median(posterior), col = &quot;turquoise4&quot;, lwd = 4)
abline(v = 35, col = &quot;pink&quot;, lwd = 4)
legend(&quot;topleft&quot;, col = c(&quot;orange&quot;, &quot;turquoise4&quot;, &quot;pink&quot;),
       c(&quot;mean&quot;, &quot;median&quot;, &quot;mode&quot;), lty = 1, lwd = 4,
       bty = &quot;n&quot;)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:L1-median"></span>
<img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/L1-median-1.svg" alt="L1 is minimized at the median of the posterior" width="960" />
<p class="caption">
Figure 12: L1 is minimized at the median of the posterior
</p>
</div>
<pre class="r"><code># dev.off()</code></pre>
<p>If your loss function is <span class="math inline">\(L_2\)</span> (i.e. a squared loss), then the total loss for a guess is the sum of the squared differences between that guess and each value in the posterior.</p>
<p>We can once again calculate the total loss under <span class="math inline">\(L_2\)</span> if your guess is 30. Table <a href="#tab:L2-table">8</a> summarizes the posterior distribution again, sorted in ascending order.</p>
<p>The first value is 4, and the squared difference between 4 and 30 is 676. The second value is 19, and the square of the difference between 19 and 30 is 121. The third value is 20, and the square difference between 20 and 30 is 100.</p>
<p>There is only one 30 in your posterior, and the loss for this value is 0 since it is equal to your guess. The remaining values in the posterior are again all different than 30, hence their losses are all different than 0.</p>
<p>To find the total loss, we simply sum over these individual losses again and the total loss comes out to 3,732. We have the visualization of the posterior distribution. Again, this time along with the squared loss function calculated for a possible serious of possible guesses within the range of the posterior distribution.</p>
<p>Creating the visualization in Figure <a href="#fig:L2-mean">13</a> had the same steps. Go through the same process described earlier for a guess of 30, for all guesses considered, and record the total loss. This time, the function has the lowest value when <span class="math inline">\(g\)</span> is equal to the <strong>mean</strong> of the posterior. Hence, <span class="math inline">\(L_2\)</span> is minimized at the <strong>mean</strong> of the posterior distribution.</p>
<pre class="r"><code># i = c(1,2,3,&quot;&quot;,14,&quot;&quot;,50,51)
# xi = c(4,19,20,&quot;...&quot;,30,&quot;...&quot;,47,49)
L2_loss = c(676,121,100,&quot;...&quot;,0,&quot;...&quot;,289,361)

temp &lt;- cbind(i,xi,L2_loss)
temp &lt;- rbind(temp, c(&quot;&quot;,&quot;Total&quot;,3732))
temp &lt;- data.frame(temp)
names(temp) &lt;- c(&quot;i&quot;,&quot;x_i&quot;,&quot;L2: (x_i-30)^2&quot;)

knitr::kable(
  x = temp, booktabs = TRUE,
  caption = &quot;L2: squared loss for g = 30&quot;, align = &#39;c&#39;
)</code></pre>
<table>
<caption><span id="tab:L2-table">Table 8: </span>L2: squared loss for g = 30</caption>
<thead>
<tr class="header">
<th align="center">i</th>
<th align="center">x_i</th>
<th align="center">L2: (x_i-30)^2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">4</td>
<td align="center">676</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">19</td>
<td align="center">121</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center">20</td>
<td align="center">100</td>
</tr>
<tr class="even">
<td align="center"></td>
<td align="center">…</td>
<td align="center">…</td>
</tr>
<tr class="odd">
<td align="center">14</td>
<td align="center">30</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center"></td>
<td align="center">…</td>
<td align="center">…</td>
</tr>
<tr class="odd">
<td align="center">50</td>
<td align="center">47</td>
<td align="center">289</td>
</tr>
<tr class="even">
<td align="center">51</td>
<td align="center">49</td>
<td align="center">361</td>
</tr>
<tr class="odd">
<td align="center"></td>
<td align="center">Total</td>
<td align="center">3732</td>
</tr>
</tbody>
</table>
<pre class="r"><code># L2 for g = 30 -----------------------------------------------------

# ((sort(posterior) - g)^2)[c(1,2,3,12,13,14,50,51)]
# sum((sort(posterior) - g)^2)

# L2 ----------------------------------------------------------------

# pdf(&quot;L2.pdf&quot;, width = 10, height = 5)
par(mfrow = c(2, 1), cex = 1.5, mar = c(2, 4, 0.5, 0), las = 1)
s = seq(0, 50, by = 0.01)
L2 = sapply(s,function(s) sum( (posterior - s)^2 ))
plot(s, L2, ylab = &quot;L2&quot;, type = &quot;l&quot;, xlim = c(0, 50), ylim = c(0, 61000), axes = FALSE)
axis(2, at = seq(0, 60000, 20000))
#
BHH2::dotPlot(posterior, pch = 19, xlim = c(0, 50), axes = FALSE)
axis(1, at = seq(from = 0, to = 50, by = 5))
abline(v = mean(posterior), col = &quot;orange&quot;, lwd = 4)
abline(v = median(posterior), col = &quot;turquoise4&quot;, lwd = 4)
abline(v = 35, col = &quot;pink&quot;, lwd = 4)
legend(&quot;topleft&quot;, col = c(&quot;orange&quot;, &quot;turquoise4&quot;, &quot;pink&quot;),
       c(&quot;mean&quot;, &quot;median&quot;, &quot;mode&quot;), lty = 1, lwd = 4,
       bty = &quot;n&quot;)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:L2-mean"></span>
<img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/L2-mean-1.svg" alt="L2 is minimized at the mean of the posterior" width="960" />
<p class="caption">
Figure 13: L2 is minimized at the mean of the posterior
</p>
</div>
<pre class="r"><code># dev.off()</code></pre>
<p>To sum up, the point estimate to report to your boss about the number of cars the dealership will sell per month <strong>depends on your loss function</strong>. In any case, you will choose to report the estimate that minimizes the loss.</p>
<ul>
<li><span class="math inline">\(L_0\)</span> is minimized at the <strong>mode</strong> of the posterior distribution.</li>
<li><span class="math inline">\(L_1\)</span> is minimized at the <strong>median</strong> of the posterior distribution.</li>
<li><span class="math inline">\(L_2\)</span> is minimized at the <strong>mean</strong> of the posterior distribution.
## Minimizing Expected Loss for Hypothesis Testing</li>
</ul>
<p>In Bayesian statistics, the inference about a parameter is made based on the posterior distribution, and let’s include this in the hypothesis test setting.</p>
<p>Suppose we have two competing hypothesis, <span class="math inline">\(H_1\)</span> and <span class="math inline">\(H_2\)</span>. Then we get</p>
<ul>
<li><span class="math inline">\(P(H_1 \text{ is true } | \text{ data})\)</span> = posterior probability of <span class="math inline">\(H_1\)</span></li>
<li><span class="math inline">\(P(H_2 \text{ is true } | \text{ data})\)</span> = posterior probability of <span class="math inline">\(H_2\)</span></li>
</ul>
<p>One straightforward way of choosing between <span class="math inline">\(H_1\)</span> and <span class="math inline">\(H_2\)</span> would be to <strong>choose the one with the higher posterior probability</strong>. In other words, the potential decision criterion is to</p>
<ul>
<li>Reject <span class="math inline">\(H_1\)</span> if <span class="math inline">\(P(H_1 \text{ is true } | \text{ data}) &lt; P(H_2 \text{ is true } | \text{ data})\)</span>.</li>
</ul>
<p>However, since hypothesis testing is a decision problem, we should also consider a loss function. Let’s revisit the HIV testing example in Section <a href="#sec:diagnostic-testing"><strong>??</strong></a>, and suppose we want to test the two competing hypotheses below:</p>
<ul>
<li><span class="math inline">\(H_1\)</span>: Patient does not have HIV</li>
<li><span class="math inline">\(H_2\)</span>: Patient has HIV</li>
</ul>
<p>These are the only two possibilities, so they are mutually exclusive hypotheses that cover the entire decision space.</p>
<p>We can define the loss function as <span class="math inline">\(L(d)\)</span> – the loss that occurs when decision <span class="math inline">\(d\)</span> is made. Then the Bayesian testing procedure minimizes the posterior expected loss.</p>
<p>The possible decisions (actions) are:</p>
<ul>
<li><span class="math inline">\(d_1\)</span>: Choose <span class="math inline">\(H_1\)</span> - decide that the patient does not have HIV</li>
<li><span class="math inline">\(d_2\)</span>: Choose <span class="math inline">\(H_2\)</span> - decide that the patient has HIV</li>
</ul>
<p>For each decision <span class="math inline">\(d\)</span>, we might be right, or we might be wrong. If the decision is right, the loss <span class="math inline">\(L(d)\)</span> associated with the decision <span class="math inline">\(d\)</span> is zero, i.e. no loss. If the decision is wrong, the loss <span class="math inline">\(L(d)\)</span> associated with the decision <span class="math inline">\(d\)</span> is some positive value <span class="math inline">\(w\)</span>.</p>
<p>For <span class="math inline">\(d=d_1\)</span>, we have</p>
<ul>
<li><p><strong>Right</strong>: Decide patient does not have HIV, and indeed they do not. <span class="math inline">\(\Rightarrow L(d_1) = 0\)</span></p>
<ul>
<li><strong>Wrong</strong>: Decide patient does not have HIV, but they do. <span class="math inline">\(\Rightarrow L(d_1) = w_1\)</span></li>
</ul>
<p>For <span class="math inline">\(d=d_2\)</span>, we also have</p></li>
<li><p><strong>Right</strong>: Decide patient has HIV, and indeed they do. <span class="math inline">\(\Rightarrow L(d_2) = 0\)</span></p>
<ul>
<li><strong>Wrong</strong>: Decide patient has HIV, but they don’t <span class="math inline">\(\Rightarrow L(d_2) = w_2\)</span></li>
</ul>
<p>The consequences of making a wrong decision <span class="math inline">\(d_1\)</span> or <span class="math inline">\(d_2\)</span> are different.</p></li>
</ul>
<p>Wrong <span class="math inline">\(d_1\)</span> is a <strong>false negative</strong>:</p>
<ul>
<li>We decide that patient does not have HIV when in reality they do.</li>
<li>Potential consequences: no treatment and premature death! (severe)</li>
</ul>
<p>Wrong <span class="math inline">\(d_2\)</span> is a <strong>false positive</strong>:</p>
<ul>
<li>We decide that the patient has HIV when in reality they do not.</li>
<li>Potential consequences: distress and unnecessary further investigation. (not ideal but less severe than the consequences of a false negative decision)</li>
</ul>
<p>Let’s put these definitions in the context of the HIV testing example with ELISA.</p>
<p><strong>Hypotheses</strong></p>
<ul>
<li><span class="math inline">\(H_1\)</span>: Patient does not have HIV</li>
<li><span class="math inline">\(H_2\)</span>: Patient has HIV</li>
</ul>
<p><strong>Decision</strong></p>
<ul>
<li><span class="math inline">\(d_1\)</span>: Choose <span class="math inline">\(H_1\)</span> - decide that the patient does not have HIV</li>
<li><span class="math inline">\(d_2\)</span>: Choose <span class="math inline">\(H_2\)</span> - decide that the patient has HIV</li>
</ul>
<p><strong>Losses</strong></p>
<ul>
<li><p><span class="math inline">\(L(d_1) = \left\{ \begin{array}{cc} 0 &amp; \text{if $d_1$ is right}\\ w_1=1000 &amp; \text{if $d_1$ is wrong} \end{array}\right.\)</span></p></li>
<li><p><span class="math inline">\(L(d_2) = \left\{ \begin{array}{cc} 0 &amp; \text{if $d_2$ is right}\\ w_2=10 &amp; \text{if $d_2$ is wrong} \end{array}\right.\)</span></p></li>
</ul>
<p>The values of <span class="math inline">\(w_1\)</span> and <span class="math inline">\(w_2\)</span> are arbitrarily chosen. But the important thing is that <span class="math inline">\(w_1\)</span>, the loss associated with a false negative determination, is much higher than <span class="math inline">\(w_2\)</span>, the loss associated with a false positive determination.</p>
<p><strong>Posteriors</strong></p>
<p>The plus sign means that our patient had tested positive on the ELISA.</p>
<ul>
<li><span class="math inline">\(P(H_1|+) \approx 0.88\)</span> - the posterior probability of the patient <strong>not</strong> having HIV given positive ELISA result</li>
<li><span class="math inline">\(P(H_2|+) \approx 0.12\)</span> - the posterior probability of the patient having HIV given positive ELISA result, as the complement value of <span class="math inline">\(P(H_1|+)\)</span></li>
</ul>
<p><strong>Expected losses</strong></p>
<ul>
<li><span class="math inline">\(E[L(d_1)] = 0.88 \times 0 + 0.12 \times 1000 = 120\)</span></li>
<li><span class="math inline">\(E[L(d_2)] = 0.88 \times 10 + 0.12 \times 0 = 8.8\)</span></li>
</ul>
<p>Since the expected loss for <span class="math inline">\(d_2\)</span> is lower, we should make this decision – the patient has HIV.</p>
<p>Note that our decision is highly influenced by the losses we assigned to <span class="math inline">\(d_1\)</span> and <span class="math inline">\(d_2\)</span>.</p>
<p>If the losses were symmetric, say <span class="math inline">\(w_1 = w_2 = 10\)</span>, then the expected loss for <span class="math inline">\(d_1\)</span> becomes</p>
<p><span class="math display">\[E[L(d_1)] = 0.88 \times 0 + 0.12 \times 10 = 1.2,\]</span></p>
<p>while the expected loss for <span class="math inline">\(d_2\)</span> would not change. Therefore, we would choose <span class="math inline">\(d_1\)</span> instead; that is, we would decide that the patient does not have HIV.</p>
<p>To recap, Bayesian methodologies allow for the integration of losses into the decision making framework easily. And in Bayesian testing, we minimize the posterior expected loss.</p>
</div>
<div id="sec:bayes-factors" class="section level2">
<h2>Posterior Probabilities of Hypotheses and Bayes Factors</h2>
<p>In this section, we will continue with the HIV testing example to introduce the concept of Bayes factors. Earlier, we introduced the concept of priors and posteriors. The <strong>prior odds</strong> is defined as <strong>the ratio of the prior probabilities of hypotheses</strong>.</p>
<p>Therefore, if there are two competing hypotheses being considered, then the prior odds of <span class="math inline">\(H_1\)</span> to <span class="math inline">\(H_2\)</span> can be defined as <span class="math inline">\(O[H_1:H_2]\)</span>, which is equal to <span class="math inline">\(P(H_1)\)</span> over probability of <span class="math inline">\(P(H_2)\)</span>. In mathematical terms,</p>
<p><span class="math display">\[O[H_1:H_2] = \frac{P(H_1)}{P(H_2)}\]</span></p>
<p>Similarly, the <strong>posterior odds</strong> is <strong>the ratio of the two posterior probabilities of hypotheses</strong>, written as</p>
<p><span class="math display">\[PO[H_1:H_2] = \frac{P(H_1|\text{data})}{P(H_2|\text{data})}\]</span></p>
<p>Using Bayes’ rule, we can rewrite the posterior probabilities as below:</p>
<p><span class="math display">\[\begin{aligned}
PO[H_1:H_2] &amp;= \frac{P(H_1|\text{data})}{P(H_2|\text{data})} \\
&amp;= \frac{(P(\text{data}|H_1) \times P(H_1)) / P(\text{data}))}{(P(\text{data}|H_2) \times P(H_2)) / P(\text{data}))} \\
&amp;= \frac{(P(\text{data}|H_1) \times P(H_1))}{(P(\text{data}|H_2) \times P(H_2))} \\
&amp;= \boxed{\frac{P(\text{data}|H_1)}{P(\text{data}|H_2)}} \times \boxed{\frac{P(H_1)}{P(H_2)}} \\
&amp;= \textbf{Bayes factor} \times \textbf{prior odds}
\end{aligned}\]</span></p>
<p>In mathematical notation, we have</p>
<p><span class="math display">\[PO[H_1:H_2] = BF[H_1:H_2] \times O[H_1:H_2]\]</span></p>
<p>In other words, the posterior odds is the product of the Bayes factor and the prior odds for these two hypotheses.</p>
<p>The Bayes factor quantifies the evidence of data arising from <span class="math inline">\(H_1\)</span> versus <span class="math inline">\(H_2\)</span>.</p>
<p>In a discrete case, the Bayes factor is simply the ratio of the likelihoods of the observed data under the two hypotheses, written as</p>
<p><span class="math display">\[BF[H_1:H_2] = \frac{P(\text{data}|H_1)}{P(\text{data}|H_2)}.\]</span></p>
<p>On the other hand, in a continuous case, the Bayes factor is the ratio of the marginal likelihoods, written as</p>
<p><span class="math display">\[BF[H_1:H_2] = \frac{\int P(\text{data}|\theta,H_1)d\theta}{\int P(\text{data}|\theta,H_2)d\theta}.\]</span></p>
<p>Note that <span class="math inline">\(\theta\)</span> is the set formed by all possible values of the model parameters.</p>
<p>In this section, we will stick with the simpler discrete case. And in upcoming sections, we will revisit calculating Bayes factors for more complicated models.</p>
<p>Let’s return to the HIV testing example from earlier, where our patient had tested positive in the ELISA.</p>
<p><strong>Hypotheses</strong></p>
<ul>
<li><span class="math inline">\(H_1\)</span>: Patient does not have HIV</li>
<li><span class="math inline">\(H_2\)</span>: Patient has HIV</li>
</ul>
<p><strong>Priors</strong></p>
<p>The prior probabilities we place on these hypothesis came from the prevalence of HIV at the time in the general population. We were told that the prevalence of HIV in the population was 1.48 out of 1000, hence the prior probability assigned to <span class="math inline">\(H_2\)</span> is 0.00148. And the prior assigned to <span class="math inline">\(H_1\)</span> is simply the complement of this.</p>
<ul>
<li><p><span class="math inline">\(P(H_1) = 0.99852\)</span> and <span class="math inline">\(P(H_2) = 0.00148\)</span></p>
<p>The prior odds are</p></li>
<li><p><span class="math inline">\(O[H_1:H_2] = \dfrac{P(H_1)}{P(H_2)} = \dfrac{0.99852}{0.00148} = 674.6757\)</span></p>
<p><strong>Posteriors</strong></p>
<p>Given a positive ELISA result, the posterior probabilities of these hypotheses can also be calculated, and these are approximately 0.88 and 0.12. We will hold on to more decimal places in our calculations to avoid rounding errors later.</p></li>
<li><p><span class="math inline">\(P(H_1|+) = 0.8788551\)</span> and <span class="math inline">\(P(H_2|+) = 0.1211449\)</span></p>
<p>The posterior odds are</p></li>
<li><p><span class="math inline">\(PO[H_1:H_2] = \dfrac{P(H_1|+)}{P(H_2|+)} = \dfrac{0.8788551}{0.1211449} = 7.254578\)</span></p>
<p><strong>Bayes Factor</strong></p>
<p>Finally, we can calculate the Bayes factor as the ratio of the posterior odds to prior odds, which comes out to approximately 0.0108. Note that in this simple discrete case the Bayes factor, it simplifies to the ratio of the likelihoods of the observed data under the two hypotheses.</p></li>
</ul>
<p><span class="math display">\[\begin{aligned}
BF[H_1:H_2] &amp;= \frac{PO[H_1:H_2]}{O[H_1:H_2]} = \frac{7.25457}{674.6757} \approx 0.0108 \\
&amp;= \frac{P(+|H_1)}{P(+|H_2)} = \frac{0.01}{0.93} \approx 0.0108
\end{aligned}\]</span></p>
<p>Alternatively, remember that the true positive rate of the test was 0.93 and the false positive rate was 0.01. Using these two values, the Bayes factor also comes out to approximately 0.0108.</p>
<p>So now that we calculated the Bayes factor, the next natural question is, what does this number mean? A commonly used scale for interpreting Bayes factors is proposed by <span class="citation">@jeffreys1961theory</span>, as in Table <a href="#tab:jeffreys1961">9</a>. If the Bayes factor is between 1 and 3, the evidence against <span class="math inline">\(H_2\)</span> is not worth a bare mention. If it is 3 to 20, the evidence is positive. If it is 20 to 150, the evidence is strong. If it is greater than 150, the evidence is very strong.</p>
<pre class="r"><code>temp &lt;- matrix(c(&quot;1 to 3&quot;, &quot;3 to 20&quot;, &quot;20 to 150&quot;, &quot;&gt; 150&quot;,
                 &quot;Not worth a bare mention&quot;,
                 &quot;Positive&quot;, &quot;Strong&quot;, &quot;Very strong&quot;),
               nrow=4, byrow=FALSE)

colnames(temp) &lt;- c(&quot;BF[H_1:H_2]&quot;,&quot;Evidence against H_2&quot;)


knitr::kable(
  x = temp, booktabs = TRUE,
  caption = &quot;Interpreting the Bayes factor&quot;, align = &#39;c&#39;
)</code></pre>
<table>
<caption><span id="tab:jeffreys1961">Table 9: </span>Interpreting the Bayes factor</caption>
<thead>
<tr class="header">
<th align="center">BF[H_1:H_2]</th>
<th align="center">Evidence against H_2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1 to 3</td>
<td align="center">Not worth a bare mention</td>
</tr>
<tr class="even">
<td align="center">3 to 20</td>
<td align="center">Positive</td>
</tr>
<tr class="odd">
<td align="center">20 to 150</td>
<td align="center">Strong</td>
</tr>
<tr class="even">
<td align="center">&gt; 150</td>
<td align="center">Very strong</td>
</tr>
</tbody>
</table>
<p>It might have caught your attention that the Bayes factor we calculated does not even appear on the scale. To obtain a Bayes factor value on the scale, we will need to change the order of our hypotheses and calculate <span class="math inline">\(BF[H_2:H_1]\)</span>, i.e. the Bayes factor for <span class="math inline">\(H_2\)</span> to <span class="math inline">\(H_1\)</span>. Then we look for evidence against <span class="math inline">\(H_1\)</span> instead.</p>
<p>We can calculate <span class="math inline">\(BF[H_2:H_1]\)</span> as a reciprocal of <span class="math inline">\(BF[H_1:H_2]\)</span> as below:</p>
<p><span class="math display">\[BF[H_2:H_1] = \frac{1}{BF[H_1:H_2]} = \frac{1}{0.0108} = 92.59259\]</span></p>
<p>For our data, this comes out to approximately 93. Hence the evidence against <span class="math inline">\(H_1\)</span> (the patient does not have HIV) is strong. Therefore, even though the posterior for having HIV given a positive result, i.e. <span class="math inline">\(P(H_2|+)\)</span>, was low, we would still decide that the patient has HIV, according to the scale based on a positive ELISA result.</p>
<p>An intuitive way of thinking about this is to consider not only the posteriors, but also the priors assigned to these hypotheses. Bayes factor is the ratio of the posterior odds to prior odds. While 12% is a low posterior probability for having HIV given a positive ELISA result, this value is still much higher than the overall prevalence of HIV in the population (in other words, the prior probability for that hypothesis).</p>
<p>Another commonly used scale for interpreting Bayes factors is proposed by <span class="citation">@kass1995bayes</span>, and it deals with the natural logarithm of the calculated Bayes factor. The values can be interpreted in Table <a href="#tab:kass1995">10</a>.</p>
<pre class="r"><code>temp &lt;- matrix(c(&quot;0 to 2&quot;, &quot;2 to 6&quot;, &quot;6 to 10&quot;, &quot;&gt; 10&quot;,
                 &quot;Not worth a bare mention&quot;,
                 &quot;Positive&quot;, &quot;Strong&quot;, &quot;Very strong&quot;),
               nrow=4, byrow=FALSE)

colnames(temp) &lt;- c(&quot;2*log(BF[H_2:H_1])&quot;,&quot;Evidence against H_1&quot;)


knitr::kable(
  x = temp, booktabs = TRUE,
  caption = &quot;Interpreting the Bayes factor&quot;, align = &#39;c&#39;
)</code></pre>
<table>
<caption><span id="tab:kass1995">Table 10: </span>Interpreting the Bayes factor</caption>
<thead>
<tr class="header">
<th align="center">2*log(BF[H_2:H_1])</th>
<th align="center">Evidence against H_1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">0 to 2</td>
<td align="center">Not worth a bare mention</td>
</tr>
<tr class="even">
<td align="center">2 to 6</td>
<td align="center">Positive</td>
</tr>
<tr class="odd">
<td align="center">6 to 10</td>
<td align="center">Strong</td>
</tr>
<tr class="even">
<td align="center">&gt; 10</td>
<td align="center">Very strong</td>
</tr>
</tbody>
</table>
<p>Reporting of the log scale can be helpful for numerical accuracy reasons when the likelihoods are very small. Taking two times the natural logarithm of the Bayes factor we calculated earlier, we would end up with the same decision that the evidence against <span class="math inline">\(H_1\)</span> is strong.</p>
<p><span class="math display">\[2 \times \log(92.59259) = 9.056418\]</span></p>
<p>To recap, we defined prior odds, posterior odds, and the Bayes factor. We learned about scales by which we can interpret these values for model selection. We also re-emphasize that in Bayesian testing, the order in which we evaluate the models of hypotheses does <strong>not</strong> matter. The Bayes factor of <span class="math inline">\(H_2\)</span> versus <span class="math inline">\(H_1\)</span>, <span class="math inline">\(BF[H_2:H_1]\)</span>, is simply the reciprocal of the Bayes factor for <span class="math inline">\(H_1\)</span> versus <span class="math inline">\(H_2\)</span>, that is, <span class="math inline">\(BF[H_1:H_2]\)</span>.</p>
</div>
</div>
<div id="inference-and-decision-making-with-multiple-parameters" class="section level1">
<h1>4 Inference and Decision-Making with Multiple Parameters</h1>
<p>We saw in <a href="#sec:normal-normal"><strong>??</strong></a> that if the data followed a normal distribution and that the variance was known, that the normal distribution was the conjugate prior distribution for the unknown mean. In this chapter, we will focus on the situation when the data follow a normal distribution with an unknown mean, but now consider the case where the variance is also unknown. When the variance <span class="math inline">\(\sigma^2\)</span> of the data is also unknown, we need to specify a joint prior distribution <span class="math inline">\(p(\mu, \sigma^2)\)</span> for both the mean <span class="math inline">\(\mu\)</span> and the variance <span class="math inline">\(\sigma^2\)</span>. We will introduce the conjugate normal-gamma family of distributions where the posterior distribution is in the same family as the prior distribution and leads to a marginal Student t distribution for posterior inference for the mean of the population.</p>
<p>We will present Monte Carlo simulation for inference about functions of the parameters as well as sampling from predictive distributions, which can also be used to assist with prior elicitation. For situations when limited prior information is available, we discuss a limiting case of the normal-gamma conjugate family, the reference prior, leading to a prior that can be used for a default or reference analysis. Finally, we will show how to create a more flexible and robust prior distribution by using mixtures of the normal-gamma conjugate prior, the Jeffreys-Zellner-Siow prior. For inference in this case we will introduce Markov Chain Monte Carlo, a powerful simulation method for Bayesian inference.</p>
<p>It is assumed that the readers have mastered the concepts of one-parameter normal-normal conjugate priors. Calculus is not required for this section; however, for those who are comfortable with calculus and would like to go deeper, we shall present optional sections with more details on the derivations.</p>
<p>Also note that some of the examples in this section use an updated version of the <code>bayes_inference</code> function.
If your local output is different from what is seen in this chapter, or the provided code fails to run for you please update to the most recent version of the <code>statsr</code> package.## The Normal-Gamma Conjugate Family {#sec:normal-gamma}</p>
<pre class="r"><code>library(tidyverse)
library(statsr)</code></pre>
<p>You may take the safety of your drinking water for granted, however, residents of Flint, Michigan were outraged over reports that the levels of a contaminant known as <strong>TTHM</strong> exceeded federal allowance levels in 2014. TTHM stands for total trihalomethanes, a group of chemical compounds first identified in drinking water in the 1970’s. Trihalomethanes are formed as a by-product from the reaction of chlorine or bromine with organic matter present in the water being disinfected for drinking. THMs have been associated through epidemiological studies with some adverse health effects and many are considered carcinogenic. In the United States, the EPA limits the total concentration of the four chief constituents (chloroform, bromoform, bromodichloromethane, and dibromochloromethane), referred to as total trihalomethanes (TTHM), to 80 parts per billion in treated water.</p>
<p>Since violations are based on annual running averages, we are interested in inference about the mean TTHM level based on measurements taken from samples.</p>
<p>In Section <a href="#sec:normal-normal"><strong>??</strong></a> we described the normal-normal conjugate family for inference about an unknown mean <span class="math inline">\(\mu\)</span> when the data <span class="math inline">\(Y_1, Y_2, \ldots, Y_n\)</span> were assumed to be a random sample of size <span class="math inline">\(n\)</span> from a normal population with a known standard deviation <span class="math inline">\(\sigma\)</span>, however, it is more common in practice to have data where the variability of observations is unknown, as in the example with TTHM. Conceptually, Bayesian inference for two (or more) parameters is not any different from the case with one parameter. As both <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span> unknown, we will need to specify a <strong>joint</strong> prior distribution, <span class="math inline">\(p(\mu, \sigma^2)\)</span> to describe our prior uncertainty about them. As before, Bayes Theorem leads to the posterior distribution for <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span> given the observed data to take the form
<span class="math display">\[
\begin{equation}
p(\mu, \sigma^2 \mid y_1, \ldots, y_n)  = 
\frac{p(y_1, \ldots, y_n \mid \mu, \sigma^2) \times
p(\mu, \sigma^2)}
{\text{normalizing constant}}. 
\end{equation}\]</span>
The <strong>likelihood function</strong> for <span class="math inline">\(\mu, \sigma^2\)</span> is proportional to the sampling distribution of the data, <span class="math inline">\({\text{Ca}l L}(\mu, \sigma^2) \propto p(y_1, \ldots, y_n \mid \mu, \sigma^2)\)</span> so that the posterior distribution can be re-expressed in proportional form
<span class="math display">\[\begin{equation}
p(\mu, \sigma^2 \mid y_1, \ldots, y_n)  \propto {\text{Ca}l L}(\mu, \sigma^2) p(\mu, \sigma^2).
\end{equation}\]</span></p>
<p>As in the earlier chapters, conjugate priors are appealing as there are nice expressions for updating the prior to obtain the posterior distribution using summaries of the data. In the case of two parameters or more parameters a conjugate pair is a sampling model for the data and a joint prior distribution for the unknown parameters such that the joint posterior distribution is in the same family of distributions as the prior distribution. In this case our sampling model is built on the assumption that the data are a random sample of size <span class="math inline">\(n\)</span> from a normal population with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>, expressed in shorthand as</p>
<p><span class="math display">\[\begin{aligned}
Y_1, \ldots Y_n  \overset{\text{iid}}{\sim}
\textsf{Normal}(\mu, \sigma^2) 
\end{aligned}\]</span>
where the ‘iid’ above the distribution symbol ‘<span class="math inline">\(\sim\)</span>’ indicates that each of the observations are <strong>i</strong>ndependent of the others (given <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span>) and are <strong>i</strong>dentically <strong>d</strong>istributed. Under this assumption, the sampling distribution of the data is the product of independent normal distributions with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>,
<span class="math display">\[\begin{equation}
p(y_1, \ldots, y_n \mid \mu, \sigma^2) = \prod_{i = 1}^n
\frac{1}{\sqrt{2 \pi \sigma^2}}
e^{\left\{- \frac{1}{2} \left(\frac{y_i - \mu}{\sigma}\right)^2\right\}}
\end{equation}\]</span>
which, after some algebraic manipulation and simplification, leads to a
likelihood function for <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span> that is proportional to
<span class="math display">\[
\begin{aligned}
{\text{Ca}l L}(\mu, \sigma^2) \propto 
(\sigma^2)^{-n/2}  \times \exp{ \left\{   
-\frac{1}{2} \frac{\sum_{i = 1}^n(y_i - \bar{y})^2 }{\sigma^2}
\right\}}  &amp; \times 
\exp{ \left\{   
-\frac{1}{2} \frac{n (\bar{y} - \mu)^2 }{\sigma^2} \right\}} \\
  \text{function of $\sigma^2$ and data} &amp; \times
  \text{function of $\mu$, $\sigma^2$ and data}
\end{aligned}
\]</span>
which depends on the data only through the sum of squares <span class="math inline">\(\sum_{i = 1}^n(y_i - \bar{y})^2\)</span> (or equivalently the sample variance <span class="math inline">\(s^2 = \sum_{i = 1}^n(y_i - \bar{y})^2/(n-1)\)</span>) and the sample mean <span class="math inline">\(\bar{y}\)</span>.
From the expression for the likelihood, we can see that the likelihood factors into two pieces: a term that is a function of <span class="math inline">\(\sigma^2\)</span> and the data; and a term that involves <span class="math inline">\(\mu\)</span>, <span class="math inline">\(\sigma^2\)</span> and the data.</p>
<p>Based on the factorization in the likelihood and the fact that any joint distribution for <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span> can be expressed as
<span class="math display">\[
p(\mu, \sigma^2) = p(\mu \mid \sigma^2) \times p(\sigma^2)
\]</span>
as the product of a <strong>conditional distribution</strong> for <span class="math inline">\(\mu\)</span> given <span class="math inline">\(\sigma^2\)</span> and a <strong>marginal distribution</strong> for <span class="math inline">\(\sigma^2\)</span>, this suggests that the posterior distribution should factor as the product of two conjugate distributions. Perhaps not surprisingly, this is indeed the case.</p>
<div id="conjugate-prior-for-mu-and-sigma2" class="section level3">
<h3>Conjugate Prior for <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span></h3>
<p>In Section <a href="#sec:normal-normal"><strong>??</strong></a>, we found that for normal data, the conjugate prior distribution for <span class="math inline">\(\mu\)</span> when the standard deviation <span class="math inline">\(\sigma\)</span> was known was a normal distribution. We will build on this to specify a conditional prior distribution for <span class="math inline">\(\mu\)</span> as a normal distribution
<span class="math display" id="eq:04-conjugate-normal">\[\begin{equation}
\mu \mid \sigma^2   \sim  \textsf{N}(m_0, \sigma^2/n_0)
\tag{8}
\end{equation}\]</span>
with hyper-parameters <span class="math inline">\(m_0\)</span>, the prior mean for <span class="math inline">\(\mu\)</span>, and <span class="math inline">\(\sigma^2/n_0\)</span> the prior variance. While previously we represented the prior variance as a fixed constant, <span class="math inline">\(\tau^2\)</span>, in this case we will replace <span class="math inline">\(\tau^2\)</span> with a multiple of <span class="math inline">\(\sigma^2\)</span>. Because <span class="math inline">\(\sigma\)</span> has the same units as the data, the presence of <span class="math inline">\(\sigma\)</span> in the prior variance automatically scales the prior for <span class="math inline">\(\mu\)</span> based on the same units. This is important, for example, if we were to change the measurement units from inches to centimeters or seconds to hours, as the prior will be re-scaled automatically. The hyper-parameter <span class="math inline">\(n_0\)</span> is unitless, but is used to express our prior precision about <span class="math inline">\(\mu\)</span> relative to the level of “noise”, captured by <span class="math inline">\(\sigma^2\)</span>, in the data. Larger values of <span class="math inline">\(n_0\)</span> indicate that we know the mean with more precision (relative to the variability in observations) with smaller values indicating less precision or more uncertainty. We will see later how the hyper-parameter <span class="math inline">\(n_0\)</span> may be interpreted as a prior sample size. Finally, while we could use a fixed value <span class="math inline">\(\tau^2\)</span> as the prior variance in a conditional conjugate prior for <span class="math inline">\(\mu\)</span> given <span class="math inline">\(\sigma^2\)</span>, that does not lead to a joint conjugate prior for <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span>.</p>
<p>As <span class="math inline">\(\sigma^2\)</span> is unknown, a Bayesian would use a
prior distribution to describe the uncertainty about the variance before seeing data. Since the variance is non-negative, continuous, and with no upper limit, based on the distributions that we have seen so far a gamma distribution might appear to be a candidate prior for the variance,. However, that choice does not lead to a posterior distribution in the same family or that is recognizable as any common distribution. It turns out that the the inverse of the variance, which is known as the precision, has a conjugate gamma prior distribution.</p>
<p>For simplification let’s express the precision (inverse variance) as a new parameter, <span class="math inline">\(\phi = 1/\sigma^2\)</span>. Then the conjugate prior for <span class="math inline">\(\phi\)</span>,
<span class="math display" id="eq:04-conjugate-gamma">\[\begin{equation}
\phi \sim \textsf{Gamma}\left(\frac{v_0}{2}, \frac{v_0 s^2_0}{2} \right)
\tag{9}
\end{equation}\]</span>
is a gamma distribution with shape parameter <span class="math inline">\(v_0/2\)</span> and <strong>rate</strong> parameter of <span class="math inline">\({v_0 s^2_0}/{2}\)</span>. Given the connections between the gamma distribution and the Chi-Squared distribution, the hyper-parameter <span class="math inline">\(v_0\)</span> may be interpreted as the prior degrees of freedom. The hyper-parameter <span class="math inline">\(s^2_0\)</span> may be interpreted as a prior variance or initial prior estimate for <span class="math inline">\(\sigma^2\)</span>. Equivalently, we may say that the inverse of the variance has a
<span class="math display">\[1/\sigma^2 \sim \textsf{Gamma}(v_0/2, s^2_0 v_0/2)\]</span></p>
<p>gamma distribution to avoid using a new symbol . Together the conditional normal distribution for <span class="math inline">\(\mu\)</span> given <span class="math inline">\(\sigma^2\)</span> in <a href="#eq:04-conjugate-normal">(8)</a> and the marginal gamma distribution for <span class="math inline">\(\phi\)</span> in <a href="#eq:04-conjugate-gamma">(9)</a> lead to a joint distribution for the pair <span class="math inline">\((\mu, \phi)\)</span> that we will call the normal-gamma family of distributions:
<span class="math display" id="eq:04-conjugate-normal-gamma">\[\begin{equation}(\mu, \phi) \sim \textsf{NormalGamma}(m_0, n_0, s^2_0, v_0)
\tag{10}
\end{equation}\]</span>
with the four hyper-parameters <span class="math inline">\(m_0\)</span>, <span class="math inline">\(n_0\)</span>, <span class="math inline">\(s^2_0\)</span>, and <span class="math inline">\(v_0\)</span>.</p>
<p>We can obtain the density for the (<span class="math inline">\(m_0, n_0, \nu_0, s^2_0\)</span>) family of distributions for <span class="math inline">\(\mu, \phi\)</span> by multiplying the conditional normal distribution for <span class="math inline">\(\mu\)</span> times the marginal gamma distribution for <span class="math inline">\(\phi\)</span>:
<span class="math display">\[\begin{equation}
p(\mu, \phi) = \frac{(n_0 \phi)^{1/2}} {\sqrt{2\pi}} e^{- \frac{\phi n_0}{2} (\mu -m_0)^2} \frac{1}{\text{Ga}mma(\nu_0/2)} (\nu_0 s^2_0 )^{\nu_0/2 -1} e^{- \phi \frac{\nu_0 s^2_0} {2}}
\label{eq:NG}
\end{equation}\]</span></p>
<p>The joint conjugate prior has simple rules for updating the prior hyper-parameters given new data to obtain the posterior hyper-parameters due to conjugacy.</p>
</div>
<div id="conjugate-posterior-distribution" class="section level3">
<h3>Conjugate Posterior Distribution</h3>
<p>As a conjugate family, the posterior
distribution of the pair of parameters (<span class="math inline">\(\mu, \phi\)</span>) is in the same family as the prior distribution when the sample data arise from a normal distribution, that is the posterior is also normal-gamma
<span class="math display">\[\begin{equation}
(\mu, \phi) \mid \text{data} \sim \textsf{NormalGamma}(m_n, n_n, s^2_n, v_n)
\end{equation}\]</span>
where the subscript <span class="math inline">\(n\)</span> on the
hyper-parameters indicates the updated values after seeing the <span class="math inline">\(n\)</span> observations from the sample data. One attraction of conjugate families is there are relatively simple updating rules for obtaining the new hyper-parameters:
<span class="math display">\[\begin{eqnarray*}
m_n &amp; = &amp; \frac{n \bar{Y} + n_0 m_0} {n + n_0}  \\
&amp; \\
n_n &amp; = &amp; n_0 + n  \\
v_n &amp; = &amp; v_0 + n  \\
s^2_n &amp; =  &amp; \frac{1}{v_n}\left[ s^2 (n-1) + s^2_0 v_0 + \frac{n_0 n}{n_n} (\bar{y} - m_0)^2 \right]. 
\end{eqnarray*}\]</span>
Let’s look more closely to try to understand the updating rules.
The updated hyper-parameter <span class="math inline">\(m_n\)</span> is the posterior mean for <span class="math inline">\(\mu\)</span>; it is also the mode and median. The posterior mean <span class="math inline">\(m_n\)</span> is a weighted average of the sample mean <span class="math inline">\(\bar{y}\)</span> and prior mean <span class="math inline">\(m_0\)</span> with weights <span class="math inline">\(n/(n + n_0)\)</span> and <span class="math inline">\(n_0/(n + n_0)\)</span> that are proportional to the precision in the data, <span class="math inline">\(n\)</span>, and the prior precision, <span class="math inline">\(n_0\)</span>, respectively.</p>
<p>The posterior sample size <span class="math inline">\(n_n\)</span> is the sum of the prior sample
size <span class="math inline">\(n_0\)</span> and the sample size <span class="math inline">\(n\)</span>, representing the combined precision after seeing the data for the posterior distribution for <span class="math inline">\(\mu\)</span>. The posterior degrees of freedom <span class="math inline">\(v_n\)</span> are also increased by adding the sample size <span class="math inline">\(n\)</span> to the prior degrees of freedom <span class="math inline">\(v_0\)</span>.</p>
<p>Finally, the posterior variance hyper-parameter <span class="math inline">\(s^2_n\)</span> combines three sources of information about <span class="math inline">\(\sigma^2\)</span> in terms of sums of squared deviations. The first term in
the square brackets is the sample variance times the sample degrees of
freedom, <span class="math inline">\(s^2 (n-1) = \sum_{i=1}^n (y_i - \bar{y})^2\)</span>, which is the sample sum of squares. Similarly, we may view the second term as a sum of squares based on prior data, where <span class="math inline">\(s^2_0\)</span> was an estimate of <span class="math inline">\(\sigma^2\)</span>. The squared difference of the sample mean and prior mean in the last term also provides an estimate of <span class="math inline">\(\sigma^2\)</span>, where a large value of <span class="math inline">\((\bar{y} - \mu_0)^2\)</span> increases the posterior sum of squares <span class="math inline">\(v_n s^2_n\)</span>.<br />
If the sample mean is far from our prior mean, this increases the probability that <span class="math inline">\(\sigma^2\)</span> is large. Adding these three sum of squares provides the posterior sum of square, and dividing by the posterior
posterior degrees of freedom we obtain the new hyper-parameter <span class="math inline">\(s^2_n\)</span>, which is an estimate of <span class="math inline">\(\sigma^2\)</span> combining the sources of variation from the prior and the data.</p>
<p>The joint posterior distribution for the pair <span class="math inline">\(\mu\)</span> and
<span class="math inline">\(\phi\)</span>
<span class="math display">\[(\mu, \phi) \mid \text{data} \sim \text{NormalGamma}(m_n, n_n, s^2_n, v_n)\]</span>
is in the normal-gamma family, and is equivalent to a <strong>hierarchical model</strong> specified in two stages: in the
first stage of the hierarchy the inverse variance or precision marginally has a gamma distribution,
<span class="math display">\[
1/\sigma^2 \mid \text{data}   \sim   \text{Gamma}(v_n/2, s^2_n v_n/2) 
\]</span>
and in the second stage, <span class="math inline">\(\mu\)</span> given <span class="math inline">\(\sigma\)</span></p>
<p><span class="math display">\[\mu \mid \text{data}, \sigma^2  \sim  \text{Normal}(m_n, \sigma^2/n_n)\]</span>
has a conditional normal distribution. We will see in the next chapter how this representation is convenient for generating samples from the posterior distribution.</p>
</div>
<div id="marginal-distribution-for-mu-student-t" class="section level3">
<h3>Marginal Distribution for <span class="math inline">\(\mu\)</span>: Student <span class="math inline">\(t\)</span></h3>
<p>The joint normal-gamma posterior summarizes our current knowledge about <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span>, however, we are generally interested in inference about <span class="math inline">\(\mu\)</span> unconditionally
as <span class="math inline">\(\sigma^2\)</span> is unknown. This marginal inference requires the unconditional or marginal distribution of <span class="math inline">\(\mu\)</span> that `averages’ over the uncertainty in <span class="math inline">\(\sigma\)</span>. For continuous variables like <span class="math inline">\(\sigma\)</span>, this averaging is performed by integration leading to a Student <span class="math inline">\(t\)</span> distribution.</p>
<p>The <em>standardized Student <span class="math inline">\(t\)</span>-distribution</em> <span class="math inline">\(t_\nu\)</span> with <span class="math inline">\(\nu\)</span> degrees of freedom is defined to be
<span class="math display">\[ p(t) = \frac{1}{\sqrt{\pi\nu}}\frac{\text{Ga}mma(\frac{\nu+1}{2})}{\text{Ga}mma(\frac{\nu}{2})}\left(1 + \frac{t^2}{\nu}\right)^{-\frac{\nu+1}{2}} \]</span>
where the <span class="math inline">\(\text{Ga}mma(\cdot)\)</span> is the Gamma function defined earlier in Equation <a href="#eq:gamma-function">(7)</a>. The standard Student’s <span class="math inline">\(t\)</span>-distribution is centered at 0 (the location parameter), with a scale parameter equal to 1, like in a standard normal, however, there is an additional parameter, <span class="math inline">\(\nu\)</span>, the degrees of freedom parameter.</p>
<p>The Student <span class="math inline">\(t\)</span> distribution is similar to the normal distribution as it is symmetric about the center and bell shaped, however, the <strong>tails</strong> of the distribution are fatter or heavier than the normal distribution and therefore, it is a little “shorter” in the middle as illustrated in Figure <a href="#fig:density"><strong>??</strong></a></p>
<pre class="r"><code>x = seq(-4, 4, by = 0.005)
y_norm = dnorm(x, mean = 0, sd = 1)
y_t = dt(x, df = 4)
my_data = data.frame(x = x, y_norm = y_norm, y_t = y_t)

ggplot(data = my_data) + geom_line(aes(x = x, y = y_norm, lty = &quot;standard normal&quot;), size = 1) + 
  geom_line(aes(x = x, y = y_t, lty = &quot;Student t t(4,0,1)&quot;), size = 1) + 
  xlab(&quot;&quot;) + ylab(&quot;density&quot;) +
  scale_linetype_manual(values = c(2, 1), name = &quot;&quot;)</code></pre>
<div class="figure"><span id="fig:t-density"></span>
<img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/t-density-1.svg" alt="Standard normal and Student t densities." width="576" />
<p class="caption">
Figure 14: Standard normal and Student t densities.
</p>
</div>
<p>Similar to the normal distribution, we can obtain other Student <span class="math inline">\(t\)</span> distributions by changing the center of the distribution and changing the scale. A Student t distribution with a location <span class="math inline">\(m\)</span> and scale <span class="math inline">\(s\)</span> with <span class="math inline">\(v\)</span> degrees of freedom is denoted as <span class="math inline">\(t(v, m, s^2)\)</span>, with the standard Student t as a special case, <span class="math inline">\(t(\nu, 0, 1)\)</span>.</p>
<p>The density for a <span class="math inline">\(X \sim t(v, m, s^2)\)</span> random variable is
<span class="math display" id="eq:Student-t-density">\[\begin{equation}
p(x) =\frac{\text{Ga}mma\left(\frac{v + 1}{2} \right)}
{\sqrt{\pi v} s \,\text{Ga}mma\left(\frac{v}{2} \right)}
\left(1 + \frac{1}{v}\left(\frac{x - m} {s} \right)^2 \right)^{-\frac{v+1}{2}} 
\tag{11}
\end{equation}\]</span>
and by subtracting the location <span class="math inline">\(m\)</span> and dividing by the scale
<span class="math inline">\(s\)</span>:
<span class="math display">\[ \frac{X - m}{s} \equiv t \sim t(v, 0 , 1)  \]</span>
we can obtain the distribution of the standardized Student <span class="math inline">\(t\)</span> distribution with degrees of freedom <span class="math inline">\(v\)</span>, location <span class="math inline">\(0\)</span> and scale <span class="math inline">\(1\)</span>. This latter representation allows us to use standard statistical functions for posterior inference such as finding credible intervals.</p>
We are now ready for our main result for the marginal distribution for <span class="math inline">\(\mu\)</span>.

<div class="definition">
<p><span id="def:unnamed-chunk-12" class="definition"><strong>Definition 2  </strong></span>If <span class="math inline">\(\mu\)</span> and <span class="math inline">\(1/\sigma^2\)</span> have a <span class="math inline">\(\textsf{NormalGamma}(m_n, n_n, v_n, s^2_n)\)</span> posterior distribution, then
<span class="math inline">\(\mu\)</span> given the data has a  distribution, <span class="math inline">\(t(v_n, m_n, s^2_n/n_n)\)</span>, expressed as
<span class="math display">\[ \mu \mid \text{data} \sim t(v_n, m_n, s^2_n/n_n)  \]</span>
with degrees of freedom <span class="math inline">\(v_n\)</span>,
location parameter, <span class="math inline">\(m_n\)</span>, and squared scale parameter, <span class="math inline">\(s^2_n/n_n\)</span>, that is the
posterior variance parameter divided by the posterior sample size.</p>
</div>
<p>The parameters <span class="math inline">\(m_n\)</span> and <span class="math inline">\(s^2_n\)</span> play similar roles in determining the center and spread of the distribution, as in the normal distribution, however, as Student <span class="math inline">\(t\)</span> distributions with degrees of freedom less than 3 do not have a mean or variance, the parameter <span class="math inline">\(m_n\)</span> is called the location or center of the distribution and the <span class="math inline">\(s_n/\sqrt{n}\)</span> is the scale.</p>
<p>Let’s use this result to find credible intervals for <span class="math inline">\(\mu\)</span>.</p>
</div>
<div id="credible-intervals-for-mu" class="section level3">
<h3>Credible Intervals for <span class="math inline">\(\mu\)</span></h3>
<p>To find a credible interval for the mean <span class="math inline">\(\mu\)</span>, we will use the marginal posterior distribution for <span class="math inline">\(\mu\)</span> as illustrated in Figure <a href="#fig:tapwater-post-mu">15</a>.
Since the Student <span class="math inline">\(t\)</span> distribution of <span class="math inline">\(\mu\)</span> is unimodal and symmetric, the shortest 95 percent credible interval or the <strong>Highest Posterior Density</strong> interval, HPD for short,
is the interval given by the dots at the
lower endpoint L and upper endpoint U where the heights of the density at L and U are equal and all other values for <span class="math inline">\(\mu\)</span> have higher posterior density. The probability that <span class="math inline">\(\mu\)</span> is in the interval (L, U) (the shaded area) equals the desired probability, e.g. 0.95 for a 95% credible interval.</p>
<pre class="r"><code>require(ggplot2)
data(tapwater)
m_0 = 35; 
n_0 = 25; 
s2_0 = 156.25;
v_0 = n_0 - 1

out = bayes_inference(tthm, data=tapwater, prior=&quot;NG&quot;,
                      mu_0 = m_0, n_0 = n_0, s_0 = sqrt(s2_0), v_0 = v_0,
                      method=&quot;theoretical&quot;, stat=&quot;mean&quot;, type=&quot;ci&quot;, 
                      show_res=FALSE, show_summ=FALSE, show_plot=TRUE)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:tapwater-post-mu"></span>
<img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/tapwater-post-mu-1.svg" alt="Highest Posterior Density region." width="480" />
<p class="caption">
Figure 15: Highest Posterior Density region.
</p>
</div>
<pre class="r"><code>den = out$post_den

ci = out$ci
d = data.frame(mu = den$x, dens = den$y)

d = d[d$dens &gt; 1e-4,]

li = min(which(d$mu &gt;= ci[1]))
ui = max(which(d$mu &lt;  ci[2]))

ci_poly = data.frame(mu = c(d$mu[c(li,li:ui,ui)]),
                     dens = c(0, d$dens[li:ui], 0))


ci_interval = data.frame(mu = ci, dens = 0)
pos_plot = ggplot(d, aes_string(x=&quot;mu&quot;, y=&quot;dens&quot;)) +
  geom_line() +
  ylab(&quot;Density&quot;) +
  xlab(expression(mu)) +
  geom_line(data  = ci_interval, size=1.5, colour=&quot;orange&quot;) +
  geom_point(data = ci_interval, size=2) +
  geom_polygon(data = ci_poly, alpha=0.5) +
  theme(panel.background = element_rect(fill = &quot;transparent&quot;, colour = NA),
        plot.background = element_rect(fill = &quot;transparent&quot;, colour = NA)) +
  theme(text = element_text(size=12))</code></pre>
<p>Using the standardized Student <span class="math inline">\(t\)</span> distribution and some algebra, these values are
<span class="math display">\[
\begin{aligned}
  L &amp; =  m_n + t_{0.025}\sqrt{s^2_n/n_n}    \\
  U &amp; =  m_n + t_{0.975}\sqrt{s^2_n/n_n}
\end{aligned}
\]</span>
or the posterior mean (our point estimate) plus quantiles of the standard <span class="math inline">\(t\)</span> distribution times the scale. Because of the symmetry in the Student <span class="math inline">\(t\)</span> distribution, the credible interval for <span class="math inline">\(\mu\)</span> is <span class="math inline">\(m_n \pm t_{0.975}\sqrt{s^2_n/n_n}\)</span>, which is similar to the expressions for confidence intervals for the mean.</p>
</div>
<div id="sec:tapwater" class="section level3">
<h3>Example: TTHM in Tapwater</h3>
<p>A municipality in North Carolina is interested in estimating the levels of TTHM in their drinking water. The data can be loaded from the <code>statsr</code> package in <code>R</code>, where the variable of interest, <code>tthm</code> is measured in parts per billion.</p>
<pre class="r"><code>library(statsr)
data(tapwater)
glimpse(tapwater)</code></pre>
<pre><code>## Rows: 28
## Columns: 6
## $ date       &lt;fct&gt; 2009-02-25, 2008-12-22, 2008-09-25, 2008-05-14, 2008-04-14,~
## $ tthm       &lt;dbl&gt; 34.38, 39.33, 108.63, 88.00, 81.00, 49.25, 75.00, 82.86, 85~
## $ samples    &lt;int&gt; 8, 9, 8, 8, 2, 8, 6, 7, 8, 4, 4, 4, 4, 6, 4, 8, 10, 10, 10,~
## $ nondetects &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,~
## $ min        &lt;dbl&gt; 32.00, 31.00, 85.00, 75.00, 81.00, 26.00, 70.00, 70.00, 80.~
## $ max        &lt;dbl&gt; 39.00, 46.00, 120.00, 94.00, 81.00, 68.00, 80.00, 90.00, 90~</code></pre>
<pre class="r"><code>Y = tapwater$tthm
ybar = mean(Y)
s2 = var(Y)
n = length(Y)
n_n = n_0 + n
m_n = (n*ybar + n_0*m_0)/n_n
v_n = v_0 + n
s2_n = round( ((n-1)*s2 + v_0*s2_0 + n_0*n*(m_0 - ybar)^2/n_n)/v_n, 1)
L = qt(.025, v_n)*sqrt(s2_n/n_n) + m_n
U = qt(.975, v_n)*sqrt(s2_n/n_n) + m_n</code></pre>
<p>Using historical prior information about TTHM from the municipality, we will adopt a normal-gamma prior distribution,
<span class="math inline">\(\textsf{NormalGamma}(35, 25, 156.25, 24)\)</span> with
a prior mean of 35 parts per billion, a prior sample
size of 25, an estimate of the variance of 156.25 with degrees of freedom 24. In Section <a href="#sec:NG-predictive"><strong>??</strong></a>, we will describe how we arrived at these values.</p>
<p>Using the summaries of the data, <span class="math inline">\(\bar{Y} = 55.5\)</span>,
variance <span class="math inline">\(s^2 = 540.7\)</span> and sample size of <span class="math inline">\(n = 28\)</span> with the
prior hyper-parameters from above, the posterior hyper-parameters are updated as follows:
<span class="math display">\[\begin{eqnarray*}
n_n &amp; = &amp;  25 +  28 = 53\\
m_n  &amp; = &amp; \frac{28 \times55.5 + 25 \times35}{53} = 45.8  \\
v_n &amp; = &amp; 24 + 28 = 52  \\
s^2_n &amp; = &amp; \frac{(n-1) s^2 + v_0 s^2_0 + n_0 n (m_0 - \bar{Y})^2 /n_n }{v_n}  \\
  &amp; = &amp; \frac{1}{52}
     \left[27 \times 540.7 +
          24 \times 156.25  +
          \frac{25 \times 28}{53} \times (35 - 55.5)^2
\right] = 459.9  \\
\end{eqnarray*}\]</span>
in the conjugate <span class="math inline">\(\textsf{NormalGamma}(45.8, 53, 459.9, 52)\)</span>
posterior distribution that now summarizes our
uncertainty about <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\phi\)</span> (<span class="math inline">\(\sigma^2\)</span>) after seeing the data.</p>
<p>We can obtain the updated hyper-parameters in <code>R</code> using the following code in <code>R</code></p>
<pre class="r"><code># prior hyper-parameters
m_0 = 35; n_0 = 25;  s2_0 = 156.25; v_0 = n_0 - 1
# sample summaries
Y = tapwater$tthm
ybar = mean(Y)
s2 = var(Y)
n = length(Y)
# posterior hyperparameters
n_n = n_0 + n
m_n = (n*ybar + n_0*m_0)/n_n
v_n = v_0 + n
s2_n = ((n-1)*s2 + v_0*s2_0 + n_0*n*(m_0 - ybar)^2/n_n)/v_n</code></pre>
<p>Using the following code in <code>R</code> the 95%
credible interval for the tap water data may be obtained using the Student <span class="math inline">\(t\)</span> quantile function <code>qt</code>.</p>
<pre class="r"><code>m_n + qt(c(0.025, 0.975), v_n)*sqrt(s2_n/n_n)</code></pre>
<pre><code>## [1] 39.93192 51.75374</code></pre>
<p>The <code>qt</code> function takes two arguments: the first is the desired quantiles, while the second is the degrees of freedom. Both arguments may be vectors, in which case, the result will be a vector.</p>
<p>While we can calculate the interval directly as above, we have provided the <code>bayes_inference</code> function in the <code>statsr</code> package to calculate the posterior hyper-parameters, credible intervals and plot the posterior density and the HPD interval given the raw data:</p>
<pre class="r"><code>bayes_inference(tthm, data=tapwater, prior=&quot;NG&quot;,
                mu_0 = m_0, n_0=n_0, s_0 = sqrt(s2_0), v_0 = v_0,
                stat=&quot;mean&quot;, type=&quot;ci&quot;, method=&quot;theoretical&quot;, 
                show_res=TRUE, show_summ=TRUE, show_plot=FALSE)</code></pre>
<pre><code>## Single numerical variable
## n = 28, y-bar = 55.5239, s = 23.254
## (Assuming proper prior:  mu | sigma^2 ~ N(35, *sigma^2/25)
## (Assuming proper prior: 1/sigma^2 ~ G(24/2,156.25*24/2)
## 
## Joint Posterior Distribution for mu and 1/sigma^2:
##  N(45.8428, sigma^2/53) G(52/2, 8.6769*52/2)
## 
## Marginal Posterior for mu:
## Student t with posterior mean = 45.8428, posterior scale = 2.9457 on 52 df
## 
## 95% CI: (39.9319 , 51.7537)</code></pre>
<p>Let’s try to understand the arguments to the function. The first argument of the function is the variable of interest, <code>tthm</code>, while the second argument is a dataframe with the variable. The argument <code>prior="NG"</code> indicates that we are using a normal-gamma prior; later we will present alternative priors. The next two lines provide our prior hyper-parameters. The line with <code>stat="mean", type="ci"</code> indicate that we are interested in inference about the population mean <span class="math inline">\(\mu\)</span> and to calculate a credible interval for <span class="math inline">\(\mu\)</span>. The argument <code>method = theoretical</code> indicates that we will use the exact quantiles of the Student <span class="math inline">\(t\)</span> distribution to obtain our posterior credible intervals. Looking at the output the credible interval agrees with the interval we calculated from the summaries using the t quantiles. The other arguments are logical variables to toggle on/off the various output. In this case we have suppressed producing the plot of the posterior distribution using the option <code>show_plot=FALSE</code>, however, setting this to <code>TRUE</code> produces the density and credible interval shown in Figure @ref{fig:tapwater-post-mu}.</p>
<p>How do we interpret these results? Based on the updated posterior, we find that there is a 95% chance that
the mean TTHM concentration is between 39.9
parts per billion and 51.8 parts per billion, suggesting that for this period that the municipality is in compliance with the limits.</p>
<pre class="r"><code>ggplot(data=tapwater, aes(x=tthm)) + geom_histogram()</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/unnamed-chunk-13-1.svg" width="576" /></p>
</div>
<div id="section-summary" class="section level3">
<h3>Section Summary</h3>
<p>The normal-gamma conjugate prior for
inference about an unknown mean and variance for samples from a normal
distribution allows simple expressions for updating prior beliefs given the data. The joint normal-gamma distribution leads to the
Student <span class="math inline">\(t\)</span> distribution for inference about <span class="math inline">\(\mu\)</span> when <span class="math inline">\(\sigma^2\)</span> is unknown. The Student <span class="math inline">\(t\)</span> distribution can be used to provide
credible intervals for <span class="math inline">\(\mu\)</span> using <code>R</code> or other software that provides quantiles of a standard <span class="math inline">\(t\)</span> distribution.</p>
<p>For the energetic learner who is comfortable with calculus, the optional material at the end of this section provides more details on how the posterior distributions were obtained and other results in this section.</p>
<p>For those that are ready to move on, we will introduce Monte Carlo sampling in the next section; Monte Carlo sampling is a simulation method that will allow us to approximate distributions of transformations of the parameters without using calculus or change of variables, as well as assist exploratory data analysis of the prior or posterior distributions.</p>
</div>
<div id="optional-derivations" class="section level3">
<h3>(Optional) Derivations</h3>
<p>From Bayes Theorem we have that the joint posterior distribution is proportional to the likelihood of the parameters times the joint prior distribution
<span class="math display">\[\begin{equation}
p(\mu, \sigma^2 \mid y_1, \ldots, y_n)  \propto {\text{Ca}l L}(\mu, \sigma^2) p(\mu, \sigma^2).
\end{equation}\]</span> where the
likelihood function for <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span> is proportional to
<span class="math display">\[
\begin{align}
{\text{Ca}l L}(\mu, \sigma^2) \propto 
(\sigma^2)^{-n/2}  \times \exp{ \left\{   
-\frac{1}{2} \frac{\sum_{i = 1}^n(y_i - \bar{y})^2 }{\sigma^2}
\right\}}  &amp; \times 
\exp{ \left\{   
-\frac{1}{2} \frac{n (\bar{y} - \mu)^2 }{\sigma^2} \right\}} \\
  \text{{function of $\sigma^2$ and data}} &amp; \times
  \text{{function of $\mu$, $\sigma^2$ and data}}
\end{align}
\]</span>
which depends on the data only through the sum of squares <span class="math inline">\(\sum_{i = 1}^n(y_i - \bar{y})^2\)</span> (or equivalently the sample variance <span class="math inline">\(s^2 = \sum_{i = 1}^n(y_i - \bar{y})^2/(n-1)\)</span>) and the sample mean <span class="math inline">\(\bar{y}\)</span>.
Since the likelihood function for <span class="math inline">\((\mu, \phi)\)</span> is obtained by just substituting <span class="math inline">\(1/\phi\)</span> for <span class="math inline">\(\sigma^2\)</span>, the likelihood may be re-expressed as
<span class="math display">\[\begin{equation}
{\text{Ca}l L}(\mu, \phi) \propto 
\phi^{n/2}  \times \exp{ \left\{   
-\frac{1}{2} \phi (n-1) s^2
\right\}}   \times 
\exp{ \left\{   
-\frac{1}{2} \phi n (\bar{y} - \mu)^2  \right\}}.
\end{equation}\]</span></p>
<p>This likelihood may be obtained also be obtained by using the sampling distribution for the summary statistics, where
<span class="math display">\[\bar{Y}  \mid \mu, \phi \sim \textsf{Normal}(\mu, 1/(\phi n))\]</span>
and is independent of the sample variance (conditional on <span class="math inline">\(\phi\)</span>) and has a gamma distribution
<span class="math display">\[ 
s^2 \mid \phi \sim  \textsf{Gamma}\left(\frac{n - 1}{2},  \frac{(n-1) \phi}{2}\right)
\]</span>
with degrees of freedom <span class="math inline">\(n-1\)</span> and rate <span class="math inline">\((n-1) \phi/2\)</span>; the likelihood is the product of the two sampling distributions: <span class="math inline">\({\text{Ca}l{L}}(\mu, \phi) \propto p(s^2 \mid \phi) p(\bar{Y} \mid \phi)\)</span>.</p>
<p>Bayes theorem in proportional form leads to the joint posterior distribution
<span class="math display">\[\begin{align}
p(\mu, \phi \mid \text{data})  \propto &amp; {\text{Ca}l{L}}(\mu, \phi) p(\phi) p(\mu \mid \phi)  \\
 =  &amp; \phi^{(n-1)/2)} 
 \exp\left\{ - \frac{ \phi (n-1) s^2 }{2}\right\} 
 \text{  (sampling distribution for  $\phi$) }\\
&amp; \times  (n\phi)^{1/2}   \exp\left\{- \frac 1 2  n \phi (\bar{y} - \mu)^2 \right\} \text{  ( sampling distribution for $\mu$)}
\\
&amp; \times \phi^{\nu_0/2 -1} \exp\{- \frac{ \phi \nu_0 s^2_0}{2}\} \text{ (prior for  $\phi$)}
\\
&amp; \times 
(n_0\phi)^{1/2} \frac{1}{\sqrt{(2 \pi)}} \exp\left\{- \frac 1 2  n_0 \phi (\mu - m_0)^2 \right\} \text{ (prior for $\mu$)}
\end{align}
\]</span>
where we have ignored constants that do not involve <span class="math inline">\(\phi\)</span> or <span class="math inline">\(\mu\)</span>.
Focusing on all the terms that involve <span class="math inline">\(\mu\)</span>, we can group the lines corresponding to the sampling distribution and prior for <span class="math inline">\(\mu\)</span> together and using the factorization of likelihood and prior distributions, we may identify that
<span class="math display">\[p(\mu \mid \phi, \text{data})  \propto  \exp\left\{- \frac 1 2  n \phi (\bar{y} - \mu)^2  - \frac 1 2  n_0 \phi (\mu - m_0)^2 \right\} 
\]</span>
where the above expression includes the sum of two quadratic expressions in the exponential. This almost looks like a normal. Can these be combined to form one quadratic expression that looks like a normal density? Yes! This is known as “completing the square”.
Taking a normal distribution for a parameter <span class="math inline">\(\mu\)</span> with mean <span class="math inline">\(m\)</span> and precision <span class="math inline">\(\rho\)</span>, the quadratic term in the exponential may be expanded as
<span class="math display">\[\rho \times (\mu - m)^2 = \rho  \mu^2 - 2 \rho  \mu m + \rho  m^2.\]</span>
From this we can read off that the precision is the term that multiplies the quadratic in <span class="math inline">\(\mu\)</span> and the term that multiplies the linear term in <span class="math inline">\(\mu\)</span> is the product of two times the mean and precision; this means that if we know the precision, we can identify the mean. The last term is the precision times the mean squared, which we will need to fill in once we identify the precision and mean.</p>
<p>For our posterior, we need to expand the quadratics and recombine
terms to identify the new precision (the coefficient multiplying the quadratic in <span class="math inline">\(\mu\)</span>) and the new mean (the linear term) and complete the square so that it may be factored. Any left over terms will be independent of <span class="math inline">\(\mu\)</span> but may depend on <span class="math inline">\(\phi\)</span>. For our case, after some algebra to group terms we have
<span class="math display">\[
\begin{align}
- \frac 1 2 \left( n \phi (\bar{y} - \mu)^2  +  n_0 \phi (\mu - m_0)^2 \right) \\
= -\frac 1 2 \left(\phi( n + n_0) \mu^2 - 2 \phi \mu (n \bar{y} + n_0 m_0) + \phi (n \bar{y}^2 + n_0 m_0^2) \right)  
\end{align}\]</span>
where we can read off that the posterior precision is <span class="math inline">\(\phi(n + n_0) \equiv \phi n_n\)</span>. The linear term is not yet of the form of the posterior precision times the posterior mean (times 2), but if we multiply and divide by <span class="math inline">\(n_n = n + n_0\)</span> it is in the appropriate form
<span class="math display">\[\begin{equation}-\frac 1 2 \left(\phi( n + n_0) \mu^2 - 2 \phi ( n + n_0) \mu \frac{(n \bar{y} + n_0 m_0) } {n + n_0} + \phi (n \bar{y}^2 + n_0 m_0^2) \right) \label{eq:quad}
 \end{equation}\]</span>
so that we may identify that the posterior mean is <span class="math inline">\(m_n = (n \bar{y} + n_0 m_0) /(n + n_0)\)</span> which combined with the precision (or inverse variance) is enough to identity the conditional posterior distribution for <span class="math inline">\(\mu\)</span>.
We next add the precision times the square of the posterior mean (the completing the square part), but to keep equality, we will need to subtract the term as well:
<span class="math display">\[
- \frac 1 2 \left( n \phi (\bar{y} - \mu)^2  +  n_0 \phi (\mu - m_0)^2 \right)  \\
= -\frac 1 2 \left(\phi n_n \mu^2 - 2 \phi n_n \mu m_n + \phi n_n m_n^2  - \phi n_n m_n^2  + \phi (n \bar{y}^2 + n_0 m_0^2) \right)  
\]</span>
which after factoring the quadratic leads to
<span class="math display">\[\begin{align}
 - \frac 1 2 \left( n \phi (\bar{y} - \mu)^2  +  n_0 \phi (\mu - m_0)^2 \right) \\
 = -\frac 1 2 \left(\phi n_n (\mu - m_n)^2 \right) -\frac 1 2 \left(\phi (-n_n m_n^2 + n \bar{y}^2 + n_0 m_0^2) \right) 
\end{align}\]</span>
where the first line is the quadratic for the posterior of <span class="math inline">\(\mu\)</span> given <span class="math inline">\(\phi\)</span> while the second line includes terms that involve <span class="math inline">\(\phi\)</span> but that are independent of <span class="math inline">\(\mu\)</span>.</p>
<p>Substituting the expressions, we can continue to simplify the expressions further
<span class="math display">\[
\begin{aligned}
p(\mu, \phi \mid \text{data})  \propto &amp; {\text{Ca}l{L}}(\mu, \phi) p(\phi) p(\mu \mid \phi)  \\
 =  &amp; \phi^{(n + \nu_0 + 1  )/2 - 1} 
 \exp\left\{ - \frac{ \phi (n-1) s^2 }{2}\right\} 
\times \exp\left\{- \frac{ \phi \nu_0 s^2_0}{2}\right\} \\
&amp; \times
\exp\left\{  -\frac 1 2 \left(\phi (-n_n m_n^2 + n \bar{y}^2 + n_0 m_0^2) \right)   \right\} 
\\
&amp; \times \exp \left\{ -\frac 1 2 \left(\phi n_n (\mu - m_n)^2 \right) \right\} \\
=   &amp; \phi^{(n + \nu_0)/2 - 1} 
 \exp\left\{ -  \frac{\phi}{2}  \left( (n-1) s^2  + \nu_0 s^2_0 +
\frac{ n_0 n }{n_n} ( m_0 - \bar{y})^2 \right)   \right\}   \quad
\text{ (gamma kernel)} \\
&amp; \times (n_n \phi)^{1/2} \exp \left\{ -\frac 1 2 \left(\phi n_n (\mu - m_n)^2 \right) \right\} \qquad \quad \text{ (normal kernel})
\end{aligned}
\]</span>
until we can recognize the product of the kernels of a gamma distribution for <span class="math inline">\(\phi\)</span>
<span class="math display">\[
\phi \mid \text{data} \sim t(v_n/2, v_n s^2_n/ 2)
\]</span>
where <span class="math inline">\(\nu_n = n + \nu_0\)</span> and <span class="math inline">\(s^2_n = \left((n-1) s^2 + n_0 s^2_0 + (m_0 - \bar{y})^2 n n_0/n_n\right)/\nu_n\)</span> times a normal:
and the kernel of a normal for <span class="math inline">\(\mu\)</span>
<span class="math display">\[ \mu \mid \phi, \text{data} \sim \text{Normal}(m_n, (\phi n_n)^{-1})
\]</span>
where <span class="math inline">\(m_m = (n \bar{y} + n_0 m_0) /(n + n_0)\)</span> a weighted average of the sample mean and the prior mean, and
<span class="math inline">\(n_n = n + n_0\)</span> is the sample and prior combined sample size.</p>
<div id="derivation-of-marginal-distribution-for-mu" class="section level4">
<h4>Derivation of Marginal Distribution for <span class="math inline">\(\mu\)</span></h4>
<p>If <span class="math inline">\(\mu\)</span> given <span class="math inline">\(\sigma^2\)</span> (and the data) has a normal distribution with mean <span class="math inline">\(m_m\)</span> and variance <span class="math inline">\(\sigma^2/n_n\)</span> and <span class="math inline">\(1/\sigma^2 \equiv \phi\)</span> (given the data) has a gamma distribution with shape parameter
<span class="math inline">\(\nu_n/2\)</span> and rate parameter <span class="math inline">\(\nu_n s^2_n/2\)</span></p>
<p><span class="math display">\[\begin{aligned}
\mu \mid \sigma^2, \text{data} &amp; \sim \text{Normal}(m_m, \sigma^2/n_n) \\ 
1/\sigma^2 \mid \text{data} &amp; \sim \text{Gamma}(\nu_n/2, \nu_n s^2_n/2) 
\end{aligned}\]</span>
then
<span class="math display">\[\mu \mid  \text{data}  \sim t(\nu_n, m_m, s^2_n/n_n)\]</span>
a Student <span class="math inline">\(t\)</span> distribution with mean <span class="math inline">\(m_m\)</span> and scale <span class="math inline">\(s^2_n/n_n\)</span> with degrees of freedom <span class="math inline">\(\nu_n\)</span>.</p>
<p>This applies to the prior as well, so that without any data we use the prior hyper-parameters <span class="math inline">\(m_0\)</span>, <span class="math inline">\(n_0\)</span>, <span class="math inline">\(\nu_0\)</span> and <span class="math inline">\(s^2_0\)</span> in place of the updated values with the subscript <span class="math inline">\(n\)</span>.</p>
<p>To simplify notation, we’ll substitute <span class="math inline">\(\phi = 1/\sigma^2\)</span>. The marginal distribution for <span class="math inline">\(\mu\)</span> is obtained by averaging over the values of <span class="math inline">\(\sigma^2\)</span>. Since <span class="math inline">\(\sigma^2\)</span> takes on continuous values rather than discrete, this averaging is represented as an integral
<span class="math display">\[\begin{align}
p(\mu \mid \text{data}) &amp; = \int_0^\infty p(\mu \mid \phi, \text{data}) p(\phi \mid \text{data}) d\phi \\
&amp; = \int_0^\infty \frac{1}{\sqrt{2 \pi}} (n_n \phi)^{1/2} 
e^{\left\{ - \frac{n_n \phi}{2} (\mu - m_n)^2 \right\}}
\frac{1}{\text{Ga}mma(\nu_n/2)} \left(\frac{\nu_n s^2_n}{2}\right)^{\nu_n/2}
\phi^{\nu_n/2 - 1} e^{\left\{- \phi \nu_n s^2_n/2\right\}} \, d\phi \\
 &amp; =  \left(\frac{n_n}{2 \pi}\right)^{1/2}\frac{1}{\text{Ga}mma\left(\frac{\nu_n}{2}\right)} \left(\frac{\nu_n s^2_n}{2}\right)^{\nu_n/2} \int_0^\infty  \phi^{(\nu_n +1)/2 - 1}
\exp{\left\{ - \phi \left( \frac{n_n  (\mu - m_n)^2 + \nu_n s^2_n}{2} \right)\right\}} \, d\phi
\\
\end{align}\]</span></p>
<p>where the terms inside the integral are the “kernel” of a Gamma density. We can multiply and divide by the normalizing constant of the Gamma density}
<span class="math display">\[\begin{align}
p(\mu \mid \text{data}) &amp; =  
\left(\frac{n_n}{2 \pi}\right)^{1/2}\frac{1}{\text{Ga}mma\left(\frac{\nu_n}{2}\right)} 
\left(\frac{\nu_n s^2_n}{2}\right)^{\nu_n/2} 
\text{Ga}mma\left(\frac{\nu_n + 1}{2}\right) 
\left( \frac{n_n  (\mu - m_n)^2 + \nu_n s^2_n}{2} \right)^{- \frac{\nu_n + 1}{2}}  \times\\
&amp; \qquad \int_0^\infty  \frac{1}{\text{Ga}mma\left(\frac{\nu_n + 1}{2}\right)}
\left( \frac{n_n  (\mu - m_n)^2 + \nu_n s^2_n}{2} \right)^{ \frac{\nu_n + 1}{2}} \phi^{(\nu_n +1)/2 - 1}
\exp{\left\{ - \phi \left( \frac{n_n  (\mu - m_n)^2 + \nu_n s^2_n}{2} \right)\right\}} \, d\phi\\
\end{align}\]</span></p>
<p>so that the term in the integral now integrates to one and the resulting distribution is
<span class="math display">\[\begin{align} 
p(\mu \mid \text{data}) &amp; =  
\left(\frac{n_n}{2 \pi}\right)^{1/2}\frac{\text{Ga}mma\left(\frac{\nu_n + 1}{2}\right) }{\text{Ga}mma\left(\frac{\nu_n}{2}\right)} 
\left(\frac{\nu_n s^2_n}{2}\right)^{\nu_n/2} 
\left( \frac{n_n  (\mu - m_n)^2 + \nu_n s^2_n}{2} \right)^{- \frac{\nu_n + 1}{2}}\\
\end{align}\]</span></p>
<p>After some algebra this simplifies to
<span class="math display">\[\begin{align}
p(\mu \mid \text{data}) &amp; =  
\frac{1}{\sqrt{\pi \nu_n s^2_n/n_n}}
\frac{\text{Ga}mma\left(\frac{\nu_n + 1}{2}\right) }
     {\text{Ga}mma\left(\frac{\nu_n}{2}\right)} 
\left( 1 +  \frac{1}{\nu_n}\frac{(\mu - m_n)^2}{s^2_n/n_n} \right)^{- \frac{\nu_n + 1}{2}}\\
\end{align}\]</span></p>
<p>and is a more standard representation for a Student <span class="math inline">\(t\)</span> distribution and the kernel of the density is the right most term.</p>
</div>
</div>
<div id="sec:NG-MC" class="section level2">
<h2>Monte Carlo Inference</h2>
<pre class="r"><code>library(statsr)
library(ggplot2)
library(ggthemes)
library(dplyr)</code></pre>
<p>In Section <a href="#sec:normal-gamma"><strong>??</strong></a>, we showed how to obtain the conditional posterior distribution for the mean of a normal population given the variance and the marginal posterior distribution of the precision (inverse variance). The marginal distribution of the mean, which “averaged over uncertainty” about the unknown variance could be obtained via integration, leading to the Student t distribution that was used for inference about the population mean. However, what if we are interested in the distribution of the standard deviation <span class="math inline">\(\sigma\)</span> itself, or other transformations of the parameters? There may not be a closed-form expression for the distributions or they may be difficult to obtain.</p>
<p>It turns out that <strong>Monte Carlo sampling</strong>, however, is an easy way to make an inference about parameters, when we cannot analytically calculate distributions of parameters, expectations, or probabilities. Monte Carlo methods are computational algorithms that rely on repeated random sampling from distributions for making inferences. The name refers to the famous Monte Carlo Casino in Monaco, home to games of chance such as roulette.</p>
<div id="monte-carlo-sampling" class="section level3">
<h3>Monte Carlo Sampling</h3>
<p>Let’s start with a case where we know the posterior distribution. As a quick recap, recall that the joint posterior distribution for the mean <span class="math inline">\(\mu\)</span> and the precision <span class="math inline">\(\phi = 1/\sigma^2\)</span> under the conjugate prior for the Gaussian distribution is:</p>
<ul>
<li>Conditional posterior distribution for the mean
<span class="math display">\[\mu \mid \text{data}, \sigma^2  \sim  \text{Normal}(m_n, \sigma^2/n_n)\]</span></li>
<li>Marginal posterior distribution for the precision <span class="math inline">\(\phi\)</span> or inverse variance:
<span class="math display">\[1/\sigma^2 = \phi \mid \text{data}   \sim   \text{Gamma}(v_n/2,s^2_n v_n/2)\]</span></li>
<li>Marginal posterior distribution for the mean <span class="math display">\[\mu \mid \text{data} \sim t(v_n, m_n, s^2_n/n_n)\]</span></li>
</ul>
<p>For posterior inference about <span class="math inline">\(\phi\)</span>, we can generate <span class="math inline">\(S\)</span> random samples from the Gamma posterior distribution:</p>
<p><span class="math display">\[\phi^{(1)},\phi^{(2)},\cdots,\phi^{(S)} \overset{\text{iid}}{\sim} \text{Gamma}(v_n/2,s^2_n v_n/2)\]</span></p>
<p>Recall that the term <strong>iid</strong> stands for <strong>i</strong>ndependent and <strong>i</strong>dentically <strong>d</strong>istributed. In other words, the <span class="math inline">\(S\)</span> draws of <span class="math inline">\(\phi\)</span> are independent and identically distributed from the gamma distribution.</p>
<p>We can use the empirical distribution (histogram) from the <span class="math inline">\(S\)</span> samples to approximate the actual posterior distribution and the sample mean of the <span class="math inline">\(S\)</span> random draws of <span class="math inline">\(\phi\)</span> can be used to approximate the posterior mean of <span class="math inline">\(\phi\)</span>.
Likewise, we can calculate probabilities, quantiles and other functions using the <span class="math inline">\(S\)</span> samples from the posterior distribution. For example, if we want to calculate the posterior expectation of some function of <span class="math inline">\(\phi\)</span>, written as <span class="math inline">\(g(\phi)\)</span>, we can approximate that by taking the average of the function, and evaluate it at the <span class="math inline">\(S\)</span> draws of <span class="math inline">\(\phi\)</span>, written as <span class="math inline">\(\frac{1}{S}\sum^S_{i=1}g(\phi^{(i)})\)</span>.</p>
<p>The approximation to the expectation of the function, <span class="math inline">\(E[g(\phi \mid \text{data})]\)</span> improves</p>
<p><span class="math display">\[\frac{1}{S}\sum^S_{i=1}g(\phi^{(i)}) \rightarrow E[g(\phi \mid \text{data})]\]</span>
as the number of draws <span class="math inline">\(S\)</span> in the Monte Carlo simulation increases.</p>
</div>
<div id="monte-carlo-inference-tap-water-example" class="section level3">
<h3>Monte Carlo Inference: Tap Water Example</h3>
<p>We will apply this to the tap water example from <a href="#sec:normal-gamma"><strong>??</strong></a>. First, reload the data and calculate the posterior hyper-parameters if needed.</p>
<pre class="r"><code># Prior
m_0 = 35;  n_0 = 25;  s2_0 = 156.25; v_0 = n_0 - 1
# Data
data(tapwater); Y = tapwater$tthm
ybar = mean(Y); s2 = var(Y); n = length(Y)
# Posterior Hyper-paramters
n_n = n_0 + n
m_n = (n*ybar + n_0*m_0)/n_n
v_n = v_0 + n
s2_n = ((n-1)*s2 + v_0*s2_0 + n_0*n*(m_0 - ybar)^2/n_n)/v_n</code></pre>
<p>Before generating our Monte Carlo samples, we will set a random seed using the <code>set.seed</code> function in <code>R</code>, which takes a small integer argument.</p>
<pre class="r"><code>set.seed(42)</code></pre>
<p>This allows the results to be replicated if you re-run the simulation at a later time.</p>
<p>To generate <span class="math inline">\(1,000\)</span> draws from the gamma posterior distribution using the hyper-parameters above, we use the <code>rgamma</code> function <code>R</code></p>
<pre class="r"><code>phi = rgamma(1000, shape = v_n/2, rate=s2_n*v_n/2)</code></pre>
<p>The first argument to the <code>rgamma</code> function is the number of samples, the second is the shape parameter and, by default, the third argument is the rate parameter.</p>
<p>The following code will produce a histogram of the Monte Carlo samples of <span class="math inline">\(\phi\)</span> and overlay the actual Gamma posterior density evaluated at the draws using the <code>dgamma</code> function in <code>R</code>.</p>
<pre class="r"><code>df = data.frame(phi = sort(phi))
df = mutate(df, 
            density = dgamma(phi, 
                             shape = v_n/2,
                             rate=s2_n*v_n/2))

ggplot(data=df, aes(x=phi)) + 
        geom_histogram(aes(x=phi, y=..density..), bins = 50) +
        geom_density(aes(phi, ..density..), color=&quot;black&quot;) +
        geom_line(aes(x=phi, y=density), color=&quot;orange&quot;) +
        xlab(expression(phi)) + theme_tufte()</code></pre>
<div class="figure" style="text-align: center"><span id="fig:phi-plot"></span>
<img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/phi-plot-1.svg" alt="Monte Carlo approximation of the posterior distribution of the precision from the tap water example" width="480" />
<p class="caption">
Figure 16: Monte Carlo approximation of the posterior distribution of the precision from the tap water example
</p>
</div>
<p>Figure <a href="#fig:phi-plot">16</a> shows the histogram of the <span class="math inline">\(1,000\)</span> draws of <span class="math inline">\(\phi\)</span> generated from the Monte Carlo simulation, representing the empirical distribution approximation to the gamma posterior distribution. The orange line represents the actual gamma posterior density, while the black line represents a <em>smoothed</em> version of the histogram.</p>
<p>We can estimate the posterior mean or a 95% equal tail area credible region using the Monte Carlo samples using <code>R</code></p>
<pre class="r"><code>mean(phi)</code></pre>
<pre><code>## [1] 0.002165663</code></pre>
<pre class="r"><code>quantile(phi, c(0.025, 0.975))</code></pre>
<pre><code>##        2.5%       97.5% 
## 0.001394921 0.003056304</code></pre>
<p>The mean of a gamma random variable is the shape/rate, so we can compare the Monte Carlo estimates to the theoretical values</p>
<pre class="r"><code># mean  (v_n/2)/(v_n*s2_n/2)
1/s2_n</code></pre>
<pre><code>## [1] 0.002174492</code></pre>
<pre class="r"><code>qgamma(c(0.025, 0.975), shape=v_n/2, rate=s2_n*v_n/2)</code></pre>
<pre><code>## [1] 0.001420450 0.003086519</code></pre>
<p>where the <code>qgamma</code> function in <code>R</code> returns the desired quantiles provided as the first argument.
We can see that we can estimate the mean accurately to three significant digits, while the quantiles are accurate to two. It increase our accuracy, we would need to increase <span class="math inline">\(S\)</span>.</p>
<p><strong>Exercise</strong>
Try increasing the number of simulations <span class="math inline">\(S\)</span> in the Monte Carlo simulation to <span class="math inline">\(10,000\)</span>, and see how the approximation changes.</p>
</div>
<div id="monte-carlo-inference-for-functions-of-parameters" class="section level3">
<h3>Monte Carlo Inference for Functions of Parameters</h3>
<p>Let’s see how to use Monte Carlo simulations to approximate the distribution of <span class="math inline">\(\sigma\)</span>. Since <span class="math inline">\(\sigma = 1/\sqrt{\phi}\)</span>, we simply apply the transformation to the <span class="math inline">\(1,000\)</span> draws of <span class="math inline">\(\phi\)</span> to obtain a random sample of <span class="math inline">\(\sigma\)</span> from its posterior distribution. We can then estimate the posterior mean of <span class="math inline">\(\sigma\)</span> by calculating the sample mean of the 1,000 draws.</p>
<pre class="r"><code>sigma = 1/sqrt(phi)
mean(sigma) # posterior mean of sigma</code></pre>
<pre><code>## [1] 21.80516</code></pre>
<p>Similarly, we can obtain a 95% credible interval for <span class="math inline">\(\sigma\)</span> by finding the sample quantiles of the distribution.</p>
<pre class="r"><code>quantile(sigma, c(0.025, 0.975))</code></pre>
<pre><code>##     2.5%    97.5% 
## 18.08847 26.77474</code></pre>
<p>and finally approximate the posterior distribution using a smoothed density estimate</p>
<pre class="r"><code>df = data.frame(sigma = sqrt(1/phi))

post = ggplot(data=df, aes(x=sigma)) + 
        geom_histogram(aes(x=sigma, y=..density..), bins = 50) +
        geom_density(aes(sigma, ..density..), color=&quot;black&quot;) +
        xlab(expression(sigma)) + theme_tufte()
print(post)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:sigma-plot"></span>
<img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/sigma-plot-1.svg" alt="Monte Carlo approximation of the posterior distribution of the standard deviation from the tap water example" width="480" />
<p class="caption">
Figure 17: Monte Carlo approximation of the posterior distribution of the standard deviation from the tap water example
</p>
</div>
<p><strong>Exercise</strong></p>
<p>Using the <span class="math inline">\(10,000\)</span> draws of <span class="math inline">\(\phi\)</span> for the tap water example, create a histogram for <span class="math inline">\(\sigma\)</span> with a smoothed density overlay for the tap water example.</p>
</div>
<div id="summary" class="section level3">
<h3>Summary</h3>
<p>To recap, we have introduced the powerful method of Monte Carlo simulation for posterior inference. Monte Carlo methods provide estimates of expectations, probabilities, and quantiles of distributions from the simulated values. Monte Carlo simulation also allows us to approximate distributions of functions of the parameters, or the transformations of the parameters where it may be difficult to get exact theoretical values.</p>
<p>Next, we will discuss predictive distributions and show how Monte Carlo simulation may be used to help choose prior hyperparameters, using the prior predictive distribution of data and draw samples from the posterior predictive distribution for predicting future observations.</p>
<pre class="r"><code>library(statsr)
library(ggplot2)</code></pre>
<pre class="r"><code>data(tapwater)
m_0 = 35; 
n_0 = 25; 
s2_0 = 156.25;
v_0 = n_0 - 1
Y = tapwater$tthm
ybar = mean(Y)
s2 = round(var(Y),1)
n = length(Y)
n_n = n_0 + n
m_n = round((n*ybar + n_0*m_0)/n_n, 1)
v_n = v_0 + n
s2_n = round( ((n-1)*s2 + v_0*s2_0 + n_0*n*(m_0 - ybar)^2/n_n)/v_n, 1)
L = qt(.025, v_n)*sqrt(s2_n/n_n) + m_n
U = qt(.975, v_n)*sqrt(s2_n/n_n) + m_n</code></pre>
<p>In this section, we will discuss prior and posterior <strong>predictive</strong> distributions of the data and show how Monte Carlo sampling from the prior predictive distribution can help select hyper-parameters, while sampling from the posterior predictive distribution can be used for predicting future events or model checking.</p>
</div>
<div id="prior-predictive-distribution" class="section level3">
<h3>Prior Predictive Distribution</h3>
<p>We can obtain the prior predictive distribution of the data from the joint distribution of the data and the parameters <span class="math inline">\((\mu, \sigma^2)\)</span> or equivalently <span class="math inline">\((\mu, \phi)\)</span>, where <span class="math inline">\(\phi = 1/\sigma^2\)</span> is the precision:</p>
<p><strong>Prior:</strong></p>
<p><span class="math display">\[ \begin{aligned}
 \phi &amp;\sim \textsf{Gamma}\left(\frac{v_0}{2}, \frac{v_0 s^2_0}{2} \right) \\
 \sigma^2 &amp; = 1/\phi \\
\mu \mid \sigma^2  &amp;\sim  \textsf{N}(m_0, \sigma^2/n_0)
\end{aligned} \]</span></p>
<p><strong>Sampling model:</strong></p>
<p><span class="math display">\[Y_i \mid \mu,\sigma^2 \overset{\text{iid}}{\sim} \text{Normal}(\mu, \sigma^2) \]</span></p>
<p><strong>Prior predictive distribution for <span class="math inline">\(Y\)</span>:</strong></p>
<p><span class="math display">\[\begin{aligned}
p(Y) &amp;= \iint p(Y \mid \mu,\sigma^2) p(\mu \mid \sigma^2) p(\sigma^2) d\mu \, d\sigma^2 \\
Y &amp;\sim t(v_0, m_0, s_0^2+s_0^2/n_0)
\end{aligned}\]</span></p>
<p>By <em>averaging</em> over the possible values of the parameters from the prior distribution in the joint distribution, technically done by a double integral, we obtain the Student t as our prior predictive distribution. For those interested, details of this derivation are provided later in an optional section.
This distribution of the observables depends only on our four hyper-parameters from the normal-gamma family. We can use Monte Carlo simulation to sample from the prior predictive distribution to help elicit prior hyper-parameters as we now illustrate with the tap water example from earlier.</p>
</div>
<div id="tap-water-example-continued" class="section level3">
<h3>Tap Water Example (continued)</h3>
<p>A report from the city water department suggests that levels of TTHM are expected to be between 10-60 parts per billion (ppb). Let’s see how we can use this information to create an informative conjugate prior.</p>
<p><strong>Prior Mean</strong>
First, the normal distribution and Student t distributions are symmetric around the mean or center parameter, so we will set the prior mean <span class="math inline">\(\mu\)</span> to be at the midpoint of the interval 10-60, which would lead to <span class="math display">\[m_0 = (60+10)/2 = 35\]</span>
as our prior hyper-parameter <span class="math inline">\(m_0\)</span>.</p>
<p><strong>Prior Variance</strong>
Based on the empirical rule for bell-shaped distributions, we would expect that 95% of observations are within plus or minus two standard deviations from the mean, <span class="math inline">\(\pm 2\sigma\)</span> of <span class="math inline">\(\mu\)</span>. Using this we expect that the range of the data should be approximately <span class="math inline">\(4\sigma\)</span>. Using the values from the report, we can use this to find our prior estimate of <span class="math inline">\(\sigma\)</span>, <span class="math inline">\(s_0 = (60-10)/4 = 12.5\)</span> or
<span class="math display">\[s_0^2 = [(60-10)/4]^2 = 156.25\]</span></p>
<p><strong>Prior Sample Size and Degrees of Freedom</strong>
To complete the specification, we also need to choose the prior sample size <span class="math inline">\(n_0\)</span> and degrees of freedom <span class="math inline">\(v_0\)</span>. For a sample of size <span class="math inline">\(n\)</span>, the sample variance has <span class="math inline">\(n-1\)</span> degrees of freedom. Thinking about a possible historic set of data of size <span class="math inline">\(n_0\)</span> that led to the reported interval, we will adopt that rule to obtain the prior degrees of freedom <span class="math inline">\(v_0 = n_0 - 1\)</span>, leaving only the prior sample size to be determined. We will draw samples from the prior predictive distribution and modify <span class="math inline">\(n_0\)</span> so that the simulated data agree with our prior assumptions.</p>
</div>
<div id="sampling-from-the-prior-predictive-in-r" class="section level3">
<h3>Sampling from the Prior Predictive in <code>R</code></h3>
<p>The following <code>R</code> code shows a simulation from the predictive distribution with the prior sample size <span class="math inline">\(n_0 = 2\)</span>. Please be careful to not confuse the prior sample size, <span class="math inline">\(n_0\)</span>, that represents the precision of our prior information with the number of Monte Carlo simulations, <span class="math inline">\(S = 10000\)</span>, that are drawn from the distributions. These Monte Carlo samples are used to estimate quantiles of the prior predictive distribution and a large value of <span class="math inline">\(S\)</span> reduces error in the Monte Carlo approximation.</p>
<pre class="r"><code>m_0 = (60+10)/2; s2_0 = ((60-10)/4)^2;
n_0 = 2; v_0 = n_0 - 1
set.seed(1234)
S = 10000
phi = rgamma(S, v_0/2, s2_0*v_0/2)
sigma = 1/sqrt(phi)
mu = rnorm(S, mean=m_0, sd=sigma/(sqrt(n_0)))
Y = rnorm(S, mu, sigma)
quantile(Y, c(0.025,0.975))</code></pre>
<pre><code>##      2.5%     97.5% 
## -140.1391  217.7050</code></pre>
<p>Let’s try to understand the code. After setting the prior hyper-parameters and random seed, we begin by simulating <span class="math inline">\(\phi\)</span> from its gamma prior distribution. We then transform <span class="math inline">\(\phi\)</span> to calculate <span class="math inline">\(\sigma\)</span>. Using the draws of <span class="math inline">\(\sigma\)</span>, we feed that into the <code>rnorm</code> function to simulate <span class="math inline">\(S\)</span> values of <span class="math inline">\(\mu\)</span> for each value of <span class="math inline">\(\sigma\)</span>. The Monte Carlo draws of <span class="math inline">\(\mu,\sigma\)</span> are used to generate <span class="math inline">\(S\)</span> possible values of TTHM denoted by <span class="math inline">\(Y\)</span>. In the above code we are exploiting that all of the functions for simulating from distributions can be vectorized, i.e. we can provide all <span class="math inline">\(S\)</span> draws of <span class="math inline">\(\phi\)</span> to the functions and get a vector result back without having to write a loop. Finally, we obtain the empirical quantiles from our Monte Carlo sample using the <code>quantile</code> function to approximate the actual quantiles from the prior predictive distriubtion.</p>
<p>This forward simulation propagates uncertainty in <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> to the prior predictive distribution of the data. Calculating the sample quantiles from the samples of the prior predictive for <span class="math inline">\(Y\)</span>, we see that the 95% predictive interval for TTHM includes negative values. Since TTHM cannot be negative, we can adjust <span class="math inline">\(n_0\)</span> and repeat. Since we need a narrower interval in order to exclude zero, we can increase <span class="math inline">\(n_0\)</span> until we achieve the desired quantiles.</p>
<p>After some trial and error, we find that the prior sample size of 25, the empirical quantiles from the prior predictive distribution are close to the range of 10 to 60 that we were given as prior information.</p>
<pre class="r"><code>m_0 = (60+10)/2; s2_0 = ((60-10)/4)^2;
n_0 = 25; v_0 = n_0 - 1
set.seed(1234)
phi = rgamma(10000, v_0/2, s2_0*v_0/2)
sigma = 1/sqrt(phi)
mu = rnorm(10000, mean=m_0, sd=sigma/(sqrt(n_0)))
y = rnorm(10000, mu, sigma)
quantile(y, c(0.025,0.975))</code></pre>
<pre><code>##      2.5%     97.5% 
##  8.802515 61.857350</code></pre>
<p>Figure <a href="#fig:hist-prior">18</a> shows an estimate of the prior distribution of <span class="math inline">\(\mu\)</span> in gray and the more dispersed prior predictive distribution in TTHM in orange, obtained from the Monte Carlo samples.</p>
<pre class="r"><code># The palette with grey:
cbPalette &lt;- c(&quot;#999999&quot;, &quot;#E69F00&quot;, &quot;#56B4E9&quot;, &quot;#009E73&quot;, &quot;#F0E442&quot;, &quot;#0072B2&quot;, &quot;#D55E00&quot;, &quot;#CC79A7&quot;)

nsim = length(mu)

df = data.frame(parameter = c(rep(&quot;mu&quot;, nsim), rep(&quot;Y&quot;, nsim)), x = c(mu, y))
#priorpred= ggplot(data=df, aes(x=y)) + geom_histogram(aes(x=y, y=..density..)) +
#         geom_density() + geom_density(aes(x=mu), col=&quot;blue&quot;)
ggplot(data=df, aes(x=y)) +
  geom_density(aes(x=x, colour=parameter, linetype=parameter),
               size=1.2, show.legend=FALSE) +
  stat_density(aes(x=x, colour=parameter, linetype=parameter),
               geom=&quot;line&quot;,position=&quot;identity&quot;, size=1.2) +
               xlab(&quot;TTHM (ppb)&quot;) + scale_colour_manual(values=cbPalette) +
  theme(panel.background = element_rect(fill = &quot;transparent&quot;, colour = NA),
        legend.key = element_rect(colour = &quot;transparent&quot;, fill = NA),
        plot.background = element_rect(fill = &quot;transparent&quot;, colour = NA),
        legend.position = c(.75, .75),
        text = element_text(size=15))</code></pre>
<div class="figure" style="text-align: center"><span id="fig:hist-prior"></span>
<img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/hist-prior-1.svg" alt="Prior density" width="480" />
<p class="caption">
Figure 18: Prior density
</p>
</div>
<p>Using the Monte Carlo samples, we can also estimate the prior probability of negative values of TTHM by counting the number of times the simulated values are less than zero out of the total number of simulations.</p>
<pre class="r"><code>sum(y &lt; 0)/length(y)  # P(Y &lt; 0) a priori</code></pre>
<pre><code>## [1] 0.0049</code></pre>
<p>With the normal prior distribution, this probability will never be zero, but may be acceptably small, so we may use the conjugate normal-gamma model for analysis.</p>
</div>
<div id="posterior-predictive" class="section level3">
<h3>Posterior Predictive</h3>
<p>We can use the same strategy to generate samples from the predictive distribution of a new measurement <span class="math inline">\(Y_{n+1}\)</span> given the observed data. In mathematical terms, the posterior predictive distribution is written as</p>
<p><span class="math display">\[Y_{n+1} \mid Y_1, \ldots, Y_n \sim t(v_n, m_n, s^2_n (1 + 1/n_n))\]</span></p>
<p>In the code, we replace the prior hyper parameters with the posterior hyper parameters from last time.</p>
<pre class="r"><code>set.seed(1234)
phi = rgamma(10000, v_n/2, s2_n*v_n/2)
sigma = 1/sqrt(phi)
post_mu = rnorm(10000, mean=m_n, sd=sigma/(sqrt(n_n)))
pred_y =  rnorm(10000,post_mu, sigma)
quantile(pred_y, c(.025, .975))</code></pre>
<pre><code>##      2.5%     97.5% 
##  3.280216 89.830212</code></pre>
<p>Figure <a href="#fig:hist-pred">19</a> shows the Monte Carlo approximation to the prior distribution of <span class="math inline">\(\mu\)</span>, and the posterior distribution of <span class="math inline">\(\mu\)</span> which is shifted to the right. The prior and posterior predictive distributions are also depicted, showing how the data have updated the prior information.</p>
<pre class="r"><code>nsim = length(post_mu)

df = data.frame(parameter = c(rep(&quot;prior mu&quot;, nsim),
                              rep(&quot;prior predictive Y&quot;, nsim), rep(&quot;posterior mu&quot;, nsim), rep(&quot;posterior predictive Y&quot;, nsim)), x = c(mu, y, post_mu, pred_y))

ggplot(data=df, aes(x=pred_y)) +
  geom_density(aes(x=x, colour=parameter, linetype=parameter),
               size=1.2, show.legend=FALSE) +
  stat_density(aes(x=x, colour=parameter, linetype=parameter),
     geom=&quot;line&quot;,position=&quot;identity&quot;, size=1.2) +
     xlab(&quot;TTHM (ppb)&quot;) + scale_colour_manual(values=cbPalette) +
  xlab(&quot;TTHM (ppb)&quot;) +
  scale_colour_manual(values=cbPalette) +
  theme(panel.background = element_rect(fill = &quot;transparent&quot;, colour = NA),
        legend.key = element_rect(colour = &quot;transparent&quot;, fill = NA),
        plot.background = element_rect(fill = &quot;transparent&quot;, colour = NA),
        legend.position=c(.75, .75),
        text = element_text(size=15))</code></pre>
<div class="figure" style="text-align: center"><span id="fig:hist-pred"></span>
<img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/hist-pred-1.svg" alt="Posterior densities" width="480" />
<p class="caption">
Figure 19: Posterior densities
</p>
</div>
<p>Using the Monte Carlo samples from the posterior predictive distribution, we can estimate the probability that a new TTHM sample will exceed the legal limit of 80 parts per billion, which is approximately 0.06.</p>
<pre class="r"><code>sum(pred_y &gt; 80)/length(pred_y)  # P(Y &gt; 80 | data)</code></pre>
<pre><code>## [1] 0.0619</code></pre>
</div>
<div id="summary-1" class="section level3">
<h3>Summary</h3>
<p>By using Monte Carlo methods, we can obtain prior and posterior predictive distributions of the data.</p>
<ul>
<li><p>Sampling from the prior predictive distribution can help with the selection of prior hyper parameters and verify that these choices reflect the prior information that is available.</p></li>
<li><p>Visualizing prior predictive distributions based on Monte Carlo simulations can help explore implications of our prior assumptions such as the choice of the hyper parameters or even assume distributions.</p></li>
<li><p>If samples are incompatible with known information, such as support on positive values, we may need to modify assumptions and look at other families of prior distributions.</p></li>
</ul>
<pre class="r"><code>library(statsr)
library(ggplot2)</code></pre>
<p>In Section <a href="#sec:NG-predictive"><strong>??</strong></a>, we demonstrated how to specify an informative prior distribution for inference about TTHM in tapwater using additional prior information. The resulting informative Normal-Gamma prior distribution had an effective prior sample size that was comparable to the observed sample size to be compatible with the reported prior interval.</p>
<p>There are, however, situations where you may wish to provide an analysis that does not depend on prior information. There may be cases where prior information is simply not available. Or, you may wish to present an <strong>objective</strong> analysis where minimal prior information is used to provide a baseline or reference analysis to contrast with other analyses based on informative prior distributions. Or perhaps, you want to use the Bayesian paradigm to make probability statements about parameters, but not use any prior information. In this section, we will examine the qustion of <strong>Can you actually perform a Bayesian analysis without using prior information?</strong>
We will present reference priors for normal data, which can be viewed as a limiting form of the Normal-Gamma conjugate prior distribution.</p>
<p>Conjugate priors can be interpreted to be based on a historical or imaginary prior sample. What happens in the conjugate Normal-Gamma prior if we take our prior sample size <span class="math inline">\(n_0\)</span> to go to zero? If we have no data, then we will define the prior sample variance <span class="math inline">\(s_0^2\)</span> to go to 0, and based on the relationship between prior sample sized and prior degrees of freedom, we will let the prior degrees of freedom go to the prior sample size minus one, or negative one, i.e. <span class="math inline">\(v_0 = n_0 - 1 \rightarrow -1\)</span>.</p>
<p>With this limit, we have the following properties:</p>
<ul>
<li><p>The posterior mean goes to the sample mean.</p></li>
<li><p>The posterior sample size is the observed sample size.</p></li>
<li><p>The posterior degrees of freedom go to the sample degrees of freedom.</p></li>
<li><p>The posterior variance parameter goes to the sample variance.</p></li>
</ul>
<p>In this limit, the posterior hyperparameters do not depend on the prior hyperparameters.</p>
<p>Since <span class="math inline">\(n_0 \rightarrow 0, s^2_0 \rightarrow 0, v_0 = n_0 - 1 \rightarrow -1\)</span>, we have in mathematical terms:</p>
<p><span class="math display">\[\begin{aligned}
m_n &amp;= \frac{n \bar{Y} + n_0 m_0} {n + n_0}  \rightarrow \bar{Y} \\
n_n &amp;= n_0 + n  \rightarrow n \\
v_n &amp;= v_0 + n  \rightarrow n-1 \\
s^2_n &amp;= \frac{1}{v_n}\left[s^2_0 v_0 + s^2 (n-1) + \frac{n_0 n}{n_n} (\bar{Y} - m_0)^2 \right] \rightarrow s^2
\end{aligned}\]</span></p>
<p>This limiting normal-gamma distribution, <span class="math inline">\(\textsf{NormalGamma}(0,0,0,-1)\)</span>, is not really a normal-gamma distribution, as the density does not integrate to 1. The form of the limit can be viewed as a prior for <span class="math inline">\(\mu\)</span> that is proportional to a constant, or uniform/flat on the whole real line. And a prior for the variance is proportional to 1 over the variance. The joint prior is taken as the product of the two.</p>
<p><span class="math display">\[\begin{aligned}
p(\mu \mid \sigma^2) &amp; \propto  1 \\
p(\sigma^2) &amp; \propto  1/\sigma^2 \\
p(\mu, \sigma^2) &amp; \propto  1/\sigma^2
\end{aligned}\]</span></p>
<p>This is refered to as a <strong>reference prior</strong> because the posterior hyperparameters do not depend on the prior hyperparameters.</p>
<p>In addition, <span class="math inline">\(\textsf{NormalGamma}(0,0,0,-1)\)</span> is a special case of a reference prior, known as the independent Jeffreys prior. While Jeffreys used other arguments to arrive at the form of the prior, the goal was to have an <strong>objective prior</strong> invariant to shifting the data by a constant or multiplying by a constant.</p>
<p>Now, a naive approach to constructing a non-informative distribution might be to use a uniform distribution to represent lack of knowledge. However, would you use a uniform distribution for <span class="math inline">\(\sigma^2\)</span>, or a uniform distribution for the precision <span class="math inline">\(1/\sigma^2\)</span>? Or perhaps a uniform distribution for <span class="math inline">\(\sigma\)</span>? These would all lead to different posteriors with little justification for any of them. This ambiguity led Sir Harold Jeffreys to propose reference distributions for the mean and variance for situations where prior information was limited. These priors are <strong>invariant</strong> to the units of the data.</p>
<p>The unnormalized priors that do not integrate to a constant are called <strong>improper distributions</strong>. An important consideration in using them is that one cannot generate samples from the prior or the prior predictive distribution to data and are referred to as <strong>non-generative distributions</strong>.</p>
<p>While the reference prior is not a proper prior distribution, and cannot reflect anyone’s actual prior beliefs, the formal application phase rule can still be used to show that <strong>the posterior distribution is a valid normal gamma distribution</strong>, leading to a formal phase posterior distribution. That depends only on summary statistics of the data.</p>
<p>The posterior distribution <span class="math inline">\(\textsf{NormalGamma}(\bar{Y}, n, s^2, n-1)\)</span> breaks down to</p>
<p><span class="math display">\[\begin{aligned}
\mu \mid \sigma^2, \text{data} &amp; \sim \text{Normal}(\bar{Y}, \sigma^2/n) \\
1/\sigma^2  \mid \text{data} &amp; \sim \text{Gamma}((n-1)/2, s^2(n - 1)/2).
\end{aligned}\]</span></p>
<ul>
<li>Under the reference prior <span class="math inline">\(p(\mu, \sigma^2) \propto 1/\sigma^2\)</span>, the posterior distribution after standardizing <span class="math inline">\(\mu\)</span> has a Student <span class="math inline">\(t\)</span> distribution with <span class="math inline">\(n-1\)</span> degrees of freedom.</li>
</ul>
<p><span class="math display">\[\frac{\mu - \bar{Y}}{\sqrt{s^2/n}} \mid \text{data} \sim  t(n-1, 0, 1)\]</span></p>
<ul>
<li>Prior to seeing the data, the distribution of the standardized sample mean given <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> also has a Student t distribution.</li>
</ul>
<p><span class="math display">\[\frac{\mu - \bar{Y}}{\sqrt{s^2/n}} \mid \mu, \sigma^2 \sim  t(n-1, 0, 1) \]</span></p>
<ul>
<li>Both frequentist sampling distributions and Bayesian reference posterior distributions lead to intervals of this form:</li>
</ul>
<p><span class="math display">\[(\bar{Y} - t_{1 - \alpha/2}\times s/\sqrt{n}, \, \bar{Y} + t_{1 - \alpha/2} \times s/\sqrt{n})\]</span></p>
<ul>
<li>However, only the Bayesian approach justifies the probability statements about <span class="math inline">\(\mu\)</span> being in the interval after seeing the data.</li>
</ul>
<p><span class="math display">\[P(\bar{Y} - t_{1 - \alpha/2}\times s/\sqrt{n} &lt; \mu &lt;  \bar{Y} + t_{1 - \alpha/2}\times s/\sqrt{n}) = 1 - \alpha\]</span></p>
<p>We can use either analytic expressions based on the t-distribution, or Monte Carlo samples from the posterior predictive distribution, to make predictions about a new sample.</p>
<pre class="r"><code>library(statsr)
data(tapwater)
# data
m_0 = 35; n_0 = 25; s2_0 = ((60-10)/4)^2; v_0 = n_0 - 1
data(tapwater); Y = tapwater$tthm
ybar = round(mean(Y), 1); s2 = round(var(Y), 1); n = length(Y)
n_n = n_0 + n
m_n = round((n*ybar + n_0*m_0)/n_n, 1)
v_n = v_0 + n
s2_n = round(((n-1)*s2 + v_0*s2_0 + n_0*n*(m_0 - ybar)^2/n_n)/v_n, 1)
set.seed(8675309)

# post-pred
phi = rgamma(10000, v_n/2, s2_n*v_n/2)
sigma = 1/sqrt(phi)
mu = rnorm(10000, mean=m_n, sd=sigma/(sqrt(n_n)))
y =  rnorm(10000, mu, sigma)</code></pre>
<p>Here is some code to generate the Monte Carlo samples from the tap water example:</p>
<pre class="r"><code>phi = rgamma(10000, (n-1)/2, s2*(n-1)/2)
sigma = 1/sqrt(phi)
post_mu = rnorm(10000, mean=ybar, sd=sigma/(sqrt(n)))
pred_y =  rnorm(10000,post_mu, sigma)
quantile(pred_y, c(.025, .975))</code></pre>
<pre><code>##       2.5%      97.5% 
##   6.692877 104.225954</code></pre>
<p>Using the Monte Carlo samples, Figure <a href="#fig:plot-post-pred">20</a> shows the posterior distribution based on the informative Normal-Gamma prior and the reference prior. Both the posterior distribution for <span class="math inline">\(\mu\)</span> and the posterior predictive distribution for a new sample are shifted to the right, and are centered at the sample mean. The posterior for <span class="math inline">\(\mu\)</span> under the reference prior is less concentrated around its mean than the posterior under the informative prior, which leads to an increased posterior sample size and hence increased precision.</p>
<pre class="r"><code>cbPalette &lt;- c(&quot;#999999&quot;, &quot;#E69F00&quot;, &quot;#56B4E9&quot;, &quot;#000000&quot;, &quot;#009E73&quot;, &quot;#0072B2&quot;, &quot;#D55E00&quot;, &quot;#CC79A7&quot;)

nsim = length(post_mu)

df = data.frame(
  parameter = c(rep(&quot;NG posterior mu&quot;, nsim), rep(&quot;NG posterior predictive&quot;, nsim),
                rep(&quot;ref posterior mu&quot;, nsim), rep(&quot;ref posterior predictive&quot;, nsim)),
  x = c(mu, y,  post_mu, pred_y))


ggplot(data=df, aes(x=pred_y)) +
  geom_density(aes(x=x, colour=parameter, linetype=parameter),
              show_legend=FALSE, size=1.0)+
  stat_density(aes(x=x, colour=parameter, linetype=parameter),
               geom=&quot;line&quot;,position=&quot;identity&quot;) + xlab(&quot;TTHM (ppb)&quot;) +
  scale_colour_manual(values=cbPalette) +
  theme(panel.background = element_rect(fill = &quot;transparent&quot;, colour = NA),
        legend.key = element_rect(colour = &quot;transparent&quot;, fill = NA),
        plot.background = element_rect(fill = &quot;transparent&quot;, colour = NA),
        legend.position=c(.76, .85),
        text = element_text(size=15))</code></pre>
<div class="figure" style="text-align: center"><span id="fig:plot-post-pred"></span>
<img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/plot-post-pred-1.svg" alt="Comparison of posterior densities" width="480" />
<p class="caption">
Figure 20: Comparison of posterior densities
</p>
</div>
<p>The posterior probability that a new sample will exceed the legal limit of 80 ppb under the reference prior is roughly 0.15, which is more than double the probability of 0.06 from the posterior under the informative prior.</p>
<pre class="r"><code>sum(pred_y &gt; 80)/length(pred_y)  # P(Y &gt; 80 | data)</code></pre>
<pre><code>## [1] 0.1534</code></pre>
<p>In constructing the informative prior from the reported interval, there are two critical assumptions. First, the prior data are exchangeable with the observed data. Second, the conjugate normal gamma distribution is suitable for representing the prior information. These assumptions may or may not be verifiable, but they should be considered carefully when using informative conjugate priors.</p>
<p>In the case of the tap water example, there are several concerns: One, it is unclear that the prior data are exchangeable with the observed data. For example, water treatment conditions may have changed. Two, the prior sample size was not based on a real prior sample, but instead selected so that the prior predictive intervals under the normal gamma model agreed with the prior data. As we do not have access to the prior data, we cannot check assumptions about normality that would help justify the prior. Other skewed distributions may be consistent with the prior interval, but lead to different conclusions.</p>
<p>To recap, we have introduced a reference prior for inference for
normal data with an unknown mean and variance. Reference priors are often part of a prior sensitivity study and are used when objectivity is of utmost importance.</p>
<p>If conclusions are fundamentally different with an informative prior and a reference prior, one may wish to carefully examine assumputions that led to the informative prior.</p>
<ul>
<li><p>Is the prior information based on a prior sample that is exchangable with the observed data?</p></li>
<li><p>Is the normal-gamma assumption appropriate?</p></li>
</ul>
<p>Informative priors can provide more accurate inference when data are limited, and the transparency of explicitly laying out prior assumptions is an important aspect of reproducible research. However, one needs to be careful that certain prior assumptions may lead to un-intended consequences.</p>
<p>Next, we will investigate a prior distribution that is a mixture of
conjugate priors, so the new prior distribution provides robustness to prior mis-specification in the prior sample size.</p>
<p>While we will no longer have nice analytical expressions for the posterior, we can simulate from the posterior distribution using a Monte Carlo algorithm
called Markov chain Monte Carlo (MCMC).</p>
<pre class="r"><code>library(statsr)
library(ggplot2)</code></pre>
<p>In this section, we will describe priors that are constructed as a mixture of conjugate priors – in particular, the Cauchy distribution. As these are no longer conjugate priors, nice analytic expressions for the posterior distribution are not available. However, we can use a Monte Carlo algorithm called Markov chain Monte Carlo (MCMC) for posterior inference.</p>
<p>In many situations, we may have reasonable prior information about the mean <span class="math inline">\(\mu\)</span>, but we are less confident in how many observations our prior beliefs are equivalent to. We can address this uncertainty in the prior sample size, through an additional prior distribution on a <span class="math inline">\(n_0\)</span> via a hierarchical prior.</p>
<p>The hierarchical prior for the normal gamma distribution is written as
<span class="math display">\[\begin{aligned}
\mu \mid \sigma^2, n_0 &amp; \sim \text{Normal}(m_0, \sigma^2/n_0) \\
n_0 \mid \sigma^2 &amp;  \sim \text{Gamma}(1/2, r^2/2)
\end{aligned}\]</span></p>
<p>If <span class="math inline">\(r=1\)</span>, then this corresponds to a prior expected sample size of one because the expectation of <span class="math inline">\(\text{Gamma}(1/2,1/2)\)</span> is one.</p>
<p>The marginal prior distribution from <span class="math inline">\(\mu\)</span> can be attained via integration, and we get</p>
<p><span class="math display">\[\mu \mid \sigma^2  \sim  \text{Ca}(m_0, \sigma^2 r^2)\]</span></p>
<p>This is a <strong>Cauchy distribution</strong> centered at the prior mean <span class="math inline">\(m_0\)</span>, with the scale parameter <span class="math inline">\(\sigma^2 r^2\)</span>. The probability density function (pdf) is:</p>
<p><span class="math display">\[p(\mu \mid \sigma) = \frac{1}{\pi \sigma r} \left( 1 +  \frac{(\mu - m_0)^2} {\sigma^2 r^2}  \right)^{-1}\]</span></p>
<p>The Cauchy distribution does not have a mean or standard deviation, but the center (location) and the scale play a similar role to the mean and standard deviation of the normal distribution. The Cauchy distribution is a special case of a student <span class="math inline">\(t\)</span> distribution with one degree of freedom.</p>
<p>As Figure <a href="#fig:cauchy-plot">21</a> shows, the standard Cauchy distribution with <span class="math inline">\(r=1\)</span> and the standard normal distribution <span class="math inline">\(\text{Normal}(0,1)\)</span> are centered at the same location. But the Cauchy distribution has heavier tails – more probability on extreme values than the normal distribution with the same scale parameter <span class="math inline">\(\sigma\)</span>. Cauchy priors were recommended by Sir Harold Jeffreys as a default objective prior for testing.</p>
<pre class="r"><code>cbPalette &lt;- c(&quot;#999999&quot;, &quot;#E69F00&quot;, &quot;#56B4E9&quot;, &quot;#000000&quot;, &quot;#009E73&quot;, &quot;#0072B2&quot;, &quot;#D55E00&quot;, &quot;#CC79A7&quot;)
N = 1000
x=seq(-5,5, length=N)
no = dnorm(x)
ca = dt(x, 1)
df = data.frame(x= c(x,x), y = c(no, ca), distribution = rep(c(&quot;Normal&quot;, &quot;Cauchy&quot;), c(N, N)))

ggplot(data=df, aes(x=x,y=y, group=distribution)) +
  geom_line(aes(linetype=distribution, colour=distribution), size=1.5) +
  xlab(&quot;y&quot;) +
  ylab(&quot;density&quot;) +
  scale_colour_manual(values=cbPalette) +
  theme(panel.background = element_rect(fill = &quot;transparent&quot;, colour = NA),
        legend.key = element_rect(colour = &quot;transparent&quot;, fill = NA),
        plot.background = element_rect(fill = &quot;transparent&quot;, colour = NA),
        legend.position=c(.75, .75),
        text = element_text(size=15))</code></pre>
<div class="figure" style="text-align: center"><span id="fig:cauchy-plot"></span>
<img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/cauchy-plot-1.svg" alt="Cauchy distribution" width="480" />
<p class="caption">
Figure 21: Cauchy distribution
</p>
</div>
</div>
</div>
<div id="sec:NG-MCMC" class="section level2">
<h2>Markov Chain Monte Carlo (MCMC)</h2>
<pre class="r"><code>library(statsr)
library(ggplot2)</code></pre>
<p>The Cauchy prior described in Section <a href="#sec:NG-Cauchy"><strong>??</strong></a> is not a conjugate prior, and therefore, the posterior distribution from <span class="math inline">\((\mu \mid \sigma^2)\)</span>, is not a Cauchy or any well-known distribution. Fortunately, the conditional distribution of <span class="math inline">\((\mu, \sigma^2 \mid n_0, \text{data})\)</span>, is normal-gamma and easy to simulate from, as we learned in the previous sections. The conditional distribution of <span class="math inline">\((n_0 \mid \mu, \sigma^2, \text{data}\)</span>) is a gamma distribution, also easy to simulate from the given <span class="math inline">\(\mu, \sigma^2\)</span>.</p>
<p>It turns out that if we alternate generating Monte Carlo samples from these conditional distributions, the sequence of samples converges to samples from the joint distribution of <span class="math inline">\((\mu, \sigma^2, n_0)\)</span>, as the number of simulated values increases. The Monte Carlo algorithm we have just described is a special case of Markov chain Monte Carlo (MCMC), known as the Gibbs sampler.</p>
<p>Let’s look at the pseudo code for the algorithm.</p>
<pre class="r"><code>S = 10000
sigma2 = rep(NA, S)
mu=rep(NA, S)
n_0 = rep(NA, S)
m_0 = 35
r = 1
p_mu = function(...) {}
p_sigma2 = function(...) {}
p_n_0 = function(...) {}</code></pre>
<pre class="r"><code># initialize MCMC
sigma2[1] = 1; n_0[1]=1; mu[1]=m_0

#draw from full conditional distributions
for (i in 2:S) {
  mu[i]     = p_mu(sigma2[i-1], n_0[i-1],  m_0, r, data)
  sigma2[i] = p_sigma2(mu[i], n_0[i-1],    m_0, r, data)
  n_0[i]    = p_n_0(mu[i], sigma2[i],      m_0, r, data)
}</code></pre>
<p>We start with the initial values of each of the parameters for <span class="math inline">\(i=1\)</span>. In theory, these can be completely arbitrary, as long as they are allowed values for the parameters.</p>
<p>For each iteration <span class="math inline">\(i\)</span>, the algorithm will cycle through generating each parameter, given the <strong>current</strong> value of the other parameters. The functions , , and  return a simulated value from the respective distribution conditional on the inputs.</p>
<p>Whenever we update a parameter, we use the <strong>new value</strong> in the subsequent steps as the <span class="math inline">\(n\)</span> draws for <span class="math inline">\(\sigma, n_0\)</span>. We will repeat this until we reach iteration <span class="math inline">\(S\)</span>, leading to a dependent sequence of s draws from the joint posterior distribution.</p>
<p>Incorporating the tap water example in Section <a href="#sec:normal-gamma"><strong>??</strong></a>, we will use MCMC to generate samples under the Cauchy prior. We set 35 as the location parameter and <span class="math inline">\(r=1\)</span>. To complete our prior specification, we use the Jeffrey’s reference prior on <span class="math inline">\(\sigma^2\)</span>. This combination is referred to as the Jeffrey’s Zellner-Siow Cauchy prior or “JZS” in the BayesFactor branch of the R  package.</p>
<pre class="r"><code>library(statsr)
data(tapwater)

m_0 = 35; n_0 = 25; s2_0 = ((60-10)/4)^2; v_0 = n_0 - 1

Y = tapwater$tthm
ybar = round(mean(Y), 1); s2 = round(var(Y), 1); n = length(Y)
n_n = n_0 + n
m_n = round((n*ybar + n_0*m_0)/n_n, 1)
#v_n = v_0 + n
v_n = n
#s2_n = round(((n-1)*s2 + v_0*s2_0 + n_0*n*(m_0 - ybar)^2/n_n)/v_n, 1)
s2_n = round(((n-1)*s2  + n_0*n*(m_0 - ybar)^2/n_n)/v_n, 1)
set.seed(8675309)
nsim = 10000
phi = rgamma(nsim, v_n/2, s2_n*v_n/2)
sigma = 1/sqrt(phi)
mu = rnorm(nsim, mean=m_n, sd=sigma/(sqrt(n_n)))
y =  rnorm(nsim, mu, sigma)

# reference

phi = rgamma(nsim, (n-1)/2, s2*(n-1)/2)
sigma = 1/sqrt(phi)
post_mu = rnorm(nsim, mean=ybar, sd=sigma/(sqrt(n)))
pred_y =  rnorm(nsim,post_mu, sigma)

library(BayesFactor)
tap.JZS = bayes_inference(y=tthm, data=tapwater, statistic=&quot;mean&quot;,
                          mu_0 = 35, rscale=1, prior=&quot;JZS&quot;, nsim=nsim,
                          type=&quot;ci&quot;, method=&quot;sim&quot;)</code></pre>
<pre><code>## Single numerical variable
## n = 28, y-bar = 55.5239, s = 23.254
## (Assuming Zellner-Siow Cauchy prior:  mu | sigma^2 ~ C(35, 1*sigma)
## (Assuming improper Jeffreys prior: p(sigma^2) = 1/sigma^2
## 
## Posterior Summaries
##             2.5%       25%       50%      75%    97.5%
## mu    45.4636624 51.833826 54.875042 57.94061 63.97510
## sigma 18.5863728 21.767884 23.777637 26.12107 31.99166
## n_0    0.2278052  2.519188  6.027598 12.29178 35.70218
## 
## 95% CI for mu: (45.4637, 63.9751)</code></pre>
<p><img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/demo-tapwater-1.svg" width="576" /></p>
<pre class="r"><code> mu.cauchy = tap.JZS$mu
 pred_y_cauchy =  tap.JZS$samples[,1] + rnorm(nsim, 0, sqrt(tap.JZS$samples[,2]))

df = data.frame(
  parameter = c(rep(&quot;NG posterior mu&quot;, nsim),
                rep(&quot;NG posterior predictive&quot;, nsim),
                rep(&quot;JZS posterior mu&quot;, nsim), rep(&quot;JZS posterior predictive&quot;, nsim)),
  x = c(mu, y, mu.cauchy, pred_y_cauchy)
)</code></pre>
<pre class="r"><code>bayes_inference(y=tthm, data=tapwater, statistic=&quot;mean&quot;,
                mu_0 = 35, rscale=1, prior=&quot;JZS&quot;,
                type=&quot;ci&quot;, method=&quot;sim&quot;)</code></pre>
<pre><code>## Single numerical variable
## n = 28, y-bar = 55.5239, s = 23.254
## (Assuming Zellner-Siow Cauchy prior:  mu | sigma^2 ~ C(35, 1*sigma)
## (Assuming improper Jeffreys prior: p(sigma^2) = 1/sigma^2
## 
## Posterior Summaries
##             2.5%       25%      50%      75%    97.5%
## mu    45.5713714 51.820910 54.87345 57.87171 64.20477
## sigma 18.4996738 21.810376 23.84572 26.30359 32.11330
## n_0    0.2512834  2.512059  6.13636 12.66747 36.37425
## 
## 95% CI for mu: (45.5714, 64.2048)</code></pre>
<p><img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/tapwater-inference-1.svg" width="480" style="display: block; margin: auto;" /></p>
<p>Using the  function from the  package, we can obtain summary statistics and a plot from the MCMC output – not only <span class="math inline">\(\mu\)</span>, but also inference about <span class="math inline">\(\sigma^2\)</span> and the prior sample size.</p>
<p>The posterior mean under the JZS model is much closer to the sample mean than what the normal gamma prior used previously. Under the informative normal gamma prior, the sample made a 55.5, about eight standard deviations above the mean – a surprising value under the normal prior. Under the Cauchy prior, the informative prior location has much less influence.</p>
<p>This is <strong>the robustness property of the Cauchy prior</strong>, leading the posterior to put more weight on the sample mean than the prior mean, especially when the prior location is not close to the sample mean. We can see that the central 50% interval for <span class="math inline">\(n_0\)</span> is well below the value 25 used in the normal prior, which placed almost equal weight on the prior in sample mean.</p>
<p>Using the MCMC draws of <span class="math inline">\(\mu, \sigma\)</span>, we can obtain Monte Carlo samples from the predictive distribution of <span class="math inline">\(y\)</span>, by plugging <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> into the corresponding functions. Figure <a href="#fig:hist-ref-pred">22</a> compares the posterior densities estimated from the simulative values of <span class="math inline">\(\mu\)</span> and the predicted draws of TTHM under the Jeffrey Zellner-Siow prior, and the informative normal prior from <span class="math inline">\(\mu\)</span> with <span class="math inline">\(n_0 = 25\)</span> and the reference prior on <span class="math inline">\(\sigma^2\)</span>.</p>
<pre class="r"><code>cbPalette &lt;- c(&quot;#999999&quot;, &quot;#E69F00&quot;, &quot;#56B4E9&quot;, &quot;#000000&quot;, &quot;#009E73&quot;, &quot;#0072B2&quot;, &quot;#D55E00&quot;, &quot;#CC79A7&quot;)


ggplot(data=df, aes(x=pred_y)) +
  geom_density(aes(x=x, colour=parameter, linetype=parameter), show.legend =FALSE, size=1.2)+
  stat_density(aes(x=x, colour=parameter, linetype=parameter),
               geom=&quot;line&quot;,position=&quot;identity&quot;) +
  xlab(&quot;TTHM (ppb)&quot;) +
  scale_colour_manual(values=cbPalette) +
  theme(panel.background = element_rect(fill = &quot;transparent&quot;, colour = NA),
        legend.key = element_rect(colour = &quot;transparent&quot;, fill = NA),
        plot.background = element_rect(fill = &quot;transparent&quot;, colour = NA),
        legend.position=c(.8, .8),
        text = element_text(size=15))</code></pre>
<div class="figure" style="text-align: center"><span id="fig:hist-ref-pred"></span>
<img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/hist-ref-pred-1.svg" alt="Comparison of posterior densities" width="768" />
<p class="caption">
Figure 22: Comparison of posterior densities
</p>
</div>
<p>To recap, we have shown how to create more flexible prior distributions, such as the Cauchy distribution using mixtures of conjugate priors. As the posterior distributions are not available in closed form, we demonstrated how MCMC can be used for inference using the hierarchical prior distribution. Starting in the late 1980’s, MCMC algorithms have led to an exponential rise in the use of Bayes in methods, because complex models built through hierarchical distributions suddenly were tractable. The Cauchy prior is well-known for being robust prior mis-specifications. For example, having a prior mean that is far from the observed mean. This provides an alternative to the reference prior as a default or objective distribution that is proper.</p>
<p>In the next sections, we will return to Bayes factors and hypothesis testing where the Cauchy prior plays an important role.</p>
</div>
</div>
<div id="hypothesis-testing-with-normal-populations" class="section level1">
<h1>5 Hypothesis Testing with Normal Populations</h1>
<p>In Section <a href="#sec:bayes-factors"><strong>??</strong></a>, we described how the Bayes factors can be used for hypothesis testing. Now we will use the Bayes factors to compare normal means, i.e., test whether the mean of a population is zero or compare the means of two groups of normally-distributed populations. We divide this mission into three cases: known variance for a single population, unknown variance for a single population using paired data, and unknown variance using two independent groups.</p>
<p>Also note that some of the examples in this section use an updated version of the <code>bayes_inference</code> function.
If your local output is different from what is seen in this chapter, or the provided code fails to run for you please make sure that you have the most recent version of the package.</p>
<div id="bayes-factors-for-testing-a-normal-mean-variance-known" class="section level2">
<h2>Bayes Factors for Testing a Normal Mean: variance known</h2>
<pre class="r"><code>library(ggplot2)</code></pre>
<pre class="r"><code>cbPalette &lt;- c(&quot;#999999&quot;, &quot;#E69F00&quot;, &quot;#56B4E9&quot;, &quot;#000000&quot;, &quot;#009E73&quot;, &quot;#0072B2&quot;, &quot;#D55E00&quot;, &quot;#CC79A7&quot;)

bf12 = function(n, Z, n0=1) {
  exp(.5*(log(n + n0) - log(n0) - n*Z^2/(n + n0)))
}

postprob = function(x){
  1/(1 + 1/x)
}

bf12_Cauchy = function(n, Z, r=1) {
  int = integrate(
    f = function(x, n, z) {
      dgamma(x, shape=.5, rate=r^2/2)/bf12(n,z,x)
    },
    lower=0, upper=Inf, n=n, z=Z
  )
  return(1/int$value)
}

bf12_point = function(ybar, m_1, m_2, n=100, sigma=1) {
  exp(dnorm(ybar, m_1, sigma/sqrt(n), log=T) -
      dnorm(ybar, m_2, sigma/sqrt(n), log=T))
}</code></pre>
<p>Now we show how to obtain Bayes factors for testing hypothesis about a normal mean, where <strong>the variance is known</strong>. To start, let’s consider a random sample of observations from a normal population with mean <span class="math inline">\(\mu\)</span> and pre-specified variance <span class="math inline">\(\sigma^2\)</span>. We consider testing whether the population mean <span class="math inline">\(\mu\)</span> is equal to <span class="math inline">\(m_0\)</span> or not.</p>
<p>Therefore, we can formulate the data and hypotheses as below:</p>
<p><strong>Data</strong>
<span class="math display">\[Y_1, \cdots, Y_n \overset{\text{iid}}{\sim} \text{N}(\mu, \sigma^2)\]</span></p>
<p><strong>Hypotheses</strong></p>
<ul>
<li><span class="math inline">\(H_1: \mu = m_0\)</span></li>
<li><span class="math inline">\(H_2: \mu \neq m_0\)</span></li>
</ul>
<p><strong>Priors</strong></p>
<p>We also need to specify priors for <span class="math inline">\(\mu\)</span> under both hypotheses. Under <span class="math inline">\(H_1\)</span>, we assume that <span class="math inline">\(\mu\)</span> is exactly <span class="math inline">\(m_0\)</span>, so this occurs with probability 1 under <span class="math inline">\(H_1\)</span>. Now under <span class="math inline">\(H_2\)</span>, <span class="math inline">\(\mu\)</span> is unspecified, so we describe our prior uncertainty with the conjugate normal distribution centered at <span class="math inline">\(m_0\)</span> and with a variance <span class="math inline">\(\sigma^2/\mathbf{n_0}\)</span>. This is centered at the hypothesized value <span class="math inline">\(m_0\)</span>, and it seems that the mean is equally likely to be larger or smaller than <span class="math inline">\(m_0\)</span>, so a dividing factor <span class="math inline">\(n_0\)</span> is given to the variance. The hyper parameter <span class="math inline">\(n_0\)</span> controls the precision of the prior as before.</p>
<p>In mathematical terms, the priors are:</p>
<ul>
<li><span class="math inline">\(H_1: \mu = m_0 \text{  with probability 1}\)</span></li>
<li><span class="math inline">\(H_2: \mu \sim \text{N}(m_0, \sigma^2/\mathbf{n_0})\)</span></li>
</ul>
<p><strong>Bayes Factor</strong></p>
<p>Now the Bayes factor for comparing <span class="math inline">\(H_1\)</span> to <span class="math inline">\(H_2\)</span> is the ratio of the distribution, the data under the assumption that <span class="math inline">\(\mu = m_0\)</span> to the distribution of the data under <span class="math inline">\(H_2\)</span>.</p>
<p><span class="math display">\[\begin{aligned}
\text{BF}[H_1 : H_2] &amp;= \frac{p(\text{data} \mid \mu = m_0, \sigma^2 )}
 {\int p(\text{data} \mid \mu, \sigma^2) p(\mu \mid m_0, \mathbf{n_0}, \sigma^2)\, d \mu} \\
\text{BF}[H_1 : H_2] &amp;=\left(\frac{n + \mathbf{n_0}}{\mathbf{n_0}} \right)^{1/2} \exp\left\{-\frac 1 2 \frac{n }{n + \mathbf{n_0}} Z^2 \right\} \\
 Z   &amp;=  \frac{(\bar{Y} - m_0)}{\sigma/\sqrt{n}}
\end{aligned}\]</span></p>
<p>The term in the denominator requires integration to account for the uncertainty in <span class="math inline">\(\mu\)</span> under <span class="math inline">\(H_2\)</span>. And it can be shown that the Bayes factor is a function of the observed sampled size, the prior sample size <span class="math inline">\(n_0\)</span> and a <span class="math inline">\(Z\)</span> score.</p>
<p>Let’s explore how the hyperparameters in <span class="math inline">\(n_0\)</span> influences the Bayes factor in Equation <a href="#eq:BayesFactor">(12)</a>. For illustration we will use the sample size of 100. Recall that for estimation, we interpreted <span class="math inline">\(n_0\)</span> as a prior sample size and considered the limiting case where <span class="math inline">\(n_0\)</span> goes to zero as a non-informative or reference prior.</p>
<p><span class="math display" id="eq:BayesFactor">\[\begin{equation}
\textsf{BF}[H_1 : H_2] = \left(\frac{n + \mathbf{n_0}}{\mathbf{n_0}}\right)^{1/2} \exp\left\{-\frac{1}{2} \frac{n }{n + \mathbf{n_0}} Z^2 \right\}
\tag{12}
\end{equation}\]</span></p>
<p>Figure <a href="#fig:vague-prior">23</a> shows the Bayes factor for comparing <span class="math inline">\(H_1\)</span> to <span class="math inline">\(H_2\)</span> on the y-axis as <span class="math inline">\(n_0\)</span> changes on the x-axis. The different lines correspond to different values of the <span class="math inline">\(Z\)</span> score or how many standard errors <span class="math inline">\(\bar{y}\)</span> is from the hypothesized mean. As expected, larger values of the <span class="math inline">\(Z\)</span> score favor <span class="math inline">\(H_2\)</span>.</p>
<pre class="r"><code>myblue = rgb(86,155,189, name=&quot;myblue&quot;, max=256)
mydarkgrey = rgb(.5,.5,.5, name=&quot;mydarkgrey&quot;, max=1)
Z = c(1.65, 1.96, 2.81, 3.62 )
nsim = 5000
n0  = seq(0, 1, length=nsim)
#n0 = 1
n  = c(25, 50,100, 10000)

bf.C = c(bf12_Cauchy(n[1], Z[1]), bf12_Cauchy(n[2], Z[2]),
         bf12_Cauchy(n[1], Z[3]),bf12_Cauchy(n[2], Z[4]))
df = data.frame(Z = rep(as.character(Z), rep(nsim, 4)),
                bf = c(bf12(n[2],Z[1], n0), bf12(n[2],Z[2], n0),
                       bf12(n[2],Z[3], n0), bf12(n[2],Z[4], n0)),
                bf.C = rep(bf.C, rep(nsim, 4)),
                n0 =c(n0, n0, n0, n0))
bfplot = ggplot(df, aes(x=n0, y=bf, group=Z, colour=Z, linetype=Z)) +
              scale_colour_manual(values=cbPalette) +
              geom_line() + geom_abline(slope=0, intercept=0) + scale_y_log10() +
              xlab(expression(n[0])) + ylab(&quot;BF[H1:H2]&quot;) +
               theme(panel.background = element_rect(fill = &quot;transparent&quot;, colour = NA),
                 legend.key = element_rect(colour = &quot;transparent&quot;, fill = NA),
                  plot.background = element_rect(fill = &quot;transparent&quot;, colour = NA)) +
                     theme(legend.position=c(.85, .85)) +
  theme(text = element_text(size=15))

#legend(30, .95, legend=paste(&quot;Z = &quot;, as.character(Z), &quot;p-value = &quot;,
#                             as.character(round(2*pnorm(-Z),4))),
#                             lty=1:4, lwd=rep(3,4),
#                             col=rep(myblue,4))
#legend(.6, 7 , col=c(myblue, &quot;darkgrey&quot;), lwd=rep(2,2),  lty=c(1,2),
#       legend=c(&quot;male&quot;, &quot;prior&quot;))

bfplot</code></pre>
<div class="figure" style="text-align: center"><span id="fig:vague-prior"></span>
<img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/vague-prior-1.svg" alt="Vague prior for mu: n=100" width="384" />
<p class="caption">
Figure 23: Vague prior for mu: n=100
</p>
</div>
<p>But as <span class="math inline">\(n_0\)</span> becomes smaller and approaches 0, the first term in
the Bayes factor goes to infinity, while the exponential term involving the
data goes to a constant and is ignored. In the limit as <span class="math inline">\(n_0 \rightarrow 0\)</span> under this noninformative prior, the Bayes factor paradoxically ends up favoring <span class="math inline">\(H_1\)</span> regardless of the value of <span class="math inline">\(\bar{y}\)</span>.</p>
<p>The takeaway from this is that we cannot use improper priors with <span class="math inline">\(n_0 = 0\)</span>, if we are going to test our hypothesis that <span class="math inline">\(\mu = n_0\)</span>. Similarly, vague priors that use a small value of <span class="math inline">\(n_0\)</span> are not recommended due to the sensitivity of the results to the choice of an arbitrarily small value of <span class="math inline">\(n_0\)</span>.</p>
<p>This problem arises with vague priors – the Bayes factor favors the null model <span class="math inline">\(H_1\)</span> even when the data are far away from the value under the null – are known as the Bartlett’s paradox or the Jeffrey’s-Lindleys paradox.</p>
<p>Now, one way to understand the effect of prior is through the standard effect size</p>
<p><span class="math display">\[\delta = \frac{\mu - m_0}{\sigma}.\]</span>
The prior of the standard effect size is</p>
<p><span class="math display">\[\delta \mid   H_2  \sim \text{N}(0, \frac{1}{\mathbf{n_0}})\]</span></p>
<p>This allows us to think about a standardized effect independent of the units of the problem. One default choice is using the unit information prior, where the prior sample size <span class="math inline">\(n_0\)</span> is 1, leading to a standard normal for the standardized effect size. This is depicted with the blue normal density in Figure <a href="#fig:effect-size">24</a>. This suggested that we expect that the mean will be within <span class="math inline">\(\pm 1.96\)</span> standard deviations of the hypothesized mean <strong>with probability 0.95</strong>. (Note that we can say this only under a Bayesian setting.)</p>
<p>In many fields we expect that the effect will be small relative to <span class="math inline">\(\sigma\)</span>. If we do not expect to see large effects, then we may want to use a more informative prior on the effect size as the density in orange with <span class="math inline">\(n_0 = 4\)</span>. So they expected the mean to be within <span class="math inline">\(\pm 1/\sqrt{n_0}\)</span> or five standard deviations of the prior mean.</p>
<pre class="r"><code>x = seq(-6,5, length=1000)
par(cex=1, cex.axis=1, cex.lab=1, mar=c(5, 5, 2, 2), col.lab=mydarkgrey, col.axis=mydarkgrey, col=mydarkgrey)
plot(x, dnorm(x) , type=&quot;l&quot;, lwd=3, ylab=&quot;density&quot;, xlab=expression(delta), col=myblue, ylim=c(0, .9), bty=&quot;n&quot;)
#lines(x, dt(x, df=1), lwd=3, col=&quot;orange&quot;)
lines(x, dnorm(x, sd=.5), lwd=3,  lty = 2, col=&quot;orange&quot;)
#lines(x, dt(x/.5, df=1)/.5, lwd=3,   lty=2, col=&quot;orange&quot;)
legend(x=&quot;topleft&quot;, legend=c(&quot;N(0,1)&quot;, &quot;N(0, .25)&quot;),
       col=c(myblue, &quot;orange&quot;),
       lty=c(1,2), lwd=3, bty=&quot;n&quot;)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:effect-size"></span>
<img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/effect-size-1.svg" alt="Prior on standard effect size" width="480" />
<p class="caption">
Figure 24: Prior on standard effect size
</p>
</div>

<div class="example">
<span id="exm:unnamed-chunk-16" class="example"><strong>Example 19  </strong></span>To illustrate, we give an example from parapsychological research. The case involved the test of the subject’s claim to affect a series of randomly generated 0’s and 1’s by means of extra sensory perception (ESP). The random sequence of 0’s and 1’s are generated by a machine with
probability of generating 1 being 0.5. The subject claims that his ESP would make the sample mean differ significantly from 0.5.
</div>
<p>Therefore, we are testing <span class="math inline">\(H_1: \mu = 0.5\)</span> versus <span class="math inline">\(H_2: \mu \neq 0.5\)</span>. Let’s use a prior that suggests we do not expect a large effect which leads
the following solution for <span class="math inline">\(n_0\)</span>. Assume we want a standard effect of 0.03, there is a 95% chance that it is between <span class="math inline">\((-0.03/\sigma, 0.03/\sigma)\)</span>, with <span class="math inline">\(n_0 = (1.96\sigma/0.03)^2 = 32.7^2\)</span>.</p>
<p>Figure <a href="#fig:prior-effect">25</a> shows our informative prior in blue, while the unit information prior is in orange. On this scale, the unit information
prior needs to be almost uniform for the range that we are interested.</p>
<pre class="r"><code>n = 104490000
y = 52263471
ybar = y/n
var = ybar*(1-ybar)
sigma = sqrt(var)
effect = .03
n0.5 = round(1.96*sigma/effect,1)
n0 = n0.5^2
Zobs = (ybar - .5)/sqrt(var/n)
pval = 2*pnorm(-abs(Zobs))
bfI = bf12(n, Zobs, n0.5^2)
bfUI = bf12(n, Zobs, 1)
#pp = postprob(bf)</code></pre>
<pre class="r"><code>x = seq(-1,1, length=1000) + .5
par(cex=1, cex.axis=1, cex.lab=1, mar=c(2, 2, 2, 2), col.lab=mydarkgrey, col.axis=mydarkgrey, col=mydarkgrey)
plot(x, dnorm(x, .5, .5/n0.5) , type=&quot;l&quot;, lwd=2, ylab=&quot;density&quot;, xlab=expression(mu), col=myblue, bty=&quot;n&quot;, ylim=c(0,30))
#lines(x, dt(x, df=1), lwd=3, col=&quot;orange&quot;)
lines(x, dnorm(x,0.5, sd=1), lwd=2,  lty = 2, col=&quot;orange&quot;)
#lines(x, dt(x/.5, df=1)/.5, lwd=3,   lty=2, col=&quot;orange&quot;)
legend(x=&quot;topleft&quot;, legend=c(paste0(&quot;N(.5,.5/&quot;,n0.5,&quot;^2)&quot;), &quot;N(.5, .5)&quot;),
       col=c(myblue, &quot;orange&quot;),
       lty=c(1,2), lwd=3, bty=&quot;n&quot;)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:prior-effect"></span>
<img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/prior-effect-1.svg" alt="Prior effect in the extra sensory perception test" width="672" />
<p class="caption">
Figure 25: Prior effect in the extra sensory perception test
</p>
</div>
<p>A very large data set with over 104 million trials was collected to test this hypothesis, so we use a normal distribution to approximate the distribution the sample mean.</p>
<ul>
<li>Sample size: <span class="math inline">\(n = 1.0449 \times 10^8\)</span></li>
<li>Sample mean: <span class="math inline">\(\bar{y} = 0.500177\)</span>, standard deviation <span class="math inline">\(\sigma = 0.5\)</span></li>
<li><span class="math inline">\(Z\)</span>-score: 3.61</li>
</ul>
<p>Now using our prior in the data, the Bayes factor for <span class="math inline">\(H_1\)</span> to <span class="math inline">\(H_2\)</span> was 0.46, implying evidence against the hypothesis <span class="math inline">\(H_1\)</span> that <span class="math inline">\(\mu = 0.5\)</span>.</p>
<ul>
<li>Informative <span class="math inline">\(\text{BF}[H_1:H_2] = 0.46\)</span></li>
<li><span class="math inline">\(\text{BF}[H_2:H_1] = 1/\text{BF}[H_1:H_2] = 2.19\)</span></li>
</ul>
<p>Now, this can be inverted to provide the evidence in favor of <span class="math inline">\(H_2\)</span>. The evidence suggests that the hypothesis that the machine operates with a probability that is not 0.5, is 2.19 times more likely than the hypothesis
the probability is 0.5. Based on the interpretation of Bayes factors from Table <a href="#tab:jeffreys1961">9</a>, this is in the range of “not worth the bare mention”.</p>
<p>To recap, we present expressions for calculating Bayes factors for a normal model with a specified variance. We show that the improper reference priors for <span class="math inline">\(\mu\)</span> when <span class="math inline">\(n_0 = 0\)</span>, or vague priors where <span class="math inline">\(n_0\)</span> is arbitrarily small,
lead to Bayes factors that favor the null hypothesis regardless of the data, and thus should not be used for hypothesis testing.</p>
<p>Bayes factors with normal priors can be sensitive to the choice of the <span class="math inline">\(n_0\)</span>. While the default value of <span class="math inline">\(n_0 = 1\)</span> is reasonable in many cases, this may be too non-informative if one expects more effects. Wherever possible, think about how large an effect you expect and use that information to help select the <span class="math inline">\(n_0\)</span>.</p>
<p>All the ESP examples suggest weak evidence and favored the machine generating random 0’s and 1’s with a probability that is different from 0.5. Note that ESP is not the only explanation – a deviation from 0.5 can also occur if the random number generator is biased. Bias in the stream of random numbers in our pseudorandom numbers has huge implications for numerous fields that depend on simulation. If the context had been about detecting a small bias in random numbers what prior would you use and how would it change the outcome? You can experiment it in <code>R</code> or other software packages that generate random Bernoulli trials.</p>
<p>Next, we will look at Bayes factors in normal models with unknown variances using the Cauchy prior so that results are less sensitive to the choice of <span class="math inline">\(n_0\)</span>.</p>
</div>
<div id="comparing-two-paired-means-using-bayes-factors" class="section level2">
<h2>Comparing Two Paired Means using Bayes Factors</h2>
<p>We previously learned that we can use a paired t-test to compare means from two paired samples. In this section, we will show how Bayes factors can be expressed as a function of the t-statistic for comparing the means and provide posterior probabilities of the hypothesis that whether the means are equal or different.</p>

<div class="example">
<p><span id="exm:zinc" class="example"><strong>Example 20  </strong></span>Trace metals in drinking water affect the flavor, and unusually high concentrations can pose a health hazard. Ten pairs of data were taken measuring the zinc concentration in bottom and surface water at ten randomly sampled locations, as listed in Table <a href="#tab:zinc-table">11</a>.</p>
Water samples collected at the the same location, on the surface and the bottom, cannot be assumed to be independent of each other. However, it may be reasonable to assume that the differences in the concentration at the bottom and the surface in randomly sampled locations are independent of each other.
</div>
<pre class="r"><code>library(statsr)
data(zinc)
knitr::kable(
  zinc,
  booktabs = TRUE,
  caption = &#39;Zinc in drinking water&#39;
)</code></pre>
<table>
<caption><span id="tab:zinc-table">Table 11: </span>Zinc in drinking water</caption>
<thead>
<tr class="header">
<th align="right">location</th>
<th align="right">bottom</th>
<th align="right">surface</th>
<th align="right">difference</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">0.430</td>
<td align="right">0.415</td>
<td align="right">0.015</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">0.266</td>
<td align="right">0.238</td>
<td align="right">0.028</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">0.567</td>
<td align="right">0.390</td>
<td align="right">0.177</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">0.531</td>
<td align="right">0.410</td>
<td align="right">0.121</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">0.707</td>
<td align="right">0.605</td>
<td align="right">0.102</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">0.716</td>
<td align="right">0.609</td>
<td align="right">0.107</td>
</tr>
<tr class="odd">
<td align="right">7</td>
<td align="right">0.651</td>
<td align="right">0.632</td>
<td align="right">0.019</td>
</tr>
<tr class="even">
<td align="right">8</td>
<td align="right">0.589</td>
<td align="right">0.523</td>
<td align="right">0.066</td>
</tr>
<tr class="odd">
<td align="right">9</td>
<td align="right">0.469</td>
<td align="right">0.411</td>
<td align="right">0.058</td>
</tr>
<tr class="even">
<td align="right">10</td>
<td align="right">0.723</td>
<td align="right">0.612</td>
<td align="right">0.111</td>
</tr>
</tbody>
</table>
<p>To start modeling, we will treat the ten differences as a random sample from a normal population where the parameter of interest is the difference between the average zinc concentration at the bottom and the average zinc concentration at the surface, or the main difference, <span class="math inline">\(\mu\)</span>.</p>
<p>In mathematical terms, we have</p>
<ul>
<li>Random sample of <span class="math inline">\(n= 10\)</span> differences <span class="math inline">\(Y_1, \ldots, Y_n\)</span></li>
<li>Normal population with mean <span class="math inline">\(\mu \equiv \mu_B - \mu_S\)</span></li>
</ul>
<p>In this case, we have no information about the variability in the data, and we will treat the variance, <span class="math inline">\(\sigma^2\)</span>, as unknown.</p>
<p>The hypothesis of the main concentration at the surface and bottom are the same is equivalent to saying <span class="math inline">\(\mu = 0\)</span>. The second hypothesis is that the difference between the mean bottom and surface concentrations, or equivalently that the mean difference <span class="math inline">\(\mu \neq 0\)</span>.</p>
<p>In other words, we are going to compare the following hypotheses:</p>
<ul>
<li><span class="math inline">\(H_1: \mu_B = \mu_S \Leftrightarrow \mu = 0\)</span></li>
<li><span class="math inline">\(H_2: \mu_B \neq \mu_S \Leftrightarrow \mu \neq 0\)</span></li>
</ul>
<p>The Bayes factor is the ratio between the distributions of the data
under each hypothesis, which does not depend on any unknown parameters.</p>
<p><span class="math display">\[\text{BF}[H_1 : H_2] = \frac{p(\text{data} \mid H_1)} {p(\text{data} \mid H_2)}\]</span></p>
<p>To obtain the Bayes factor, we need to use integration over the prior distributions under each hypothesis to obtain those distributions of the data.</p>
<p><span class="math display">\[\text{BF}[H_1 : H_2] = \iint p(\text{data} \mid \mu, \sigma^2) p(\mu \mid \sigma^2) p(\sigma^2 \mid H_2)\, d \mu \, d\sigma^2\]</span></p>
<p>This requires specifying the following priors:</p>
<ul>
<li><span class="math inline">\(\mu \mid \sigma^2, H_2 \sim \text{N}(0, \sigma^2/n_0)\)</span></li>
<li><span class="math inline">\(p(\sigma^2) \propto 1/\sigma^2\)</span> for both <span class="math inline">\(H_1\)</span> and <span class="math inline">\(H_2\)</span></li>
</ul>
<p><span class="math inline">\(\mu\)</span> is exactly zero under the hypothesis <span class="math inline">\(H_1\)</span>. For <span class="math inline">\(\mu\)</span> in <span class="math inline">\(H_2\)</span>, we start with the same conjugate normal prior as we used in Section <a href="#sec:known-var"><strong>??</strong></a> – testing the normal mean with known variance. Since we assume that <span class="math inline">\(\sigma^2\)</span> is known, we model <span class="math inline">\(\mu \mid \sigma^2\)</span> instead of <span class="math inline">\(\mu\)</span> itself.</p>
<p>The <span class="math inline">\(\sigma^2\)</span> appears in both the numerator and denominator of the Bayes factor. For default or reference case, we use the Jeffreys prior (a.k.a. reference prior) on <span class="math inline">\(\sigma^2\)</span>. As long as we have more than two observations, this (improper) prior will lead to a proper posterior.</p>
<p>After integration and rearranging, one can derive a simple expression for the Bayes factor:</p>
<p><span class="math display">\[\text{BF}[H_1 : H_2] = \left(\frac{n + n_0}{n_0} \right)^{1/2} \left(
  \frac{ t^2  \frac{n_0}{n + n_0} + \nu }
  { t^2  + \nu} \right)^{\frac{\nu + 1}{2}}\]</span></p>
<p>This is a function of the t-statistic</p>
<p><span class="math display">\[t = \frac{|\bar{Y}|}{s/\sqrt{n}},\]</span></p>
<p>where <span class="math inline">\(s\)</span> is the sample standard deviation and the degrees of freedom <span class="math inline">\(\nu = n-1\)</span> (sample size minus one).</p>
<p>As we saw in the case of Bayes factors with known variance, we cannot use the improper prior on <span class="math inline">\(\mu\)</span> because when <span class="math inline">\(n_0 \to 0\)</span>, then <span class="math inline">\(\text{BF}[H1:H_2] \to \infty\)</span> favoring <span class="math inline">\(H_1\)</span> regardless of the magnitude of the t-statistic. Arbitrary, vague small choices for <span class="math inline">\(n_0\)</span> also lead to arbitrary large Bayes factors in favor of <span class="math inline">\(H_1\)</span>. Another example of the Barlett’s or Jeffreys-Lindley paradox.</p>
<p>Sir Harold Jeffrey discovered another paradox testing using the conjugant normal prior, known as the <strong>information paradox</strong>. His thought experiment assumed that our sample size <span class="math inline">\(n\)</span> and the prior sample size <span class="math inline">\(n_0\)</span>. He then considered what would happen to the Bayes factor as the sample mean moved further and further away from the hypothesized mean, measured in terms standard errors with the t-statistic, i.e., <span class="math inline">\(|t| \to \infty\)</span>. As the t-statistic or information about the mean moved further and further from zero, the Bayes factor goes to a constant depending on <span class="math inline">\(n, n_0\)</span> rather than providing overwhelming support for <span class="math inline">\(H_2\)</span>.</p>
<p>The bounded Bayes factor is</p>
<p><span class="math display">\[\text{BF}[H_1 : H_2] \to \left( \frac{n_0}{n_0 + n}  \right)^{\frac{n - 1}{2}}\]</span></p>
<p>Jeffrey wanted a prior with <span class="math inline">\(\text{BF}[H_1 : H_2] \to 0\)</span> (or equivalently, <span class="math inline">\(\text{BF}[H_2 : H_1] \to \infty\)</span>), as the information from the t-statistic grows, indicating the sample mean is as far as from the hypothesized mean and should favor <span class="math inline">\(H_2\)</span>.</p>
<p>To resolve the paradox when the information the t-statistic favors <span class="math inline">\(H_2\)</span> but the Bayes factor does not, Jeffreys showed that <strong>no normal prior</strong> could resolve the paradox.</p>
<p>But a <strong>Cauchy prior</strong> on <span class="math inline">\(\mu\)</span>, would resolve it. In this way, <span class="math inline">\(\text{BF}[H_2 : H_1]\)</span> goes to infinity as the sample mean becomes further away from the hypothesized mean. Recall that the Cauchy prior is written as <span class="math inline">\(\text{Ca}(0, r^2 \sigma^2)\)</span>. While Jeffreys used a default of <span class="math inline">\(r = 1\)</span>, smaller values of <span class="math inline">\(r\)</span> can be used if smaller effects are expected.</p>
<p>The combination of the Jeffrey’s prior on <span class="math inline">\(\sigma^2\)</span> and this Cauchy prior on <span class="math inline">\(\mu\)</span> under <span class="math inline">\(H_2\)</span> is sometimes referred to as the <strong>Jeffrey-Zellener-Siow prior</strong>.</p>
<p>However, there is no closed form expressions for the Bayes factor under the Cauchy distribution. To obtain the Bayes factor, we must use the
numerical integration or simulation methods.</p>
<p>We will use the  function from the  package to test whether the mean difference is zero in Example <a href="#exm:zinc">20</a> (zinc), using the JZS (Jeffreys-Zellener-Siow) prior.</p>
<pre class="r"><code>library(statsr)
bayes_inference(difference, data=zinc, statistic=&quot;mean&quot;, type=&quot;ht&quot;,
                prior=&quot;JZS&quot;, mu_0=0, method=&quot;theo&quot;, alt=&quot;twosided&quot;)</code></pre>
<pre><code>## Single numerical variable
## n = 10, y-bar = 0.0804, s = 0.0523
## (Using Zellner-Siow Cauchy prior:  mu ~ C(0, 1*sigma)
## (Using Jeffreys prior: p(sigma^2) = 1/sigma^2
## 
## Hypotheses:
## H1: mu = 0 versus H2: mu != 0
## Priors:
## P(H1) = 0.5 , P(H2) = 0.5
## Results:
## BF[H2:H1] = 50.7757
## P(H1|data) = 0.0193  P(H2|data) = 0.9807 
## 
## Posterior summaries for mu under H2:
## Single numerical variable
## n = 10, y-bar = 0.0804, s = 0.0523
## (Assuming Zellner-Siow Cauchy prior:  mu | sigma^2 ~ C(0, 1*sigma)
## (Assuming improper Jeffreys prior: p(sigma^2) = 1/sigma^2
## 
## Posterior Summaries
##             2.5%        25%        50%         75%       97.5%
## mu    0.03658322 0.06328524 0.07535867  0.08716296  0.11223976
## sigma 0.03668785 0.04739511 0.05529708  0.06554917  0.09547547
## n_0   0.16376796 1.89626968 4.74287640 10.10750012 32.29002013
## 
## 95% CI for mu: (0.0366, 0.1122)</code></pre>
<p><img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/bayes-inference-1.svg" width="384" style="display: block; margin: auto;" /></p>
<p>With equal prior probabilities on the two hypothesis, the Bayes factor is the posterior odds. From the output, we see this indicates that the hypothesis <span class="math inline">\(H_2\)</span>, the mean difference is different from 0, is almost 51 times more likely than the hypothesis <span class="math inline">\(H_1\)</span> that the average concentration is the same at the surface and the bottom.</p>
<p>To sum up, we have used the <strong>Cauchy prior</strong> as a default prior testing hypothesis about a normal mean when variances are unknown. This does require numerical integration, but it is available in the  function from the  package. If you expect that the effect sizes will be small, smaller values of <span class="math inline">\(r\)</span> are recommended.</p>
<p>It is often important to quantify the magnitude of the difference in addition to testing. The Cauchy Prior provides a default prior for both testing and inference; it avoids problems that arise with choosing a value of <span class="math inline">\(n_0\)</span> (prior sample size) in both cases. In the next section, we will illustrate using the Cauchy prior for comparing two means from independent normal samples.</p>
</div>
<div id="sec:indep-means" class="section level2">
<h2>Comparing Independent Means: Hypothesis Testing</h2>
<p>In the previous section, we described Bayes factors for testing whether the mean difference of <strong>paired</strong> samples was zero. In this section, we will consider a slightly different problem – we have two <strong>independent</strong> samples, and we would like to test the hypothesis that the means are different or equal.</p>

<div class="example">
<p><span id="exm:birth-records" class="example"><strong>Example 21  </strong></span>We illustrate the testing of independent groups with data from a 2004 survey of birth records from North Carolina, which are available in the  package.</p>
<p>The variable of interest is  – the weight gain of mothers during pregnancy. We have two groups defined by the categorical variable, , with levels, younger mom and older mom.</p>
<strong>Question of interest</strong>: Do the data provide convincing evidence of a difference between the average weight gain of older moms and the average weight gain of younger moms?
</div>
<p>We will view the data as a random sample from two populations, older and younger moms. The two groups are modeled as:</p>
<p><span class="math display" id="eq:half-alpha">\[\begin{equation}
\begin{aligned}
Y_{O,i} &amp; \mathrel{\mathop{\sim}\limits^{\rm iid}} \textsf{N}(\mu + \alpha/2, \sigma^2) \\
Y_{Y,i} &amp; \mathrel{\mathop{\sim}\limits^{\rm iid}} \textsf{N}(\mu - \alpha/2, \sigma^2)
\end{aligned}
\tag{13}
\end{equation}\]</span></p>
<p>The model for weight gain for older moms using the subscript <span class="math inline">\(O\)</span>, and it assumes that the observations are independent and identically distributed, with a mean <span class="math inline">\(\mu+\alpha/2\)</span> and variance <span class="math inline">\(\sigma^2\)</span>.</p>
<p>For the younger women, the observations with the subscript <span class="math inline">\(Y\)</span> are independent and identically distributed with a mean <span class="math inline">\(\mu-\alpha/2\)</span> and variance <span class="math inline">\(\sigma^2\)</span>.</p>
<p>Using this representation of the means in the two groups, the difference in means simplifies to <span class="math inline">\(\alpha\)</span> – the parameter of interest.</p>
<p><span class="math display">\[(\mu + \alpha/2)  - (\mu - \alpha/2) =  \alpha\]</span></p>
<p>You may ask, “Why don’t we set the average weight gain of older women to <span class="math inline">\(\mu+\alpha\)</span>, and the average weight gain of younger women to <span class="math inline">\(\mu\)</span>?” We need the parameter <span class="math inline">\(\alpha\)</span> to be present in both <span class="math inline">\(Y_{O,i}\)</span> (the group of older women) and <span class="math inline">\(Y_{Y,i}\)</span> (the group of younger women).</p>
<p>We have the following competing hypotheses:</p>
<ul>
<li><span class="math inline">\(H_1: \alpha = 0 \Leftrightarrow\)</span> The means are not different.</li>
<li><span class="math inline">\(H_2: \alpha \neq 0 \Leftrightarrow\)</span> The means are different.</li>
</ul>
<p>In this representation, <span class="math inline">\(\mu\)</span> represents the overall weight gain for all women. (Does the model in Equation <a href="#eq:half-alpha">(13)</a> make more sense now?) To test the hypothesis, we need to specify prior distributions for <span class="math inline">\(\alpha\)</span> under <span class="math inline">\(H_2\)</span> (c.f. <span class="math inline">\(\alpha = 0\)</span> under <span class="math inline">\(H_1\)</span>) and priors for <span class="math inline">\(\mu,\sigma^2\)</span> under both hypotheses.</p>
<p>Recall that the Bayes factor is the ratio of the distribution of the data under the two hypotheses.</p>
<p><span class="math display">\[\begin{aligned}
 \text{BF}[H_1 : H_2] &amp;=  \frac{p(\text{data} \mid H_1)} {p(\text{data} \mid H_2)} \\
  &amp;= \frac{\iint p(\text{data} \mid \alpha = 0,\mu,  \sigma^2 )p(\mu, \sigma^2 \mid H_1) \, d\mu \,d\sigma^2}
 {\int \iint p(\text{data} \mid \alpha, \mu, \sigma^2) p(\alpha \mid \sigma^2) p(\mu, \sigma^2 \mid H_2) \, d \mu \, d\sigma^2 \, d \alpha}
\end{aligned}\]</span></p>
<p>As before, we need to average over uncertainty and the parameters to obtain the unconditional distribution of the data. Now, as in the test about a single mean, we cannot use improper or non-informative priors for <span class="math inline">\(\alpha\)</span> for testing.</p>
<p>Under <span class="math inline">\(H_2\)</span>, we use the Cauchy prior for <span class="math inline">\(\alpha\)</span>, or equivalently, the Cauchy prior on the standardized effect <span class="math inline">\(\delta\)</span> with the scale of <span class="math inline">\(r\)</span>:</p>
<p><span class="math display">\[\delta = \alpha/\sigma^2 \sim \text{Ca}(0, r^2)\]</span></p>
<p>Now, under both <span class="math inline">\(H_1\)</span> and <span class="math inline">\(H_2\)</span>, we use the Jeffrey’s reference prior on <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span>:</p>
<p><span class="math display">\[p(\mu, \sigma^2) \propto 1/\sigma^2\]</span></p>
<p>While this is an improper prior on <span class="math inline">\(\mu\)</span>, this does not suffer from the Bartlett’s-Lindley’s-Jeffreys’ paradox as <span class="math inline">\(\mu\)</span> is a common parameter in the model in <span class="math inline">\(H_1\)</span> and <span class="math inline">\(H_2\)</span>. This is another example of the Jeffreys-Zellner-Siow prior.</p>
<p>As in the single mean case, we will need numerical algorithms to obtain the Bayes factor. Now the following output illustrates testing of Bayes factors, using the Bayes inference function from the  package.</p>
<pre class="r"><code>library(statsr)
data(nc)
bayes_inference(y=gained, x=mature, data=nc,type=&#39;ht&#39;, 
                statistic=&#39;mean&#39;,  alternative=&#39;twosided&#39;, null=0,
                prior=&#39;JZS&#39;, r=1, method=&#39;theo&#39;, show_summ=FALSE)</code></pre>
<pre><code>## Hypotheses:
## H1: mu_mature mom  = mu_younger mom
## H2: mu_mature mom != mu_younger mom
## 
## Priors: P(H1) = 0.5  P(H2) = 0.5 
## 
## Results:
## BF[H1:H2] = 5.7162
## P(H1|data) = 0.8511 
## P(H2|data) = 0.1489 
## 
## Posterior summaries for under H2:
## 95% Cred. Int.: (-4.387 , 0.9328)</code></pre>
<p><img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/bf-1.svg" width="384" style="display: block; margin: auto;" /></p>
<p>We see that the Bayes factor for <span class="math inline">\(H_1\)</span> to <span class="math inline">\(H_2\)</span> is about 5.7, with positive support for <span class="math inline">\(H_1\)</span> that there is no difference in average weight gain between younger and older women. Using equal prior probabilities, the probability that there is a difference in average weight gain between the two groups is about 0.15 given the data. Based on the interpretation of Bayes factors from Table <a href="#tab:jeffreys1961">9</a>, this is in the range of “positive” (between 3 and 20).</p>
<p>To recap, we have illustrated testing hypotheses about population means with two independent samples, using a Cauchy prior on the difference in the means. One assumption that we have made is that <strong>the variances are equal in both groups</strong>. The case where the variances are unequal is referred to as the Behren-Fisher problem, and this is beyond the scope for this course. In the next section, we will look at another example to put everything together with testing and discuss summarizing results.</p>
</div>
<div id="inference-after-testing" class="section level2">
<h2>Inference after Testing</h2>
<p>In this section, we will work through another example for comparing two means using both hypothesis tests and interval estimates, with an informative prior.
We will also illustrate how to adjust the credible interval after testing.</p>

<div class="example">
<span id="exm:smoking" class="example"><strong>Example 22  </strong></span>We will use the North Carolina survey data to examine the relationship
between infant birth weight and whether the mother smoked during pregnancy. The response variable, , is the birth weight of the baby in pounds. The categorical variable  provides the status of the mother as a smoker or non-smoker.
</div>
<p>We would like to answer two questions:</p>
<ol style="list-style-type: decimal">
<li><p>Is there a difference in average birth weight between the two groups?</p></li>
<li><p>If there is a difference, how large is the effect?</p></li>
</ol>
<p>As before, we need to specify models for the data and priors. We treat the data as a random sample for the two populations, smokers and non-smokers.</p>
<p>The birth weights of babies born to non-smokers, designated by a subgroup <span class="math inline">\(N\)</span>, are assumed to be independent and identically distributed from a normal distribution with mean <span class="math inline">\(\mu + \alpha/2\)</span>, as in Section <a href="#sec:indep-means"><strong>??</strong></a>.</p>
<p><span class="math display">\[Y_{N,i} \overset{\text{iid}}{\sim} \text{N}(\mu + \alpha/2, \sigma^2)\]</span></p>
<p>While the birth weights of the babies born to smokers, designated by the subgroup <span class="math inline">\(S\)</span>, are also assumed to have a normal distribution, but with mean <span class="math inline">\(\mu - \alpha/2\)</span>.</p>
<p><span class="math display">\[Y_{S,i} \overset{\text{iid}}{\sim} \text{N}(\mu - \alpha/2, \sigma^2)\]</span></p>
<p>The difference in the average birth weights is the parameter <span class="math inline">\(\alpha\)</span>, because</p>
<p><span class="math display">\[(\mu + \alpha/2) - (\mu - \alpha/2) =  \alpha\]</span>.</p>
<p>The hypotheses that we will test are <span class="math inline">\(H_1: \alpha = 0\)</span> versus <span class="math inline">\(H_2: \alpha \ne 0\)</span>.</p>
<p>We will still use the Jeffreys-Zellner-Siow Cauchy prior. However, since we may expect the standardized effect size to not be as strong, we will use a scale of <span class="math inline">\(r = 0.5\)</span> rather than 1.</p>
<p>Therefore, under <span class="math inline">\(H_2\)</span>, we have<br />
<span class="math display">\[\delta = \alpha/\sigma \sim \text{Ca}(0, r^2), \text{ with } r = 0.5.\]</span></p>
<p>Under both <span class="math inline">\(H_1\)</span> and <span class="math inline">\(H_2\)</span>, we will use the reference priors on <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span>:</p>
<p><span class="math display">\[\begin{aligned}
p(\mu) &amp;\propto 1 \\
p(\sigma^2) &amp;\propto 1/\sigma^2
\end{aligned}\]</span></p>
<p>The input to the base inference function is similar, but now we will specify that <span class="math inline">\(r = 0.5\)</span>.</p>
<pre class="r"><code>library(statsr)
data(nc)
out =bayes_inference(y=weight, x=habit, data=nc,type=&#39;ht&#39;, null=0,
                     statistic=&#39;mean&#39;,  alternative=&#39;twosided&#39;,
                     prior=&#39;JZS&#39;, r=.5, method=&#39;sim&#39;, show_summ=FALSE)</code></pre>
<pre><code>## Hypotheses:
## H1: mu_nonsmoker  = mu_smoker
## H2: mu_nonsmoker != mu_smoker
## 
## Priors: P(H1) = 0.5  P(H2) = 0.5 
## 
## Results:
## BF[H2:H1] = 1.4402
## P(H1|data) = 0.4098 
## P(H2|data) = 0.5902 
## 
## Posterior summaries for under H2:
## 95% Cred. Int.: (0.0225 , 0.5665)</code></pre>
<p><img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/BF-NC-1.svg" width="384" style="display: block; margin: auto;" /></p>
<p>We see that the Bayes factor is 1.44, which weakly favors there being a difference in average birth weights for babies whose mothers are smokers versus mothers who did not smoke. Converting this to a probability, we find that there is about a 60% chance of the average birth weights are different.</p>
<p>While looking at evidence of there being a difference is useful, Bayes factors and posterior probabilities do <strong>not</strong> convey any information about the magnitude of the effect. Reporting a credible interval or the complete posterior distribution is more relevant for quantifying the magnitude of the effect.</p>
<p>Using the  function, we can generate samples from the posterior distribution under <span class="math inline">\(H_2\)</span> using the  option.</p>
<pre class="r"><code>out.ci = bayes_inference(y=weight, x=habit, data=nc, type=&#39;ci&#39;,
                         statistic=&#39;mean&#39;, prior=&#39;JZS&#39;, mu_0=0,
                         r=.5, method=&#39;sim&#39;, verbose=FALSE)
print(out.ci$summary, digits=2)</code></pre>
<pre><code>##                             2.5%     25%    50%     75%   97.5%
## overall mean               6.853    6.94    7.0    7.04 7.1e+00
## mu_nonsmoker - mu_smoker   0.022    0.21    0.3    0.40 5.7e-01
## sigma^2                    2.078    2.19    2.3    2.33 2.5e+00
## effect size                0.015    0.14    0.2    0.26 3.8e-01
## n_0                      169.957 1926.57 4581.2 9401.10 2.5e+04</code></pre>
<p>The 2.5 and 97.5 percentiles for the difference in the means provide a 95% credible interval of 0.023 to 0.57 pounds for the difference in average birth weight. The MCMC output shows not only summaries about the difference in the mean <span class="math inline">\(\alpha\)</span>, but the other parameters in the model.</p>
<p>In particular, the Cauchy prior arises by placing a gamma prior on <span class="math inline">\(n_0\)</span> and the conjugate normal prior. This provides quantiles about <span class="math inline">\(n_0\)</span> after updating with the current data.</p>
<p>The row labeled effect size is the standardized effect size <span class="math inline">\(\delta\)</span>, indicating that the effects are indeed small relative to the noise in the data.</p>
<pre class="r"><code>library(ggplot2)
out = bayes_inference(y=weight, x=habit, data=nc,type=&#39;ht&#39;,
                statistic=&#39;mean&#39;,  alternative=&#39;twosided&#39;,
                prior=&#39;JZS&#39;, null=0, r=.5, method=&#39;theo&#39;,
                show_summ=FALSE, show_res=FALSE, show_plot=TRUE)</code></pre>
<div class="figure" style="text-align: center"><span id="fig:BF-NC-plot"></span>
<img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/BF-NC-plot-1.svg" alt="Estimates of effect under H2" width="384" />
<p class="caption">
Figure 26: Estimates of effect under H2
</p>
</div>
<p>Figure <a href="#fig:BF-NC-plot">26</a> shows the posterior density for
the difference in means, with the 95% credible interval indicated by the shaded area. Under <span class="math inline">\(H_2\)</span>, there is a 95% chance that the average birth weight of babies born to non-smokers is 0.023 to 0.57 pounds higher than that of babies born to smokers.</p>
<p>The previous statement assumes that <span class="math inline">\(H_2\)</span> is true and is a conditional probability statement. In mathematical terms, the statement is equivalent to</p>
<p><span class="math display">\[P(0.023 &lt; \alpha &lt; 0.57 \mid \text{data}, H_2) =  0.95\]</span></p>
<p>However, we still have quite a bit of uncertainty based on the current data, because given the data, the probability of <span class="math inline">\(H_2\)</span> being true is 0.59.</p>
<p><span class="math display">\[P(H_2 \mid \text{data}) = 0.59\]</span></p>
<p>Using the law of total probability, we can compute the probability that <span class="math inline">\(\mu\)</span> is between 0.023 and 0.57 as below:</p>
<p><span class="math display">\[\begin{aligned}
&amp; P(0.023 &lt; \alpha &lt; 0.57 \mid \text{data}) \\
= &amp; P(0.023 &lt; \alpha &lt; 0.57 \mid \text{data}, H_1)P(H_1 \mid \text{data})  + P(0.023 &lt; \alpha &lt; 0.57 \mid \text{data}, H_2)P(H_2 \mid \text{data}) \\
= &amp; I( 0 \text{ in CI }) P(H_1 \mid \text{data})  + 0.95 \times P(H_2 \mid \text{data}) \\
= &amp; 0 \times 0.41 + 0.95 \times 0.59 = 0.5605
\end{aligned}\]</span></p>
<p>Finally, we get that the probability that <span class="math inline">\(\alpha\)</span> is in the interval, given the data, averaging over both hypotheses, is roughly 0.56. The unconditional statement is the average birth weight of babies born to nonsmokers is 0.023 to 0.57 pounds higher than that of babies born to smokers with probability 0.56. This adjustment addresses the posterior uncertainty and how likely <span class="math inline">\(H_2\)</span> is.</p>
<p>To recap, we have illustrated testing, followed by reporting credible intervals, and using a Cauchy prior distribution that assumed smaller standardized effects. After testing, it is common to report credible intervals conditional on <span class="math inline">\(H_2\)</span>. We also have shown how to adjust the probability of the interval to reflect our posterior uncertainty about <span class="math inline">\(H_2\)</span>. In the next chapter, we will turn to regression models to incorporate continuous explanatory variables.</p>
</div>
</div>
<div id="introduction-to-bayesian-regression" class="section level1">
<h1>6 Introduction to Bayesian Regression</h1>
<p>In the previous chapter, we introduced Bayesian decision making using posterior probabilities and a variety of loss functions. We discussed how to minimize the expected loss for hypothesis testing. Moreover, we instroduced the concept of Bayes factors and gave some examples on how Bayes factors can be used in Bayesian hypothesis testing for comparison of two means. We also discussed how to choose appropriate and robust priors. When there is no conjugacy, we applied Markov Chain Monte Carlo simulation to approximate the posterior distributions of parameters of interest.</p>
<p>In this chapter, we will apply Bayesian inference methods to linear regression. We will first apply Bayesian statistics to simple linear regression models, then generalize the results to multiple linear regression models. We will see when using the reference prior, the posterior means, posterior standard deviations, and credible intervals of the coefficients coincide with the counterparts in the frequentist ordinary least square (OLS) linear regression models. However, using the Bayesian framework, we can now interpret credible intervals as the probabilities of the coefficients lying in such intervals.</p>
<div id="sec:simple-linear" class="section level2">
<h2>Bayesian Simple Linear Regression</h2>
<p>In this section, we will turn to Bayesian inference in simple linear regressions. We will use the reference prior distribution on coefficients, which will provide a connection between the frequentist solutions and Bayesian answers. This provides a baseline analysis for comparisons with more informative prior distributions. To illustrate the ideas, we will use an example of predicting body fat.</p>
<div id="frequentist-ordinary-least-square-ols-simple-linear-regression" class="section level3">
<h3>Frequentist Ordinary Least Square (OLS) Simple Linear Regression</h3>
<p>Obtaining accurate measurements of body fat is expensive and not easy to be done. Instead, predictive models that predict the percentage of body fat which use readily available measurements such as abdominal circumference are easy to use and inexpensive. We will apply a simple linear regression to predict body fat using abdominal circumference as an example to illustrate the Bayesian approach of linear regression. The data set <code>bodyfat</code> can be found from the library <code>BAS</code>.</p>
<p>To start, we load the <code>BAS</code> library (which can be downloaded from CRAN) to access the dataframe. We print out a summary of the variables in this dataframe.</p>
<pre class="r"><code>library(BAS)
data(bodyfat)
summary(bodyfat)</code></pre>
<pre><code>##     Density         Bodyfat           Age            Weight     
##  Min.   :0.995   Min.   : 0.00   Min.   :22.00   Min.   :118.5  
##  1st Qu.:1.041   1st Qu.:12.47   1st Qu.:35.75   1st Qu.:159.0  
##  Median :1.055   Median :19.20   Median :43.00   Median :176.5  
##  Mean   :1.056   Mean   :19.15   Mean   :44.88   Mean   :178.9  
##  3rd Qu.:1.070   3rd Qu.:25.30   3rd Qu.:54.00   3rd Qu.:197.0  
##  Max.   :1.109   Max.   :47.50   Max.   :81.00   Max.   :363.1  
##      Height           Neck           Chest           Abdomen      
##  Min.   :29.50   Min.   :31.10   Min.   : 79.30   Min.   : 69.40  
##  1st Qu.:68.25   1st Qu.:36.40   1st Qu.: 94.35   1st Qu.: 84.58  
##  Median :70.00   Median :38.00   Median : 99.65   Median : 90.95  
##  Mean   :70.15   Mean   :37.99   Mean   :100.82   Mean   : 92.56  
##  3rd Qu.:72.25   3rd Qu.:39.42   3rd Qu.:105.38   3rd Qu.: 99.33  
##  Max.   :77.75   Max.   :51.20   Max.   :136.20   Max.   :148.10  
##       Hip            Thigh            Knee           Ankle          Biceps     
##  Min.   : 85.0   Min.   :47.20   Min.   :33.00   Min.   :19.1   Min.   :24.80  
##  1st Qu.: 95.5   1st Qu.:56.00   1st Qu.:36.98   1st Qu.:22.0   1st Qu.:30.20  
##  Median : 99.3   Median :59.00   Median :38.50   Median :22.8   Median :32.05  
##  Mean   : 99.9   Mean   :59.41   Mean   :38.59   Mean   :23.1   Mean   :32.27  
##  3rd Qu.:103.5   3rd Qu.:62.35   3rd Qu.:39.92   3rd Qu.:24.0   3rd Qu.:34.33  
##  Max.   :147.7   Max.   :87.30   Max.   :49.10   Max.   :33.9   Max.   :45.00  
##     Forearm          Wrist      
##  Min.   :21.00   Min.   :15.80  
##  1st Qu.:27.30   1st Qu.:17.60  
##  Median :28.70   Median :18.30  
##  Mean   :28.66   Mean   :18.23  
##  3rd Qu.:30.00   3rd Qu.:18.80  
##  Max.   :34.90   Max.   :21.40</code></pre>
<p></br></p>
<p>This data frame includes 252 observations of men’s body fat and other measurements, such as waist circumference (<code>Abdomen</code>). We will construct a Bayesian model of simple linear regression, which uses <code>Abdomen</code> to predict the response variable <code>Bodyfat</code>. Let <span class="math inline">\(y_i,\ i=1,\cdots, 252\)</span> denote the measurements of the response variable <code>Bodyfat</code>, and let <span class="math inline">\(x_i\)</span> be the waist circumference measurements <code>Abdomen</code>. We regress <code>Bodyfat</code> on the predictor <code>Abdomen</code>. This regression model can be formulated as
<span class="math display">\[ y_i = \alpha + \beta x_i + \epsilon_i, \quad i = 1,\cdots, 252.\]</span>
Here, we assume error <span class="math inline">\(\epsilon_i\)</span> is independent and identically distributed as normal random variables with mean zero and constant variance <span class="math inline">\(\sigma^2\)</span>:
<span class="math display">\[ \epsilon_i \overset{\text{iid}}{\sim} \text{N}(0, \sigma^2). \]</span></p>
<p>The figure below shows the percentage body fat obtained from under water weighing and the abdominal circumference measurements for 252 men. To predict body fat, the line overlayed on the scatter plot illustrates the best fitting ordinary least squares (OLS) line obtained with the <code>lm</code> function in R.</p>
<pre class="r"><code># Frequentist OLS linear regression
bodyfat.lm = lm(Bodyfat ~ Abdomen, data = bodyfat)
summary(bodyfat.lm)</code></pre>
<pre><code>## 
## Call:
## lm(formula = Bodyfat ~ Abdomen, data = bodyfat)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -19.0160  -3.7557   0.0554   3.4215  12.9007 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -39.28018    2.66034  -14.77   &lt;2e-16 ***
## Abdomen       0.63130    0.02855   22.11   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 4.877 on 250 degrees of freedom
## Multiple R-squared:  0.6617, Adjusted R-squared:  0.6603 
## F-statistic: 488.9 on 1 and 250 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code># Extract coefficients
beta = coef(bodyfat.lm)

# Visualize regression line on the scatter plot
library(ggplot2)
ggplot(data = bodyfat, aes(x = Abdomen, y = Bodyfat)) +
  geom_point(color = &quot;blue&quot;) +
  geom_abline(intercept = beta[1], slope = beta[2], size = 1) +
  xlab(&quot;abdomen circumference (cm)&quot;) </code></pre>
<p><img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/unnamed-chunk-17-1.svg" width="70%" style="display: block; margin: auto;" /></p>
<p>From the summary, we see that this model has an estimated slope, <span class="math inline">\(\hat{\beta}\)</span>, of 0.63 and an estimated <span class="math inline">\(y\)</span>-intercept, <span class="math inline">\(\hat{\alpha}\)</span>, of about -39.28%. This gives us the prediction formula
<span class="math display">\[ \widehat{\text{Bodyfat}} = -39.28 + 0.63\times\text{Abdomen}. \]</span>
For every additional centimeter, we expect body fat to increase by 0.63%. The negative <span class="math inline">\(y\)</span>-intercept of course does not make sense as a physical model, but neither does predicting a male with a waist of zero centimeters. Nevertheless, this linear regression may be an accurate approximation for prediction purposes for measurements that are in the observed range for this population.</p>
<p>Each of the residuals, which provide an estimate of the fitting error, is equal to <span class="math inline">\(\hat{\epsilon}_i = y_i - \hat{y}_i\)</span>, the difference between the observed value <span class="math inline">\(y_i\)</span> and the fitted value <span class="math inline">\(\hat{y}_i = \hat{\alpha} + \hat{\beta}x_i\)</span>, where <span class="math inline">\(x_i\)</span> is the abdominal circumference for the <span class="math inline">\(i\)</span>th male. <span class="math inline">\(\hat{\epsilon}_i\)</span> is used for diagnostics as well as estimating the constant variance in the assumption of the model <span class="math inline">\(\sigma^2\)</span> via the mean squared error (MSE):
<span class="math display">\[ \hat{\sigma}^2 = \frac{1}{n-2}\sum_i^n (y_i-\hat{y}_i)^2 = \frac{1}{n-2}\sum_i^n \hat{\epsilon}_i^2. \]</span>
Here the degrees of freedom <span class="math inline">\(n-2\)</span> are the number of observations adjusted for the number of parameters (which is 2) that we estimated in the regression. The MSE, <span class="math inline">\(\hat{\sigma}^2\)</span>, may be calculated through squaring the residuals of the output of <code>bodyfat.lm</code>.</p>
<pre class="r"><code># Obtain residuals and n
resid = residuals(bodyfat.lm)
n = length(resid)

# Calculate MSE
MSE = 1/ (n - 2) * sum((resid ^ 2))
MSE</code></pre>
<pre><code>## [1] 23.78985</code></pre>
<p>If this model is correct, the residuals and fitted values should be uncorrelated, and the expected value of the residuals is zero. We apply the scatterplot of residuals versus fitted values, which provides an additional visual check of the model adequacy.</p>
<pre class="r"><code># Combine residuals and fitted values into a data frame
result = data.frame(fitted_values = fitted.values(bodyfat.lm),
                    residuals = residuals(bodyfat.lm))

# Load library and plot residuals versus fitted values
library(ggplot2)
ggplot(data = result, aes(x = fitted_values, y = residuals)) +
  geom_point(pch = 1, size = 2) + 
  geom_abline(intercept = 0, slope = 0) + 
  xlab(expression(paste(&quot;fitted value &quot;, widehat(Bodyfat)))) + 
  ylab(&quot;residuals&quot;)</code></pre>
<p><img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/unnamed-chunk-18-1.svg" width="70%" style="display: block; margin: auto;" /></p>
<pre class="r"><code># Readers may also use `plot` function</code></pre>
<p>With the exception of one observation for the individual with the largest fitted value, the residual plot suggests that this linear regression is a reasonable approximation. The case number of the observation with the largest fitted value can be obtained using the <code>which</code> function in R. Further examination of the data frame shows that this case also has the largest waist measurement <code>Abdomen</code>. This may be our potential outlier and we will have more discussion on outliers in Section <a href="#sec:Checking-outliers"><strong>??</strong></a>.</p>
<pre class="r"><code># Find the observation with the largest fitted value
which.max(as.vector(fitted.values(bodyfat.lm)))</code></pre>
<pre><code>## [1] 39</code></pre>
<pre class="r"><code># Shows this observation has the largest Abdomen
which.max(bodyfat$Abdomen)</code></pre>
<pre><code>## [1] 39</code></pre>
<p>Furthermore, we can check the normal probability plot of the residuals for the assumption of normally distributed errors. We see that only Case 39, the one with the largest waist measurement, is exceptionally away from the normal quantile.</p>
<pre class="r"><code>plot(bodyfat.lm, which = 2)</code></pre>
<p><img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/unnamed-chunk-19-1.svg" width="70%" style="display: block; margin: auto;" /></p>
<p>The confidence interval of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> can be constructed using the standard errors <span class="math inline">\(\text{se}_{\alpha}\)</span> and <span class="math inline">\(\text{se}_{\beta}\)</span> respectively. To proceed, we introduce notations of some “sums of squares”
<span class="math display">\[
\begin{aligned}
\text{S}_{xx} = &amp; \sum_i^n (x_i-\bar{x})^2\\
\text{S}_{yy} = &amp; \sum_i^n (y_i-\bar{y})^2 \\
\text{S}_{xy} = &amp; \sum_i^n (x_i-\bar{x})(y_i-\bar{y}) \\
\text{SSE}    = &amp; \sum_i^n (y_i-\hat{y}_i)^2 = \sum_i^n \hat{\epsilon}_i^2. 
\end{aligned}
\]</span></p>
<p>The estimates of the <span class="math inline">\(y\)</span>-intercept <span class="math inline">\(\alpha\)</span>, and the slope <span class="math inline">\(\beta\)</span>, which are denoted as <span class="math inline">\(\hat{\alpha}\)</span> and <span class="math inline">\(\hat{\beta}\)</span> respectively, can be calculated using these “sums of squares”
<span class="math display">\[ \hat{\beta} = \frac{\sum_i (x_i-\bar{x})(y_i-\bar{y})}{\sum_i (x_i-\bar{x})^2} = \frac{\text{S}_{xy}}{\text{S}_{xx}},\qquad \qquad \hat{\alpha} = \bar{y} - \hat{\beta}\bar{x} = \bar{y}-\frac{\text{S}_{xy}}{\text{S}_{xx}}\bar{x}. \]</span></p>
<p>The last “sum of square” is the <em>sum of squares of errors</em> (SSE). Its sample mean is exactly the mean squared error (MSE) we introduced previously
<span class="math display">\[
\hat{\sigma}^2 = \frac{\text{SSE}}{n-2} = \text{MSE}.
\]</span></p>
<p>The standard errors, <span class="math inline">\(\text{se}_{\alpha}\)</span> and <span class="math inline">\(\text{se}_{\beta}\)</span>, are given as
<span class="math display">\[ 
\begin{aligned}
\text{se}_{\alpha} = &amp;  \sqrt{\frac{\text{SSE}}{n-2}\left(\frac{1}{n}+\frac{\bar{x}^2}{\text{S}_{xx}}\right)} = \hat{\sigma}\sqrt{\frac{1}{n}+\frac{\bar{x}^2}{\text{S}_{xx}}},\\
\text{se}_{\beta} = &amp; \sqrt{\frac{\text{SSE}}{n-2}\frac{1}{\text{S}_{xx}}} = \frac{\hat{\sigma}}{\sqrt{\text{S}_{xx}}}.
\end{aligned}
\]</span></p>
<p>We may construct the confidence intervals of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> using the <span class="math inline">\(t\)</span>-statistics
<span class="math display">\[ 
t_\alpha^\ast = \frac{\alpha - \hat{\alpha}}{\text{se}_{\alpha}},\qquad \qquad t_\beta^\ast = \frac{\beta-\hat{\beta}}{\text{se}_{\beta}}.
\]</span></p>
<p>They both have degrees of freedom <span class="math inline">\(n-2\)</span>.</p>
</div>
<div id="bayesian-simple-linear-regression-using-the-reference-prior" class="section level3">
<h3>Bayesian Simple Linear Regression Using the Reference Prior</h3>
<p>Let us now turn to the Bayesian version and show that under the reference prior, we will obtain the posterior distributions of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> analogous with the frequentist OLS results.</p>
<p>The Bayesian model starts with the same model as the classical frequentist approach:
<span class="math display">\[ y_i = \alpha + \beta x_i + \epsilon_i,\quad i = 1,\cdots, n. \]</span>
with the assumption that the errors, <span class="math inline">\(\epsilon_i\)</span>, are independent and identically distributed as normal random variables with mean zero and constant variance <span class="math inline">\(\sigma^2\)</span>. This assumption is exactly the same as in the classical inference case for testing and constructing confidence intervals for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>.</p>
<p>Our goal is to update the distributions of the unknown parameters <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>, and <span class="math inline">\(\sigma^2\)</span>, based on the data <span class="math inline">\(x_1, y_1, \cdots, x_n, y_n\)</span>, where <span class="math inline">\(n\)</span> is the number of observations.</p>
<p>Under the assumption that the errors <span class="math inline">\(\epsilon_i\)</span> are normally distributed with constant variance <span class="math inline">\(\sigma^2\)</span>, we have for the random variable of each response <span class="math inline">\(Y_i\)</span>, conditioning on the observed data <span class="math inline">\(x_i\)</span> and the parameters <span class="math inline">\(\alpha,\ \beta,\ \sigma^2\)</span>, is normally distributed:
<span class="math display">\[ Y_i~|~x_i, \alpha, \beta,\sigma^2~ \sim~ \text{N}(\alpha + \beta x_i, \sigma^2),\qquad i = 1,\cdots, n. \]</span></p>
<p>That is, the likelihood of each <span class="math inline">\(Y_i\)</span> given <span class="math inline">\(x_i, \alpha, \beta\)</span>, and <span class="math inline">\(\sigma^2\)</span> is given by
<span class="math display">\[ p(y_i~|~x_i, \alpha, \beta, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{(y_i-(\alpha+\beta  x_i))^2}{2\sigma^2}\right). \]</span></p>
<p>The likelihood of <span class="math inline">\(Y_1,\cdots,Y_n\)</span> is the product of each likelihood <span class="math inline">\(p(y_i~|~x_i, \alpha, \beta,\sigma^2)\)</span>, since we assume each response <span class="math inline">\(Y_i\)</span> is independent from each other. Since this likelihood depends on the values of <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>, and <span class="math inline">\(\sigma^2\)</span>, it is sometimes denoted as a function of <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>, and <span class="math inline">\(\sigma^2\)</span>: <span class="math inline">\(\mathcal{L}(\alpha, \beta, \sigma^2)\)</span>.</p>
<p>We first consider the case under the reference prior, which is our standard noninformative prior. Using the reference prior, we will obtain familiar distributions as the posterior distributions of <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>, and <span class="math inline">\(\sigma^2\)</span>, which gives the analogue to the frequentist results. Here we assume the joint prior distribution of <span class="math inline">\(\alpha,\ \beta\)</span>, and <span class="math inline">\(\sigma^2\)</span> to be proportional to the inverse of <span class="math inline">\(\sigma^2\)</span></p>
<p><span class="math display" id="eq:joint-prior">\[\begin{equation} 
p(\alpha, \beta, \sigma^2)\propto \frac{1}{\sigma^2}.
\tag{14}
\end{equation}\]</span></p>
<p>Using the hierachical model framework, this is equivalent to assuming that the joint prior distribution of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> under <span class="math inline">\(\sigma^2\)</span> is the uniform prior, while the prior distribution of <span class="math inline">\(\sigma^2\)</span> is proportional to <span class="math inline">\(\displaystyle \frac{1}{\sigma^2}\)</span>. That is
<span class="math display">\[ p(\alpha, \beta~|~\sigma^2) \propto 1, \qquad\qquad p(\sigma^2) \propto \frac{1}{\sigma^2}, \]</span>
Combining the two using conditional probability, we will get the same joint prior distribution <a href="#eq:joint-prior">(14)</a>.</p>
<p>Then we apply the Bayes’ rule to derive the joint posterior distribution after observing data <span class="math inline">\(y_1,\cdots, y_n\)</span>. Bayes’ rule states that the joint posterior distribution of <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>, and <span class="math inline">\(\sigma^2\)</span> is proportional to the product of the likelihood and the joint prior distribution:
<span class="math display">\[
\begin{aligned}
p^*(\alpha, \beta, \sigma^2~|~y_1,\cdots,y_n) \propto &amp; \left[\prod_i^n p(y_i~|~x_i,\alpha,\beta,\sigma^2)\right]p(\alpha, \beta,\sigma^2) \\
\propto &amp; \left[\left(\frac{1}{(\sigma^2)^{1/2}}\exp\left(-\frac{(y_1-(\alpha+\beta x_1 ))^2}{2\sigma^2}\right)\right)\times\cdots \right.\\
&amp; \left. \times \left(\frac{1}{(\sigma^2)^{1/2}}\exp\left(-\frac{(y_n-(\alpha +\beta x_n))^2}{2\sigma^2}\right)\right)\right]\times\left(\frac{1}{\sigma^2}\right)\\
\propto &amp; \frac{1}{(\sigma^2)^{(n+2)/2}}\exp\left(-\frac{\sum_i\left(y_i-\alpha-\beta  x_i\right)^2}{2\sigma^2}\right)
\end{aligned}
\]</span></p>
<p>To obtain the marginal posterior distribution of <span class="math inline">\(\beta\)</span>, we need to integrate <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\sigma^2\)</span> out from the joint posterior distribution
<span class="math display">\[ p^*(\beta~|~y_1,\cdots,y_n) = \int_0^\infty \left(\int_{-\infty}^\infty p^*(\alpha, \beta, \sigma^2~|~y_1,\cdots, y_n)\, d\alpha\right)\, d\sigma^2. \]</span></p>
<p>We leave the detailed calculation in Section <a href="#sec:derivations"><strong>??</strong></a>. It can be shown that the marginal posterior distribution of <span class="math inline">\(\beta\)</span> is the Student’s <span class="math inline">\(t\)</span>-distribution
<span class="math display">\[ \beta~|~y_1,\cdots,y_n ~\sim~ \text{St}\left(n-2,\ \hat{\beta},\ \frac{\hat{\sigma}^2}{\text{S}_{xx}}\right) = \text{St}\left(n-2,\  \hat{\beta},\ (\text{se}_{\beta})^2\right), \]</span>
with degrees of freedom <span class="math inline">\(n-2\)</span>, center at <span class="math inline">\(\hat{\beta}\)</span>, the slope estimate we obtained from the frequentist OLS model, and scale parameter <span class="math inline">\(\displaystyle \frac{\hat{\sigma}^2}{\text{S}_{xx}}=\left(\text{se}_{\beta}\right)^2\)</span>, which is the square of the standard error of <span class="math inline">\(\hat{\beta}\)</span> under the frequentist OLS model.</p>
<p>Similarly, we can integrate out <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\sigma^2\)</span> from the joint posterior distribution to get the marginal posterior distribution of <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(p^*(\alpha~|~y_1,\cdots, y_n)\)</span>. It turns out that <span class="math inline">\(p^*(\alpha~|~y_1,\cdots,y_n)\)</span> is again a Student’s <span class="math inline">\(t\)</span>-distribution with degrees of freedom <span class="math inline">\(n-2\)</span>, center at <span class="math inline">\(\hat{\alpha}\)</span>, the <span class="math inline">\(y\)</span>-intercept estimate from the frequentist OLS model, and scale parameter <span class="math inline">\(\displaystyle \hat{\sigma}^2\left(\frac{1}{n}+\frac{\bar{x}^2}{\text{S}_{xx}}\right) = \left(\text{se}_{\alpha}\right)^2\)</span>, which is the square of the standard error of <span class="math inline">\(\hat{\alpha}\)</span> under the frequentist OLS model
<span class="math display">\[ \alpha~|~y_1,\cdots,y_n~\sim~  \text{St}\left(n-2,\ \hat{\alpha},\ \hat{\sigma}^2\left(\frac{1}{n}+\frac{\bar{x}^2}{\text{S}_{xx}}\right)\right) = \text{St}\left(n-2,\ \hat{\alpha},\ (\text{se}_{\alpha})^2\right).\]</span></p>
<p>Finally, we can show that the marginal posterior distribution of <span class="math inline">\(\sigma^2\)</span> is the inverse Gamma distribution, or equivalently, the reciprocal of <span class="math inline">\(\sigma^2\)</span>, which is the precision <span class="math inline">\(\phi\)</span>, follows the Gamma distribution
<span class="math display">\[ \phi = \frac{1}{\sigma^2}~|~y_1,\cdots,y_n \sim \text{Ga}\left(\frac{n-2}{2}, \frac{\text{SSE}}{2}\right). \]</span></p>
<p>Moreover, similar to the Normal-Gamma conjugacy under the reference prior introduced in the previous chapters, the joint posterior distribution of <span class="math inline">\(\beta, \sigma^2\)</span>, and the joint posterior distribution of <span class="math inline">\(\alpha, \sigma^2\)</span> are both Normal-Gamma. In particular, the posterior distribution of <span class="math inline">\(\beta\)</span> conditioning on <span class="math inline">\(\sigma^2\)</span> is
<span class="math display">\[ \beta~|~\sigma^2, \text{data}~\sim ~\text{N}\left(\hat{\beta}, \frac{\sigma^2}{\text{S}_{xx}}\right), \]</span></p>
<p>and the posterior distribution of <span class="math inline">\(\alpha\)</span> conditioning on <span class="math inline">\(\sigma^2\)</span> is
<span class="math display">\[ \alpha~|~\sigma^2, \text{data}~\sim ~\text{N}\left(\hat{\alpha}, \sigma^2\left(\frac{1}{n}+\frac{\bar{x}^2}{\text{S}_{xx}}\right)\right).\]</span></p>
<p><strong>Credible Intervals for Slope <span class="math inline">\(\beta\)</span> and <span class="math inline">\(y\)</span>-Intercept <span class="math inline">\(\alpha\)</span> </strong></p>
<p>The Bayesian posterior distribution results of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> show that under the reference prior, the posterior credible intervals are in fact <strong>numerically equivalent</strong> to the confidence intervals from the classical frequentist OLS analysis. This provides a baseline analysis for other Bayesian analyses with other informative prior distributions or perhaps other “objective” prior distributions, such as the Cauchy distribution. (Cauchy distribution is the Student’s <span class="math inline">\(t\)</span> prior with 1 degree of freedom.)</p>
<p>Since the credible intervals are numerically the same as the confidence intervals, we can use the <code>lm</code> function to obtain the OLS estimates and construct the credible intervals of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span></p>
<pre class="r"><code>output = summary(bodyfat.lm)$coef[, 1:2]
output</code></pre>
<pre><code>##                Estimate Std. Error
## (Intercept) -39.2801847 2.66033696
## Abdomen       0.6313044 0.02855067</code></pre>
<p>The columns labeled <code>Estimate</code> and <code>Std. Error</code> are equivalent to the centers (or posterior means) and scale parameters (or standard deviations) in the two Student’s <span class="math inline">\(t\)</span>-distributions respectively. The credible intervals of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> are the same as the frequentist confidence intervals, but now we can interpret them from the Bayesian perspective.</p>
<p>The <code>confint</code> function provides 95% confidence intervals. Under the reference prior, they are equivalent to the 95% credible intervals. The code below extracts them and relabels the output as the Bayesian results.</p>
<pre class="r"><code>out = cbind(output, confint(bodyfat.lm))
colnames(out) = c(&quot;posterior mean&quot;, &quot;posterior std&quot;, &quot;2.5&quot;, &quot;97.5&quot;)
round(out, 2)</code></pre>
<pre><code>##             posterior mean posterior std    2.5   97.5
## (Intercept)         -39.28          2.66 -44.52 -34.04
## Abdomen               0.63          0.03   0.58   0.69</code></pre>
<p>These intervals coincide with the confidence intervals from the frequentist approach. The primary difference is the interpretation. For example, based on the data, we believe that there is a 95% chance that body fat will increase by 5.75% up to 6.88% for every additional 10 centimeter increase in the waist circumference.</p>
<p><strong>Credible Intervals for the Mean <span class="math inline">\(\mu_Y\)</span> and the Prediction <span class="math inline">\(y_{n+1}\)</span></strong></p>
<p>From our assumption of the model
<span class="math display">\[ y_i = \alpha + \beta x_i + \epsilon_i, \]</span>
the mean of the response variable <span class="math inline">\(Y\)</span>, <span class="math inline">\(\mu_Y\)</span>, at the point <span class="math inline">\(x_i\)</span> is
<span class="math display">\[ \mu_Y~|~x_i = E[Y~|~x_i] = \alpha + \beta x_i. \]</span></p>
<p>Under the reference prior, <span class="math inline">\(\mu_Y\)</span> has a posterior distributuion
<span class="math display">\[ 
\alpha + \beta x_i ~|~ \text{data} \sim \text{St}(n-2,\ \hat{\alpha} + \hat{\beta} x_i,\ \text{S}_{Y|X_i}^2), 
\]</span>
where
<span class="math display">\[
\text{S}_{Y|X_i}^2 = \hat{\sigma}^2\left(\frac{1}{n}+\frac{(x_i-\bar{x})^2}{\text{S}_{xx}}\right)
\]</span></p>
<p>Any new prediction <span class="math inline">\(y_{n+1}\)</span> at a point <span class="math inline">\(x_{n+1}\)</span> also follows the Student’s <span class="math inline">\(t\)</span>-distribution
<span class="math display">\[ 
y_{n+1}~|~\text{data}, x_{n+1}\ \sim \text{St}\left(n-2,\  \hat{\alpha}+\hat{\beta} x_{n+1},\ \text{S}_{Y|X_{n+1}}^2\right), 
\]</span></p>
<p>where
<span class="math display">\[ 
\text{S}_{Y|X_{n+1}}^2 =\hat{\sigma}^2+\hat{\sigma}^2\left(\frac{1}{n}+\frac{(x_{n+1}-\bar{x})^2}{\text{S}_{xx}}\right) = \hat{\sigma}^2\left(1+\frac{1}{n}+\frac{(x_{n+1}-\bar{x})^2}{\text{S}_{xx}}\right).
\]</span></p>
<p>The variance for predicting a new observation <span class="math inline">\(y_{n+1}\)</span> has an extra <span class="math inline">\(\hat{\sigma}^2\)</span> which comes from the uncertainty of a new observation about the mean <span class="math inline">\(\mu_Y\)</span> estimated by the regression line.</p>
<p>We can extract these intervals using the <code>predict</code> function</p>
<pre class="r"><code>library(ggplot2)
# Construct current prediction
alpha = bodyfat.lm$coefficients[1]
beta = bodyfat.lm$coefficients[2]
new_x = seq(min(bodyfat$Abdomen), max(bodyfat$Abdomen), 
            length.out = 100)
y_hat = alpha + beta * new_x

# Get lower and upper bounds for mean
ymean = data.frame(predict(bodyfat.lm,
                            newdata = data.frame(Abdomen = new_x),
                            interval = &quot;confidence&quot;,
                            level = 0.95))

# Get lower and upper bounds for prediction
ypred = data.frame(predict(bodyfat.lm,
                          newdata = data.frame(Abdomen = new_x),
                          interval = &quot;prediction&quot;,
                          level = 0.95))

output = data.frame(x = new_x, y_hat = y_hat, ymean_lwr = ymean$lwr, ymean_upr = ymean$upr, 
                    ypred_lwr = ypred$lwr, ypred_upr = ypred$upr)

# Extract potential outlier data point
outlier = data.frame(x = bodyfat$Abdomen[39], y = bodyfat$Bodyfat[39])

# Scatter plot of original
plot1 = ggplot(data = bodyfat, aes(x = Abdomen, y = Bodyfat)) + geom_point(color = &quot;blue&quot;)

# Add bounds of mean and prediction
plot2 = plot1 + 
  geom_line(data = output, aes(x = new_x, y = y_hat, color = &quot;first&quot;), lty = 1) +
  geom_line(data = output, aes(x = new_x, y = ymean_lwr, lty = &quot;second&quot;)) +
  geom_line(data = output, aes(x = new_x, y = ymean_upr, lty = &quot;second&quot;)) +
  geom_line(data = output, aes(x = new_x, y = ypred_upr, lty = &quot;third&quot;)) +
  geom_line(data = output, aes(x = new_x, y = ypred_lwr, lty = &quot;third&quot;)) + 
  scale_colour_manual(values = c(&quot;orange&quot;), labels = &quot;Posterior mean&quot;, name = &quot;&quot;) + 
  scale_linetype_manual(values = c(2, 3), labels = c(&quot;95% CI for mean&quot;, &quot;95% CI for predictions&quot;)
                        , name = &quot;&quot;) + 
  theme_bw() + 
  theme(legend.position = c(1, 0), legend.justification = c(1.5, 0))

# Identify potential outlier
plot2 + geom_point(data = outlier, aes(x = x, y = y), color = &quot;orange&quot;, pch = 1, cex = 6)</code></pre>
<p><img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/predict-intervals-1.svg" width="80%" style="display: block; margin: auto;" /></p>
<p>Note in the above plot, the legend “CI” can mean either confidence interval or credible interval. The difference comes down to the interpretation. For example, the prediction at the same abdominal circumference as in Case 39 is</p>
<pre class="r"><code>pred.39 = predict(bodyfat.lm, newdata = bodyfat[39, ], interval = &quot;prediction&quot;, level = 0.95)
out = cbind(bodyfat[39,]$Abdomen, pred.39)
colnames(out) = c(&quot;abdomen&quot;, &quot;prediction&quot;, &quot;lower&quot;, &quot;upper&quot;)
out</code></pre>
<pre><code>##    abdomen prediction   lower    upper
## 39   148.1   54.21599 44.0967 64.33528</code></pre>
<p>Based on the data, a Bayesian would expect that a man with waist circumference of 148.1 centimeters should have bodyfat of 54.216% with a 95% chance that it is between 44.097% and 64.335%.</p>
<p>While we expect the majority of the data will be within the prediction intervals (the short dashed grey lines), Case 39 seems to be well below the interval. We next use Bayesian methods in Section <a href="#sec:Checking-outliers"><strong>??</strong></a> to calculate the probability that this case is abnormal or is an outlier by falling more than <span class="math inline">\(k\)</span> standard deviations from either side of the mean.</p>
</div>
<div id="sec:informative-prior" class="section level3">
<h3>Informative Priors</h3>
<p>Except from the noninformative reference prior, we may also consider using a more general semi-conjugate prior distribution of <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>, and <span class="math inline">\(\sigma^2\)</span> when there is information available about the parameters.</p>
<p>Since the data <span class="math inline">\(y_1,\cdots,y_n\)</span> are normally distributed, from Chapter 3 we see that a Normal-Gamma distribution will form a conjugacy in this situation. We then set up prior distributions through a hierarchical model. We first assume that, given <span class="math inline">\(\sigma^2\)</span>, <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> together follow the bivariate normal prior distribution, from which their marginal distributions are both normal,
<span class="math display">\[ 
\begin{aligned}
\alpha~|~\sigma^2 \sim &amp; \text{N}(a_0, \sigma^2\text{S}_\alpha) \\
\beta ~|~ \sigma^2 \sim &amp; \text{N}(b_0, \sigma^2\text{S}_\beta),
\end{aligned}
\]</span>
with covariance
<span class="math display">\[ \text{Cov}(\alpha, \beta ~|~\sigma^2) =\sigma^2 \text{S}_{\alpha\beta}. \]</span></p>
<p>Here, <span class="math inline">\(\sigma^2\)</span>, <span class="math inline">\(S_\alpha\)</span>, <span class="math inline">\(S_\beta\)</span>, and <span class="math inline">\(S_{\alpha\beta}\)</span> are hyperparameters. This is equivalent to setting the coefficient vector <span class="math inline">\(\bv = (\alpha, \beta)^T\)</span><a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> to have a bivariate normal distribution with covariance matrix <span class="math inline">\(\Sigma_0\)</span>
<span class="math display">\[ \Sigma_0 = \sigma^2\left(\begin{array}{cc} S_\alpha &amp; S_{\alpha\beta} \\
S_{\alpha\beta} &amp; S_\beta \end{array} \right). \]</span>
That is,
<span class="math display">\[ \bv = (\alpha, \beta)^T ~|~\sigma^2 \sim \textsf{BivariateNormal}(\mathbf{b} = (a_0, b_0)^T, \sigma^2\Sigma_0). \]</span></p>
<p>Then for <span class="math inline">\(\sigma^2\)</span>, we will impose an inverse Gamma distribution as its prior distribution
<span class="math display">\[ 1/\sigma^2 \sim \text{Ga}\left(\frac{\nu_0}{2}, \frac{\nu_0\sigma_0}{2}\right). \]</span></p>
<p>Now the joint prior distribution of <span class="math inline">\(\alpha, \beta\)</span>, and <span class="math inline">\(\sigma^2\)</span> form a distribution that is analogous to the Normal-Gamma distribution. Prior information about <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>, and <span class="math inline">\(\sigma^2\)</span> are encoded in the hyperparameters <span class="math inline">\(a_0\)</span>, <span class="math inline">\(b_0\)</span>, <span class="math inline">\(\text{S}_\alpha\)</span>, <span class="math inline">\(\text{S}_\beta\)</span>, <span class="math inline">\(\text{S}_{\alpha\beta}\)</span>, <span class="math inline">\(\nu_0\)</span>, and <span class="math inline">\(\sigma_0\)</span>.</p>
<p>The marginal posterior distribution of the coefficient vector <span class="math inline">\(\bv = (\alpha, \beta)\)</span> will be bivariate normal, and the marginal posterior distribution of <span class="math inline">\(\sigma^2\)</span> is again an inverse Gamma distribution
<span class="math display">\[ 1/\sigma^2~|~y_1,\cdots,y_n \sim \text{Ga}\left(\frac{\nu_0+n}{2}, \frac{\nu_0\sigma_0^2+\text{SSE}}{2}\right). \]</span></p>
<p>One can see that the reference prior is the limiting case of this conjugate prior we impose. We usually use Gibbs sampling to approximate the joint posterior distribution instead of using the result directly, especially when we have more regression coefficients in multiple linear regression models. We omit the deviations of the posterior distributions due to the heavy use of advanced linear algebra. One can refer to <span class="citation">@hoff2009first</span> for more details.</p>
<p>Based on any prior information we have for the model, we can also impose other priors and assumptions on <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>, and <span class="math inline">\(\sigma^2\)</span> to get different Bayesian results. Most of these priors will not form any conjugacy and will require us to use simulation methods such as Markov Chain Monte Carlo (MCMC) for approximations. We will introduce the general idea of MCMC in Chapter 8.</p>
</div>
<div id="sec:derivations" class="section level3">
<h3>(Optional) Derivations of Marginal Posterior Distributions of <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>, <span class="math inline">\(\sigma^2\)</span></h3>
<p>In this section, we will use the notations we introduced earlier such as <span class="math inline">\(\text{SSE}\)</span>, the sum of squares of errors, <span class="math inline">\(\hat{\sigma}^2\)</span>, the mean squared error, <span class="math inline">\(\text{S}_{xx}\)</span>, <span class="math inline">\(\text{se}_{\alpha}\)</span>, <span class="math inline">\(\text{se}_{\beta}\)</span> and so on to simplify our calculations.</p>
<p>We will also use the following quantities derived from the formula of <span class="math inline">\(\bar{x}\)</span>, <span class="math inline">\(\bar{y}\)</span>, <span class="math inline">\(\hat{\alpha}\)</span>, and <span class="math inline">\(\hat{\beta}\)</span>
<span class="math display">\[
\begin{aligned}
&amp; \sum_i^n (x_i-\bar{x}) = 0 \\
&amp; \sum_i^n (y_i-\bar{y}) = 0 \\
&amp; \sum_i^n (y_i - \hat{y}_i) = \sum_i^n (y_i - (\hat{\alpha} + \hat{\beta} x_i)) = 0\\
&amp; \sum_i^n (x_i-\bar{x})(y_i - \hat{y}_i) = \sum_i^n (x_i-\bar{x})(y_i-\bar{y}-\hat{\beta}(x_i-\bar{x})) = \sum_i^n (x_i-\bar{x})(y_i-\bar{y})-\hat{\beta}\sum_i^n(x_i-\bar{x})^2 = 0\\
&amp; \sum_i^n x_i^2 = \sum_i^n (x_i-\bar{x})^2 + n\bar{x}^2 = \text{S}_{xx}+n\bar{x}^2
\end{aligned}
\]</span></p>
<p>We first further simplify the numerator inside the exponential function in the formula of <span class="math inline">\(p^*(\alpha, \beta, \sigma^2~|~y_1,\cdots,y_n)\)</span>:
<span class="math display">\[ 
\begin{aligned}
 &amp; \sum_i^n \left(y_i - \alpha - \beta x_i\right)^2 \\
 = &amp; \sum_i^n \left(y_i - \hat{\alpha} - \hat{\beta}x_i - (\alpha - \hat{\alpha}) - (\beta - \hat{\beta})x_i\right)^2 \\
= &amp; \sum_i^n \left(y_i - \hat{\alpha} - \hat{\beta}x_i\right)^2 + \sum_i^n (\alpha - \hat{\alpha})^2 + \sum_i^n (\beta-\hat{\beta})^2(x_i)^2 \\
  &amp; - 2\sum_i^n (\alpha - \hat{\alpha})(y_i-\hat{\alpha}-\hat{\beta}x_i) - 2\sum_i^n (\beta-\hat{\beta})(x_i)(y_i-\hat{\alpha}-\hat{\beta}x_i) + 2\sum_i^n(\alpha - \hat{\alpha})(\beta-\hat{\beta})(x_i)\\
= &amp; \text{SSE} + n(\alpha-\hat{\alpha})^2 + (\beta-\hat{\beta})^2\sum_i^n x_i^2 - 2(\alpha-\hat{\alpha})\sum_i^n (y_i-\hat{y}_i) -2(\beta-\hat{\beta})\sum_i^n x_i(y_i-\hat{y}_i)+2(\alpha-\hat{\alpha})(\beta-\hat{\beta})(n\bar{x})
\end{aligned}
\]</span></p>
<p>It is clear that
<span class="math display">\[ -2(\alpha-\hat{\alpha})\sum_i^n(y_i-\hat{y}_i) = 0 \]</span></p>
<p>And
<span class="math display">\[
\begin{aligned}
-2(\beta-\hat{\beta})\sum_i^n x_i(y_i-\hat{y}_i) = &amp; -2(\beta-\hat{\beta})\sum_i(x_i-\bar{x})(y_i-\hat{y}_i) - 2(\beta-\hat{\beta})\sum_i^n \bar{x}(y_i-\hat{y}_i) \\
= &amp; -2(\beta-\hat{\beta})\times 0 - 2(\beta-\hat{\beta})\bar{x}\sum_i^n(y_i-\hat{y}_i) = 0
\end{aligned}
\]</span></p>
<p>Finally, we use the quantity that <span class="math inline">\(\displaystyle \sum_i^n x_i^2 = \sum_i^n(x_i-\bar{x})^2+ n\bar{x}^2\)</span> to combine the terms <span class="math inline">\(n(\alpha-\hat{\alpha})^2\)</span>, <span class="math inline">\(2\displaystyle (\alpha-\hat{\alpha})(\beta-\hat{\beta})\sum_i^n x_i\)</span>, and <span class="math inline">\(\displaystyle (\beta-\hat{\beta})^2\sum_i^n x_i^2\)</span> together.</p>
<p><span class="math display">\[
\begin{aligned}
 &amp; \sum_i^n (y_i-\alpha-\beta x_i)^2 \\
 = &amp; \text{SSE} + n(\alpha-\hat{\alpha})^2 +(\beta-\hat{\beta})^2\sum_i^n (x_i-\bar{x})^2 + (\beta-\hat{\beta})^2 (n\bar{x}^2)  +2(\alpha-\hat{\alpha})(\beta-\hat{\beta})(n\bar{x})\\
= &amp; \text{SSE} + (\beta-\hat{\beta})^2\text{S}_{xx} + n\left[(\alpha-\hat{\alpha}) +(\beta-\hat{\beta})\bar{x}\right]^2
\end{aligned}
\]</span></p>
<p>Therefore, the posterior joint distribution of <span class="math inline">\(\alpha, \beta, \sigma^2\)</span> can be simplied as
<span class="math display">\[ 
\begin{aligned}
p^*(\alpha, \beta,\sigma^2 ~|~y_1,\cdots, y_n) \propto &amp; \frac{1}{(\sigma^2)^{(n+2)/2}}\exp\left(-\frac{\sum_i(y_i - \alpha - \beta x_i)^2}{2\sigma^2}\right) \\
= &amp; \frac{1}{(\sigma^2)^{(n+2)/2}}\exp\left(-\frac{\text{SSE} + n(\alpha-\hat{\alpha}+(\beta-\hat{\beta})\bar{x})^2 + (\beta - \hat{\beta})^2\sum_i (x_i-\bar{x})^2}{2\sigma^2}\right)
\end{aligned}
\]</span></p>
</div>
<div id="marginal-posterior-distribution-of-beta" class="section level3">
<h3>Marginal Posterior Distribution of <span class="math inline">\(\beta\)</span></h3>
<p>To get the marginal posterior distribution of <span class="math inline">\(\beta\)</span>, we need to integrate out <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\sigma^2\)</span> from <span class="math inline">\(p^*(\alpha, \beta, \sigma^2~|~y_1,\cdots,y_n)\)</span>:</p>
<p><span class="math display">\[
\begin{aligned}
p^*(\beta ~|~y_1,\cdots,y_n) = &amp; \int_0^\infty \int_{-\infty}^\infty p^*(\alpha, \beta, \sigma^2~|~y_1,\cdots, y_n)\, d\alpha\, d\sigma^2 \\
= &amp; \int_0^\infty \left(\int_{-\infty}^\infty \frac{1}{(\sigma^2)^{(n+2)/2}}\exp\left(-\frac{\text{SSE} + n(\alpha-\hat{\alpha}+(\beta-\hat{\beta})\bar{x})^2+(\beta-\hat{\beta})\sum_i(x_i-\bar{x})^2}{2\sigma^2}\right)\, d\alpha\right)\, d\sigma^2\\
= &amp; \int_0^\infty p^*(\beta, \sigma^2~|~y_1,\cdots, y_n)\, d\sigma^2
\end{aligned}
\]</span></p>
<p>We first calculate the inside integral, which gives us the joint posterior distribution of <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\sigma^2\)</span>
<span class="math display">\[
\begin{aligned}
&amp; p^*(\beta, \sigma^2~|~y_1,\cdots,y_n) \\
= &amp; \int_{-\infty}^\infty \frac{1}{(\sigma^2)^{(n+2)/2}}\exp\left(-\frac{\text{SSE}+n(\alpha-\hat{\alpha}+(\beta-\hat{\beta})\bar{x})^2+(\beta-\hat{\beta})^2\sum_i(x_i-\bar{x})^2}{2\sigma^2}\right)\, d\alpha\\
= &amp; \int_{-\infty}^\infty \frac{1}{(\sigma^2)^{(n+2)/2}}\exp\left(-\frac{\text{SSE}+(\beta-\hat{\beta})^2\sum_i(x_i-\bar{x})^2}{2\sigma^2}\right) \exp\left(-\frac{n(\alpha-\hat{\alpha}+(\beta-\hat{\beta})\bar{x})^2}{2\sigma^2}\right)\, d\alpha \\
= &amp; \frac{1}{(\sigma^2)^{(n+2)/2}}\exp\left(-\frac{\text{SSE}+(\beta-\hat{\beta})^2\sum_i(x_i-\bar{x})^2}{2\sigma^2}\right) \int_{-\infty}^\infty \exp\left(-\frac{n(\alpha-\hat{\alpha}+(\beta-\hat{\beta})\bar{x})^2}{2\sigma^2}\right)\, d\alpha
\end{aligned}
\]</span></p>
<p>Here,
<span class="math display">\[ \exp\left(-\frac{n(\alpha-\hat{\alpha}+(\beta - \hat{\beta})\bar{x})^2}{2\sigma^2}\right) \]</span>
can be viewed as part of a normal distribution of <span class="math inline">\(\alpha\)</span>, with mean <span class="math inline">\(\hat{\alpha}-(\beta-\hat{\beta})\bar{x}\)</span>, and variance <span class="math inline">\(\sigma^2/n\)</span>. Therefore, the integral from the last line above is proportional to <span class="math inline">\(\sqrt{\sigma^2/n}\)</span>. We get</p>
<p><span class="math display">\[
\begin{aligned}
p^*(\beta, \sigma^2~|~y_1,\cdots,y_n) 
\propto &amp; \frac{1}{(\sigma^2)^{(n+2)/2}}\exp\left(-\frac{\text{SSE}+(\beta-\hat{\beta})^2\sum_i(x_i-\bar{x})^2}{2\sigma^2}\right) \times \sqrt{\frac{\sigma^2}{n}}\\
\propto &amp; \frac{1}{(\sigma^2)^{(n+1)/2}}\exp\left(-\frac{\text{SSE}+(\beta-\hat{\beta})^2\sum_i (x_i-\bar{x})^2}{2\sigma^2}\right)
\end{aligned}
\]</span></p>
<p>We then integrate <span class="math inline">\(\sigma^2\)</span> out to get the marginal distribution of <span class="math inline">\(\beta\)</span>. Here we first perform change of variable and set <span class="math inline">\(\sigma^2 = \frac{1}{\phi}\)</span>. Then the integral becomes
<span class="math display">\[
\begin{aligned}
p^*(\beta~|~y_1,\cdots, y_n) \propto &amp; \int_0^\infty \frac{1}{(\sigma^2)^{(n+1)/2}}\exp\left(-\frac{\text{SSE} + (\beta-\hat{\beta})^2\sum_i(x_i-\bar{x})^2}{2\sigma^2}\right)\, d\sigma^2 \\
\propto &amp; \int_0^\infty \phi^{\frac{n-3}{2}}\exp\left(-\frac{\text{SSE}+(\beta-\hat{\beta})^2\sum_i(x_i-\bar{x})^2}{2}\phi\right)\, d\phi\\
\propto &amp; \left(\frac{\text{SSE}+(\beta-\hat{\beta})^2\sum_i(x_i-\bar{x})^2}{2}\right)^{-\frac{(n-2)+1}{2}}\int_0^\infty s^{\frac{n-3}{2}}e^{-s}\, ds
\end{aligned}
\]</span></p>
<p>Here we use another change of variable by setting <span class="math inline">\(\displaystyle s= \frac{\text{SSE}+(\beta-\hat{\beta})^2\sum_i(x_i-\bar{x})^2}{2}\phi\)</span>, and the fact that <span class="math inline">\(\displaystyle \int_0^\infty s^{(n-3)/2}e^{-s}\, ds\)</span> gives us the Gamma function <span class="math inline">\(\text{Ga}mma(n-2)\)</span>, which is a constant.</p>
<p>We can rewrite the last line from above to obtain the marginal posterior distribution of <span class="math inline">\(\beta\)</span>. This marginal distribution is the Student’s <span class="math inline">\(t\)</span>-distribution with degrees of freedom <span class="math inline">\(n-2\)</span>, center <span class="math inline">\(\hat{\beta}\)</span>, and scale parameter <span class="math inline">\(\displaystyle \frac{\hat{\sigma}^2}{\sum_i(x_i-\bar{x})^2}\)</span></p>
<p><span class="math display">\[ p^*(\beta~|~y_1,\cdots,y_n) \propto
 \left[1+\frac{1}{n-2}\frac{(\beta - \hat{\beta})^2}{\frac{\text{SSE}}{n-2}/(\sum_i (x_i-\bar{x})^2)}\right]^{-\frac{(n-2)+1}{2}} = \left[1 + \frac{1}{n-2}\frac{(\beta - \hat{\beta})^2}{\hat{\sigma}^2/(\sum_i (x_i-\bar{x})^2)}\right]^{-\frac{(n-2)+1}{2}},
\]</span></p>
<p>where <span class="math inline">\(\displaystyle \frac{\hat{\sigma}^2}{\sum_i (x_i-\bar{x})^2}\)</span> is exactly the square of the standard error of <span class="math inline">\(\hat{\beta}\)</span> from the frequentist OLS model.</p>
<p>To summarize, under the reference prior, the marginal posterior distribution of the slope of the Bayesian simple linear regression follows the Student’s <span class="math inline">\(t\)</span>-distribution
<span class="math display">\[ 
\beta ~|~y_1,\cdots, y_n \sim \text{St}\left(n-2, \ \hat{\beta},\  \left(\text{se}_{\beta}\right)^2\right) 
\]</span></p>
</div>
<div id="marginal-posterior-distribution-of-alpha" class="section level3">
<h3>Marginal Posterior Distribution of <span class="math inline">\(\alpha\)</span></h3>
<p>A similar approach will lead us to the marginal distribution of <span class="math inline">\(\alpha\)</span>. We again start from the joint posterior distribution
<span class="math display">\[ p^*(\alpha, \beta, \sigma^2~|~y_1,\cdots,y_n) \propto \frac{1}{(\sigma^2)^{(n+2)/2}}\exp\left(-\frac{\text{SSE} + n(\alpha-\hat{\alpha}-(\beta-\hat{\beta})\bar{x})^2 + (\beta - \hat{\beta})^2\sum_i (x_i-\bar{x})^2}{2\sigma^2}\right) \]</span></p>
<p>This time we integrate <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\sigma^2\)</span> out to get the marginal posterior distribution of <span class="math inline">\(\alpha\)</span>. We first compute the integral
<span class="math display">\[
\begin{aligned}
p^*(\alpha, \sigma^2~|~y_1,\cdots, y_n) = &amp; \int_{-\infty}^\infty p^*(\alpha, \beta, \sigma^2~|~y_1,\cdots, y_n)\, d\beta\\
= &amp; \int_{-\infty}^\infty \frac{1}{(\sigma^2)^{(n+2)/2}}\exp\left(-\frac{\text{SSE} + n(\alpha-\hat{\alpha}+(\beta-\hat{\beta})\bar{x})^2 + (\beta - \hat{\beta})^2\sum_i (x_i-\bar{x})^2}{2\sigma^2}\right)\, d\beta 
\end{aligned}
\]</span></p>
<p>Here we group the terms with <span class="math inline">\(\beta-\hat{\beta}\)</span> together, then complete the square so that we can treat is as part of a normal distribution function to simplify the integral
<span class="math display">\[
\begin{aligned}
&amp; n(\alpha-\hat{\alpha}+(\beta-\hat{\beta})\bar{x})^2+(\beta-\hat{\beta})^2\sum_i(x_i-\bar{x})^2 \\
= &amp; (\beta-\hat{\beta})^2\left(\sum_i (x_i-\bar{x})^2 + n\bar{x}^2\right) + 2n\bar{x}(\alpha-\hat{\alpha})(\beta-\hat{\beta}) + n(\alpha-\hat{\alpha})^2 \\
= &amp; \left(\sum_i (x_i-\bar{x})^2 + n\bar{x}^2\right)\left[(\beta-\hat{\beta})+\frac{n\bar{x}(\alpha-\hat{\alpha})}{\sum_i(x_i-\bar{x})^2+n\bar{x}^2}\right]^2+ n(\alpha-\hat{\alpha})^2\left[\frac{\sum_i(x_i-\bar{x})^2}{\sum_i (x_i-\bar{x})^2+n\bar{x}^2}\right]\\
= &amp; \left(\sum_i (x_i-\bar{x})^2 + n\bar{x}^2\right)\left[(\beta-\hat{\beta})+\frac{n\bar{x}(\alpha-\hat{\alpha})}{\sum_i(x_i-\bar{x})^2+n\bar{x}^2}\right]^2+\frac{(\alpha-\hat{\alpha})^2}{\frac{1}{n}+\frac{\bar{x}^2}{\sum_i (x_i-\bar{x})^2}}
\end{aligned}
\]</span></p>
<p>When integrating, we can then view
<span class="math display">\[ \exp\left(-\frac{\sum_i (x_i-\bar{x})^2+n\bar{x}^2}{2\sigma^2}\left(\beta-\hat{\beta}+\frac{n\bar{x}(\alpha-\hat{\alpha})}{\sum_i (x_i-\bar{x})^2+n\bar{x}^2}\right)^2\right) \]</span>
as part of a normal distribution function, and get
<span class="math display">\[
\begin{aligned}
&amp; p^*(\alpha, \sigma^2~|~y_1,\cdots,y_n) \\
\propto &amp; \frac{1}{(\sigma^2)^{(n+2)/2}}\exp\left(-\frac{\text{SSE}+(\alpha-\hat{\alpha})^2/(\frac{1}{n}+\frac{\bar{x}^2}{\sum_i (x_i-\bar{x})^2})}{2\sigma^2}\right)\\
&amp; \times\int_{-\infty}^\infty \exp\left(-\frac{\sum_i (x_i-\bar{x})^2+n\bar{x}^2}{2\sigma^2}\left(\beta-\hat{\beta}+\frac{n\bar{x}(\alpha-\hat{\alpha})}{\sum_i (x_i-\bar{x})^2+n\bar{x}^2}\right)^2\right)\, d\beta \\
\propto &amp; \frac{1}{(\sigma^2)^{(n+1)/2}}\exp\left(-\frac{\text{SSE}+(\alpha-\hat{\alpha})^2/(\frac{1}{n}+\frac{\bar{x}^2}{\sum_i (x_i-\bar{x})^2})}{2\sigma^2}\right)
\end{aligned}
\]</span></p>
<p>To get the marginal posterior distribution of <span class="math inline">\(\alpha\)</span>, we again integrate <span class="math inline">\(\sigma^2\)</span> out. using the same change of variable <span class="math inline">\(\displaystyle \sigma^2=\frac{1}{\phi}\)</span>, and <span class="math inline">\(s=\displaystyle \frac{\text{SSE}+(\alpha-\hat{\alpha})^2/(\frac{1}{n}+\frac{\bar{x}^2}{\sum_i (x_i-\bar{x})^2})}{2}\phi\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
&amp; p^*(\alpha~|~y_1,\cdots,y_n) \\
= &amp; \int_0^\infty p^*(\alpha, \sigma^2~|~y_1,\cdots, y_n)\, d\sigma^2 \\
\propto &amp; \int_0^\infty \phi^{(n-3)/2}\exp\left(-\frac{\text{SSE}+(\alpha-\hat{\alpha})^2/(\frac{1}{n}+\frac{\bar{x}^2}{\sum_i (x_i-\bar{x})^2})}{2}\phi\right)\, d\phi\\
\propto &amp; \left(\text{SSE}+(\alpha-\hat{\alpha})^2/(\frac{1}{n}+\frac{\bar{x}^2}{\sum_i (x_i-\bar{x})^2})\right)^{-\frac{(n-2)+1}{2}}\int_0^\infty s^{(n-3)/2}e^{-s}\, ds\\
\propto &amp; \left[1+\frac{1}{n-2}\frac{(\alpha-\hat{\alpha})^2}{\frac{\text{SSE}}{n-2}\left(\frac{1}{n}+\frac{\bar{x}^2}{\sum_i (x_i-\bar{x})^2}\right)}\right]^{-\frac{(n-2)+1}{2}} = \left[1 + \frac{1}{n-2}\left(\frac{\alpha-\hat{\alpha}}{\text{se}_{\alpha}}\right)^2\right]^{-\frac{(n-2)+1}{2}}
\end{aligned}
\]</span></p>
<p>In the last line, we use the same trick as we did for <span class="math inline">\(\beta\)</span> to derive the form of the Student’s <span class="math inline">\(t\)</span>-distribution. This shows that the marginal posterior distribution of <span class="math inline">\(\alpha\)</span> also follows a Student’s <span class="math inline">\(t\)</span>-distribution, with <span class="math inline">\(n-2\)</span> degrees of freedom. Its center is <span class="math inline">\(\hat{\alpha}\)</span>, the estimate of
<span class="math inline">\(\alpha\)</span> in the frequentist OLS estimate, and its scale parameter is <span class="math inline">\(\displaystyle \hat{\sigma}^2\left(\frac{1}{n}+\frac{\bar{x}^2}{\sum_i (x_i-\bar{x})^2}\right)\)</span>, which is the square of the standard error of <span class="math inline">\(\hat{\alpha}\)</span>.</p>
</div>
<div id="marginal-posterior-distribution-of-sigma2" class="section level3">
<h3>Marginal Posterior Distribution of <span class="math inline">\(\sigma^2\)</span></h3>
<p>To show that the marginal posterior distribution of <span class="math inline">\(\sigma^2\)</span> follows the inverse Gamma distribution, we only need to show the precision <span class="math inline">\(\displaystyle \phi = \frac{1}{\sigma^2}\)</span> follows a Gamma distribution.</p>
<p>We have shown in Week 3 that taking the prior distribution of <span class="math inline">\(\sigma^2\)</span> proportional to <span class="math inline">\(\displaystyle \frac{1}{\sigma^2}\)</span> is equivalent to taking the prior distribution of <span class="math inline">\(\phi\)</span> proportional to <span class="math inline">\(\displaystyle \frac{1}{\phi}\)</span>
<span class="math display">\[ p(\sigma^2) \propto \frac{1}{\sigma^2}\qquad \Longrightarrow \qquad p(\phi)\propto \frac{1}{\phi} \]</span></p>
<p>Therefore, under the parameters <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>, and the precision <span class="math inline">\(\phi\)</span>, we have the joint prior distribution as
<span class="math display">\[ p(\alpha, \beta, \phi) \propto \frac{1}{\phi} \]</span>
and the joint posterior distribution as
<span class="math display">\[ 
p^*(\alpha, \beta, \phi~|~y_1,\cdots,y_n) \propto \phi^{\frac{n}{2}-1}\exp\left(-\frac{\sum_i(y_i-\alpha-\beta x_i)}{2}\phi\right) 
\]</span></p>
<p>Using the partial results we have calculated previously, we get
<span class="math display">\[
p^*(\beta, \phi~|~y_1,\cdots,y_n) = \int_{-\infty}^\infty p^*(\alpha, \beta, \phi~|~y_1,\cdots,y_n)\, d\alpha \propto \phi^{\frac{n-3}{2}}\exp\left(-\frac{\text{SSE}+(\beta-\hat{\beta})^2\sum_i (x_i-\bar{x})^2}{2}\phi\right) 
\]</span></p>
<p>Intergrating over <span class="math inline">\(\beta\)</span>, we finally have
<span class="math display">\[
\begin{aligned}
&amp; p^*(\phi~|~y_1,\cdots,y_n) \\
\propto &amp; \int_{-\infty}^\infty \phi^{\frac{n-3}{2}}\exp\left(-\frac{\text{SSE}+(\beta-\hat{\beta})^2\sum_i (x_i-\bar{x})^2}{2}\phi\right)\, d\beta\\
= &amp; \phi^{\frac{n-3}{2}}\exp\left(-\frac{\text{SSE}}{2}\phi\right)\int_{-\infty}^\infty \exp\left(-\frac{(\beta-\hat{\beta})^2\sum_i(x_i-\bar{x})^2}{2}\phi\right)\, d\beta\\
\propto &amp; \phi^{\frac{n-4}{2}}\exp\left(-\frac{\text{SSE}}{2}\phi\right) = \phi^{\frac{n-2}{2}-1}\exp\left(-\frac{\text{SSE}}{2}\phi\right).
\end{aligned}
\]</span></p>
<p>This is a Gamma distribution with shape parameter <span class="math inline">\(\displaystyle \frac{n-2}{2}\)</span> and rate parameter <span class="math inline">\(\displaystyle \frac{\text{SSE}}{2}\)</span>. Therefore, the updated <span class="math inline">\(\sigma^2\)</span> follows the inverse Gamma distribution
<span class="math display">\[ \phi = 1/\sigma^2~|~y_1,\cdots,y_n \sim \text{Ga}\left(\frac{n-2}{2}, \frac{\text{SSE}}{2}\right). \]</span>
That is,
<span class="math display">\[ p(\phi~|~\text{data}) \propto \phi^{\frac{n-2}{2}-1}\exp\left(-\frac{\text{SSE}}{2}\phi\right). \]</span></p>
</div>
<div id="joint-normal-gamma-posterior-distributions" class="section level3">
<h3>Joint Normal-Gamma Posterior Distributions</h3>
<p>Recall that the joint posterior distribution of <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\sigma^2\)</span> is
<span class="math display">\[ p^*(\beta, \sigma^2~|~\text{data}) \propto \frac{1}{\sigma^{n+1}}\exp\left(-\frac{\text{SSE}+(\beta-\hat{\beta})^2\sum_i(x_i-\bar{x})^2}{2\sigma^2}\right). \]</span></p>
<p>If we rewrite this using precision <span class="math inline">\(\phi=1/\sigma^2\)</span>, we get the joint posterior distribution of <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\phi\)</span> to be
<span class="math display">\[ p^*(\beta, \phi~|~\text{data}) \propto \phi^{\frac{n-2}{2}}\exp\left(-\frac{\phi}{2}\left(\text{SSE}+(\beta-\hat{\beta})^2\sum_i (x_i-\bar{x})^2\right)\right). \]</span>
This joint posterior distribution can be viewed as the product of the posterior distribution of <span class="math inline">\(\beta\)</span> conditioning on <span class="math inline">\(\phi\)</span> and the posterior distribution of <span class="math inline">\(\phi\)</span>,
<span class="math display">\[ \pi^*(\beta~|~\phi,\text{data}) \times \pi^*(\phi~|~\text{data}) \propto \left[\phi\exp\left(-\frac{\phi}{2}(\beta-\hat{\beta})^2\sum_i (x_i-\bar{x})^2\right)\right] \times \left[\phi^{\frac{n-2}{2}-1}\exp\left(-\frac{\text{SSE}}{2}\phi\right)\right]. \]</span>
The first term in the product is exactly the Normal distribution with mean <span class="math inline">\(\hat{\beta}\)</span> and standard deviation <span class="math inline">\(\displaystyle \frac{\sigma^2}{\sum_i(x_i-\bar{x})^2} = \frac{\sigma^2}{\text{S}_{xx}}\)</span></p>
<p><span class="math display">\[ \beta ~|~\sigma^2,\ \text{data}~ \sim ~ \text{N}\left(\hat{\beta},\ \frac{\sigma^2}{\text{S}_{xx}}\right). \]</span>
The second term is the Gamma distribution of the precision <span class="math inline">\(\phi\)</span>, or the inverse Gamma distribution of the variance <span class="math inline">\(\sigma^2\)</span>
<span class="math display">\[ 1/\sigma^2~|~\text{data}~\sim~\text{Ga}\left(\frac{n-2}{2},\frac{\text{SSE}}{2}\right).\]</span></p>
<p>This means, the joint posterior distribution of <span class="math inline">\(\beta\)</span> and <span class="math inline">\(\sigma^2\)</span>, under the reference prior, is a Normal-Gamma distribution. Similarly, the joint posterior distribution of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\sigma^2\)</span> is also a Normal-Gamma distribution.
<span class="math display">\[ \alpha~|~\sigma^2, \text{data} ~\sim~\text{N}\left(\hat{\alpha}, \sigma^2\left(\frac{1}{n}+\frac{\bar{x}^2}{\text{S}_{xx}}\right)\right),\qquad \qquad 1/\sigma^2~|~\text{data}~\sim~ \text{Ga}\left(\frac{n-2}{2}, \frac{\text{SSE}}{2}\right). \]</span></p>
<p>In fact, when we impose the bivariate normal distribution on <span class="math inline">\(\bv = (\alpha, \beta)^T\)</span>, and the inverse Gamma distribution on <span class="math inline">\(\sigma^2\)</span>, as we have discussed in Section <a href="#sec:informative-prior"><strong>??</strong></a>, the joint posterior distribution of <span class="math inline">\(\bv\)</span> and <span class="math inline">\(\sigma^2\)</span> is a Normal-Gamma distribution. Since the reference prior is just the limiting case of this informative prior, it is not surprising that we will also get the limiting case Normal-Gamma distribution for <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span>, and <span class="math inline">\(\sigma^2\)</span>.
## Checking Outliers {#sec:Checking-outliers}</p>
<p>The plot and predictive intervals suggest that predictions for Case 39 are not well captured by the model. There is always the possibility that this case does not meet the assumptions of the simple linear regression model (wrong mean or variance) or could be in error. Model diagnostics such as plots of residuals versus fitted values are useful in identifying potential outliers. Now with the interpretation of Bayesian paradigm, we can go further to calculate the probability to demonstrate whether a case falls too far from the mean.</p>
<p>The article by <span class="citation">@chaloner1988bayesian</span> suggested an approach for defining outliers and then calculating the probability that a case or multiple cases were outliers, based on the posterior information of all observations. The assumed model for our simple linear regression is <span class="math inline">\(y_i=\alpha + \beta x_i+\epsilon_i\)</span>, with <span class="math inline">\(\epsilon_i\)</span> having independent, identical distributions that are normal with mean zero and constant variance <span class="math inline">\(\sigma^2\)</span>, i.e., <span class="math inline">\(\epsilon_i \overset{\text{iid}}{\sim} \text{N}(0, \sigma^2)\)</span>. Chaloner &amp; Brant considered outliers to be points where the error or the model discrepancy <span class="math inline">\(\epsilon_i\)</span> is greater than <span class="math inline">\(k\)</span> standard deviations for some large <span class="math inline">\(k\)</span>, and then proceed to calculate the posterior probability that a case <span class="math inline">\(j\)</span> is an outlier to be
<span class="math display" id="eq:outlier-prob">\[\begin{equation} 
P(|\epsilon_j| &gt; k\sigma ~|~\text{data})
\tag{15}
\end{equation}\]</span></p>
<p>Since <span class="math inline">\(\epsilon_j = y_j - \alpha-\beta x_j\)</span>, this is equivalent to calculating
<span class="math display">\[ P(|y_j-\alpha-\beta x_j| &gt; k\sigma~|~\text{data}).\]</span></p>
</div>
<div id="posterior-distribution-of-epsilon_j-conditioning-on-sigma2" class="section level3">
<h3>Posterior Distribution of <span class="math inline">\(\epsilon_j\)</span> Conditioning On <span class="math inline">\(\sigma^2\)</span></h3>
<p>At the end of Section <a href="#sec:simple-linear"><strong>??</strong></a>, we have discussed the posterior distributions of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>. It turns out that under the reference prior, both posterior distributions of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>, conditioning on <span class="math inline">\(\sigma^2\)</span>, are both normal
<span class="math display">\[ 
\begin{aligned}
\alpha ~|~\sigma^2, \text{data}~ &amp; \sim ~ \text{N}\left(\hat{\alpha}, \sigma^2\left(\frac{1}{n}+\frac{\bar{x}^2}{\text{S}_{xx}}\right)\right), \\
\beta ~|~ \sigma^2, \text{data}~ &amp;\sim ~\text{N}\left(\hat{\beta}, \frac{\sigma^2}{\text{S}_{xx}}\right).
\end{aligned}
\]</span>
Using this information, we can obtain the posterior distribution of any residual <span class="math inline">\(\epsilon_j = y_j-\alpha-\beta x_j\)</span> conditioning on <span class="math inline">\(\sigma^2\)</span></p>
<p><span class="math display" id="eq:post-distribution">\[\begin{equation} 
\epsilon_j~|~\sigma^2, \text{data} ~\sim ~ \text{N}\left(y_j-\hat{\alpha}-\hat{\beta}x_j,\ \frac{\sigma^2\sum_i(x_i-x_j)^2}{n\text{S}_{xx}}\right).
\tag{16}
\end{equation}\]</span></p>
<p>Since <span class="math inline">\(\hat{\alpha}+\hat{\beta}x_j\)</span> is exactly the fitted value <span class="math inline">\(\hat{y}_j\)</span>, the mean of this Normal distribution is <span class="math inline">\(y_j-\hat{y}_j=\hat{\epsilon}_j\)</span>, which is the residual under the OLS estimates of the <span class="math inline">\(j\)</span>th observation.</p>
<p>Using this posterior distribution and the property of conditional probability, we can calculate the probability that the error <span class="math inline">\(\epsilon_j\)</span> lies outside of <span class="math inline">\(k\)</span> standard deviations of the mean, defined in equation <a href="#eq:outlier-prob">(15)</a></p>
<p><span class="math display" id="eq:total-prob">\[\begin{equation} 
P(|\epsilon_j|&gt;k\sigma~|~\text{data}) = \int_0^\infty P(|\epsilon_j|&gt;k\sigma~|~\sigma^2,\text{data})p(\sigma^2~|~\text{data})\, d\sigma^2.
\tag{17}
\end{equation}\]</span></p>
<p>The probability <span class="math inline">\(P(|\epsilon_j|&gt;k\sigma~|~\sigma^2, \text{data})\)</span> can be calculated using the posterior distribution of <span class="math inline">\(\epsilon_j\)</span> conditioning on <span class="math inline">\(\sigma^2\)</span> <a href="#eq:post-distribution">(16)</a>
<span class="math display">\[ P(|\epsilon_j|&gt;k\sigma~|~\sigma^2,\text{data}) = \int_{|\epsilon_j|&gt;k\sigma}p(\epsilon_j~|~\sigma^2, \text{data})\, d\epsilon_j = \int_{k\sigma}^\infty p(\epsilon_j~|~\sigma^2, \text{data})\, d\epsilon_j+\int_{-\infty}^{-k\sigma}p(\epsilon_j~|~\sigma^2, \text{data})\, d\epsilon_j. \]</span></p>
<p>Recall that <span class="math inline">\(p(\epsilon_j~|~\sigma^2, \text{data})\)</span> is just a Normal distribution with mean <span class="math inline">\(\hat{\epsilon}_j\)</span>, standard deviation <span class="math inline">\(\displaystyle s=\sigma\sqrt{\frac{\sum_i (x_i-x_j)^2}{n\text{S}_{xx}}}\)</span>, we can use the <span class="math inline">\(z\)</span>-score and <span class="math inline">\(z\)</span>-table to look for this number. Let
<span class="math display">\[ z^* = \frac{\epsilon_j-\hat{\epsilon}_j}{s}. \]</span></p>
<p>The first integral <span class="math inline">\(\displaystyle \int_{k\sigma}^\infty p(\epsilon_j~|~\sigma^2,\text{data})\, d\epsilon_j\)</span> is equivalent to the probability
<span class="math display">\[ P\left(z^* &gt; \frac{k\sigma - \hat{\epsilon}_j}{s}\right) = P\left(z^*&gt; \frac{k\sigma-\hat{\epsilon}_j}{\sigma\sqrt{\sum_i(x_i-x_j)^2/\text{S}_{xx}}}\right) = P \left(z^* &gt; \frac{k-\hat{\epsilon}_j/\sigma}{\sqrt{\sum_i(x_i-x_j)^2/\text{S}_{xx}}}\right). \]</span>
That is the upper tail of the area under the standard Normal distribution when <span class="math inline">\(z^*\)</span> is larger than the critical value <span class="math inline">\(\displaystyle \frac{k-\hat{\epsilon}_j/\sigma}{\sqrt{\sum_i(x_i-x_j)^2/\text{S}_{xx}}}.\)</span></p>
<p>The second integral, <span class="math inline">\(\displaystyle \int_{-\infty}^{-k\sigma} p(\epsilon_j~|~\sigma^2, \text{data})\, d\epsilon_j\)</span>, is the same as the probability
<span class="math display">\[ P\left(z^* &lt; \frac{-k-\hat{\epsilon}_j/\sigma}{\sqrt{\sum_i(x_i-x_j)^2/\text{S}_{xx}}}\right), \]</span>
which is the lower tail of the area under the standard Normal distribution when <span class="math inline">\(z^*\)</span> is smaller than the critical value <span class="math inline">\(\displaystyle \frac{-k-\hat{\epsilon}_j/\sigma}{\sqrt{\sum_i(x_i-x_j)^2/\text{S}_{xx}}}.\)</span></p>
<p>After obtaining the two probabilities, we can move on to calculate the probability <span class="math inline">\(P(|\epsilon_j|&gt;k\sigma~|~\text{data})\)</span> using the formula given by <a href="#eq:total-prob">(17)</a>. Since manual calculation is complicated, we often use numerical integration functions provided in R to finish the final integral.</p>
</div>
<div id="implementation-using-bas-package" class="section level3">
<h3>Implementation Using <code>BAS</code> Package</h3>
<p>The code for calculating the probability of outliers involves integration. We have implemented this in the function <code>Bayes.outlier</code> from the <code>BAS</code> package. This function takes an <code>lm</code> object and the value of <code>k</code> as arguments. Applying this to the <code>bodyfat</code> data for Case 39, we get</p>
<pre class="r"><code># Load `BAS` library and data. Run linear regression as in Section 6.1
library(BAS)
data(bodyfat)
bodyfat.lm = lm(Bodyfat ~ Abdomen, data = bodyfat)

#
outliers = Bayes.outlier(bodyfat.lm, k=3)

# Extract the probability that Case 39 is an outlier
prob.39 = outliers$prob.outlier[39]
prob.39</code></pre>
<pre><code>## [1] 0.9916833</code></pre>
<p>We see that this case has an extremely high probability of 0.992 of being more an outlier, that is, the error is greater than <span class="math inline">\(k=3\)</span> standard deviations, based on the fitted model and data.</p>
<p>With <span class="math inline">\(k=3\)</span>, however, there may be a high probability a priori of at least one outlier in a large sample. Let <span class="math inline">\(p = P(\text{any error $\epsilon_j$ lies within 3 standard deviations}) = P(\text{observation $j$ is not a outlier})\)</span>. Since we assume the prior distribution of <span class="math inline">\(\epsilon_j\)</span> is normal, we can calculate <span class="math inline">\(p\)</span> using the <code>pnorm</code> function. Let <span class="math inline">\(\Phi(z)\)</span> be the cumulative distribution of the standard Normal distribution, that is,
<span class="math display">\[ \Phi(z) = \int_{-\infty}^z \frac{1}{\sqrt{2\pi}}\exp\left(-\frac{x^2}{2}\right)\, dx. \]</span></p>
<p>Then <span class="math inline">\(p = 1-2\Phi(-k) = 1 - 2\Phi(-3)\)</span>.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> Since we assume <span class="math inline">\(\epsilon_j\)</span> is independent, that the probability of no outlier is just the <span class="math inline">\(n\)</span>th power of <span class="math inline">\(p\)</span>. The event of getting at least 1 outlier is the complement of the event of getting no outliers. Therefore, the probability of getting at least 1 outlier is
<span class="math display">\[ P(\text{at least 1 outlier}) = 1 - P(\text{no outlier}) = 1 - p^n = 1 - (1 - 2\Phi(-3))^n.\]</span></p>
<p>We can compute this in R using</p>
<pre class="r"><code>n = nrow(bodyfat)
# probability of no outliers if outliers have errors greater than 3 standard deviation
prob = (1 - (2 * pnorm(-3))) ^ n
prob</code></pre>
<pre><code>## [1] 0.5059747</code></pre>
<pre class="r"><code># probability of at least one outlier
prob.least1 = 1 - (1 - (2 * pnorm(-3))) ^ n
prob.least1</code></pre>
<pre><code>## [1] 0.4940253</code></pre>
<p>With <span class="math inline">\(n=252\)</span>, the probability of at least one outlier is much larger than say the marginal probability that one point is an outlier of 0.05. So we would expect that there will be at least one point where the error is more than 3 standard deviations from zero almost 50% of the time. Rather than fixing <span class="math inline">\(k\)</span>, we can fix the prior probability of no outliers <span class="math inline">\(P(\text{no outlier}) = 1 - p^n\)</span> to be say 0.95, and back solve the value of <span class="math inline">\(k\)</span> using the <code>qnorm</code> function</p>
<pre class="r"><code>new_k = qnorm(0.5 + 0.5 * 0.95 ^ (1 / n))
new_k</code></pre>
<pre><code>## [1] 3.714602</code></pre>
<p>This leads to a larger value of <span class="math inline">\(k\)</span>. After adjusting <span class="math inline">\(k\)</span> the prior probability of no outliers is 0.95, we examine Case 39 again under this <span class="math inline">\(k\)</span></p>
<pre class="r"><code># Calculate probability of being outliers using new `k` value
outliers.new = Bayes.outlier(bodyfat.lm, k = new_k)

# Extract the probability of Case 39
prob.new.39 = outliers.new$prob.outlier[39]
prob.new.39</code></pre>
<pre><code>## [1] 0.6847509</code></pre>
<p>The posterior probability of Case 39 being an outlier is about 0.685. While this is not strikingly large, it is much larger than the marginal prior probability of for a value lying about 3.7<span class="math inline">\(\sigma\)</span> away from 0, if we assume the error <span class="math inline">\(\epsilon_j\)</span> is normally distributed with mean 0 and variance <span class="math inline">\(\sigma^2\)</span>.</p>
<pre class="r"><code>2 * pnorm(-new_k)</code></pre>
<pre><code>## [1] 0.0002035241</code></pre>
<p>There is a substantial probability that Case 39 is an outlier. If you do view it as an outlier, what are your options? One option is to investigate the case and determine if the data are input incorrectly, and fix it. Another option is when you cannot confirm there is a data entry error, you may delete the observation from the analysis and refit the model without the case. If you do take this option, be sure to describe what you did so that your research is reproducible. You may want to apply diagnostics and calculate the probability of a case being an outlier using this reduced data. As a word of caution, if you discover that there are a large number of points that appear to be outliers, take a second look at your model assumptions, since the problem may be with the model rather than the data! A third option we will talk about later, is to combine inference under the model that retains this case as part of the population, and the model that treats it as coming from another population. This approach incorporates our uncertainty about whether the case is an outlier given the data.</p>
<p>The code of <code>Bayes.outlier</code> function is based on using a <strong>reference prior</strong> for the linear model and extends to multiple regression.</p>
</div>
</div>
<div id="sec:Bayes-multiple-regression" class="section level2">
<h2>Bayesian Multiple Linear Regression</h2>
<p>In this section, we will discuss Bayesian inference in multiple linear regression. We will use the reference prior to provide the default or base line analysis of the model, which provides the correspondence between Bayesian and frequentist approaches.</p>
<div id="the-model" class="section level3">
<h3>The Model</h3>
<p>To illustrate the idea, we use the data set on kid’s cognitive scores that we examined earlier. We predicted the value of the kid’s cognitive score from the mother’s high school status, mother’s IQ score, whether or not the mother worked during the first three years of the kid’s life, and the mother’s age. We set up the model as follows</p>
<p><span class="math display" id="eq:multi-model1">\[\begin{equation}
y_{\text{score},i} = \alpha + \beta_1 x_{\text{hs},i} + \beta_2 x_{\text{IQ},i} + \beta_3x_{\text{work},i} + \beta_4 x_{\text{age},i} + \epsilon_i, \quad i = 1,\cdots, n.
\tag{18}
\end{equation}\]</span></p>
<p>Here, <span class="math inline">\(y_{\text{score},i}\)</span> is the <span class="math inline">\(i\)</span>th kid’s cognitive score. <span class="math inline">\(x_{\text{hs},i}\)</span>, <span class="math inline">\(x_{\text{IQ},i}\)</span>, <span class="math inline">\(x_{\text{work},i}\)</span>, and <span class="math inline">\(x_{\text{age},i}\)</span> represent the high school status, the IQ score, the work status during the first three years of the kid’s life, and the age of the <span class="math inline">\(i\)</span>th kid’s mother. <span class="math inline">\(\epsilon_i\)</span> is the error term. <span class="math inline">\(n\)</span> denotes the number of observations in this data set.</p>
<p>For better analyses, one usually centers the variable, which ends up getting the following form</p>
<p><span class="math display" id="eq:multi-model2">\[\begin{equation} 
y_{\text{score}, i} = \beta_0 + \beta_1 (x_{\text{hs},i}-\bar{x}_{\text{hs}}) + \beta_2 (x_{\text{IQ},i}-\bar{x}_{\text{IQ}}) + \beta_3(x_{\text{work},i}-\bar{x}_{\text{work}}) + \beta_4 (x_{\text{age},i}-\bar{x}_{\text{age}}) + \epsilon_i.
\tag{19}
\end{equation}\]</span></p>
<p>Under this tranformation, the coefficients, <span class="math inline">\(\beta_1,\ \beta_2,\ \beta_3\)</span>, <span class="math inline">\(\beta_4\)</span>, that are in front of the variables, are unchanged compared to the ones in <a href="#eq:multi-model1">(18)</a>. However, the constant coefficient <span class="math inline">\(\beta_0\)</span> is no longer the constant coefficient <span class="math inline">\(\alpha\)</span> in <a href="#eq:multi-model1">(18)</a>. Instead, under the assumption that <span class="math inline">\(\epsilon_i\)</span> is independently, identically normal, <span class="math inline">\(\hat{\beta}_0\)</span> is the sample mean of the response variable <span class="math inline">\(Y_{\text{score}}\)</span>.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> This provides more meaning to <span class="math inline">\(\beta_0\)</span> as this is the mean of <span class="math inline">\(Y\)</span> when each of the predictors is equal to their respective means. Moreover, it is more convenient to use this “centered” model to derive analyses. The R codes in the <code>BAS</code> package are based on the form <a href="#eq:multi-model2">(19)</a>.</p>
</div>
<div id="data-pre-processing" class="section level3">
<h3>Data Pre-processing</h3>
<p>We can download the data set from Gelman’s website and read the summary information of the data set using the <code>read.dta</code> function in the <code>foreign</code> package.</p>
<pre class="r"><code>library(foreign)
cognitive = read.dta(&quot;http://www.stat.columbia.edu/~gelman/arm/examples/child.iq/kidiq.dta&quot;)
summary(cognitive)</code></pre>
<pre><code>##    kid_score         mom_hs           mom_iq          mom_work    
##  Min.   : 20.0   Min.   :0.0000   Min.   : 71.04   Min.   :1.000  
##  1st Qu.: 74.0   1st Qu.:1.0000   1st Qu.: 88.66   1st Qu.:2.000  
##  Median : 90.0   Median :1.0000   Median : 97.92   Median :3.000  
##  Mean   : 86.8   Mean   :0.7857   Mean   :100.00   Mean   :2.896  
##  3rd Qu.:102.0   3rd Qu.:1.0000   3rd Qu.:110.27   3rd Qu.:4.000  
##  Max.   :144.0   Max.   :1.0000   Max.   :138.89   Max.   :4.000  
##     mom_age     
##  Min.   :17.00  
##  1st Qu.:21.00  
##  Median :23.00  
##  Mean   :22.79  
##  3rd Qu.:25.00  
##  Max.   :29.00</code></pre>
<p>From the summary statistics, variables <code>mom_hs</code> and <code>mom_work</code> should be considered as categorical variables. We transform them into indicator variables where <code>mom_work = 1</code> if the mother worked for 1 or more years, and <code>mom_hs = 1</code> indicates the mother had more than a high school education.</p>
<p>The code is as below:<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></p>
<pre class="r"><code>cognitive$mom_work = as.numeric(cognitive$mom_work &gt; 1)
cognitive$mom_hs = as.numeric(cognitive$mom_hs &gt; 0)

# Modify column names of the data set
colnames(cognitive) = c(&quot;kid_score&quot;, &quot;hs&quot;, &quot;IQ&quot;, &quot;work&quot;, &quot;age&quot;)</code></pre>
</div>
<div id="specify-bayesian-prior-distributions" class="section level3">
<h3>Specify Bayesian Prior Distributions</h3>
<p>For Bayesian inference, we need to specify a prior distribution for the error term <span class="math inline">\(\epsilon_i\)</span>. Since each kid’s cognitive score <span class="math inline">\(y_{\text{score},i}\)</span> is continuous, we assume that <span class="math inline">\(\epsilon_i\)</span> is independent, and identically distributed with the Normal distribution
<span class="math display">\[ \epsilon_i \overset{\text{iid}}{\sim} \text{N}(0, \sigma^2), \]</span>
where <span class="math inline">\(\sigma^2\)</span> is the commonly shared variance of all observations.</p>
<p>We will also need to specify the prior distributions for all the coefficients <span class="math inline">\(\beta_0,\ \beta_1,\ \beta_2,\ \beta_3\)</span>, and <span class="math inline">\(\beta_4\)</span>. An informative prior, which assumes that the <span class="math inline">\(\beta\)</span>’s follow the multivariate normal distribution with covariance matrix <span class="math inline">\(\sigma^2\Sigma_0\)</span> can be used. We may further impose the inverse Gamma distribution to <span class="math inline">\(\sigma^2\)</span>, to complete the hierachical model
<span class="math display">\[ 
\begin{aligned}
\beta_0, \beta_1, \beta_2, \beta_3, \beta_4 ~|~\sigma^2 ~\sim ~ &amp; \text{N}((b_0, b_1, b_2, b_3, b_4)^T, \sigma^2\Sigma_0)\\
1/\sigma^2 \ ~\sim ~&amp; \text{Ga}(\nu_0/2, \nu_0\sigma_0^2/2) 
\end{aligned}
\]</span></p>
<p>This gives us the multivariate Normal-Gamma conjugate family, with hyperparameters <span class="math inline">\(b_0, b_1, b_2, b_3, b_4, \Sigma_0, \nu_0\)</span>, and <span class="math inline">\(\sigma_0^2\)</span>. For this prior, we will need to specify the values of all the hyperparameters. This elicitation can be quite involved, especially when we do not have enough prior information about the variances, covariances of the coefficients and other prior hyperparameters. Therefore, we are going to adopt the noninformative reference prior, which is a limiting case of this multivariate Normal-Gamma prior.</p>
<p>The reference prior in the multiple linear regression model is similar to the reference prior we used in the simple linear regression model. The prior distribution of all the coefficients <span class="math inline">\(\beta\)</span>’s conditioning on <span class="math inline">\(\sigma^2\)</span> is the uniform prior, and the prior of <span class="math inline">\(\sigma^2\)</span> is proportional to its reciprocal
<span class="math display">\[ p(\beta_0,\beta_1,\beta_2,\beta_3,\beta_4~|~\sigma^2) \propto 1,\qquad\quad p(\sigma^2) \propto \frac{1}{\sigma^2}. \]</span></p>
<p>Under this reference prior, the marginal posterior distributions of the coefficients, <span class="math inline">\(\beta\)</span>’s, are parallel to the ones in simple linear regression. The marginal posterior distribution of <span class="math inline">\(\beta_j\)</span> is the Student’s <span class="math inline">\(t\)</span>-distributions with centers given by the frequentist OLS estimates <span class="math inline">\(\hat{\beta}_j\)</span>, scale parameter given by the standard error <span class="math inline">\((\text{se}_{\beta_j})^2\)</span> obtained from the OLS estimates
<span class="math display">\[
\beta_j~|~y_1,\cdots,y_n ~\sim ~\text{St}(n-p-1,\ \hat{\beta}_j,\ (\text{se}_{\beta_j})^2),\qquad j = 0, 1, \cdots, p.
\]</span></p>
<p>The degree of freedom of these <span class="math inline">\(t\)</span>-distributions is <span class="math inline">\(n-p-1\)</span>, where <span class="math inline">\(p\)</span> is the number of predictor variables. In the kid’s cognitive score example, <span class="math inline">\(p=4\)</span>. The posterior mean, <span class="math inline">\(\hat{\beta}_j\)</span>, is the center of the <span class="math inline">\(t\)</span>-distribution of <span class="math inline">\(\beta_j\)</span>, which is the same as the OLS estimates of <span class="math inline">\(\beta_j\)</span>. The posterior standard deviation of <span class="math inline">\(\beta_j\)</span>, which is the square root of the scale parameter of the <span class="math inline">\(t\)</span>-distribution, is <span class="math inline">\(\text{se}_{\beta_j}\)</span>, the standard error of <span class="math inline">\(\beta_j\)</span> under the OLS estimates. That means, under the reference prior, we can easily obtain the posterior mean and posterior standard deviation from using the <code>lm</code> function, since they are numerically equivalent to the counterpart of the frequentist approach.</p>
</div>
<div id="fitting-the-bayesian-model" class="section level3">
<h3>Fitting the Bayesian Model</h3>
<p>To gain more flexibility in choosing priors, we will instead use the <code>bas.lm</code> function in the <code>BAS</code> library, which allows us to specify different model priors and coefficient priors.</p>
<pre class="r"><code># Import library
library(BAS)

# Use `bas.lm` to run regression model
cog.bas = bas.lm(kid_score ~ ., data = cognitive, prior = &quot;BIC&quot;, 
                 modelprior = Bernoulli(1), 
                 include.always = ~ ., 
                 n.models = 1)</code></pre>
<p>The above <code>bas.lm</code> function uses the same model formula as in the <code>lm</code>. It first specifies the response and predictor variables, a data argument to provide the data frame. The additional arguments further include the prior on the coefficients. We use <code>"BIC"</code> here to indicate that the model is based on the non-informative reference prior. (We will explain in the later section why we use the name <code>"BIC"</code>.) Since we will only provide one model, which is the one that includes all variables, we place all model prior probability to this exact model. This is specified in the <code>modelprior = Bernoulli(1)</code> argument. Because we want to fit using all variables, we use <code>include.always = ~ .</code> to indicate that the intercept and all 4 predictors are included. The argument <code>n.models = 1</code> fits just this one model.</p>
</div>
<div id="posterior-means-and-posterior-standard-deviations" class="section level3">
<h3>Posterior Means and Posterior Standard Deviations</h3>
<p>Similar to the OLS regression process, we can extract the posterior means and standard deviations of the coefficients using the <code>coef</code> function</p>
<pre class="r"><code>cog.coef = coef(cog.bas)
cog.coef</code></pre>
<pre><code>## 
##  Marginal Posterior Summaries of Coefficients: 
## 
##  Using  BMA 
## 
##  Based on the top  1 models 
##            post mean  post SD   post p(B != 0)
## Intercept  86.79724    0.87092   1.00000      
## hs          5.09482    2.31450   1.00000      
## IQ          0.56147    0.06064   1.00000      
## work        2.53718    2.35067   1.00000      
## age         0.21802    0.33074   1.00000</code></pre>
<p>From the last column in this summary, we see that the probability of the coefficients to be non-zero is always 1. This is because we specify the argument <code>include.always = ~ .</code> to force the model to include all variables. Notice on the first row we have the statistics of the <code>Intercept</code> <span class="math inline">\(\beta_0\)</span>. The posterior mean of <span class="math inline">\(\beta_0\)</span> is 86.8, which is completely different from the original <span class="math inline">\(y\)</span>-intercept of this model under the frequentist OLS regression. As we have stated previously, we consider the “centered” model under the Bayesian framework. Under this “centered” model and the reference prior, the posterior mean of the <code>Intercept</code> <span class="math inline">\(\beta_0\)</span> is now the sample mean of the response variable <span class="math inline">\(Y_{\text{score}}\)</span>.</p>
<p>We can visualize the coefficients <span class="math inline">\(\beta_1,\ \beta_2,\ \beta_3,\ \beta_4\)</span> using the <code>plot</code> function. We use the <code>subset</code> argument to plot only the coefficients of the predictors.</p>
<pre class="r"><code>par(mfrow = c(2, 2), col.lab = &quot;darkgrey&quot;, col.axis = &quot;darkgrey&quot;, col = &quot;darkgrey&quot;)
plot(cog.coef, subset = 2:5, ask = F)</code></pre>
<p><img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/plot-coef-1.svg" width="576" /></p>
<p>These distributions all center the posterior distributions at their respective OLS estimates <span class="math inline">\(\hat{\beta}_j\)</span>, with the spread of the distribution related to the standard errors <span class="math inline">\(\text{se}_{\beta_j}\)</span>. Recall, that <code>bas.lm</code> uses centered predictors so that the intercept is always the sample mean.</p>
</div>
</div>
<div id="credible-intervals-summary" class="section level2">
<h2>Credible Intervals Summary</h2>
<p>We can also report the posterior means, posterior standard deviations, and the 95% credible intervals of the coefficients of all 4 predictors, which may give a clearer and more useful summary. The <code>BAS</code> library provides the method <code>confint</code> to extract the credible intervals from the output <code>cog.coef</code>. If we are only interested in the distributions of the coefficients of the 4 predictors, we may use the <code>parm</code> argument to restrict the variables shown in the summary</p>
<pre class="r"><code>confint(cog.coef, parm = 2:5)</code></pre>
<pre><code>##            2.5%     97.5%      beta
## hs    0.5456507 9.6439990 5.0948248
## IQ    0.4422784 0.6806616 0.5614700
## work -2.0830879 7.1574454 2.5371788
## age  -0.4320547 0.8680925 0.2180189
## attr(,&quot;Probability&quot;)
## [1] 0.95
## attr(,&quot;class&quot;)
## [1] &quot;confint.bas&quot;</code></pre>
<p>All together, we can generate a summary table showing the posterior means, posterior standard deviations, the upper and lower bounds of the 95% credible intervals of all coefficients <span class="math inline">\(\beta_0, \beta_1, \beta_2, \beta_3\)</span>, and <span class="math inline">\(\beta_4\)</span>.</p>
<pre class="r"><code>out = confint(cog.coef)[, 1:2]  

# Extract the upper and lower bounds of the credible intervals
names = c(&quot;posterior mean&quot;, &quot;posterior std&quot;, colnames(out))
out = cbind(cog.coef$postmean, cog.coef$postsd, out)
colnames(out) = names

round(out, 2)</code></pre>
<pre><code>##           posterior mean posterior std  2.5% 97.5%
## Intercept          86.80          0.87 85.09 88.51
## hs                  5.09          2.31  0.55  9.64
## IQ                  0.56          0.06  0.44  0.68
## work                2.54          2.35 -2.08  7.16
## age                 0.22          0.33 -0.43  0.87</code></pre>
<p>As in the simple linear aggression, the posterior estimates from the reference prior, that are in the table, are <strong>equivalent to the numbers</strong> reported from the <code>lm</code> function in R, or using the confident function in the OLS estimates. These intervals are centered at the posterior mean <span class="math inline">\(\hat{\beta}_j\)</span> with width given by the appropriate <span class="math inline">\(t\)</span> quantile with <span class="math inline">\(n-p-1\)</span> degrees of freedom times the posterior standard deviation <span class="math inline">\(\text{se}_{\beta_j}\)</span>. <strong>The primary difference is the interpretation of the intervals</strong>. For example, given this data, we believe there is a 95% chance that the kid’s cognitive score increases by 0.44 to 0.68 with one additional increase of the mother’s IQ score. The mother’s high school status has a larger effect where we believe that there is a 95% chance the kid would score of 0.55 up to 9.64 points higher if the mother had three or more years of high school. The credible intervals of the predictors <code>work</code> and <code>age</code> include 0, which implies that we may improve this model so that the model will accomplish a desired level of explanation or prediction with fewer predictors. We will explore model selection using Bayesian information criterion in the next chapter.</p>
</div>
<div id="summary-2" class="section level2">
<h2>Summary</h2>
<p>We have provided Bayesian analyses for both simple linear regression and multiple linear regression using the default reference prior. We have seen that, under this reference prior, the marginal posterior distribution of the coefficients is the Student’s <span class="math inline">\(t\)</span>-distribution. Therefore, the posterior mean and posterior standard deviation of any coefficients are numerically equivalent to the corresponding frequentist OLS estimate and the standard error. This has provided us a base line analysis of Bayesian approach, which we can extend later when we introduce more different coefficient priors.</p>
<p>The difference is the interpretation. Since we have obtained the distribution of each coefficient, we can construct the credible interval, which provides us the probability that a specific coefficient falls into this credible interval.</p>
<p>We have also used the posterior distribution to analyze the probability of a particular observation being an outlier. We defined such probabiilty to be the probability that the error term is <span class="math inline">\(k\)</span> standard deviations away from 0. This probability is based on information of all data, instead of just the observation itself.</p>
</div>
</div>
<div id="bayesian-model-choice" class="section level1">
<h1>7 Bayesian Model Choice</h1>
<p>In Section <a href="#sec:Bayes-multiple-regression"><strong>??</strong></a> of Chapter 6, we provided a Bayesian inference analysis for kid’s cognitive scores using multiple linear regression. We found that several credible intervals of the coefficients contain zero, suggesting that we could potentially simplify the model.
In this chapter, we will discuss model selection, model uncertainty, and model averaging. Bayesian model selection is to pick variables for multiple linear regression based on Bayesian information criterion, or BIC. Later, we will also discuss other model selection methods, such as using Bayes factors.
## Bayesian Information Criterion (BIC) {#sec:BIC}</p>
<p>In inferential statistics, we compare model selections using <span class="math inline">\(p\)</span>-values or adjusted <span class="math inline">\(R^2\)</span>. Here we will take the Bayesian propectives. We are going to discuss the Bayesian model selections using the Bayesian information criterion, or BIC. BIC is one of the Bayesian criteria used for Bayesian model selection, and tends to be one of the most popular criteria.</p>
<div id="definition-of-bic" class="section level3">
<h3>Definition of BIC</h3>
<p>The Bayesian information criterion, BIC, is defined to be</p>
<p><span class="math display" id="eq:BIC-def">\[\begin{equation}
\text{BIC} = -2\ln(\widehat{\text{likelihood}}) + (p+1)\ln(n).
\tag{20}
\end{equation}\]</span></p>
<p>Here <span class="math inline">\(n\)</span> is the number of observations in the model, and <span class="math inline">\(p\)</span> is the number of predictors. That is, <span class="math inline">\(p+1\)</span> is the number of total parameters (also the total number of coefficients, including the intercept) in the model. Recall that in the Bayesian simple linear regression (Section <a href="#sec:simple-linear"><strong>??</strong></a>), we mentioned the likelihood of the model <span class="math inline">\(y_i=\alpha + \beta x_i+\epsilon_i\)</span> is the probability (or probability distribution) for the observed data <span class="math inline">\(y_i,\  i = 1,\cdots, n\)</span> occur under the given parameters <span class="math inline">\(\alpha,\ \beta,\ \sigma^2\)</span>
<span class="math display">\[ \text{likelihood} = p(y_i~|~\alpha,\ \beta, \ \sigma^2) = \mathcal{L}(\alpha,\ \beta,\ \sigma^2), \]</span>
where <span class="math inline">\(\sigma^2\)</span> is the variance of the assumed Normal distribution of the error term <span class="math inline">\(\epsilon_i\)</span>. In general, under any model <span class="math inline">\(M\)</span>, we can write the likelihood of this model as the function of parameter <span class="math inline">\(\boldsymbol{\theta}\)</span> (<span class="math inline">\(\boldsymbol{\theta}\)</span> may be a vector of several parameters) and the model <span class="math inline">\(M\)</span>
<span class="math display">\[ \text{likelihood} = p(\text{data}~|~\boldsymbol{\theta}, M) = \mathcal{L}(\boldsymbol{\theta}, M). \]</span>
If the likelihood function <span class="math inline">\(\mathcal{L}(\boldsymbol{\theta}, M)\)</span> is nice enough (say it has local maximum), the maximized value of the likelihood, <span class="math inline">\(\widehat{\text{likelihood}}\)</span>, can be achieved by some special value of the parameter <span class="math inline">\(\boldsymbol{\theta}\)</span>, denoted as <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span>
<span class="math display">\[ \widehat{\text{likelihood}} = p(\text{data}~|~\hat{\boldsymbol{\theta}}, M) = \mathcal{L}(\hat{\boldsymbol{\theta}}, M).\]</span></p>
<p>This is the likelihood that defines BIC.</p>
<p>When the sample size <span class="math inline">\(n\)</span> is large enough and the data distribution belongs to the exponential family such as the Normal distribution, BIC can be approximated by -2 times likelihood that data are produced under model <span class="math inline">\(M\)</span>:</p>
<p><span class="math display" id="eq:BIC-approx">\[\begin{equation}
\text{BIC}\approx -2\ln(p(\text{data}~|~M)) = -2\ln\left(\int p(\text{data}~|~\boldsymbol{\theta}, M)p(\boldsymbol{\theta}~|~M)\, d\boldsymbol{\theta}\right),\qquad \quad \text{when $n$ is large.} \tag{21}
\end{equation}\]</span></p>
<p>Here <span class="math inline">\(p(\boldsymbol{\theta}~|~M)\)</span> is the prior distribution of the parameter <span class="math inline">\(\boldsymbol{\theta}\)</span>. We will not go into detail why the approximation holds and how we perform the integration in this book. However, we wanted to remind readers that, since BIC can be approximated by the prior distribution of the parameter <span class="math inline">\(\boldsymbol{\theta}\)</span>, we will see later how we utilize BIC to approximate the model likelihood under the reference prior.<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a></p>
<p>One more observation of formula <a href="#eq:BIC-approx">(21)</a> is that it involves the marginal likelihood of data under model <span class="math inline">\(M\)</span>, <span class="math inline">\(p(\text{data}~|~M)\)</span>. We have seen this quantity when we introduced Bayes factor between two hypotheses or models
<span class="math display">\[ \text{BF}[M_1:M_2] = \frac{p(\text{data}~|~M_1)}{p(\text{data}~|~M_2)}. \]</span>
This also provides connection between BIC and Bayes factor, which we will leverage later.</p>
<p>Similar to AIC, the Akaike information criterion, the model with the smallest BIC is preferrable. Formula <a href="#eq:BIC-def">(20)</a> can be re-expressed using the model <span class="math inline">\(R^2\)</span>, which is easier to calculate
<span class="math display" id="eq:BIC-new">\[\begin{equation}
\text{BIC} = n\ln(1-R^2)+(p+1)\ln(n)+\text{constant},
\tag{22}
\end{equation}\]</span>
where the last term constant only depends on the sample size <span class="math inline">\(n\)</span>, and the observed data <span class="math inline">\(y_1,\cdots, y_n\)</span>. Since this constant does not depend on the choice of model, i.e., the choice of variables, ignoring this constant will not affect the comparison of BICs between models. Therefore, we usually define BIC to be
<span class="math display">\[\begin{equation*}
\text{BIC} = n\ln(1-R^2) + (p+1)\ln(n).
\end{equation*}\]</span></p>
<p>From this expression, we see that adding more predictors, that is, increasing <span class="math inline">\(p\)</span>, will result in larger <span class="math inline">\(R^2\)</span>, which leads to a smaller <span class="math inline">\(\ln(1-R^2)\)</span> in the first term of BIC. While larger <span class="math inline">\(R^2\)</span> means better goodness of fit of the data, too many predictors may result in overfitting the data. Therefore, the second term <span class="math inline">\((p+1)\ln(n)\)</span> is added in the BIC expression to penalize models with too many predictors. When <span class="math inline">\(p\)</span> increases, the second term increases as well. This provides a trade-off between the goodness of fit given by the first term and the model complexity represented by the second term.</p>
</div>
<div id="backward-elimination-with-bic" class="section level3">
<h3>Backward Elimination with BIC</h3>
<p>We will use the kid’s cognitive score data set <code>cognitive</code> as an example. We first read in the data set from Gelman’s website and transform the data types of the two variables <code>mom_work</code> and <code>mom_hs</code>, like what we did in Section <a href="#sec:Bayes-multiple-regression"><strong>??</strong></a>.</p>
<pre class="r"><code># Load the library in order to read in data from website
library(foreign)    

# Read in cognitive score data set and process data tranformations
cognitive = read.dta(&quot;http://www.stat.columbia.edu/~gelman/arm/examples/child.iq/kidiq.dta&quot;)

cognitive$mom_work = as.numeric(cognitive$mom_work &gt; 1)
cognitive$mom_hs =  as.numeric(cognitive$mom_hs &gt; 0)
colnames(cognitive) = c(&quot;kid_score&quot;, &quot;hs&quot;,&quot;IQ&quot;, &quot;work&quot;, &quot;age&quot;)</code></pre>
<p>We start with the full model, with all possible predictors: <code>hs</code>, <code>IQ</code>, <code>work</code>, and <code>age</code>. We will drop one variable at a time and record all BICs. Then we will choose the model with the smallest BIC. We will repeat this process until none of the models yields a decrease in BIC. We use the <code>step</code> function in R to perform the BIC model selection. Notice the default value of the <code>k</code> argument in the <code>step</code> function is <code>k=2</code>, which is for the AIC score. For BIC, <code>k</code> should be <code>log(n)</code> correspondingly.</p>
<pre class="r"><code># Compute the total number of observations
n = nrow(cognitive)

# Full model using all predictors
cog.lm = lm(kid_score ~ ., data=cognitive)

# Perform BIC elimination from full model
# k = log(n): penalty for BIC rather than AIC
cog.step = step(cog.lm, k=log(n))   </code></pre>
<pre><code>## Start:  AIC=2541.07
## kid_score ~ hs + IQ + work + age
## 
##        Df Sum of Sq    RSS    AIC
## - age   1     143.0 141365 2535.4
## - work  1     383.5 141605 2536.2
## - hs    1    1595.1 142817 2539.9
## &lt;none&gt;              141222 2541.1
## - IQ    1   28219.9 169441 2614.1
## 
## Step:  AIC=2535.44
## kid_score ~ hs + IQ + work
## 
##        Df Sum of Sq    RSS    AIC
## - work  1     392.5 141757 2530.6
## - hs    1    1845.7 143210 2535.0
## &lt;none&gt;              141365 2535.4
## - IQ    1   28381.9 169747 2608.8
## 
## Step:  AIC=2530.57
## kid_score ~ hs + IQ
## 
##        Df Sum of Sq    RSS    AIC
## &lt;none&gt;              141757 2530.6
## - hs    1    2380.2 144137 2531.7
## - IQ    1   28504.1 170261 2604.0</code></pre>
<p>In the summary chart, the <code>AIC</code> should be interpreted as BIC, since we have chosen to use the BIC expression where <span class="math inline">\(k=\ln(n)\)</span>.</p>
<p>From the full model, we predict the kid’s cognitive score from mother’s high school status, mother’s IQ score, mother’s work status and mother’s age. The BIC for the full model is 2541.1.</p>
<p>At the first step, we try to remove each variable from the full model to record the resulting new BIC. From the summary statistics, we see that removing variable <code>age</code> results in the smallest BIC. But if we try to drop the <code>IQ</code> variable, this will increase the BIC, which implies that <code>IQ</code> would be a really important predictor of <code>kid_score</code>. Comparing all the results, we drop the <code>age</code> variable at the first step. After dropping <code>age</code>, the new BIC is 2535.4.</p>
<p>At the next step, we see that dropping <code>work</code> variable will result in the lowest BIC, which is 2530.6. Now the model has become
<span class="math display">\[ \text{score} \sim \text{hs} + \text{IQ} \]</span></p>
<p>Finally, when we try dropping either <code>hs</code> or <code>IQ</code>, it will result in higher BIC than 2530.6. This suggests that we have reached the best model. This model predicts kid’s cognitive score using mother’s high school status and mother’s IQ score.</p>
<p>However, using the adjusted <span class="math inline">\(R^2\)</span>, the best model would be the one including not only <code>hs</code> and <code>IQ</code> variables, but also mother’s work status, <code>work</code>. In general, using BIC leads to fewer variables for the best model compared to using adjusted <span class="math inline">\(R^2\)</span> or AIC.</p>
<p>We can also use the <code>BAS</code> package to find the best BIC model without taking the stepwise backward process.</p>
<pre class="r"><code># Import library
library(BAS)

# Use `bas.lm` to run regression model
cog.BIC = bas.lm(kid_score ~ ., data = cognitive,
                 prior = &quot;BIC&quot;, modelprior = uniform())

cog.BIC</code></pre>
<pre><code>## 
## Call:
## bas.lm(formula = kid_score ~ ., data = cognitive, prior = &quot;BIC&quot;, 
##     modelprior = uniform())
## 
## 
##  Marginal Posterior Inclusion Probabilities: 
## Intercept         hs         IQ       work        age  
##   1.00000    0.61064    1.00000    0.11210    0.06898</code></pre>
<p>Here we set the <code>modelprior</code> argument as <code>uniform()</code> to assign equal prior probability for each possible model.</p>
<p>The <code>logmarg</code> information inside the <code>cog.BIC</code> summary list records the log of marginal likelihood of each model after seeing the data <span class="math inline">\(\ln(p(\text{data}~|~M))\)</span>. Recall that this is approximately proportional to negative BIC when the sample size <span class="math inline">\(n\)</span> is large
<span class="math display">\[ \text{BIC}\approx -2 \ln(p(\text{data}~|~M)).\]</span></p>
<p>We can use this information to retrieve the model with the largest log of marginal likelihood, which corresponds to the model with the smallest BIC.</p>
<pre class="r"><code># Find the index of the model with the largest logmarg
best = which.max(cog.BIC$logmarg)

# Retrieve the index of variables in the best model, with 0 as the index of the intercept
bestmodel = cog.BIC$which[[best]]
bestmodel</code></pre>
<pre><code>## [1] 0 1 2</code></pre>
<pre class="r"><code># Create an indicator vector indicating which variables are used in the best model
# First, create a 0 vector with the same dimension of the number of variables in the full model
bestgamma = rep(0, cog.BIC$n.vars) 

# Change the indicator to 1 where variables are used
bestgamma[bestmodel + 1] = 1  

bestgamma</code></pre>
<pre><code>## [1] 1 1 1 0 0</code></pre>
<p>From the indicator vector <code>bestgamma</code> we see that only the intercept (indexed as 0), mother’s high school status variable <code>hs</code> (indexed as 1), and mother’s IQ score <code>IQ</code> (indexed as 2) are used in the best model, with 1’s in the corresponding slots of the 5-dimensional vector <span class="math inline">\((1, 1, 1, 0, 0)\)</span>.</p>
</div>
<div id="coefficient-estimates-under-reference-prior-for-best-bic-model" class="section level3">
<h3>Coefficient Estimates Under Reference Prior for Best BIC Model</h3>
<p>The best BIC model <span class="math inline">\(M\)</span> can be set up as follows and we have adopted the “centered” model convention for convenient analyses
<span class="math display">\[ y_{\text{score},i} = \beta_0 + \beta_1(x_{\text{hs},i} - \bar{x}_{\text{hs}, i})+\beta_2(x_{\text{IQ},i}-\bar{x}_{\text{IQ}})+\epsilon_i,\qquad \quad i = 1,\cdots, n \]</span></p>
<p>We would like to get the posterior distributions of the coefficients <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, and <span class="math inline">\(\beta_2\)</span> under this model. Recall that the reference prior imposes a uniformly flat prior distribution on coefficients <span class="math inline">\(p(\beta_0, \beta_1, \beta_2~|~M)\propto 1\)</span> and that <span class="math inline">\(p(\sigma^2~|~M) \propto 1/\sigma^2\)</span>, so together the joint prior distribution <span class="math inline">\(p(\beta_0, \beta_1, \beta_2, \sigma^2~|~M)\)</span> is proportional to <span class="math inline">\(1/\sigma^2\)</span>. When the sample size <span class="math inline">\(n\)</span> is large, any proper prior distribution <span class="math inline">\(p(\beta_0, \beta_1, \beta_2, \sigma^2~|~M)\)</span> is getting flatter and flatter, which can be approximated by the reference prior. At the same time, the log of marginal likelihood <span class="math inline">\(\ln(p(\text{data}~|~M))\)</span> can be approximated by the BIC. Therefore, we use <code>prior = "BIC"</code> in the <code>bas.lm</code> function when we use the BIC as an approximation of the log of marginal likelihood under the reference prior. The posterior mean of <span class="math inline">\(\beta_0\)</span> in the result is the sample mean of the kids’ cognitive scores, or <span class="math inline">\(\bar{Y}_{\text{score}}\)</span>, since we have centered the model.</p>
<pre class="r"><code># Fit the best BIC model by imposing which variables to be used using the indicators
cog.bestBIC = bas.lm(kid_score ~ ., data = cognitive,
                     prior = &quot;BIC&quot;, n.models = 1,  # We only fit 1 model
                     bestmodel = bestgamma,  # We use bestgamma to indicate variables 
                     modelprior = uniform())

# Retrieve coefficients information
cog.coef = coef(cog.bestBIC)

# Retrieve bounds of credible intervals
out = confint(cog.coef)[, 1:2]

# Combine results and construct summary table
coef.BIC = cbind(cog.coef$postmean, cog.coef$postsd, out)
names = c(&quot;post mean&quot;, &quot;post sd&quot;, colnames(out))
colnames(coef.BIC) = names
coef.BIC</code></pre>
<pre><code>##           post mean    post sd       2.5%      97.5%
## Intercept 86.797235 0.87054033 85.0862025 88.5082675
## hs         5.950117 2.21181218  1.6028370 10.2973969
## IQ         0.563906 0.06057408  0.4448487  0.6829634
## work       0.000000 0.00000000  0.0000000  0.0000000
## age        0.000000 0.00000000  0.0000000  0.0000000</code></pre>
<p>Comparing the coefficients in the best model with the ones in the full model (which can be found in Section <a href="#sec:Bayes-multiple-regression"><strong>??</strong></a>), we see that the 95% credible interval for <code>IQ</code> variable is the same. However, the credible interval for high school status <code>hs</code> has shifted slightly to the right, and it is also slighly narrower, meaning a smaller posterior standard deviation. All credible intervals of coefficients exclude 0, suggesting that we have found a parsimonious model.<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a></p>
</div>
<div id="other-criteria" class="section level3">
<h3>Other Criteria</h3>
<p>BIC is one of the criteria based on penalized likelihoods. Other examples such as AIC (Akaike information criterion) or adjusted <span class="math inline">\(R^2\)</span>, employ the form of
<span class="math display">\[ -2\ln(\widehat{\text{likelihood}}) + (p+1)\times\text{some constant},\]</span>
where <span class="math inline">\(p\)</span> is the number of predictor variables and “some constant” is a constant value depending on different criteria. BIC tends to select parsimonious models (with fewer predictor variables) while AIC and adjusted <span class="math inline">\(R^2\)</span> may include variables that are not statistically significant, but may do better for predictions.</p>
<p>Other Bayesian model selection decisions may be based on selecting models with the highest posterior probability. If predictions are important, we can use decision theory to help pick the model with the smallest expected prediction error. In addiciton to goodness of fit and parsimony, loss functions that include costs associated with collecting variables for predictive models may be of important consideration.
## Bayesian Model Uncertainty {#sec:BMU}</p>
<p>In the last section, we discussed how to use Bayesian Information Criterion (BIC) to pick the best model, and we demonstrated the method on the kid’s cognitive score data set. However, we may often have several models with similar BIC. If we only pick the one with the lowest BIC, we may ignore the presence of other models that are equally good or can provide useful information. The credible intervals of coefficients may be narrower since the uncertainty is being ignored when we consider only one model. Narrower intervals are not always better if they miss the true values of the parameters. To account for the uncertainty, getting the posterior probability of all possible models is necessary. In this section, we will talk about how to convert BIC into Bayes factor to find the posterior probability of all possible models. We will again use the <code>BAS</code> package in R to achieve this goal.</p>
</div>
<div id="model-uncertainty" class="section level3">
<h3>Model Uncertainty</h3>
<p>When forecasting the path of a hurricane, having an accurate prediction and measurement of uncertainty is important for early warning. In this case, we would consider the probability of several potential paths that the hurricane may make landfall. Similar to hurricane forecasting, we would also like to obtain the posterior probability of all possible models for uncertainty measurement.</p>
<p>To represent model uncertainty, we need to construct a probability distribution over all possible models where the each probability provides measure of how likely the model is to happen.</p>
<p>Suppose we have a multiple linear regression
<span class="math display">\[ y_i = \beta_0+\beta_1(x_{1,i} - \bar{x}_1)+\beta_2(x_{2,i} - \bar{x}_2)+\cdots+\beta_p(x_{p,i}-\bar{x}_p)+\epsilon_i, \quad 1\leq i \leq n,\]</span>
with <span class="math inline">\(p\)</span> predictor variables <span class="math inline">\(x_1,\cdots, x_p\)</span>. There are in total <span class="math inline">\(2^p\)</span> different models, corresponding to <span class="math inline">\(2^p\)</span> combinations of variable selections. there are 2 possibilities for each variable: either getting selected or not, and we have in total <span class="math inline">\(p\)</span> variables. We denote each model as <span class="math inline">\(M_m,\ m=1,\cdots,2^p\)</span>. To obtian the posterior probability of each model <span class="math inline">\(p(M_m~|~\text{data})\)</span>, Bayes’ rule tells that that we need to assign the prior probability <span class="math inline">\(p(M_m)\)</span> to each model, and to then obtain the marginal likelihood of each model <span class="math inline">\(p(\text{data}~|~M_m)\)</span>. By Bayes’ rule, we update the posterior probability of each model <span class="math inline">\(M_m\)</span> after seeing the date, via marginal likelihood of model <span class="math inline">\(M_m\)</span>:</p>
<p><span class="math display" id="eq:model-post-prob">\[\begin{equation} 
p(M_m~|~\text{data}) = \frac{\text{marginal likelihood of }M_m\times p(M_m)}{\sum_{j=1}^{2^p}\text{marginal likelihood of }M_j\times p(M_j)} = \frac{p(\text{data}~|~M_m)p(M_m)}{\sum_{j=1}^{2^p}p(\text{data}~|~M_j)p(M_j)}. 
\tag{23} 
\end{equation}\]</span></p>
<p>The marginal likelihood <span class="math inline">\(p(\text{data}~|~M_m)\)</span> of each model <span class="math inline">\(M_m\)</span> serves to reweight the prior probability <span class="math inline">\(p(M_m)\)</span>, so that models with higher likelihoods have larger weights, and models with lower likelihoods receive smaller weights. We renormalize this weighted prior probability by dividing it by the sum <span class="math inline">\(\displaystyle \sum_{j=1}^{2^p}p(\text{data}~|~M_j)p(M_j)\)</span> to get the posterior probability of each model.</p>
<p>Recall that the prior odd between two models <span class="math inline">\(M_1\)</span> and <span class="math inline">\(M_2\)</span> is defined to be</p>
<p><span class="math display">\[
\text{Odd}[M_1:M_2] =  \frac{p(M_1)}{p(M_2)},
\]</span>
and the Bayes factor is defined to be the ratio of the likelihoods of two models
<span class="math display">\[ \text{BF}[M_1:M_2] = \frac{p(\text{data}~|~M_1)}{p(\text{data}~|~M_2)}. \]</span></p>
<p>Suppose we have chosen a base model <span class="math inline">\(M_b\)</span>, we may divide both the numerator and the denominator of the formula <a href="#eq:model-post-prob">(23)</a> by <span class="math inline">\(p(\text{data}~|~M_b)\times p(M_b)\)</span>. This gives us a new formula to calculate the posterior probability of model <span class="math inline">\(M_m\)</span> based on the prior odd and the Bayes factor. In this new formula, we can see that the evidence from the data in the Bayes factor <span class="math inline">\(\text{BF}[M_j:M_b],\ j=1,\cdots, 2^p\)</span> serve to upweight or downweight the prior odd <span class="math inline">\(\text{Odd}[M_j:M_b],\ j=1,\cdots,2^p\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
p(M_m~|~\text{data}) = &amp; \frac{p(\text{data}~|~M_m)\times p(M_m)/(p(\text{data}~|~M_b)\times p(M_b))}{\sum_{j=1}^{2^p}(p(\text{data}~|~M_j)\times p(M_j))/(p(\text{data}~|~M_b)\times p(M_b))} \\
 &amp; \\
= &amp; \frac{[p(\text{data}~|~M_m)/p(\text{data}~|~M_b)]\times[p(M_m)/p(M_b)]}{\sum_{j=1}^{2^p}[p(\text{data}~|~M_j)/p(\text{data}~|~M_b)]\times[p(M_j)/p(M_b)]}\\
  &amp; \\
= &amp; \frac{\text{BF}[M_m:M_b]\times \text{Odd}[M_m:M_b]}{\sum_{j=1}^{2^p}\text{BF}[M_j:M_b]\times \text{Odd}[M_j:M_b]}.
\end{aligned}
\]</span>
Any model can be used as the base model <span class="math inline">\(M_b\)</span>. It could be the model with the highest posterior probability, or the null model <span class="math inline">\(M_0\)</span> with just the intercept <span class="math inline">\(y_i = \beta_0+\epsilon_i\)</span>.</p>
<p>Using BIC, we can approximate the Bayes factor between two models by their OLS <span class="math inline">\(R\)</span>-squared’s and the numbers of predictors used in the models, when we have large sample of data. This provides a much easier way to approximate the posterior probability of models since obtaining <span class="math inline">\(R^2\)</span> can be done by the usual OLS linear regression. Recall that in Section <a href="#sec:BIC"><strong>??</strong></a>, we provided the fact that BIC of any model <span class="math inline">\(M_m\)</span> (denoted as <span class="math inline">\(\text{BIC}_m\)</span>) is an asymptotic approximation of the log of marginal likelihood of <span class="math inline">\(M_m\)</span> when the sample size <span class="math inline">\(n\)</span> is large (Equation <a href="#eq:BIC-approx">(21)</a>)
<span class="math display">\[ \text{BIC}_m \approx -2 \ln(\text{marginal likelihood}) = -2\ln(p(\text{data}~|~M_m)). \]</span></p>
<p>Using this fact, we can approximate Bayes factor between two models by their BICs
<span class="math display">\[ \text{BF}[M_1:M_2] = \frac{p(\text{data}~|~M_1)}{p(\text{data}~|~M_2)} \approx \frac{\exp(-\text{BIC}_1/2)}{\exp(-\text{BIC}_2/2)}=\exp\left(-\frac{1}{2}(\text{BIC}_1-\text{BIC}_2)\right).\]</span></p>
<p>We also know that BIC can be calculated by the OLS <span class="math inline">\(R^2\)</span> and the number of predictors <span class="math inline">\(p\)</span> from Equation <a href="#eq:BIC-new">(22)</a> in Section <a href="#sec:BIC"><strong>??</strong></a>
<span class="math display">\[ \text{BIC} = n\ln(1-R^2) + (p+1)\ln(n) + \text{constant}. \]</span>
(We usually ignore the constant in the last term since it does not affect the difference betweeen two BICs.)</p>
<p>Using this formula, we can approximate Bayes factor between model <span class="math inline">\(M_1\)</span> and <span class="math inline">\(M_2\)</span> by their corresponding <span class="math inline">\(R\)</span>-squared’s and the numbers of predictors
<span class="math display" id="eq:BF-Rsquared">\[\begin{equation}
\text{BF}[M_1:M_2]\approx \left(\frac{1-R_1^2}{1-R_2^2}\right)^{\frac{n}{2}}\times n^{\frac{p_1-p_2}{2}}.
\tag{24}
\end{equation}\]</span></p>
<p>As for the null model <span class="math inline">\(M_0:\ y_i = \beta_0+\epsilon_i\)</span>, <span class="math inline">\(R_0^2 = 0\)</span> and <span class="math inline">\(p_0=0\)</span>. Equation <a href="#eq:BF-Rsquared">(24)</a> can be further simplified as
<span class="math display">\[ \text{BF}[M_m:M_0] = (1-R_m^2)^{\frac{n}{2}}\times n^{\frac{p_m}{2}}. \]</span></p>
</div>
<div id="calculating-posterior-probability-in-r" class="section level3">
<h3>Calculating Posterior Probability in R</h3>
<p>Back to the kid’s cognitive score example, we will see how the summary of results using <code>bas.lm</code> tells us about the posterior probability of all possible models.</p>
<pre class="r"><code># Load the library in order to read in data from website
library(foreign)    

# Read in cognitive score data set and process data tranformations
cognitive = read.dta(&quot;http://www.stat.columbia.edu/~gelman/arm/examples/child.iq/kidiq.dta&quot;)

cognitive$mom_work = as.numeric(cognitive$mom_work &gt; 1)
cognitive$mom_hs =  as.numeric(cognitive$mom_hs &gt; 0)
colnames(cognitive) = c(&quot;kid_score&quot;, &quot;hs&quot;,&quot;IQ&quot;, &quot;work&quot;, &quot;age&quot;)</code></pre>
<p>Suppose we have already loaded the data and pre-processed the columns <code>mom_work</code> and <code>mom_hs</code> using <code>as.numeric</code> function, as what we did in the last section. To represent model certainty, we construct the probability distribution overall possible 16 (=<span class="math inline">\(2^4\)</span>) models where each probability <span class="math inline">\(p(M_m)\)</span> provides a measure of how likely the model <span class="math inline">\(M_m\)</span> is. Inside the <code>bas.lm</code> function, we first specify the full model, which in this case is the <code>kid_score</code>, being regressed by all predictors: mother’s high school status <code>hs</code>, mother’s IQ <code>IQ</code>, mother’s work status <code>work</code> and mother’s age <code>age</code>. We take the <code>data = cognitive</code> in the next argument. For the prior distribution of the coefficients for calculating marginal likelihoods, we use <code>prior = "BIC"</code> to approximate the marginal likelihood <span class="math inline">\(p(\text{data}~|~M_m)\)</span>. We then use <code>modelprior = uniform()</code> in the argument to assign equal prior probability <span class="math inline">\(p(M_m),\ m=1,\cdots, 16\)</span> to all 16 models. That is, <span class="math inline">\(\displaystyle p(M_m) = \frac{1}{16}\)</span>.</p>
<pre class="r"><code># Import libary
library(BAS)

# Use `bas.lm` for regression
cog_bas = bas.lm(kid_score ~ hs + IQ + work + age, 
                 data = cognitive, prior = &quot;BIC&quot;,
                 modelprior = uniform())</code></pre>
<p><code>cog_bas</code> is a <code>bas</code> object. The usual <code>print</code>, <code>summary</code>, <code>plot</code>, <code>coef</code>, <code>fitted</code>, <code>predict</code> functions are available and can be used on <code>bas</code> objects similar to <code>lm</code> objects created by the usual <code>lm</code> function. From calling</p>
<pre class="r"><code>names(cog_bas)</code></pre>
<pre><code>##  [1] &quot;probne0&quot;        &quot;which&quot;          &quot;logmarg&quot;        &quot;postprobs&quot;     
##  [5] &quot;priorprobs&quot;     &quot;sampleprobs&quot;    &quot;mse&quot;            &quot;mle&quot;           
##  [9] &quot;mle.se&quot;         &quot;shrinkage&quot;      &quot;size&quot;           &quot;R2&quot;            
## [13] &quot;rank&quot;           &quot;rank_deficient&quot; &quot;n.models&quot;       &quot;namesx&quot;        
## [17] &quot;n&quot;              &quot;prior&quot;          &quot;modelprior&quot;     &quot;alpha&quot;         
## [21] &quot;probne0.RN&quot;     &quot;postprobs.RN&quot;   &quot;include.always&quot; &quot;df&quot;            
## [25] &quot;n.vars&quot;         &quot;Y&quot;              &quot;X&quot;              &quot;mean.x&quot;        
## [29] &quot;call&quot;           &quot;xlevels&quot;        &quot;terms&quot;          &quot;model&quot;</code></pre>
<p>one can see the outputs and analyses that we can extract from a <code>bas</code> object.</p>
<p>The <code>bas</code> object takes the <code>summary</code> method</p>
<pre class="r"><code>round(summary(cog_bas), 3)</code></pre>
<pre><code>##           P(B != 0 | Y)   model 1   model 2   model 3   model 4   model 5
## Intercept         1.000     1.000     1.000     1.000     1.000     1.000
## hs                0.611     1.000     0.000     0.000     1.000     1.000
## IQ                1.000     1.000     1.000     1.000     1.000     1.000
## work              0.112     0.000     0.000     1.000     1.000     0.000
## age               0.069     0.000     0.000     0.000     0.000     1.000
## BF                   NA     1.000     0.562     0.109     0.088     0.061
## PostProbs            NA     0.529     0.297     0.058     0.046     0.032
## R2                   NA     0.214     0.201     0.206     0.216     0.215
## dim                  NA     3.000     2.000     3.000     4.000     4.000
## logmarg              NA -2583.135 -2583.712 -2585.349 -2585.570 -2585.939</code></pre>
<p>The summary table shows us the following information of the top 5 models</p>
<table>
<colgroup>
<col width="22%" />
<col width="77%" />
</colgroup>
<thead>
<tr class="header">
<th>Item</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>P(B!=0 | Y)</code></td>
<td>Posterior inclusion probability (pip) of each coefficient under data <span class="math inline">\(Y\)</span></td>
</tr>
<tr class="even">
<td><code>0</code> or <code>1</code> in the column</td>
<td>indicator of whether the variable is included in the model</td>
</tr>
<tr class="odd">
<td><code>BF</code></td>
<td>Bayes factor <span class="math inline">\(\text{BF}[M_m:M_b]\)</span>, where <span class="math inline">\(M_b\)</span> is the model with highest posterior probability</td>
</tr>
<tr class="even">
<td><code>PostProbs</code></td>
<td>Posterior probability of each model</td>
</tr>
<tr class="odd">
<td><code>R2</code></td>
<td><span class="math inline">\(R\)</span>-squared in the ordinary least square (OLS) regression</td>
</tr>
<tr class="even">
<td><code>dim</code></td>
<td>Number of variables (including the intercept) included in the model</td>
</tr>
<tr class="odd">
<td><code>logmarg</code></td>
<td>Log of marginal likelihood of the model, which is approximately <span class="math inline">\(-\displaystyle\frac{1}{2}\text{BIC}\)</span></td>
</tr>
</tbody>
</table>
<p><br/></p>
<pre class="r"><code>cog_prob = sort(cog_bas$postprobs)</code></pre>
<p>All top 5 models suggest to exclude <code>age</code> variable and include <code>IQ</code> variable. The first model includes intercept <span class="math inline">\(\beta_0\)</span> and only <code>hs</code> and <code>IQ</code>, with a posterior probability of about 0. The model with the 2nd highest posterior probability, which includes only the intercept and the variable <code>IQ</code>, has posterior probability of about 0. These two models compose of total posterior probability of about 0, leaving only 1 posterior probability to the remaining 14 models.</p>
<p>Using the <code>print</code> method, we obtain the marginal posterior inclusion probability (pip) <span class="math inline">\(p(\beta_j\neq 0)\)</span> of each variable <span class="math inline">\(x_j\)</span>.</p>
<!--

```r
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy = F)
```
-->
<pre class="r"><code>print(cog_bas)</code></pre>
<pre><code>## 
## Call:
## bas.lm(formula = kid_score ~ hs + IQ + work + age, data = cognitive, 
##     prior = &quot;BIC&quot;, modelprior = uniform())
## 
## 
##  Marginal Posterior Inclusion Probabilities: 
## Intercept         hs         IQ       work        age  
##   1.00000    0.61064    1.00000    0.11210    0.06898</code></pre>
</div>
<div id="bayesian-model-averaging" class="section level2">
<h2>Bayesian Model Averaging</h2>
<p>In the last section, we explored model uncertainty using posterior probability of models based on BIC. In this section, we will continue the kid’s cognitive score example to see how to obtain an Bayesian model averaging results using model posterior probability.</p>
<div id="visualizing-model-uncertainty" class="section level3">
<h3>Visualizing Model Uncertainty</h3>
<p>Recall that in the last section, we used the <code>bas.lm</code> function in the <code>BAS</code> package to obtain posterior probability of all models in the kid’s cognitive score example.
<span class="math display">\[ \text{score} ~\sim~ \text{hq} + \text{IQ} + \text{work} + \text{age} \]</span></p>
<p>We have found the posterior distribution under model uncertainty using all possible combinations of the predictors, the mother’s high school status <code>hs</code>, mother’s IQ score <code>IQ</code>, whether the mother worked during the first three years of the kid’s life <code>work</code>, and mother’s age <code>age</code>. With 4 predictors, there are <span class="math inline">\(2^4 = 16\)</span> possible models. In general, for linear regression model with <span class="math inline">\(p\)</span> predictor variables
<span class="math display">\[ y_i = \beta_0+\beta_1(x_{p,i}-\bar{x}) + \cdots + \beta_p(x_{p,i}-\bar{x}_p)+\epsilon_i,\qquad i = 1, \cdots,n,\]</span>
there will be in total <span class="math inline">\(2^p\)</span> possible models.</p>
<p>We can also visualize model uncertainty from the <code>bas</code> object <code>cog_bas</code> that we generated in the previous section.</p>
<pre class="r"><code># Load the library in order to read in data from website
library(foreign)    

# Read in cognitive score data set and process data tranformations
cognitive = read.dta(&quot;http://www.stat.columbia.edu/~gelman/arm/examples/child.iq/kidiq.dta&quot;)

cognitive$mom_work = as.numeric(cognitive$mom_work &gt; 1)
cognitive$mom_hs =  as.numeric(cognitive$mom_hs &gt; 0)
colnames(cognitive) = c(&quot;kid_score&quot;, &quot;hs&quot;,&quot;IQ&quot;, &quot;work&quot;, &quot;age&quot;)

library(BAS)
cog_bas = bas.lm(kid_score ~ hs + IQ + work + age, 
                 data = cognitive,
                 prior = &quot;BIC&quot;,
                 modelprior = uniform())</code></pre>
<p>In R, the image function may be used to create an image of the model space that looks like a crossword puzzle.</p>
<pre class="r"><code>image(cog_bas, rotate = F)</code></pre>
<p><img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/visualize-1.svg" width="576" /></p>
<p>To obtain a clearer view for model comparison, we did not rotate the image. Here, the predictors, including the intercept, are on the <span class="math inline">\(y\)</span>-axis, while the <span class="math inline">\(x\)</span>-axis corresponds to each different model. Each vertical column corresponds to one model. For variables that are not included in one model, they will be represented by black blocks. For example, model 1 includes the intercept, <code>hs</code>, and <code>IQ</code>, but not <code>work</code> or <code>age</code>. These models are ordered according to the log of posterior odd over the null model (model with only the intercept). The log of posterior odd is calculated as
<span class="math display">\[\ln(\PO[M_m:M_0]) = \ln (\text{BF}[M_m:M_0]\times \text{Odd}[M_m:M_0]).\]</span>
Since we assing same prior probability for all models, <span class="math inline">\(\text{O}[M_m:M_0] = 1\)</span> and therefore, the log of posterior odd is the same as the log of the Bayes factor. The color of each column is proportional to the log of the posterior probability. Models with same colors have similar posterior probabilities. This allows us to view models that are clustered together, when the difference within a cluster is not worth a bare mention.</p>
<p>If we view the image by rows, we can see whether one variable is included in a particular model. For each variable, there are only 8 models in which it will appear. For example, we see that <code>IQ</code> appears in all the top 8 models with larger posterior probabilities, but not the last 8 models. The <code>image</code> function shows up to 20 models by default.</p>
</div>
<div id="bayesian-model-averaging-using-posterior-probability" class="section level3">
<h3>Bayesian Model Averaging Using Posterior Probability</h3>
<p>Once we have obtained the posterior probability of each model, we can make inference and obtain weighted averages of quantities of interest using these probabilities as weights. Models with higher posterior probabilities receive higher weights, while models with lower posterior probabilities receive lower weights. This gives the name “Bayesian Model Averaging” (BMA). For example, the probability of the next prediction <span class="math inline">\(\hat{Y}^*\)</span> after seeing the data can be calculated as a “weighted average” of the prediction of next observation <span class="math inline">\(\hat{Y}^*_j\)</span> under each model <span class="math inline">\(M_j\)</span>, with the posterior probability of <span class="math inline">\(M_j\)</span> being the “weight”
<span class="math display">\[ \hat{Y}^* = \sum_{j=1}^{2^p}\hat{Y}^*_j\ p(M_j~|~\text{data}). \]</span></p>
<p>In general, we can use this weighted average formula to obtain the value of a quantity of interest <span class="math inline">\(\Delta\)</span>. <span class="math inline">\(\Delta\)</span> can <span class="math inline">\(Y^*\)</span>, the next observation; <span class="math inline">\(\beta_j\)</span>, the coefficient of variable <span class="math inline">\(X_j\)</span>; <span class="math inline">\(p(\beta_j~|~\text{data})\)</span>, the posterior probability of <span class="math inline">\(\beta_j\)</span> after seeing the data. The posterior probability of <span class="math inline">\(\Delta\)</span> seeing the data can be calculated using the formula</p>
<p><span class="math display" id="eq:general">\[\begin{equation} 
p(\Delta~|~\text{data}) = \sum_{j=1}^{2^p}p(\Delta~|~ M_j,\ \text{data})p(M_j~|~\text{data}).
\tag{25}
\end{equation}\]</span></p>
<p>This formula is similar to the one we have seen in Week 2 lecture <strong>Predictive Inference</strong> when we used posterior probability of two different success rates of getting the head in a coin flip to calculate the predictive probability of getting heads in <strong>future</strong> coin flips. Recall in that example, we have two competing hypothese, that the success rate (also known as the probability) of getting heads in coin flips, are
<span class="math display">\[ H_1: p = 0.7,\qquad \text{vs}\qquad H_2: p=0.4.\]</span></p>
<p>We calcualted the posterior probability of each success rate. They are
<span class="math display">\[ 
\begin{aligned}
P(p=0.7~|~\text{data})= &amp; P(H_1~|~\text{data})= p^* = 0.754,\\
P(p=0.4~|~\text{data}) = &amp; P(H_2~|~\text{data}) = 1-p^* = 0.246.
\end{aligned}
\]</span></p>
<p>We can use these two probabilities to calculate the posterior probability of getting head in the next coin flip
<span class="math display" id="eq:example">\[\begin{equation}
P(\text{head}~|~\text{data}) = P(\text{head}~|~H_1,\text{data})P(H_1~|~\text{data}) + P(\text{head}~|~H_2,\text{data})P(H_2~|~\text{data}).
\tag{26}
\end{equation}\]</span></p>
<p>We can see that equation <a href="#eq:example">(26)</a> is just a special case of the general equation <a href="#eq:general">(25)</a> when the posterior probability of hypotheses <span class="math inline">\(P(H_1~|~\text{data})\)</span> and <span class="math inline">\(P(H_2~|~\text{data})\)</span> serve as weights.</p>
<p>Moreover, the expected value of <span class="math inline">\(\Delta\)</span> can also be obtained by a weighted average formula of expected values on each model, using conditional probability</p>
<p><span class="math display">\[ E[\Delta~|~\text{data}] = \sum_{j=1}^{2^p}E[\Delta~|~M_j,\ \text{data}]p(M_j~|~\text{data}).\]</span></p>
<p>Since the weights <span class="math inline">\(p(M_j~|~\text{data})\)</span> are probabilities and have to sum to one, if the best model had posterior probability one, all of the weights would be placed on that single best model. In this case, using BMA would be equivalent to selecting the best model with the highest posterior probability. However, if there are several models that receive substantial probability, they would all be included in the inference and account for the uncertainty about the true model.</p>
</div>
<div id="coefficient-summary-under-bma" class="section level3">
<h3>Coefficient Summary under BMA</h3>
<p>We can obtain the coefficients by the <code>coef</code> function.</p>
<pre class="r"><code>cog_coef = coef(cog_bas)
cog_coef</code></pre>
<pre><code>## 
##  Marginal Posterior Summaries of Coefficients: 
## 
##  Using  BMA 
## 
##  Based on the top  16 models 
##            post mean  post SD   post p(B != 0)
## Intercept  86.79724    0.87287   1.00000      
## hs          3.59494    3.35643   0.61064      
## IQ          0.58101    0.06363   1.00000      
## work        0.36696    1.30939   0.11210      
## age         0.02089    0.11738   0.06898</code></pre>
<p>Under Bayesian model averaging, the table above provides the posterior mean, the posterior standard deviation, and the posterior inclusion probability (pip) of each coefficient. The posterior mean of the coefficient <span class="math inline">\(\hat{\beta}_j\)</span> under BMA would be used for future predictions. The posterior standard deviation <span class="math inline">\(\text{se}_{\beta_j}\)</span> provides measure of variability of the coefficient <span class="math inline">\(\beta_j\)</span>. An approximate range of plausible values for each of the coefficients may be obtained via the empirical rule
<span class="math display">\[ (\hat{\beta}_j-\text{critical value}\times \text{se}_{\beta_j},\  \hat{\beta}_j+\text{critical value}\times \text{se}_{\beta_j}).\]</span></p>
<p>However, this only applies if the posterior distribution is symmetric or unimodal.</p>
<p>The posterior mean of the intercept, <span class="math inline">\(\hat{\beta}_0\)</span>, is obtained after we have centered the variables. We have discussed the effect of centering the model. One of the advantage of doing so is that the intercept <span class="math inline">\(\beta_0\)</span> represents the sample mean of the observed response <span class="math inline">\(Y\)</span>. Under the reference prior, the point estimate of the intercept <span class="math inline">\(\hat{\beta}_0\)</span> is exactly the mean <span class="math inline">\(\bar{Y}\)</span>.</p>
<p>We see that the posterior mean, standard deviation and inclusion probability are slightly different than the ones we obtained in Section <a href="#sec:Bayes-multiple-regression"><strong>??</strong></a> when we forced the model to include all variables. Under BMA, <code>IQ</code> has posterior inclusion probability 1, suggesting that it is very likely that <code>IQ</code> should be included in the model. <code>hs</code> also has a high posterior inclusion probability of about 0.61. However, the posterior inclusion probability of mother’s work status <code>work</code> and mother’s age <code>age</code> are relatively small compared to <code>IQ</code> and <code>hs</code>.</p>
<p>We can also <code>plot</code> the posterior distributions of these coefficients to take a closer look at the distributions</p>
<pre class="r"><code>par(mfrow = c(2, 2))
plot(cog_coef, subset = c(2:5))</code></pre>
<p><img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/plot-dis-1.svg" width="576" /></p>
<p>This plot agrees with the summary table we obtained above, which shows that the posterior probability distributions of <code>work</code> and <code>age</code> have a very large point mass at 0, while the distribution of <code>hs</code> has a relatively small mass at 0. There is a slighly little tip at 0 for the variable <code>IQ</code>, indicating that the posterior inclusion probability of <code>IQ</code> is not exactly 1. However, since the probability mass for <code>IQ</code> to be 0 is so small, that we are almost certain that <code>IQ</code> should be included under Bayesian model averaging.</p>
</div>
</div>
<div id="summary-3" class="section level2">
<h2>Summary</h2>
<p>In this chapter, we have discussed Bayesian model uncertainty and Bayesian model averaging. We have shown how Bayesian model averaging can be used to address model uncertainty using the ensemble of models for inference, rather than selecting a single model. We applied this to the kid’s cognitive score data set using <code>BAS</code> package in R. Here we illustrated the concepts using BIC and reference prior on the coefficients. In the next chapter, we will explore alternative priors for coefficients, taking into account the sensitivity of model selection to prior choices. We will also explore Markov Chain Monte Carlo algorithm for model sampling when the model space is too large for theoretical calculations.</p>
</div>
</div>
<div id="stochastic-explorations-using-mcmc" class="section level1">
<h1>8 Stochastic Explorations Using MCMC</h1>
<p>In this chapter, we will discuss stochastic explorations of the model space using Markov Chain Monte Carlo method. This is particularly usefull when the number of models in the model space is relatively large. We will introduce the idea and the algorithm that we apply on the kid’s cognitive score example. Then We will introduce some alternative priors for the coefficients other than the reference priors that we have been focused on. We will demonstrate using Markov Chain Monte Carlo on the crime data set to see how to use this stochastic method to explore the model space and how different priors may lead to different posterior inclusion probability of coefficients. Finally, we will summarize decision making strategies under Bayesian model uncertainty.## Stochastic Exploration</p>
<p>In the last chapter, we explored model uncertainty using posterior probability of each model and Bayesian model averaging based on BIC. We applied the idea on the kid’s cognitive score data set. With 4 predictors, we had <span class="math inline">\(2^4 = 16\)</span> possible models. Since the total number of models is relatively small, it is easy to enumerate all possible models to obtain Bayesian model averaging results. However, in general we often have data sets with large number of variables, which may lead to long computating time via enumeration. In this section, we will present one of the common stochastic methods, Markov Chain Monte Carlo (MCMC), to explore model spaces and implement Bayesian model averaging to estimate quantities of interest.</p>
<div id="markov-chain-monte-carlo-exploration" class="section level3">
<h3>Markov Chain Monte Carlo Exploration</h3>
<p>Let us assume that we have a pseudo population of possible models that we obtained from all the possible combinations of regression models from the kid’s cognitive score example. We prepare the data set as in Section <a href="#sec:Bayes-multiple-regression"><strong>??</strong></a> and run <code>bas.lm</code> to obtain posterior probability of each model as we did in Section <a href="#sec:BMU"><strong>??</strong></a>.</p>
<pre class="r"><code># Data processing
library(foreign)
cognitive = read.dta(&quot;http://www.stat.columbia.edu/~gelman/arm/examples/child.iq/kidiq.dta&quot;)
cognitive$mom_work = as.numeric(cognitive$mom_work &gt; 1)
cognitive$mom_hs =  as.numeric(cognitive$mom_hs &gt; 0)
colnames(cognitive) = c(&quot;kid_score&quot;, &quot;hs&quot;,&quot;IQ&quot;, &quot;work&quot;, &quot;age&quot;) 

# Run regression
library(BAS)
cog_bas = bas.lm(kid_score ~ hs + IQ + work + age,
                prior = &quot;BIC&quot;,
                modelprior = uniform(),
                data = cognitive)</code></pre>
<p>We will use this example to explore the idea of MCMC and generalize it to regression models with much larger model spaces. To explore the models, we may arrange them by their model sizes, the number of predictors plus the intercept, on the <span class="math inline">\(x\)</span>-axis, and their posterior probabilities on the <span class="math inline">\(y\)</span>-axis.</p>
<pre class="r"><code>library(ggplot2)

# Construct data frame for plotting
output = data.frame(model.size = cog_bas$size, model.prob = cog_bas$postprobs)

# Plot model size vs mode posterior probability
ggplot(data = output, aes(x = model.size, y = model.prob)) +
  geom_point(color = &quot;blue&quot;, pch = 17, size = 3) +
  xlab(&quot;model size&quot;) + ylab(&quot;model posterior probability&quot;)</code></pre>
<p><img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/model-space2-1.svg" width="70%" style="display: block; margin: auto;" /></p>
<p>We could then take a sample from this population of models with replacement (therefore, some models may be selected more than once in this sample). This process could be done using the <code>sample</code> function in R. We hope that the frequency of appearance of a model would be a good approximation of the posterior probability of this model. We use <span class="math inline">\(I(M_j = M_m)\)</span> as the indicator function to indicate that the current model <span class="math inline">\(M_j\)</span> we sample is the model of interest <span class="math inline">\(M_m\)</span>, that is
<span class="math display">\[ I(M_j=M_m) = \left\{\begin{array}{ll} 1, &amp; \text{if $M_j = M_m$} \\ 0, &amp; \text{if $M_j\neq M_m$}\end{array}\right. \]</span></p>
<p>Suppose we are going to sample <span class="math inline">\(J\)</span> models in total, we hope that
<span class="math display" id="eq:MCMC-formula">\[\begin{equation} 
p(M_m~|~\text{data}) \approx \frac{\sum_{j=1}^J I(M_j=M_m)}{J} = \sum_{j=1}^J \frac{I(M_j=M_m)}{J}.
\tag{27}
\end{equation}\]</span></p>
<p>After all, we would not need to calculate the model posterior probability <span class="math inline">\(P(M_m~|~\text{data})\)</span>. The quantity from the sampling <span class="math inline">\(\displaystyle \sum_{j=1}^J\frac{I(M_j=M_m)}{J}\)</span> would provide a good approximation, which only requires simple counting.</p>
<p>In order to ensure that we would sample models with a probability that is equal to their posterior probability, or in a simpler way, proportional to the marginal likelihood times the prior probability <span class="math inline">\(p(\text{data}~|~M_m)\times p(M_m)\)</span>, we need to design a sampling method that replaces old models with new models when the posterior probability goes up, and keeps the old models when the posterior probability is not improved.</p>
<p>Here, we propose the Metropolis-Hastings algorithm. We start with an initial model <span class="math inline">\(M^{(0)}\)</span>. This could be any model we like in the model space. We start iterating over the entire model space, randomly pick the next model <span class="math inline">\(M^{*(1)}\)</span> and see whether this model improves the posterior probability. We use the notation <span class="math inline">\(M^{*(1)}\)</span> instead of <span class="math inline">\(M^{(1)}\)</span> because we are not sure whether we should include this model in our final sample, or we should consider other models. Therefore, we calculate the ratio between the posterior probability of the two models, the original model <span class="math inline">\(M^{(0)}\)</span>, and the proposed model <span class="math inline">\(M^{*(1)}\)</span>, which turns out to be the posterior odd between the two models
<span class="math display">\[ R=\frac{p(M^{*(1)}~|~\text{data})}{p(M^{(0)}~|~\text{data})}=\text{PO}[M^{*(1)}:M^{(0)}]. \]</span></p>
<p>Our goal is to avoid actually calculating the posterior probability of each model, so we instead would compute <span class="math inline">\(R\)</span> using the Bayes factor and the prior odd of the two models.
<span class="math display">\[ R=\frac{p(M^{*(1)}~|~\text{data})}{p(M^{(0)}~|~\text{data})}=\PO[M^{*(1)}:M^{(0)}]=\text{BF}[M^{*(1)}:M^{(0)}]\times \text{Odd}[M^{*(1)}:M^{(0)}]. \]</span></p>
<p>If <span class="math inline">\(R\geq 1\)</span>, that means <span class="math inline">\(M^{*(1)}\)</span> will surely improve the posterior probability after seeing the data compared to <span class="math inline">\(M^{(0)}\)</span>. So we would like to include <span class="math inline">\(M^{*(1)}\)</span> into our sample, because <span class="math inline">\(M^{*(1)}\)</span> deserves more occurrence. In this case, we set <span class="math inline">\(M^{*(1)}\)</span> to be <span class="math inline">\(M^{(1)}\)</span>, indicating that it is part of our final sample. However, if <span class="math inline">\(R&lt;1\)</span>, we are not that sure whether <span class="math inline">\(M^{*(1)}\)</span> should be in the sample. But we also do not want to only include models with higher posterior probabilities. Remember that the purpose of this algorithm is to reproduce the frequency of model occurance in the final sample so that the relative frequency of occurrence of each model could be a good proxy of its posterior probability. Even though the proposed model <span class="math inline">\(M^{*(1)}\)</span> has lower posterior probability, we should still have some representatives of this model in our final sample. Hence we set <span class="math inline">\(M^{*(1)}\)</span> to be <span class="math inline">\(M^{(1)}\)</span> with probability <span class="math inline">\(R\)</span>, reflecting the chance that this model would be in our sample is <span class="math inline">\(R\)</span>.</p>
<p>To include <span class="math inline">\(M^{*(1)}\)</span> in the final sample with probability <span class="math inline">\(R\)</span>, we may use a random number generator to generate number between 0 and 1 and see whether this number is larger than <span class="math inline">\(R\)</span>. Or we may set a coin flip with heads showing up with probability <span class="math inline">\(R\)</span>. If the random number is larger than <span class="math inline">\(R\)</span>, or the head shows up using the biased coin, we include this model. Otherwise, we neglect this proposed model and keep on selecting the next model.</p>
<p>Once the first model <span class="math inline">\(M^*{(1))}\)</span> is sampled, we move onto the second model <span class="math inline">\(M^{(2)}\)</span> with the same process. In general, after we have obtained model <span class="math inline">\(M^{(i)}\)</span>, we propose a model <span class="math inline">\(M^{*(i+1)}\)</span> and calculate the ratio of the posterior probabilities of the two models
<span class="math display">\[ R = \frac{p(M^{*(i+1)}~|~\text{data})}{p(M^{(i)}~|~\text{data})}=\text{BF}[M^{*(i+1)}:M^{(i)}]\times \text{Odd}[M^{*(i+1)}:M^{(i)}].\]</span>
If <span class="math inline">\(R\geq 1\)</span>, we unconditionally accept <span class="math inline">\(M^{*(i+1)}\)</span> to be our next model <span class="math inline">\(M^{(i)}\)</span>. If <span class="math inline">\(R&lt;1\)</span>, we accept <span class="math inline">\(M^{*(i+1)}\)</span> to be <span class="math inline">\(M^{(i)}\)</span> with probability <span class="math inline">\(R\)</span>.</p>
<p>After obtaining <span class="math inline">\(J\)</span> models, <span class="math inline">\(M^{(1)}, M^{(2)}, \cdots, M^{(J)}\)</span>, we can count how many models inside this sample is <span class="math inline">\(M_m\)</span>, the model we are interested. Then we use the formula <a href="#eq:MCMC-formula">(27)</a> to approximate the posterior probability of <span class="math inline">\(M_m\)</span>. These estimated probabilities can be used in model selection or BMA instead of the exact expressions.</p>
<p>We propose model randomly in the above algorithm, i.e., all models are equally likely to be proposed. This can be pretty inefficient if there are lots of models with low probabilities. We may come up with other ways to propose models. For example, we may look at neighboring models of our current model by either adding one predictor that is currently not in the model, or randomly dropping one of the current predictors from the model. We may flip a fair coin to decide whether to add or to drop. This forms a random walk across neighboring models. We may also propose to swap out a current predictor with one that is currently not in the model, which maintains the size of the model. This has the potential to take bigger jumps in the model space. There are other possible moves that can be designed to help move around over the model space. However, we have to be careful to adjust for any potential bias, due to how we propose new models, to ensure that the relative frequency eventually would converge to the posterior probability. In the lecture video, we have demonstrated the Markov Chain Monte Carlo method on the kid’s cognitive score using animation to show how each model was proposed and finally selected.</p>
</div>
<div id="other-priors-for-bayesian-model-uncertainty" class="section level2">
<h2>Other Priors for Bayesian Model Uncertainty</h2>
<p>So far, we have discussed Bayesian model selection and Bayesian model averaging using BIC. BIC is an asymptotic approximation of the log of marginal likelihood of models when the number of data points is large. Under BIC, prior distribution of <span class="math inline">\(\bv = (\beta_0, \beta_1,\cdots, \beta_p)^T\)</span> is uniformaly flat, which is the same as applying the reference prior on <span class="math inline">\(\bv\)</span> conditioning on <span class="math inline">\(\sigma^2\)</span>. In this section, we will introduce a new conjugate prior distribution, called the Zellner’s <span class="math inline">\(g\)</span>-prior. We will see that this prior leads to simple expressions for the Bayes factor, in terms of summary statistics from ordinary least square (OLS). We will talk about choosing the parameter <span class="math inline">\(g\)</span> in the prior and conduct a sensitivity analysis, using the kid’s cognitive score data that we used in earlier sections.</p>
<div id="zellners-g-prior" class="section level3">
<h3>Zellner’s <span class="math inline">\(g\)</span>-Prior</h3>
<p>To analyze the model more conveniently, we still stick with the “centered” regression model. Let <span class="math inline">\(y_1,\cdots,y_n\)</span> to be the observations of the response variable <span class="math inline">\(Y\)</span>. The multiple regression model is</p>
<p><span class="math display">\[ y_i = \beta_0 + \beta_1(x_{1,i}-\bar{x}_1) + \beta_2(x_{2, i}-\bar{x}_2)+\cdots +\beta_p(x_{p, i}-\bar{x}_p)+\epsilon_i, \quad 1\leq i\leq n.\]</span></p>
<p>As before, <span class="math inline">\(\bar{x}_1, \cdots,\bar{x}_p\)</span>, are the sample means of the variables <span class="math inline">\(X_1,\cdots,X_p\)</span>. Since we have centered all the variables, <span class="math inline">\(\beta_0\)</span> is no longer the <span class="math inline">\(y\)</span>-intercept. Instead, it is the sample mean of <span class="math inline">\(Y\)</span> when taking <span class="math inline">\(X_1=\bar{x}_1,\cdots, X_p=\bar{x}_p\)</span>. <span class="math inline">\(\beta_1,\cdots,\beta_p\)</span> are the coefficients for the <span class="math inline">\(p\)</span> variables. <span class="math inline">\(\bv=(\beta_0,\beta_1,\cdots,\beta_p)^T\)</span> is the vector notation representing all coefficients, including <span class="math inline">\(\beta_0\)</span>.</p>
<p>Under this model, we assume</p>
<p><span class="math display">\[ y_i~|~ \bv, \sigma^2~\iid~\No(\beta_0+\beta_1(x_{1,i}-\bar{x}_1)+\cdots+\beta_p(x_{p,i}-\bar{x}_p), \sigma^2), \]</span>
which is equivalent to
<span class="math display">\[ \epsilon_i~|~ \bv, \sigma^2 ~\iid~\No(0, \sigma^2). \]</span></p>
<p>We then specify the prior distributions for <span class="math inline">\(\beta_j,\ 0\leq j\leq p\)</span>. Zellner proposed a simple informative conjugate multivariate normal prior for <span class="math inline">\(\bv\)</span> conditioning on <span class="math inline">\(\sigma^2\)</span> as</p>
<p><span class="math display">\[ \bv~|~\sigma^2 ~\sim ~\No(\boldsymbol{b}_0, \Sigma = g\sigma^2\text{S}_{\text{BF}{xx}}^{-1}). \]</span></p>
<p>Here
<span class="math display">\[ \text{S}_{\text{BF}{xx}} = (\mathbf{X}-\bar{\mathbf X})^T(\mathbf X - \bar{\mathbf X}), \]</span></p>
<p>where the matrix <span class="math inline">\(\mathbf{X}-\bar{\mathbf X}\)</span> is
<span class="math display">\[ \mathbf{X}-\bar{\mathbf X} = \left(\begin{array}{cccc}
|  &amp; |  &amp; \cdots &amp; | \\
X_1-\bar{X}_1 &amp; X_2 - \bar{X}_2 &amp; \cdots &amp; X_p-\bar{X}_p \\
|  &amp; |  &amp; \cdots &amp; | 
\end{array}\right) = \left(\begin{array}{cccc}
x_{1, 1} - \bar{x}_1 &amp; x_{2, 1} - \bar{x}_2 &amp; \cdots &amp; x_{p, 1} - \bar{x}_p \\
\vdots &amp; \vdots &amp;  &amp; \vdots \\
x_{1, n} - \bar{x}_1 &amp; x_{2, n} - \bar{x}_2 &amp; \cdots &amp; x_{p, n} - \bar{x}_p
\end{array}
\right).
\]</span></p>
<p>When <span class="math inline">\(p=1\)</span>, this <span class="math inline">\(\text{S}_{\text{BF}{xx}}\)</span> simplifies to <span class="math inline">\(\displaystyle \text{S}_{\text{xx}} = \sum_{i=1}^n(x_{i}-bar{x})^2\)</span>, the sum of squares of a single variable <span class="math inline">\(X\)</span> that we used in Section <a href="#sec:simple-linear"><strong>??</strong></a>. In multiple regression, <span class="math inline">\(\text{S}_{\text{BF}{xx}}\)</span> provides the variance and covariance for OLS.</p>
<p>The parameter <span class="math inline">\(g\)</span> scales the prior variance of <span class="math inline">\(\bv\)</span>, over the OLS variances <span class="math inline">\(\sigma^2\text{S}_{\text{BF}{xx}}^{-1}\)</span>. One of the advantages of using this prior is ,that it reduces prior elicitation down to two components; the prior mean <span class="math inline">\(\boldsymbol{b}_0\)</span> and the scalar <span class="math inline">\(g\)</span>. We use <span class="math inline">\(g\)</span> to control the size of the variance of the prior, rather than set separate priors for all the variances and covariances (there would be <span class="math inline">\(p(p+1)/2\)</span> such priors for a <span class="math inline">\(p+1\)</span> dimensional multivariate normal distribution).</p>
<p>Another advantage of using Zellner’s <span class="math inline">\(g\)</span>-prior is that it leads to simple updating rules, like all conjugate priors. Moreover, the posterior mean and posterior variance have simple forms. The posterior mean is
<span class="math display">\[ \frac{g}{1+g}\hat{\bv} + \frac{1}{1+g}\boldsymbol{b}_0, \]</span>
where <span class="math inline">\(\hat{\bv}\)</span> is the frequentist OLS estimates of coefficients <span class="math inline">\(\bv\)</span>. The posterior variance is
<span class="math display">\[  \frac{g}{1+g}\sigma^2\text{S}_{\text{BF}{xx}}^{-1}. \]</span></p>
<p>From the posterior mean formula, we can see that the posterior mean is a weighted average of the prior mean <span class="math inline">\(\boldsymbol{b}_0\)</span> and the OLS estimate <span class="math inline">\(\hat{\bv}\)</span>. Since <span class="math inline">\(\displaystyle \frac{g}{1+g}\)</span> is strictly less than 1, Zellner’s <span class="math inline">\(g\)</span>-prior shrinks the OLS estimates <span class="math inline">\(\hat{\bv}\)</span> towards the prior mean <span class="math inline">\(\boldsymbol{b}_0\)</span>. As <span class="math inline">\(g\rightarrow \infty\)</span>, <span class="math inline">\(\displaystyle \frac{g}{1+g}\rightarrow 1\)</span> and <span class="math inline">\(\displaystyle \frac{1}{1+g}\rightarrow 0\)</span>, and we recover the OLS estimate as in the reference prior.</p>
<p>Similarly, the posterior variancc is a shrunken version of the OLS variance, by a factor of <span class="math inline">\(\displaystyle \frac{g}{1+g}\)</span>. The posterior distribution of <span class="math inline">\(\bv\)</span> conditioning on <span class="math inline">\(\sigma^2\)</span> is a normal distribution
<span class="math display">\[ \bv~|~\sigma^2, \text{data}~\sim~ \No(\frac{g}{1+g}\hat{\bv} + \frac{1}{1+g}\boldsymbol{b}_0,\ \frac{g}{1+g}\sigma^2\text{S}_{\text{BF}{xx}}^{-1}). \]</span></p>
</div>
<div id="bayes-factor-of-zellners-g-prior" class="section level3">
<h3>Bayes Factor of Zellner’s <span class="math inline">\(g\)</span>-Prior</h3>
<p>Because of this simplicity, Zellner’s <span class="math inline">\(g\)</span>-prior has been widely used in Bayesian model selection and Bayesian model averaging. One of the most popular versions uses the <span class="math inline">\(g\)</span>-prior for all coefficients except the intercept, and takes the prior mean to be the zero vector <span class="math inline">\(\boldsymbol{b}_0 = \text{BF}{0}\)</span>. If we are not testing any hypotheses about the intercept <span class="math inline">\(\beta_0\)</span>, we may combine this <span class="math inline">\(g\)</span>-prior with the reference prior for the intercept <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\sigma^2\)</span>, that is, we set
<span class="math display">\[ p(\beta_0, \sigma^2) \propto \frac{1}{\sigma^2}, \]</span>
and use the <span class="math inline">\(g\)</span>-prior for the rest of the coefficients <span class="math inline">\((\beta_1, \cdots, \beta_p)^T\)</span>.</p>
<p>Under this prior, the Bayes factor for comparing model <span class="math inline">\(M_m\)</span> to the null model <span class="math inline">\(M_0\)</span>, which only has the intercept, is simply
<span class="math display">\[ \text{BF}[M_m:M_0] = (1+g)^{(n-p_m-1)/2}(1+g(1-R_m^2))^{-(n-1)/2}. \]</span></p>
<p>Here <span class="math inline">\(p_m\)</span> is the number of predictors in <span class="math inline">\(M_m\)</span>, <span class="math inline">\(R_m^2\)</span> is the <span class="math inline">\(R\)</span>-squared of model <span class="math inline">\(M_m\)</span>.</p>
<p>With the Bayes factor, we can compare any two models using posterior odds. For example, we can compare model <span class="math inline">\(M_m\)</span> with the null model <span class="math inline">\(M_0\)</span> by
<span class="math display">\[ \frac{p(M_m~|~\text{data}, g)}{p(M_0~|~\text{data}, g)} = \PO[M_m:M_0] =  \text{BF}[M_m:M_0]\frac{p(M_m)}{p(M_0)}. \]</span></p>
<p>Now the question is, how do we pick <span class="math inline">\(g\)</span>? As we see that, the Bayes factor depends on <span class="math inline">\(g\)</span>. If <span class="math inline">\(g\rightarrow \infty\)</span>, <span class="math inline">\(\text{BF}[M_m:M_0]\rightarrow 0\)</span>. This provides overwhelming evidence against model <span class="math inline">\(M_m\)</span>, no matter how many predictors we pick for <span class="math inline">\(M_m\)</span> and the data. This is the Bartlett’s/Jeffrey-Lindley’s paradox.</p>
<p>On the other hand, if we use any arbitrary fixed value of <span class="math inline">\(g\)</span>, and include more and more predictors, the <span class="math inline">\(R\)</span>-squared <span class="math inline">\(R_m^2\)</span> will get closer and closer to 1, but the Bayes factor will remain bounded. With <span class="math inline">\(R_m^2\)</span> getting larger and larger, we would expect the alternative model <span class="math inline">\(M_m\)</span> would be supported. However, a bounded Bayes factor would not provide overwhelming support for <span class="math inline">\(M_m\)</span>, even in the frequentist approach we are getting better and better fit for the data. This is the information paradox, when the Bayes factor comes to a different conclusion from the frequentist approach due to the boundedness of Bayes factor in the limiting case.</p>
<p>There are some solutions which appear to lead to reasonable results in small and large samples based on empirical results with real data to theory, and provide resolution to these two paradoxes. In the following examples, we let the prior distribution of <span class="math inline">\(g\)</span> depend on <span class="math inline">\(n\)</span>, the size of the data. Since <span class="math inline">\(\text{S}_{\text{BF}{xx}}\)</span> is getting larger with larger <span class="math inline">\(n\)</span>, <span class="math inline">\(g\sigma^2\text{S}_{\text{BF}{xx}}^{-1}\)</span> may get balanced if <span class="math inline">\(g\)</span> also grows relatively to the size of <span class="math inline">\(n\)</span>.</p>
<p><strong>Unit Information Prior</strong></p>
<p>In the case of the unit information prior, we let <span class="math inline">\(g=n\)</span>. This is the same as saying <span class="math inline">\(\displaystyle \frac{n}{g}=1\)</span>. In this prior, we will only need to specify the prior mean <span class="math inline">\(\boldsymbol{b}_0\)</span> for the coefficients of the predicor variables <span class="math inline">\((\beta_1,\cdots,\beta_p)^T\)</span>.</p>
<p><strong>Zellner-Siow Cauchly Prior</strong></p>
<p>However, taking <span class="math inline">\(g=n\)</span> ignores the uncertainty of the choice of <span class="math inline">\(g\)</span>. Since we do not know <span class="math inline">\(g\)</span> a priori, we may pick a prior so that the expected value of <span class="math inline">\(\displaystyle \frac{n}{g}=1\)</span>. One exmaple is the Zellner-Siow cauchy prior. In this prior, we let
<span class="math display">\[ \frac{n}{g}~\sim~ \Ga(\frac{1}{2}, \frac{1}{2}). \]</span></p>
<p><strong>Hyper-<span class="math inline">\(g/n\)</span> Prior</strong></p>
<p>Another example is to set
<span class="math display">\[ \frac{1}{1+n/g}~\sim~ \Be(\frac{a}{2}, \frac{b}{2}), \]</span>
with hyperparameters <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>. Since the Bayes factor under this prior distribution can be expressed in terms of hypergeometric functions, this is called the hyper-<span class="math inline">\(g/n\)</span> prior.</p>
</div>
<div id="kids-cognitive-score-example" class="section level3">
<h3>Kid’s Cognitive Score Example</h3>
<p>We apply these priors on the kid’s cognitive score example and compare the posterior probability that each coefficient <span class="math inline">\(\beta_i,\ i = 1,2,3,4\)</span> to be non-zero. We first read in data and store the size of the data into <span class="math inline">\(n\)</span>. We will use this <span class="math inline">\(n\)</span> later, when setting priors for <span class="math inline">\(n/g\)</span>.</p>
<pre class="r"><code>library(foreign)
cognitive = read.dta(&quot;http://www.stat.columbia.edu/~gelman/arm/examples/child.iq/kidiq.dta&quot;)
cognitive$mom_work = as.numeric(cognitive$mom_work &gt; 1)
cognitive$mom_hs =  as.numeric(cognitive$mom_hs &gt; 0)
colnames(cognitive) = c(&quot;kid_score&quot;, &quot;hs&quot;,&quot;IQ&quot;, &quot;work&quot;, &quot;age&quot;) 

# Extract size of data set
n = nrow(cognitive)</code></pre>
<p>We then fit the full model using different priors. Here we set model prior to be <code>uniform()</code>, meaning each model has equal prior probability.</p>
<pre class="r"><code>library(BAS)
# Unit information prior
cog.g = bas.lm(kid_score ~ ., data=cognitive, prior=&quot;g-prior&quot;, 
               a=n, modelprior=uniform())
# a is the hyperparameter in this case g=n

# Zellner-Siow prior with Jeffrey&#39;s reference prior on sigma^2
cog.ZS = bas.lm(kid_score ~ ., data=cognitive, prior=&quot;JZS&quot;, 
               modelprior=uniform())

# Hyper g/n prior
cog.HG = bas.lm(kid_score ~ ., data=cognitive, prior=&quot;hyper-g-n&quot;, 
                a=3, modelprior=uniform()) 
# hyperparameter a=3

# Empirical Bayesian estimation under maximum marginal likelihood
cog.EB = bas.lm(kid_score ~ ., data=cognitive, prior=&quot;EB-local&quot;, 
                a=n, modelprior=uniform())

# BIC to approximate reference prior
cog.BIC = bas.lm(kid_score ~ ., data=cognitive, prior=&quot;BIC&quot;, 
                 modelprior=uniform())

# AIC
cog.AIC = bas.lm(kid_score ~ ., data=cognitive, prior=&quot;AIC&quot;, 
                 modelprior=uniform())</code></pre>
<p>Here <code>cog.g</code> is the model corresponding to the unit information prior <span class="math inline">\(g=n\)</span>. <code>cog.ZS</code> is the model under the Zellner-Siow cauchy prior with Jeffrey’s reference prior on <span class="math inline">\(\sigma^2\)</span>. <code>cog.HG</code> gives the model under the hyper-<span class="math inline">\(g/n\)</span> prior. <code>cog.EB</code> is the empirical Bayesian estimates which maximizes the marginal likelihood. <code>cog.BIC</code> and <code>cog.AIC</code> are the ones corresponding to using <code>BIC</code> and <code>AIC</code> for marginal likelihood approximation.</p>
<p>In order to compare the posterior inclusion probability (pip) of each coefficient, we group the results <span class="math inline">\(p(\beta_i\neq 0)\)</span> obtained from the <code>probne0</code> attribute of each model for later comparison</p>
<pre class="r"><code>probne0 = cbind(cog.BIC$probne0, cog.g$probne0, cog.ZS$probne0, cog.HG$probne0,
                cog.EB$probne0, cog.AIC$probne0)

colnames(probne0) = c(&quot;BIC&quot;, &quot;g&quot;, &quot;ZS&quot;, &quot;HG&quot;, &quot;EB&quot;, &quot;AIC&quot;)
rownames(probne0) = c(cog.BIC$namesx)</code></pre>
<p>We can compare the results by printing the matrix <code>probne0</code> that we just generated. If we want to visualize them to get a clearer idea, we may plot them using bar plots.</p>
<pre class="r"><code>library(ggplot2)

# Generate plot for each variable and save in a list
P = list()
for (i in 2:5){
  mydata = data.frame(prior = colnames(probne0), posterior = probne0[i, ])
  mydata$prior = factor(mydata$prior, levels = colnames(probne0))
  p = ggplot(mydata, aes(x = prior, y = posterior)) +
    geom_bar(stat = &quot;identity&quot;, fill = &quot;blue&quot;) + xlab(&quot;&quot;) +
    ylab(&quot;&quot;) + 
    ggtitle(cog.g$namesx[i])
  P = c(P, list(p))
}

library(cowplot)
do.call(plot_grid, c(P))</code></pre>
<p><img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/plots-1.svg" width="576" />
In the plots above, the <span class="math inline">\(x\)</span>-axis lists all the prior distributions we consider, and the bar heights represent the posterior inclusion probability of each coefficient, i.e., <span class="math inline">\(p(\beta_i\neq 0)\)</span>.</p>
<p>We can see that mother’s IQ score is included almost as probability 1 in all priors. So all methods agree that we should include variable <code>IQ</code>. Mother’s high school status also has probability of more than 0.5 in each prior, suggesting that we may also consider including the variable <code>hs</code>. However, mother’s work status and mother’s age have much lower posterior inclusion probability in all priors. From left to right in each bar plot, we see that method <code>BIC</code> is the most conservative method (meaning it will exclude the most variables), while <code>AIC</code> is being the less conservative method.
## R Demo on <code>BAS</code> Package</p>
<p>In this section, we will apply Bayesian model selection and model averaging on the US crime data set <code>UScrime</code> using the <code>BAS</code> package. We will introduce some additional diagnostic plots, and talk about the effect of multicollinearity in model uncertainty.</p>
</div>
<div id="the-uscrime-data-set-and-data-processing" class="section level3">
<h3>The <code>UScrime</code> Data Set and Data Processing</h3>
<p>We will demo the <code>BAS</code> commands using the US crime data set in the R libarry <code>MASS</code>.</p>
<pre class="r"><code># Load library and data set
library(MASS)</code></pre>
<pre><code>## 
## Attaching package: &#39;MASS&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     select</code></pre>
<pre class="r"><code>data(UScrime)</code></pre>
<p>This data set contains data on 47 states of the US for the year of 1960. The response variable <span class="math inline">\(Y\)</span> is the rate of crimes in a particular category per head of population of each state. There are 15 potential explanatory variables with values for each of the 47 states related to crime and other demographics. Here is the table of all the potential explanatory variables and their descriptions.</p>
<table>
<thead>
<tr class="header">
<th>Variable</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>M</code></td>
<td>Percentage of males aged 14-24</td>
</tr>
<tr class="even">
<td><code>So</code></td>
<td>Indicator variable for southern states</td>
</tr>
<tr class="odd">
<td><code>Ed</code></td>
<td>Mean years of schooling</td>
</tr>
<tr class="even">
<td><code>Po1</code></td>
<td>Police expenditure in 1960</td>
</tr>
<tr class="odd">
<td><code>Po2</code></td>
<td>Police expenditure in 1959</td>
</tr>
<tr class="even">
<td><code>LF</code></td>
<td>Labour force participation rate</td>
</tr>
<tr class="odd">
<td><code>M.F</code></td>
<td>Number of males per 1000 females</td>
</tr>
<tr class="even">
<td><code>Pop</code></td>
<td>State population</td>
</tr>
<tr class="odd">
<td><code>NW</code></td>
<td>Number of non-whites per 1000 people</td>
</tr>
<tr class="even">
<td><code>U1</code></td>
<td>Unemployment rate of urban males aged 14-24</td>
</tr>
<tr class="odd">
<td><code>U2</code></td>
<td>Unemployment rate of urban males aged 35-39</td>
</tr>
<tr class="even">
<td><code>GDP</code></td>
<td>Gross domestic product per head</td>
</tr>
<tr class="odd">
<td><code>Ineq</code></td>
<td>Income inequality</td>
</tr>
<tr class="even">
<td><code>Prob</code></td>
<td>Probability of imprisonment</td>
</tr>
<tr class="odd">
<td><code>Time</code></td>
<td>Average time served in state prisons</td>
</tr>
</tbody>
</table>
<p><br/></p>
<p>We may use the <code>summary</code> function to describe each variable in the data set.</p>
<pre class="r"><code>summary(UScrime)</code></pre>
<pre><code>##        M               So               Ed             Po1       
##  Min.   :119.0   Min.   :0.0000   Min.   : 87.0   Min.   : 45.0  
##  1st Qu.:130.0   1st Qu.:0.0000   1st Qu.: 97.5   1st Qu.: 62.5  
##  Median :136.0   Median :0.0000   Median :108.0   Median : 78.0  
##  Mean   :138.6   Mean   :0.3404   Mean   :105.6   Mean   : 85.0  
##  3rd Qu.:146.0   3rd Qu.:1.0000   3rd Qu.:114.5   3rd Qu.:104.5  
##  Max.   :177.0   Max.   :1.0000   Max.   :122.0   Max.   :166.0  
##       Po2               LF             M.F              Pop        
##  Min.   : 41.00   Min.   :480.0   Min.   : 934.0   Min.   :  3.00  
##  1st Qu.: 58.50   1st Qu.:530.5   1st Qu.: 964.5   1st Qu.: 10.00  
##  Median : 73.00   Median :560.0   Median : 977.0   Median : 25.00  
##  Mean   : 80.23   Mean   :561.2   Mean   : 983.0   Mean   : 36.62  
##  3rd Qu.: 97.00   3rd Qu.:593.0   3rd Qu.: 992.0   3rd Qu.: 41.50  
##  Max.   :157.00   Max.   :641.0   Max.   :1071.0   Max.   :168.00  
##        NW              U1               U2             GDP       
##  Min.   :  2.0   Min.   : 70.00   Min.   :20.00   Min.   :288.0  
##  1st Qu.: 24.0   1st Qu.: 80.50   1st Qu.:27.50   1st Qu.:459.5  
##  Median : 76.0   Median : 92.00   Median :34.00   Median :537.0  
##  Mean   :101.1   Mean   : 95.47   Mean   :33.98   Mean   :525.4  
##  3rd Qu.:132.5   3rd Qu.:104.00   3rd Qu.:38.50   3rd Qu.:591.5  
##  Max.   :423.0   Max.   :142.00   Max.   :58.00   Max.   :689.0  
##       Ineq            Prob              Time             y         
##  Min.   :126.0   Min.   :0.00690   Min.   :12.20   Min.   : 342.0  
##  1st Qu.:165.5   1st Qu.:0.03270   1st Qu.:21.60   1st Qu.: 658.5  
##  Median :176.0   Median :0.04210   Median :25.80   Median : 831.0  
##  Mean   :194.0   Mean   :0.04709   Mean   :26.60   Mean   : 905.1  
##  3rd Qu.:227.5   3rd Qu.:0.05445   3rd Qu.:30.45   3rd Qu.:1057.5  
##  Max.   :276.0   Max.   :0.11980   Max.   :44.00   Max.   :1993.0</code></pre>
<p>However, these variables have been pre-processed for modeling purpose, so the summary statistics may not be so meaningful. The values of all these variables have been aggregated over each state, so this is a case of ecological regression. We will not model directly the rate for a person to commit a crime. Instead, we will use the total number of crimes and average values of predictors at the state level to predict the total crime rate of each state.</p>
<p>We transform the variables using the natural log function, except the indicator variable <code>So</code> (2nd column of the data set). We perform this transformation based on the analysis of this data set.<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a> Notice that <code>So</code> is already a numeric variable (<code>1</code> indicating Southern state and <code>0</code> otherwise), not as a categorical variable. Hence we do not need any data processing of this variable, unlike mother’s high school status <code>hs</code> and mother’s work status <code>work</code> in the kid’s cognitive score data set.</p>
<pre class="r"><code>UScrime[,-2] = log(UScrime[,-2])</code></pre>
</div>
<div id="bayesian-models-and-diagnostics" class="section level3">
<h3>Bayesian Models and Diagnostics</h3>
<p>We run <code>bas.lm</code> function from the <code>BAS</code> package. We first run the full model and use this information for later decision on what variables to include. Here we have 15 potential predictors. The total number of models is<span class="math inline">\(\ 2^{15} = 32768\)</span>. This is not a very large number and <code>BAS</code> can enumerate all the models pretty quickly. However, we want to illustrate how to explore models using stochastic methods. Hence we set argument <code>method = MCMC</code> inside the <code>bas.lm</code> function. We also use the Zellner-Siow cauchy prior for the prior distributions of the coefficients in this regression.</p>
<pre class="r"><code>library(BAS)
crime.ZS =  bas.lm(y ~ ., data=UScrime,
                   prior=&quot;ZS-null&quot;, modelprior=uniform(), method = &quot;MCMC&quot;) </code></pre>
<p><code>BAS</code> will run the MCMC sampler until the number of unique models in the sample exceeds <span class="math inline">\(\text{number of models} = 2^{p}\)</span> (when <span class="math inline">\(p &lt; 19\)</span>) or until the number of MCMC iterations exceeds <span class="math inline">\(2\times\text{number of models}\)</span> by default, whichever is smaller. Here <span class="math inline">\(p\)</span> is the number of predictors.</p>
<p><strong>Diagnostic Plots</strong></p>
<p>To analyze the result, we first look at the diagnostic plot using <code>diagnostics</code> function and see whether we have run the MCMC exploration long enough so that the posterior inclusion probability (pip) has converged.</p>
<pre class="r"><code>diagnostics(crime.ZS, type=&quot;pip&quot;, col = &quot;blue&quot;, pch = 16, cex = 1.5)</code></pre>
<p><img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/diagnostics-1.svg" width="80%" style="display: block; margin: auto;" /></p>
<p>In this plot, the <span class="math inline">\(x\)</span>-axis is the renormalized posterior inclusion probability (pip) of each coefficient <span class="math inline">\(\beta_i,\ i=1,\cdots, 15\)</span> in this model. This can be calculated as
<span class="math display" id="eq:pip">\[\begin{equation} 
p(\beta_i\neq 0~|~\text{data}) = \sum_{M_m\in\text{ model space}}I(X_i\in M_m)\left(\frac{\text{BF}[M_m:M_0]\text{Odd}[M_m:M_0]}{\displaystyle \sum_{M_j}\text{BF}[M_j:M_0]\text{Odd}[M_j:M_0]}\right).
\tag{28}
\end{equation}\]</span></p>
<p>Here, <span class="math inline">\(X_i\)</span> is the <span class="math inline">\(i\)</span>th predictor variable, and <span class="math inline">\(I(X_i\in M_m)\)</span> is the indicator function which is 1 if <span class="math inline">\(X_i\)</span> is included in model <span class="math inline">\(M_m\)</span> and 0 if <span class="math inline">\(X_i\)</span> is not included. The first <span class="math inline">\(\Sigma\)</span> notation indicates that we sum over all models <span class="math inline">\(M_m\)</span> in the model space. And we use
<span class="math display" id="eq:weights">\[\begin{equation} 
\frac{\text{BF}[M_m:M_0]\text{Odd}[M_m:M_0]}{\displaystyle \sum_{M_j}\text{BF}[M_j:M_0]\text{Odd}[M_j:M_0]} 
\tag{29}
\end{equation}\]</span>
as the weights. You may recognize that the numerator of <a href="#eq:weights">(29)</a> is exactly the ratio of the posterior probability of model <span class="math inline">\(M_m\)</span> over the posterior probability of the null model <span class="math inline">\(M_0\)</span>, i.e., the posterier odd <span class="math inline">\(\PO[M_m:M_0]\)</span>. We devide the posterior odd by the total sum of posterior odds of all models in the model space, to make sure these weights are between 0 and 1. The weight in Equation <a href="#eq:weights">(29)</a> represents the posterior probability of the model <span class="math inline">\(M_m\)</span> after seeing the data <span class="math inline">\(p(M_m~|~\text{data})\)</span>, the one we used in Section <a href="#sec:BMU"><strong>??</strong></a>. So Equation <a href="#eq:pip">(28)</a> is the theoretical calculation of pip, which can be rewrited as
<span class="math display">\[ p(\beta_i\neq 0~|~\text{data}) = \sum_{M_m\in \text{ model space}}I(X_i\in M_m)p(M_m~|~\text{data}). \]</span>
The null model <span class="math inline">\(M_0\)</span>, as we recall, is the model that only includes the intercept.</p>
<p>On the <span class="math inline">\(y\)</span>-axis of the plot, we lay out the posterior inclusion probability of coefficient <span class="math inline">\(\beta_i\)</span>, which is calculated using
<span class="math display">\[ p(\beta_i\neq 0~|~\text{data}) = \frac{1}{J}\sum_{j=1}^J I(X_i\in M^{(j)}).\]</span>
Here <span class="math inline">\(J\)</span> is the total number of models that we sample using MCMC; each model is denoted as <span class="math inline">\(M^{(j)}\)</span> (some models may repeat themselves in the sample). We count the frequency of variable <span class="math inline">\(X_i\)</span> occuring in model <span class="math inline">\(M^{(j)}\)</span>, and divide this number by the total number of models <span class="math inline">\(J\)</span>. This is a frequentist approach to approximate the posterior probability of including <span class="math inline">\(X_i\)</span> after seeing the data.</p>
<p>When all points are on the 45 degree diagonal, we say that the posterior inclusion probability of each variable from MCMC have converged well enough to the theoretical posterior inclusion probability.</p>
<p>We can also use <code>diagnostics</code> function to see whether the model posterior probability has converged:</p>
<pre class="r"><code>diagnostics(crime.ZS, type = &quot;model&quot;, col = &quot;blue&quot;, pch = 16, cex = 1.5)</code></pre>
<p><img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/model-prob-1.svg" width="70%" style="display: block; margin: auto;" /></p>
<p>We can see that some of the points still fall slightly away from the 45 degree diagonal line. This may suggest we should increase the number of MCMC iterations. We may do that by imposing the argument on <code>MCMC.iterations</code> inside the <code>bas.lm</code> function</p>
<pre class="r"><code># Re-run regression using larger number of MCMC iterations
crime.ZS = bas.lm(y ~ ., data = UScrime,
                  prior = &quot;ZS-null&quot;, modelprior = uniform(),
                  method = &quot;MCMC&quot;, MCMC.iterations = 10 ^ 6)

# Plot diagnostics again
diagnostics(crime.ZS, type = &quot;model&quot;, col = &quot;blue&quot;, pch = 16, cex = 1.5)</code></pre>
<p><img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/more-MCMC-1.svg" width="80%" style="display: block; margin: auto;" /></p>
<p>With more number of iterations, we see that most points stay in the 45 degree diagonal line, meaing the posterior inclusion probability from the MCMC method has mostly converged to the theoretical posterior inclusion probability.</p>
<p>We will next look at four other plots of the <code>BAS</code> object, <code>crime.ZS</code>.</p>
<p><strong>Residuals Versus Fitted Values Using BMA</strong></p>
<p>The first plot is the residuals over the fitted value under Bayesian model averaging results.</p>
<pre class="r"><code>plot(crime.ZS, which = 1, add.smooth = F, 
     ask = F, pch = 16, sub.caption=&quot;&quot;, caption=&quot;&quot;)
abline(a = 0, b = 0, col = &quot;darkgrey&quot;, lwd = 2)</code></pre>
<p><img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/plot1-1.svg" width="70%" style="display: block; margin: auto;" /></p>
<p>We can see that the residuals lie around the dash line <span class="math inline">\(y=0\)</span>, and has a constant variance. Observations 11, 22, and 46 may be the potential outliers, which are indicated in the plot.</p>
<p><strong>Cumulative Sampled Probability</strong></p>
<p>The second plot shows the cumulative sampled model probability.</p>
<pre class="r"><code>plot(crime.ZS, which=2, add.smooth = F, sub.caption=&quot;&quot;, caption=&quot;&quot;)</code></pre>
<p><img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/CMP-1.svg" width="70%" style="display: block; margin: auto;" /></p>
<p>We can see that after we have discovered about 5,000 unique models with MCMC sampling, the probability is starting to level off, indicating that these additional models have very small probability and do not contribute substantially to the posterior distribution. These probabilities are proportional to the product of marginal likelihoods of models and priors, <span class="math inline">\(p(\text{data}~|~M_m)p(M_m)\)</span>, rather than Monte Carlo frequencies.</p>
<p><strong>Model Complexity</strong></p>
<p>The third plot is the model size versus the natural log of the marginal likelihood, or the Bayes factor, to compare each model to the null model.</p>
<pre class="r"><code>plot(crime.ZS, which=3, ask=F, caption=&quot;&quot;, sub.caption=&quot;&quot;)</code></pre>
<p><img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/model-comp-1.svg" width="70%" style="display: block; margin: auto;" /></p>
<p>We see that the models with the highest Bayes factors or logs of marginal likelihoods have around 8 or 9 predictors. The null model has a log of marginal likelihood of 0, or a Bayes factor of 1.</p>
<p><strong>Marginal Inclusion Probability</strong></p>
<p>Finally, we have a plot showing the importance of different predictors.</p>
<pre class="r"><code>plot(crime.ZS, which = 4, ask = F, caption = &quot;&quot;, sub.caption = &quot;&quot;, 
     col.in = &quot;blue&quot;, col.ex = &quot;darkgrey&quot;, lwd = 3)</code></pre>
<p><img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/MIP-1.svg" width="70%" style="display: block; margin: auto;" /></p>
<p>The lines in blue correspond to the variables where the marginal posterior inclusion probability (pip), is greater than 0.5, suggesting that these variables are important for prediction. The variables represented in grey lines have posterior inclusion probability less than 0.5. Small posterior inclusion probability may arise when two or more variables are highly correlated, similar to large <span class="math inline">\(p\)</span>-values with multicollinearity. So we should be cautious to use these posterior inclusion probabilities to eliminate variables.</p>
<p><strong>Model Space Visualization</strong></p>
<p>To focus on the high posterior probability models, we can look at the image of the model space.</p>
<pre class="r"><code>image(crime.ZS, rotate = F)</code></pre>
<p><img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/model-space1-1.svg" width="576" /></p>
<p>By default, we only include the top 20 models. An interesting feature of this plot is, that whenever <code>Po1</code>, the police expenditures in 1960, is included, <code>Po2</code>, the police expenditures in 1959, will be excluded from the model, and vice versa.</p>
<pre class="r"><code>out = cor(UScrime$Po1, UScrime$Po2)
out </code></pre>
<pre><code>## [1] 0.9933688</code></pre>
<p>Calculating the correlation between the two variables, we see that that <code>Po1</code> and <code>Po2</code> are highly correlated with positive correlation 0.993.</p>
</div>
<div id="posterior-uncertainty-in-coefficients" class="section level3">
<h3>Posterior Uncertainty in Coefficients</h3>
<p>Due to the interesting inclusion relationship between <code>Po1</code> and <code>Po2</code> in the top 20 models, we extract the two coefficients under Bayesian model averaging and take a look at the plots for the coefficients for <code>Po1</code> and <code>Po2</code>.</p>
<pre class="r"><code># Extract coefficients
coef.ZS=coef(crime.ZS)

# Po1 and Po2 are in the 5th and 6th columns in UScrime
par(mfrow = c(1,2))
plot(coef.ZS, subset = c(5:6), 
     col.lab = &quot;darkgrey&quot;, col.axis = &quot;darkgrey&quot;, col = &quot;darkgrey&quot;, ask = F)</code></pre>
<p><img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/Po1-Po2-plots-1.svg" width="576" /></p>
<p>Under Bayesian model averaging, there is more mass at 0 for <code>Po2</code> than <code>Po1</code>, giving more posterior inclusion probability for <code>Po1</code>. This is also the reason why in the marginal posterior plot of variable importance, <code>Po1</code> has a blue line while <code>Po2</code> has a grey line. When <code>Po1</code> is excluded, the distributions of other coefficients in the model, except the one for <code>Po2</code>, will have similar distributions as when both <code>Po1</code> and <code>Po2</code> are in the model. However, when both predictors are included, the adjusted coefficient for <code>Po2</code> has more support on negative values, since we are over compensating for having both variables included in the model. In extreme cases of correlations, one may find that the coefficient plot is multimodal. If this is the case, the posterior mean may not be in the highest probability density credible interval, and this mean is not necessarily an informative summary. We will discuss more in the next section about making decisions on highly correlated variables.</p>
<p>We can read the credible intervals of each variable using the <code>confint</code> function on the coefficient object <code>coef.ZS</code> of the model. Here we round the results in 4 decimal places.</p>
<pre class="r"><code>round(confint(coef.ZS), 4)</code></pre>
<pre><code>##              2.5%  97.5%    beta
## Intercept  6.6687 6.7823  6.7249
## M          0.0000 2.1610  1.1450
## So        -0.0513 0.3199  0.0356
## Ed         0.6378 3.1680  1.8606
## Po1       -0.0065 1.4330  0.6041
## Po2       -0.1299 1.4369  0.3148
## LF        -0.4673 1.0385  0.0588
## M.F       -2.4347 1.7917 -0.0273
## Pop       -0.1294 0.0040 -0.0223
## NW         0.0000 0.1649  0.0665
## U1        -0.4960 0.3610 -0.0246
## U2        -0.0016 0.6628  0.2069
## GDP       -0.0019 1.2322  0.2076
## Ineq       0.6765 2.1161  1.3914
## Prob      -0.4072 0.0000 -0.2152
## Time      -0.5232 0.0331 -0.0843
## attr(,&quot;Probability&quot;)
## [1] 0.95
## attr(,&quot;class&quot;)
## [1] &quot;confint.bas&quot;</code></pre>
</div>
<div id="prediction" class="section level3">
<h3>Prediction</h3>
<p>We can use the usual <code>predict</code> function that we used for <code>lm</code> objects to obtain prediction from the <code>BAS</code> object <code>crime.ZS</code>. However, since we have different models to choose from under the Bayesian framework, we need to first specify which particular model we use to obtain the prediction. For example, if we would like to use the Bayesian model averaging results for coefficients to obtain predictions, we would specify the <code>estimator</code> argument in the <code>predict</code> function like the following</p>
<pre class="r"><code>crime.BMA = predict(crime.ZS, estimator = &quot;BMA&quot;, se.fit = TRUE)</code></pre>
<p>The fitted values can be obtained using the <code>fit</code> attribute of <code>crime.BMA</code>. We have transposed the fitted values into a vector to better present all the values.</p>
<pre class="r"><code>fitted = crime.BMA$fit
as.vector(fitted)</code></pre>
<pre><code>##  [1] 6.661631 7.298878 6.178628 7.611009 7.054662 6.513674 6.784484 7.266292
##  [9] 6.629354 6.601315 7.054880 6.570698 6.472944 6.582517 6.556996 6.904668
## [17] 6.229243 6.809685 6.943121 6.961983 6.609332 6.428658 6.898718 6.777020
## [25] 6.406076 7.400874 6.019326 7.156832 7.089617 6.500307 6.208417 6.606196
## [33] 6.798152 6.820010 6.625396 7.028713 6.793663 6.363562 6.603183 7.045303
## [41] 6.548430 6.046330 6.930121 7.006045 6.236269 6.608770 6.830020</code></pre>
<p>We may use these fitted values for further error calculations. We will talk about decision making on models and how to obtain predictions under different models in the next section.
## Decision Making Under Model Uncertainty</p>
<p>We are closing this chapter by presenting the last topic, decision making under model uncertainty. We have seen that under the Bayesian framework, we can use different prior distributions for coefficients, different model priors for models, and we can even use stochastic exploration methods for complex model selections. After selecting these coefficient priors and model priors, we can obtain the marginal posterior inclusion probability for each variable in the full model, which may provide some information about whether or not to include a particular variable in the model for further model analysis and predictions. With all the information presented in the results, which model would be the most appropriate model?</p>
<p>In this section, we will talk about different methods for selecting models and decision making for posterior distributions and predictions. We will illustrate this process using the US crime data <code>UScrime</code> as an example and process it using the <code>BAS</code> package.</p>
<p>We first prepare the data as in the last section and run <code>bas.lm</code> on the full model</p>
<pre class="r"><code>data(UScrime, package=&quot;MASS&quot;)

# take the natural log transform on the variables except the 2nd column `So`
UScrime[, -2] = log(UScrime[, -2])

# run Bayesian linear regression
library(BAS)
crime.ZS =  bas.lm(y ~ ., data = UScrime,
                   prior = &quot;ZS-null&quot;, modelprior = uniform()) </code></pre>
</div>
<div id="model-choice" class="section level3">
<h3>Model Choice</h3>
<p>For Bayesian model choice, we start with the full model, which includes all the predictors. The uncertainty of selecting variables, or model uncertainty that we have been discussing, arises when we believe that some of the explanatory variables may be unrelated to the response variable. This corresponds to setting a regression coefficient <span class="math inline">\(\beta_j\)</span> to be exactly zero. We specify prior distributions that reflect our uncertainty about the importance of variables. We then update the model based on the data we obtained, resulting in posterior distributions over all models and the coefficients and variances within each model.</p>
<p>Now the question has become, how to select a single model from the posterior distribution and use it for furture inference? What are the objectives from inference?</p>
<p><strong>BMA Model</strong></p>
<p>We do have a single model, the one that is obtained by averaging all models using their posterior probabilities, the Bayesian model averaging model, or BMA. This is referred to as a hierarchical model and it is composed of many simpler models as building blocks. This represents the full posterior uncertainty after seeing the data.</p>
<p>We can obtain the posterior predictive mean by using the weighted average of all of the predictions from each sub model</p>
<p><span class="math display">\[\hat{\mu} = E[\hat{Y}~|~\text{data}] = \sum_{M_m \in \text{ model space}}\hat{Y}\times p(M_m~|~\text{data}).\]</span>
This prediction is the best under the squared error loss <span class="math inline">\(L_2\)</span>. From <code>BAS</code>, we can obtain predictions and fitted values using the usual <code>predict</code> and <code>fitted</code> functions. To specify which model we use for these results, we need to include argument <code>estimator</code>.</p>
<pre class="r"><code>crime.BMA = predict(crime.ZS, estimator = &quot;BMA&quot;)
mu_hat = fitted(crime.ZS, estimator = &quot;BMA&quot;)</code></pre>
<p><code>crime.BMA</code>, the object obtained by the <code>predict</code> function, has additional slots storing results from the BMA model.</p>
<pre class="r"><code>names(crime.BMA)</code></pre>
<pre><code>##  [1] &quot;fit&quot;         &quot;Ybma&quot;        &quot;Ypred&quot;       &quot;postprobs&quot;   &quot;se.fit&quot;     
##  [6] &quot;se.pred&quot;     &quot;se.bma.fit&quot;  &quot;se.bma.pred&quot; &quot;df&quot;          &quot;best&quot;       
## [11] &quot;bestmodel&quot;   &quot;best.vars&quot;   &quot;estimator&quot;</code></pre>
<p>Plotting the two sets of fitted values, one obtained from the <code>fitted</code> function, another obtained from the <code>fit</code> attribute of the <code>predict</code> object <code>crime.BMA</code>, we see that they are in perfect agreement.</p>
<pre class="r"><code># Load library and prepare data frame
library(ggplot2)
output = data.frame(mu_hat = mu_hat, fitted = crime.BMA$fit)

# Plot result from `fitted` function and result from `fit` attribute
ggplot(data = output, aes(x = mu_hat, y = fitted)) + 
  geom_point(pch = 16, color = &quot;blue&quot;, size = 3) + 
  geom_abline(intercept = 0, slope = 1) + 
  xlab(expression(hat(mu[i]))) + ylab(expression(hat(Y[i])))</code></pre>
<p><img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/BMA-fit-1.svg" width="70%" style="display: block; margin: auto;" /></p>
<p><strong>Highest Probability Model</strong></p>
<p>If our objective is to learn what is the most likely model to have generated the data using a 0-1 loss <span class="math inline">\(L_0\)</span>, then the highest probability model (HPM) is optimal.</p>
<pre class="r"><code>crime.HPM = predict(crime.ZS, estimator = &quot;HPM&quot;)</code></pre>
<p>The variables selected from this model can be obtained using the <code>bestmodel</code> attribute from the <code>crime.HPM</code> object. We extract the variable names from the <code>crime.HPM</code></p>
<pre class="r"><code>crime.HPM$best.vars</code></pre>
<pre><code>## [1] &quot;Intercept&quot; &quot;M&quot;         &quot;Ed&quot;        &quot;Po1&quot;       &quot;NW&quot;        &quot;U2&quot;       
## [7] &quot;Ineq&quot;      &quot;Prob&quot;      &quot;Time&quot;</code></pre>
<p>We see that, except the intercept, which is always in any models, the highest probability model also includes <code>M</code>, percentage of males aged 14-24; <code>Ed</code>, mean years of schooling; <code>Po1</code>, police expenditures in 1960; <code>NW</code>, number of non-whites per 1000 people; <code>U2</code>, unemployment rate of urban males aged 35-39; <code>Ineq</code>, income inequlity; <code>Prob</code>, probability of imprisonment, and <code>Time</code>, average time in state prison.</p>
<p>To obtain the coefficients and their posterior means and posterior standard deviations, we tell give an optional argument to <code>coef</code> to indicate that we want to extract coefficients under the HPM.</p>
<pre class="r"><code># Select coefficients of HPM

# Posterior means of coefficients
coef.crime.ZS = coef(crime.ZS, estimator=&quot;HPM&quot;)
coef.crime.ZS</code></pre>
<pre><code>## 
##  Marginal Posterior Summaries of Coefficients: 
## 
##  Using  HPM 
## 
##  Based on the top  1 models 
##            post mean  post SD   post p(B != 0)
## Intercept   6.72494    0.02623   1.00000      
## M           1.42422    0.42278   0.85357      
## So          0.00000    0.00000   0.27371      
## Ed          2.14031    0.43094   0.97466      
## Po1         0.82141    0.15927   0.66516      
## Po2         0.00000    0.00000   0.44901      
## LF          0.00000    0.00000   0.20224      
## M.F         0.00000    0.00000   0.20497      
## Pop         0.00000    0.00000   0.36961      
## NW          0.10491    0.03821   0.69441      
## U1          0.00000    0.00000   0.25258      
## U2          0.27823    0.12492   0.61494      
## GDP         0.00000    0.00000   0.36012      
## Ineq        1.19269    0.27734   0.99654      
## Prob       -0.29910    0.08724   0.89918      
## Time       -0.27616    0.14574   0.37180</code></pre>
<p>We can also obtain the posterior probability of this model using</p>
<pre class="r"><code>postprob.HPM = crime.ZS$postprobs[crime.HPM$best]
postprob.HPM</code></pre>
<pre><code>## [1] 0.01824728</code></pre>
<p>we see that this highest probability model has posterior probability of only 0.018. There are many models that have comparable posterior probabilities. So even this model has the highest posterior probability, we are still pretty unsure about whether it is the best model.</p>
<p><strong>Median Probability Model</strong></p>
<p>Another model that is frequently reported, is the median probability model (MPM). This model includes all predictors whose marginal posterior inclusion probabilities are greater than 0.5. If the variables are all uncorrelated, this will be the same as the highest posterior probability model. For a sequence of nested models such as polynomial regression with increasing powers, the median probability model is the best single model for prediction.</p>
<p>However, since in the US crime example, <code>Po1</code> and <code>Po2</code> are highly correlated, we see that the variables included in MPM are slightly different than the variables included in HPM.</p>
<pre class="r"><code>crime.MPM = predict(crime.ZS, estimator = &quot;MPM&quot;)
crime.MPM$best.vars</code></pre>
<pre><code>## [1] &quot;Intercept&quot; &quot;M&quot;         &quot;Ed&quot;        &quot;Po1&quot;       &quot;NW&quot;        &quot;U2&quot;       
## [7] &quot;Ineq&quot;      &quot;Prob&quot;</code></pre>
<p>As we see, this model only includes 7 variables, <code>M</code>, <code>Ed</code>, <code>Po1</code>, <code>NW</code>, <code>U2</code>, <code>Ineq</code>, and <code>Prob</code>. It does not include <code>Time</code> variable as in HPM.</p>
<p>When there are correlated predictors in non-nested models, MPM in general does well. However, if the correlations among variables increase, MPM may miss important variables as the correlations tend to dilute the posterior inclusing probabilities of related variables.</p>
<p>To obtain the coefficients in the median probability model, we specify that the estimator is now “MPM”:</p>
<pre class="r"><code># Obtain coefficients of the  Median Probabilty Model
coef(crime.ZS, estimator = &quot;MPM&quot;)</code></pre>
<pre><code>## 
##  Marginal Posterior Summaries of Coefficients: 
## 
##  Using  MPM 
## 
##  Based on the top  1 models 
##            post mean  post SD   post p(B != 0)
## Intercept   6.72494    0.02713   1.00000      
## M           1.46180    0.43727   1.00000      
## So          0.00000    0.00000   0.00000      
## Ed          2.30642    0.43727   1.00000      
## Po1         0.87886    0.16204   1.00000      
## Po2         0.00000    0.00000   0.00000      
## LF          0.00000    0.00000   0.00000      
## M.F         0.00000    0.00000   0.00000      
## Pop         0.00000    0.00000   0.00000      
## NW          0.08162    0.03743   1.00000      
## U1          0.00000    0.00000   0.00000      
## U2          0.31053    0.12816   1.00000      
## GDP         0.00000    0.00000   0.00000      
## Ineq        1.18815    0.28710   1.00000      
## Prob       -0.18401    0.06466   1.00000      
## Time        0.00000    0.00000   0.00000</code></pre>
<p><strong>Best Predictive Model</strong></p>
<p>If our objective is prediction from a single model, the best choice is to find the model whose predictions are closest to those given by BMA. “Closest” could be based on squared error loss for predictions, or be based on any other loss functions. Unfortunately, there is no nice expression for this model. However, we can still calculate the loss for each of our sampled models to try to identify this best predictive model, or BPM.</p>
<p>Using the squared error loss, we find that the best predictive model is the one whose predictions are closest to BMA.</p>
<pre class="r"><code>crime.BPM = predict(crime.ZS, estimator = &quot;BPM&quot;)
crime.BPM$best.vars</code></pre>
<pre><code>##  [1] &quot;Intercept&quot; &quot;M&quot;         &quot;So&quot;        &quot;Ed&quot;        &quot;Po1&quot;       &quot;Po2&quot;      
##  [7] &quot;M.F&quot;       &quot;NW&quot;        &quot;U2&quot;        &quot;Ineq&quot;      &quot;Prob&quot;</code></pre>
<p>The best predictive model includes not only the 7 variables that MPM includes, but also <code>M.F</code>, number of males per 1000 females, and <code>Po2</code>, the police expenditures in 1959.</p>
<p>Using the <code>se.fit = TRUE</code> option with <code>predict</code> we can calculate standard deviations for the predictions or for the mean. Then we can use this as input for the <code>confint</code> function for the prediction object. Here we only show the results of the first 20 data points.</p>
<pre class="r"><code># This code chunk is for function which provides options to show partial results
library(knitr)
# the default output hook
hook_output &lt;- knit_hooks$get(&#39;output&#39;)
knit_hooks$set(output = function(x, options) {
  if (!is.null(n &lt;- options$out.lines)) {
    n &lt;- as.numeric(n)
    x &lt;- unlist(stringr::str_split(x, &quot;\n&quot;))
    nx &lt;- length(x) 
    x &lt;- x[pmin(n,nx)]
    if(min(n) &gt; 1)  
      x &lt;- c(paste(options$comment, &quot;[...]&quot;), x)
    if(max(n) &lt; nx) 
      x &lt;- c(x, paste(options$comment, &quot;[...]&quot;))
    x &lt;- paste(c(x, &quot;\n&quot;), collapse = &quot;\n&quot;)
  }
  hook_output(x, options)
    })</code></pre>
<pre class="r"><code>crime.BPM = predict(crime.ZS, estimator = &quot;BPM&quot;, se.fit = TRUE)
crime.BPM.conf.fit = confint(crime.BPM, parm = &quot;mean&quot;)
crime.BPM.conf.pred = confint(crime.BPM, parm = &quot;pred&quot;)
cbind(crime.BPM$fit, crime.BPM.conf.fit, crime.BPM.conf.pred)
##                    2.5%    97.5%     mean     2.5%    97.5%     pred
##  [1,] 6.668988 6.513238 6.824738 6.668988 6.258715 7.079261 6.668988
##  [2,] 7.290854 7.151787 7.429921 7.290854 6.886619 7.695089 7.290854
##  [3,] 6.202166 6.039978 6.364354 6.202166 5.789406 6.614926 6.202166
##  [4,] 7.661307 7.490608 7.832006 7.661307 7.245129 8.077484 7.661307
##  [5,] 7.015570 6.847647 7.183493 7.015570 6.600523 7.430617 7.015570
##  [6,] 6.469547 6.279276 6.659818 6.469547 6.044966 6.894128 6.469547
##  [7,] 6.776133 6.555130 6.997135 6.776133 6.336920 7.215346 6.776133
##  [8,] 7.299560 7.117166 7.481955 7.299560 6.878450 7.720670 7.299560
##  [9,] 6.614927 6.482384 6.747470 6.614927 6.212890 7.016964 6.614927
## [10,] 6.596912 6.468988 6.724836 6.596912 6.196374 6.997449 6.596912
## [11,] 7.032834 6.877582 7.188087 7.032834 6.622750 7.442918 7.032834
## [12,] 6.581822 6.462326 6.701317 6.581822 6.183896 6.979748 6.581822
## [13,] 6.467921 6.281998 6.653843 6.467921 6.045271 6.890571 6.467921
## [14,] 6.566239 6.403813 6.728664 6.566239 6.153385 6.979092 6.566239
## [15,] 6.550129 6.388987 6.711270 6.550129 6.137779 6.962479 6.550129
## [16,] 6.888592 6.746097 7.031087 6.888592 6.483166 7.294019 6.888592
## [17,] 6.252735 6.063944 6.441526 6.252735 5.828815 6.676654 6.252735
## [18,] 6.795764 6.564634 7.026895 6.795764 6.351369 7.240160 6.795764
## [19,] 6.945687 6.766289 7.125086 6.945687 6.525866 7.365508 6.945687
## [20,] 7.000331 6.840374 7.160289 7.000331 6.588442 7.412220 7.000331
## [...]
</code></pre>
<p>The option <code>estimator = "BPM</code> is not yet available in <code>coef()</code>, so we will need to work a little harder to get the coefficients by refitting the BPM.
First we need to extract a vector of zeros and ones representing which variables are included in the BPM model.</p>
<pre class="r"><code># Extract a binary vector of zeros and ones for the variables included 
# in the BPM
BPM = as.vector(which.matrix(crime.ZS$which[crime.BPM$best],
                             crime.ZS$n.vars))
BPM</code></pre>
<pre><code>##  [1] 1 1 1 1 1 1 0 1 0 1 0 1 0 1 1 0</code></pre>
<p>Next, we will refit the model with <code>bas.lm</code> using the optional argument <code>bestmodel = BPM</code>. In general, this is the starting model for the stochastic search, which is helpful for starting the MCMC.
We will also specify that want to have 1 model by setting <code>n.models = 1</code>. In this way, <code>bas.lm</code> starts with the BPM and fits only that model.</p>
<pre class="r"><code># Re-run regression and specify `bestmodel` and `n.models`
crime.ZS.BPM = bas.lm(y ~ ., data = UScrime,
                      prior = &quot;ZS-null&quot;,
                      modelprior = uniform(),
                      bestmodel = BPM, n.models = 1)</code></pre>
<p>Now since we have only one model in our new object representing the BPM, we can use the <code>coef</code> function to obtain the summaries.</p>
<pre class="r"><code># Obtain coefficients of MPM
coef(crime.ZS.BPM)</code></pre>
<pre><code>## 
##  Marginal Posterior Summaries of Coefficients: 
## 
##  Using  BMA 
## 
##  Based on the top  1 models 
##            post mean  post SD   post p(B != 0)
## Intercept   6.72494    0.02795   1.00000      
## M           1.28189    0.49219   1.00000      
## So          0.09028    0.11935   1.00000      
## Ed          2.24197    0.54029   1.00000      
## Po1         0.70543    0.75949   1.00000      
## Po2         0.16669    0.76781   1.00000      
## LF          0.00000    0.00000   0.00000      
## M.F         0.55521    1.22456   1.00000      
## Pop         0.00000    0.00000   0.00000      
## NW          0.06649    0.04244   1.00000      
## U1          0.00000    0.00000   0.00000      
## U2          0.28567    0.13836   1.00000      
## GDP         0.00000    0.00000   0.00000      
## Ineq        1.15756    0.30841   1.00000      
## Prob       -0.21012    0.07452   1.00000      
## Time        0.00000    0.00000   0.00000</code></pre>
<p>Note the posterior probabilities that coefficients are zero is either zero or one since we have selected a model.</p>
<p><strong>Comparison of Models</strong></p>
<p>After discussing all 4 different models, let us compare their prediction results.</p>
<pre class="r"><code># Set plot settings
par(cex = 1.8, cex.axis = 1.8, cex.lab = 2, mfrow = c(2,2), mar = c(5, 5, 3, 3),
    col.lab = &quot;darkgrey&quot;, col.axis = &quot;darkgrey&quot;, col = &quot;darkgrey&quot;)

# Load library and plot paired-correlations
library(GGally)
ggpairs(data.frame(HPM = as.vector(crime.HPM$fit),  
                   MPM = as.vector(crime.MPM$fit),  
                   BPM = as.vector(crime.BPM$fit),  
                   BMA = as.vector(crime.BMA$fit))) </code></pre>
<p><img src="../../../../2021/05/25/bayesian-thinking/index_files/figure-html/paired-cor-1.svg" width="70%" style="display: block; margin: auto;" /></p>
<p>From the above paired correlation plots, we see that the correlations among them are extremely high. As expected, the single best predictive model (BPM) has the highest correlation with MPM, with a correlation of 0.998. However, the highest posterior model (HPM) and the Bayesian model averaging model (BMA) are nearly equally as good.</p>
</div>
<div id="prediction-with-new-data" class="section level3">
<h3>Prediction with New Data</h3>
<p>Using the <code>newdata</code> option in the <code>predict</code> function, we can obtain prediction from a new data set. Here we pretend that <code>UScrime</code> is an another new data set, and we use BMA to obtain the prediction of new observations. Here we only show the results of the first 20 data points.</p>
<pre class="r"><code>BMA.new = predict(crime.ZS, newdata = UScrime, estimator = &quot;BMA&quot;,
                  se.fit = TRUE, nsim = 10000)
crime.conf.fit.new = confint(BMA.new, parm = &quot;mean&quot;)
crime.conf.pred.new = confint(BMA.new, parm = &quot;pred&quot;)

# Show the combined results compared to the fitted values in BPM
cbind(crime.BPM$fit, crime.conf.fit.new, crime.conf.pred.new)
##                    2.5%    97.5%     mean     2.5%    97.5%     pred
##  [1,] 6.668988 6.511029 6.815780 6.661770 6.278642 7.100182 6.661770
##  [2,] 7.290854 7.137491 7.461855 7.298827 6.872579 7.712403 7.298827
##  [3,] 6.202166 5.961461 6.400882 6.179308 5.730735 6.630020 6.179308
##  [4,] 7.661307 7.378464 7.826481 7.610585 7.155874 8.055595 7.610585
##  [5,] 7.015570 6.852673 7.259911 7.054238 6.599186 7.462053 7.054238
##  [6,] 6.469547 6.292627 6.732761 6.514064 6.078801 6.972546 6.514064
##  [7,] 6.776133 6.503858 7.063877 6.784846 6.301557 7.266160 6.784846
##  [8,] 7.299560 7.044126 7.480983 7.266344 6.800003 7.688393 7.266344
##  [9,] 6.614927 6.484359 6.782041 6.629448 6.227432 7.048349 6.629448
## [10,] 6.596912 6.466392 6.738982 6.601246 6.181023 7.001233 6.601246
## [11,] 7.032834 6.869461 7.241972 7.055003 6.607736 7.462386 7.055003
## [12,] 6.581822 6.413825 6.714531 6.570625 6.150600 6.986558 6.570625
## [13,] 6.467921 6.205606 6.719277 6.472327 6.014612 6.924743 6.472327
## [14,] 6.566239 6.400063 6.770166 6.582374 6.148809 7.003967 6.582374
## [15,] 6.550129 6.359214 6.756436 6.556880 6.131190 7.002942 6.556880
## [16,] 6.888592 6.744094 7.060227 6.905017 6.484966 7.334888 6.905017
## [17,] 6.252735 5.994733 6.472804 6.229073 5.758570 6.661390 6.229073
## [18,] 6.795764 6.545435 7.095830 6.809572 6.336860 7.287637 6.809572
## [19,] 6.945687 6.741712 7.130428 6.943294 6.520286 7.366765 6.943294
## [20,] 7.000331 6.785262 7.150731 6.961980 6.551834 7.404326 6.961980
## [...]
</code></pre>
</div>
</div>
<div id="summary-4" class="section level2">
<h2>Summary</h2>
<p>In this chapter, we have introduced one of the common stochastic exploration methods, Markov Chain Monte Carlo, to explore the model space to obtain approximation of posterior probability of each model when the model space is too large for theoretical enumeration. We see that model selection can be sensitive to the prior distributions of coefficients, and introduced Zellner’s <span class="math inline">\(g\)</span>-prior so that we have to elicit only one hyper-parameter to specify the prior. Still model selection can be sensitive to the choice of <span class="math inline">\(g\)</span> where values that are too large may unintentially lead to the null model receiving high probability in Bartlett’s paradox. To resolve this and other paradoxes related to the choice of <span class="math inline">\(g\)</span>, we recommend default choices that have improved robustness to prior misspecification such as the unit information <span class="math inline">\(g\)</span>-prior, the Zellner-Siow Cauchy prior, and the hyper-<span class="math inline">\(g/n\)</span> prior.</p>
<p>We then demonstrated a multiple linear regression process using the <code>BAS</code> package and the US crime data <code>UScrime</code> using the Zellner-Siow cauchy prior, and have tried to understand the importance of variables.
Finally, we have compared the prediction results from different models, such as the ones from Bayesian model average (BMA), the highest probability model (HPM), the median probability model (MPM), and the best predictive model (BPM). For the comparison, we have used the Zellner-Siow Cauchy prior. But of course there is not one single best prior that is the best overall. If you do have prior information about a variable, you should include it. If you expect that there should be many predictors related to the response variable <span class="math inline">\(Y\)</span>, but that each has a small effect, an alternate prior may be better. Also, think critically about whether model selection is important. If you believe that all the variables should be relevant but are worried about over fitting, there are alternative priors that will avoid putting probabilities on coefficients that are exactly zero and will still prevent over fitting by shrinkage of coefficients to prior means. Examples include the Bayesian lasso or Bayesian horseshoe.</p>
<p>There are other forms of model uncertainty that you may want to consider, such as linearity in the relationship between the predictors and the response, uncertainty about the presence of outliers, and uncertainty about the distribution of the response. These forms of uncertainty can be incorporated by expanding the models and priors similar to what we have covered here.</p>
<p>Multiple linear regression is one of the most widely used statistical methods, however, this is just the tip of the iceberg of what you can do with Bayesian methods.</p>
</div>
</div>
<div id="references" class="section level1">
<h1>References</h1>
<p><a href="https://statswithr.github.io/book/" class="uri">https://statswithr.github.io/book/</a></p>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p><span class="math inline">\((\alpha, \beta)^T\)</span> means we transpose the row vector <span class="math inline">\((\alpha, \beta)\)</span> into a column vector <span class="math inline">\(\left(\begin{array}{c} \alpha \\ \beta \end{array}\right)\)</span>.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p><span class="math inline">\(\Phi(-k)\)</span> actually represents the area of the lower tail under the standard Normal distribution curve <span class="math inline">\(k\)</span> standard deviations away from the mean 0.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>Under the normal assumption, the mean of the error is 0. Taking mean on both sides of equation <a href="#eq:multi-model2">(19)</a> immediately gives <span class="math inline">\(\beta_0=\bar{y}_{\text{score}}\)</span>.<a href="#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>Note: <code>as.numeric</code> is not necessary here. We use <code>as.numeric</code> to keep the names of the levels of the two variables short.<a href="#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>Recall that the reference prior is the limiting case of the multivariate Normal-Gamma distribution.<a href="#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>A parsimonious model is a model that accomplishes a desired level of explanation or prediction with as few predictor variables as possible. More discussion of parsimonious models can be found in Course 3 Linear Regression and Modeling.<a href="#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p>More details can be found in <span class="citation">@venables2013modern</span>.<a href="#fnref7" class="footnote-back">↩︎</a></p></li>
</ol>
</div>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
          </li>
          <li>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="../../../../js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

