<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.80.0" />


<title>Algorithms in SICP - A Hugo website</title>
<meta property="og:title" content="Algorithms in SICP - A Hugo website">


  <link href='../../../../favicon.ico' rel='icon' type='image/x-icon'/>



  








<link href='//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css' rel='stylesheet' type='text/css' />



<link rel="stylesheet" href="../../../../css/fonts.css" media="all">
<link rel="stylesheet" href="../../../../css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="../../../../" class="nav-logo">
    <img src="../../../../images/logo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="../../../../about/">about</a></li>
    
    <li><a href="../../../../vitae/">CV</a></li>
    
    <li><a href="https://github.com/danli349">GitHub</a></li>
    
    <li><a href="https://scholar.google.com/citations?user=mNjLK8EAAAAJ&amp;hl=en">Googlr Scholar</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">11 min read</span>
    

    <h1 class="article-title">Algorithms in SICP</h1>

    
    <span class="article-date">2021-01-22</span>
    

    <div class="article-content">
      
<script src="../../../../2021/01/22/algorithms-in-sicp/index_files/header-attrs/header-attrs.js"></script>

<div id="TOC">
<ul>
<li><a href="#building-abstractions-with-procedures">1 Building Abstractions with Procedures</a>
<ul>
<li><a href="#procedures-and-the-processes-they-generate">1.2 Procedures and the Processes They Generate</a>
<ul>
<li><a href="#linear-recursion-and-iteration">1.2.1 Linear Recursion and Iteration</a></li>
</ul></li>
<li><a href="#formulating-abstractions-with-higher-order-procedures">1.3 Formulating Abstractions with Higher-Order Procedures</a>
<ul>
<li><a href="#procedures-as-arguments">1.3.1 Procedures as Arguments</a></li>
<li><a href="#constructing-procedures-using-lambda">1.3.2 Constructing Procedures Using <em>lambda</em></a></li>
<li><a href="#procedures-as-general-methods">1.3.3 Procedures as General Methods</a></li>
<li><a href="#procedures-as-returned-values">1.3.4 Procedures as Returned Values</a></li>
</ul></li>
</ul></li>
<li><a href="#building-abstractions-with-data">2 Building Abstractions with Data</a>
<ul>
<li><a href="#introduction-to-data-abstraction">2.1 Introduction to Data Abstraction</a>
<ul>
<li><a href="#example-arithmetic-operations-for-rational-numbers">2.1.1 Example: Arithmetic Operations for Rational Numbers</a></li>
</ul></li>
</ul></li>
</ul>
</div>

<p><a href="https://mitpress.mit.edu/sites/default/files/sicp/full-text/book/book.html">The book</a></p>
<div id="building-abstractions-with-procedures" class="section level1">
<h1>1 Building Abstractions with Procedures</h1>
<div id="procedures-and-the-processes-they-generate" class="section level2">
<h2>1.2 Procedures and the Processes They Generate</h2>
<div id="linear-recursion-and-iteration" class="section level3">
<h3>1.2.1 Linear Recursion and Iteration</h3>
<pre class="r bg-success"><code># Recursive function to find factorial
recursive.factorial &lt;- function(x) {
  if (x == 0)    return (1)
  else           return (x * recursive.factorial(x-1))
}
recursive.factorial(5)</code></pre>
<pre class="bg-warning"><code>## [1] 120</code></pre>
</div>
</div>
<div id="formulating-abstractions-with-higher-order-procedures" class="section level2">
<h2>1.3 Formulating Abstractions with Higher-Order Procedures</h2>
<div id="procedures-as-arguments" class="section level3">
<h3>1.3.1 Procedures as Arguments</h3>
<pre class="r bg-success"><code># Recursive function for new_sum and sum_cubes
increase1 &lt;- function(x) {
  return (x + 1)
}
cube &lt;- function(x) {
  return (x*x*x)
}
new_sum &lt;- function(term, a, nextstep, b) {
  if (a&gt;b)    return (0)
  else           return (term(a)+
                         new_sum(term, nextstep(a), nextstep, b))
}

sum_cubes &lt;- function(a,b) {
  new_sum(cube, a, increase1, b)
}
sum_cubes(1,10)</code></pre>
<pre><code>## [1] 3025</code></pre>
<pre class="r bg-success"><code>sum_cubes(10,10)</code></pre>
<pre><code>## [1] 1000</code></pre>
<pre class="r bg-success"><code># Recursive function for sum_integers
increase1 &lt;- function(x) {
  return (x + 1)
}
identity &lt;- function(x) {
  return (x)
}
new_sum &lt;- function(term, a, nextstep, b) {
  if (a&gt;b)    return (0)
  else           return (term(a)+
                         new_sum(term, nextstep(a), nextstep, b))
}

sum_integers &lt;- function(a,b) {
  new_sum(identity, a, increase1, b)
}
sum_integers(1,10)</code></pre>
<pre><code>## [1] 55</code></pre>
<pre class="r bg-success"><code>sum_integers(10,10)</code></pre>
<pre><code>## [1] 10</code></pre>
<p>Since <span class="math display">\[\frac{\pi}{8}=\frac{1}{1\cdot3}+\frac{1}{5\cdot7}+\frac{1}{9\cdot11}+\cdots\]</span></p>
<pre class="r bg-success"><code># Recursive function for pi-sum
pi_next &lt;- function(x) {
  return (x + 4)
}
pi_term &lt;- function(x) {
  return (1.0/(x*(x+2)))
}
new_sum &lt;- function(term, a, nextstep, b) {
  if (a&gt;b)    return (0)
  else           return (term(a)+
                         new_sum(term, nextstep(a), nextstep, b))
}
pi_sum &lt;- function(a, b) {
  return (8*new_sum(pi_term, a, pi_next, b))
}

pi_sum(1,1000)</code></pre>
<pre><code>## [1] 3.139593</code></pre>
<p>Since the integral can be approximated numerically using the formula <span class="math display">\[\int_a^b f=\Bigl[f\Bigl(a+\frac{dx}{2}\Bigr)+f\Bigl(a+dx+\frac{dx}{2}\Bigr)+f\Bigl(a+2dx+\frac{dx}{2}\Bigr)+\cdots\Bigr]dx\]</span></p>
<pre class="r bg-success"><code># Recursive function for pi-sum

new_sum &lt;- function(term, a, nextstep, b) {
  if (a&gt;b)    return (0)
  else           return (term(a)+
                         new_sum(term, nextstep(a), nextstep, b))
}
integral &lt;- function(f, a, b, dx) {
  add_dx &lt;- function(x) {
  return (x + dx)
}
  return (new_sum(f, (a+dx/2.0), add_dx, b)*dx)
}

integral(cube, 0, 1, 0.01)</code></pre>
<pre><code>## [1] 0.2499875</code></pre>
<pre class="r bg-success"><code>integral(cube, 0, 1, 0.001)</code></pre>
<pre><code>## [1] 0.2499999</code></pre>
</div>
<div id="constructing-procedures-using-lambda" class="section level3">
<h3>1.3.2 Constructing Procedures Using <em>lambda</em></h3>
<p>The lambda or anonymous functions in R have no identity, no name, and they will not live in the global environment.</p>
<pre class="r bg-success"><code>(function(x)  x + 4 )(1)</code></pre>
<pre><code>## [1] 5</code></pre>
<pre class="r bg-success"><code>(function(x) (1.0/(x*(x+2))))(1)</code></pre>
<pre><code>## [1] 0.3333333</code></pre>
<p>Then the pi-sum procedure can be expressed without defining any auxiliary procedures as:</p>
<pre class="r bg-success"><code>new_sum &lt;- function(term, a, nextstep, b) {
  if (a&gt;b)    return (0)
  else           return (term(a)+
                         new_sum(term, nextstep(a), nextstep, b))
}
pi_sum &lt;- function(a, b) {
  return (8*new_sum((function(x) (1.0/(x*(x+2)))), a, (function(x)  x + 4), b))
}
pi_sum(1,1000)</code></pre>
<pre><code>## [1] 3.139593</code></pre>
<p>We can write the integral procedure without having to define the auxiliary procedure <em>add-dx</em></p>
<pre class="r bg-success"><code># Recursive function for pi-sum
new_sum &lt;- function(term, a, nextstep, b) {
  if (a&gt;b)    return (0)
  else        return (term(a)+
                         new_sum(term, nextstep(a), nextstep, b))
}
integral &lt;- function(f, a, b, dx) {
  return (new_sum(f, (a+dx/2.0), function(x)(x + dx), b)*dx)
}

integral(cube, 0, 1, 0.01)</code></pre>
<pre><code>## [1] 0.2499875</code></pre>
<pre class="r bg-success"><code>integral(cube, 0, 1, 0.001)</code></pre>
<pre><code>## [1] 0.2499999</code></pre>
</div>
<div id="procedures-as-general-methods" class="section level3">
<h3>1.3.3 Procedures as General Methods</h3>
<p>The <em>half-interval</em> method is a simple but powerful technique for finding roots of an equation <span class="math inline">\(f(x) = 0\)</span>, where <span class="math inline">\(f\)</span> is a continuous function. The idea is that, if we are given points <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> such that <span class="math inline">\(f (a) &lt; 0 &lt; f (b)\)</span>, then <span class="math inline">\(f\)</span> must have at least one zero between <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>. To locate a zero, let <span class="math inline">\(x\)</span> be the average of <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>, and compute <span class="math inline">\(f (x)\)</span>. If <span class="math inline">\(f (x) &gt; 0\)</span>, then <span class="math inline">\(f\)</span> must have a zero between <span class="math inline">\(a\)</span> and <span class="math inline">\(x\)</span>. If <span class="math inline">\(f (x) &lt; 0\)</span>, then <span class="math inline">\(f\)</span> must have a zero between <span class="math inline">\(x\)</span> and <span class="math inline">\(b\)</span>. Continuing in this way, we can identify smaller and smaller intervals on which <span class="math inline">\(f\)</span> must have a zero. Since the interval of uncertainty is reduced by half at each step of the process, the number of steps required grows as <span class="math inline">\(\Theta(log(L/T))\)</span>, where <span class="math inline">\(L\)</span> is the length of the original interval and <span class="math inline">\(T\)</span> is the error tolerance (that is, the size of the interval we will consider “small enough”).<br />
The procedure checks to see which of the endpoints has a negative function value and which has a positive value, and calls the search procedure accordingly. If the function has the same sign on the two given points, the half-interval method cannot be used, in which case the procedure signals an error. Since <span class="math inline">\(\pi\)</span> is the root of <span class="math inline">\(\sin(x)=0,\quad 0&lt;x&lt;2\pi\)</span></p>
<pre class="r bg-success"><code>search &lt;- function(f, neg_point, pos_point) {
  midpoint &lt;- (neg_point + pos_point)/2.0
  if(abs(neg_point-pos_point) &lt; 0.0001) return(midpoint)
  else if (f(midpoint) &gt; 0)    return(search(f, neg_point, midpoint))
  else if (f(midpoint) &lt; 0)   return(search(f, midpoint, pos_point))
  else return(midpoint)
}

half_interval_method &lt;- function(f, a, b){
  a_value &lt;- f(a)
  b_value &lt;- f(b)
  if (a_value &lt; 0 &amp;&amp; b_value &gt; 0)    return(search(f, a, b))
  else if (a_value &gt; 0 &amp;&amp; b_value &lt; 0)    return(search(f, b, a))
  else return(&quot;error: Function values are not of opposite sign&quot;)
}

half_interval_method(sin, 2.0, 4.0)</code></pre>
<pre><code>## [1] 3.141571</code></pre>
<pre class="r bg-success"><code>half_interval_method(sin, 3.5, 4.0)</code></pre>
<pre><code>## [1] &quot;error: Function values are not of opposite sign&quot;</code></pre>
<p>Using the half-interval method to search for a root of the equation <span class="math display">\[x^3-2x-3=0, quad 1&lt;x&lt;2\]</span></p>
<pre class="r bg-success"><code>half_interval_method(function(x)(x^3-2*x-3), 1.0, 2.0)</code></pre>
<pre><code>## [1] 1.89328</code></pre>
<p>A number <span class="math inline">\(x\)</span> is called a <span style="color: red;"><strong>fixed point</strong></span> of a function <span class="math inline">\(f\)</span> if <span class="math inline">\(x\)</span> satisfies the equation <span class="math inline">\(f (x) = x\)</span>. we can devise a procedure <em>fixed-point</em> that takes as inputs a function and an initial guess and produces an approximation to a fixed point of the function. We apply the function repeatedly until we find two successive values whose difference is less than some prescribed tolerance:</p>
<pre class="r bg-success"><code>tolerance &lt;- 0.00001
fixed_point &lt;- function(f, first_guess) {
  close_enough &lt;- function(v1, v2){
    return(abs(v1-v2) &lt; tolerance)
  }
  tryguess &lt;- function(guess) {
    nextvalue &lt;- f(guess)
    if (close_enough(guess, nextvalue)) return(nextvalue)
    else tryguess(nextvalue)
  }
  tryguess(first_guess)
}
fixed_point(cos, 1.0)</code></pre>
<pre><code>## [1] 0.7390823</code></pre>
<p>We can find a solution to the equation <span class="math display">\[y=\sin y+\cos y\]</span></p>
<pre class="r bg-success"><code>fixed_point(function(y)(sin(y)+cos(y)), 1.0)</code></pre>
<pre><code>## [1] 1.258732</code></pre>
<p>We can formulate the square-root computation as a fixed-point search. If <span class="math inline">\(y=\sqrt{x}\)</span> then <span class="math inline">\(y^2=x\)</span> and <span class="math inline">\(y=x/y\)</span>, we can therefore try to compute square roots as</p>
<pre class="r bg-success"><code>square_root &lt;- function(x){
  fixed_point(function(y)(x/y), 1.0)
}</code></pre>
<p>Unfortunately, this fixed-point search does not converge. Consider an initial guess <span class="math inline">\(y_1\)</span>. The next guess is <span class="math inline">\(y_2 = x/y_1\)</span> and the next guess is <span class="math inline">\(y_3 =x/y_2 = x/(x/y_1) = y_1\)</span>. This results in an infinite loop in which the two guesses <span class="math inline">\(y_1\)</span> and <span class="math inline">\(y_2\)</span> repeat over and over, oscillating about the answer. Since the answer is always between our guess <span class="math inline">\(y\)</span> and <span class="math inline">\(x/y\)</span>, we can make a new guess that is not as far from <span class="math inline">\(y\)</span> as <span class="math inline">\(x/y\)</span> by averaging <span class="math inline">\(y\)</span> with <span class="math inline">\(x/y\)</span>, so that the next guess after <span class="math inline">\(y\)</span> is <span class="math inline">\(\frac{1}{2} (y + x/y)\)</span> instead of <span class="math inline">\(x/y\)</span>. This approach of averaging successive approximations to a solution, a technique that we call <span style="color: red;"><strong>average damping</strong></span>, often aids the convergence of fixed-point searches.</p>
<pre class="r bg-success"><code>square_root &lt;- function(x){
  fixed_point(function(y)((y+x/y)/2.0), 1.0)
}
square_root(2)</code></pre>
<pre><code>## [1] 1.414214</code></pre>
</div>
<div id="procedures-as-returned-values" class="section level3">
<h3>1.3.4 Procedures as Returned Values</h3>
<p>We can express the idea of average damping by means of the following procedure:</p>
<pre class="r bg-success"><code>average_damp &lt;- function(f){
  function(x)((x+f(x))/2.0)
}
square &lt;- function(x){
  return(x^2)
}
(average_damp(square))(10)</code></pre>
<pre><code>## [1] 55</code></pre>
<p>Average-damp is a procedure that takes a procedure <span class="math inline">\(f\)</span> as its argument and returns a procedure (produced by the <em>lambda</em> function) as its value that, when applied to a number <span class="math inline">\(x\)</span>, produces the average of <span class="math inline">\(x\)</span> and <span class="math inline">\(f(x)\)</span>. Using average-damp, we can reformulate the square-root procedure as follows:</p>
<pre class="r bg-success"><code>square_root &lt;- function(x){
  fixed_point(average_damp(function(y)(x/y)), 1.0)
}
square_root(2)</code></pre>
<pre><code>## [1] 1.414214</code></pre>
<pre class="r bg-success"><code>square_root(3)</code></pre>
<pre><code>## [1] 1.732051</code></pre>
<p>Notice that the cube root of <span class="math inline">\(x\)</span> is a fixed point of the function <span class="math inline">\(y \mapsto x/y^2\)</span>, so we can immediately generalize our square-root procedure to one that extracts cube roots:</p>
<pre class="r bg-success"><code>cube_root &lt;- function(x){
  fixed_point(average_damp(function(y)(x/(y^2))), 1.0)
}
cube_root(2)</code></pre>
<pre><code>## [1] 1.259923</code></pre>
<pre class="r bg-success"><code>cube_root(3)</code></pre>
<pre><code>## [1] 1.442252</code></pre>
<p><span style="color: red;"><strong>Newton’s method</strong></span> uses tangent lines of the graph of <span class="math inline">\(y = ƒ(x)\)</span> near the points where <span class="math inline">\(ƒ(x)=0\)</span> to estimate the solution. The goal of Newton’s method for estimating a solution of an equation <span class="math inline">\(ƒ(x) = 0\)</span> is to produce a sequence of approximations that approach the solution. The initial estimate, <span class="math inline">\(x_0\)</span>, may be found by just plain guessing. The method then uses the tangent to the curve <span class="math inline">\(y = ƒ(x)\)</span> at <span class="math inline">\((x_0, ƒ(x_0))\)</span> to approximate the curve, calling the point <span class="math inline">\(x_1\)</span> where the tangent meets the <span class="math inline">\(x\)</span>-axis. The number <span class="math inline">\(x_1\)</span> is usually a better approximation to the solution than is <span class="math inline">\(x_0\)</span>. The point <span class="math inline">\(x_2\)</span> where the tangent to the curve at <span class="math inline">\((x_1, ƒ(x_1))\)</span> crosses the <span class="math inline">\(x\)</span>-axis is the next approximation in the sequence. We continue on, using each approximation to generate the next, until we are close enough to the root to stop.<br />
Given the approximation <span class="math inline">\(x_n\)</span>, the point-slope equation for the tangent to the curve at <span class="math inline">\((x_n,ƒ(x_n))\)</span> is <span class="math display">\[y = ƒ(x_n) + ƒ&#39;(x_n)(x - x_n)\]</span> We can find where it crosses the <span class="math inline">\(x\)</span>-axis by setting <span class="math inline">\(y=0\)</span>, <span class="math display">\[0 = ƒ(x_n) + ƒ&#39;(x_n)(x - x_n)\]</span> <span class="math display">\[x - x_n=-\frac{ƒ(x_n)}{ƒ&#39;(x_n)}\]</span> <span class="math display">\[x=x_n-\frac{ƒ(x_n)}{ƒ&#39;(x_n)}\]</span> This value of <span class="math inline">\(x\)</span> is the next approximation <span class="math inline">\(x_{n+1}\)</span>. Then a solution of the equation <span class="math inline">\(f(x)=0\)</span> is a fixed point of the function <span class="math display">\[x \mapsto x-\frac{f(x)}{f&#39;(x)}\]</span> Newton’s method is the use of the fixed-point method to approximate a solution of the equation by finding a fixed point of the function <span class="math display">\[x-\frac{f(x)}{f&#39;(x)}\]</span><br />
We can express the idea of derivative (taking <span class="math inline">\(dx\)</span> to be, say, 0.00001) as the procedure:</p>
<pre class="r bg-success"><code>dx &lt;- 0.00001
deriv &lt;- function(f){
  function(x)((f(x+dx)-f(x))/dx)
}
cube &lt;- function(x) {
  return (x*x*x)
}
deriv(cube)(5)</code></pre>
<pre><code>## [1] 75.00015</code></pre>
<pre class="r bg-success"><code>(3*5^2)</code></pre>
<pre><code>## [1] 75</code></pre>
<p>Like average-damp, <em>deriv</em> is a procedure that takes a procedure as argument and returns a procedure as value. With the aid of deriv, we can express Newton’s method as a fixed-point process:</p>
<pre class="r bg-success"><code>newton_transform &lt;- function(f){
  function(x)(x-f(x)/deriv(f)(x))
}
newtons_method &lt;- function(f, guess){
  fixed_point(newton_transform(f), guess)
}</code></pre>
<p>The <em>newtons-method</em> takes as arguments a procedure that computes the function for which we want to find a zero, together with an initial guess. For instance, to find the square root of <span class="math inline">\(x\)</span>, we can use Newton’s method to find a zero of the function <span class="math inline">\(y \mapsto y^2 - x\)</span> starting with an initial guess of <span class="math inline">\(1\)</span>. This provides yet another form of the square-root procedure:</p>
<pre class="r bg-success"><code>square_root2 &lt;- function(x){
  newtons_method(function(y)(y^2-x), 1.0)
}
square_root2(2)</code></pre>
<pre><code>## [1] 1.414214</code></pre>
<p>Since Newton’s method was itself expressed as a fixed-point process, we actually saw two ways to compute square roots as fixed points. Each method begins with a function and finds a fixed point of some transformation of the function. We can express this general idea itself as a procedure:</p>
<pre class="r bg-success"><code>fixed_point_of_transform &lt;- function(f, transform, guess){
  fixed_point(transform(f), guess)
}</code></pre>
<p>This very general procedure takes as its arguments a procedure <span class="math inline">\(f\)</span> that computes some function, a procedure that transforms <span class="math inline">\(f\)</span>, and an initial guess. The returned result is a fixed point of the transformed function.<br />
The first square-root computation is a fixed point of the average-damped version of <span class="math inline">\(y \mapsto x/y\)</span>,</p>
<pre class="r bg-success"><code>square_root3 &lt;- function(x){
  fixed_point_of_transform(function(y)(x/y), average_damp, 1.0)
}
square_root3(2)</code></pre>
<pre><code>## [1] 1.414214</code></pre>
<p>The second square-root computation is a fixed point of the Newton transform of <span class="math inline">\(y \mapsto y^2-x\)</span>,</p>
<pre class="r bg-success"><code>square_root4 &lt;- function(x){
  fixed_point_of_transform(function(y)(y^2-x), newton_transform, 1.0)
}
square_root4(2)</code></pre>
<pre><code>## [1] 1.414214</code></pre>
</div>
</div>
</div>
<div id="building-abstractions-with-data" class="section level1">
<h1>2 Building Abstractions with Data</h1>
<div id="introduction-to-data-abstraction" class="section level2">
<h2>2.1 Introduction to Data Abstraction</h2>
<div id="example-arithmetic-operations-for-rational-numbers" class="section level3">
<h3>2.1.1 Example: Arithmetic Operations for Rational Numbers</h3>
<p>The name cons stands for “construct.” The names “car” and “cdr” derive from the original implementation of Lisp on the IBM 704. That machine had an addressing scheme that allowed one to reference the “address” and “decrement” parts of a memory location. “car” stands for “Contents of Address part of Register” and “cdr” (pronounced “could-er”) stands for “Contents of Decrement part of Register.”</p>
<pre class="r bg-success"><code>knitr::knit_engines$set(Racket = function(options) {
  code &lt;- paste(options$code, collapse = &#39;\n&#39;)
  out  &lt;- system2(
    &#39;Racket&#39;,  c(&#39;-e&#39;, shQuote(code)), stdout = TRUE
  )
  knitr::engine_output(options, code, out)
})</code></pre>
<pre class="racket bg-success"><code>(define x (cons 1 2))
(car x)
(cdr x)</code></pre>
<pre><code>## 1
## 2</code></pre>
<pre class="racket bg-success"><code>(define x (cons 1 2))
(define y (cons 3 4))
(define z (cons x y))
z
(car z)
(car (car z))
(car (cdr z))</code></pre>
<pre><code>## &#39;((1 . 2) 3 . 4)
## &#39;(1 . 2)
## 1
## 3</code></pre>
<p>Using R:</p>
<pre class="r bg-success"><code>a &lt;- list(1, 2) 
b &lt;- list(3, 4) 
x &lt;- list(a,b) 
cons &lt;- function(a, b) list(a, b)
cons(a,b)</code></pre>
<pre><code>## [[1]]
## [[1]][[1]]
## [1] 1
## 
## [[1]][[2]]
## [1] 2
## 
## 
## [[2]]
## [[2]][[1]]
## [1] 3
## 
## [[2]][[2]]
## [1] 4</code></pre>
<pre class="r bg-success"><code>car &lt;- function(x) x[[1]] 
cdr &lt;- function(x) x[[2]]
car(car(x))</code></pre>
<pre><code>## [1] 1</code></pre>
<pre class="r bg-success"><code>cdr(car(x))</code></pre>
<pre><code>## [1] 2</code></pre>
<pre class="r bg-success"><code>car(cdr(x))</code></pre>
<pre><code>## [1] 3</code></pre>
<pre class="r bg-success"><code>cdr(cdr(x))</code></pre>
<pre><code>## [1] 4</code></pre>
<p>Representing rational numbers</p>
<pre class="r bg-success"><code>make_rat &lt;- function(a, b) cons(a,b)
numer &lt;- function(x) car(x)
denom &lt;- function(x) cdr(x)
print_rat &lt;- function(x){
  paste0(numer(x),&quot;/&quot;,denom(x))
}
x &lt;- make_rat(1,2)
print_rat(x)</code></pre>
<pre><code>## [1] &quot;1/2&quot;</code></pre>
<p>Since <span class="math display">\[\frac{n_1}{d_1}+\frac{n_2}{d_2}=\frac{n_1d_2+n_2d_1}{d_1d_2}\]</span></p>
<pre class="r bg-success"><code>one_half &lt;- make_rat(1,2)
one_third &lt;- make_rat(1,3)
add_rat &lt;- function(x, y){
  make_rat(numer(x)*denom(y)+numer(y)*denom(x), denom(x)*denom(y))
}
print_rat(add_rat(one_half, one_third))</code></pre>
<pre><code>## [1] &quot;5/6&quot;</code></pre>
<p><strong>BIBLIOGRAPHY</strong></p>
<div id="refs" class="references csl-bib-body">
<div id="ref-HaroldSICP" class="csl-entry">
1. Abelson GJ Harold; Sussman. Structure and interpretation of computer programs. The MIT Press. ISBN 9780262510875; 1996.
</div>
</div>
</div>
</div>
</div>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
          </li>
          <li>
          </li>
        </ul>
      </footer>

    </div>
    



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>



<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
<script>hljs.configure({languages: []}); hljs.initHighlightingOnLoad();</script>



    
<script src="../../../../js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

