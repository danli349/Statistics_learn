<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.75.1" />


<title>Comparisons of several means - A Hugo website</title>
<meta property="og:title" content="Comparisons of several means - A Hugo website">


  <link href='../../../../favicon.ico' rel='icon' type='image/x-icon'/>



  







<link rel="stylesheet" href="../../../../css/fonts.css" media="all">
<link rel="stylesheet" href="../../../../css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="../../../../" class="nav-logo">
    <img src="../../../../images/logo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="../../../../vitae.html">CV</a></li>
    
    <li><a href="https://github.com/danli349">GitHub</a></li>
    
    <li><a href="https://scholar.google.com/citations?user=mNjLK8EAAAAJ&amp;hl=en">Googlr Scholar</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">3 min read</span>
    

    <h1 class="article-title">Comparisons of several means</h1>

    
    <span class="article-date">2020-09-29</span>
    

    <div class="article-content">
      
<script src="../../../../rmarkdown-libs/header-attrs/header-attrs.js"></script>


<ul>
<li><p>Paired Comparisons:<br />
If there are <span class="math inline">\(2\)</span> treatments over multivariate <span class="math inline">\(\mathbf x_p\)</span>, the difference between treatment <span class="math inline">\(1\)</span> and treatment <span class="math inline">\(2\)</span> is <span class="math inline">\(\mathbf d_j=\mathbf x_{j1}-\mathbf x_{j2},\quad j=1,2,\cdots,n\)</span> if <span class="math inline">\(\mathbf d_j\)</span> are independent <span class="math inline">\(N_p(\boldsymbol\delta, \mathbf\Sigma_d)\)</span> random vectors, inferences
about the vector of mean differences <span class="math inline">\(\boldsymbol\delta\)</span> can be based upon a <span class="math inline">\(T^2\)</span>-statistic: <span class="math inline">\(T^2=n(\overline{\mathbf d}-\boldsymbol\delta)^T\mathbf S_d^{-1}(\overline{\mathbf d}-\boldsymbol\delta)\)</span> is distributed as an <span class="math inline">\(\frac{(n-1)p}{n-p}F_{p,n-p}\)</span> random variable, where <span class="math inline">\(\overline{\mathbf d}=\displaystyle\frac{1}{n}\displaystyle\sum_{j=1}^{n}\mathbf d_j\)</span> and <span class="math inline">\(\mathbf S_d=\displaystyle\frac{1}{n-1}\displaystyle\sum_{j=1}^{n}(\mathbf d_j-\overline{\mathbf d})(\mathbf d_j-\overline{\mathbf d})^T\)</span>, then an <span class="math inline">\(\alpha\)</span>-level hypothesis test of <span class="math inline">\(H_0:\boldsymbol\delta=\mathbf 0\)</span> versus <span class="math inline">\(H_1:\boldsymbol\delta\ne\mathbf 0\)</span>, rejects <span class="math inline">\(H_0\)</span> if the observed <span class="math inline">\(T^2=n\overline{\mathbf d}^T\mathbf S_d^{-1}\overline{\mathbf d}&gt;\frac{(n-1)p}{n-p}F_{p,n-p}(\alpha)\)</span>.<br />
A <span class="math inline">\(100(1-\alpha)\%\)</span> <strong>confidence region</strong> for <span class="math inline">\(\boldsymbol\delta\)</span> is the ellipsoid determined by all <span class="math inline">\(\boldsymbol\delta\)</span> that <span class="math inline">\((\overline{\mathbf d}-\boldsymbol\delta)^T\mathbf S_d^{-1}(\overline{\mathbf d}-\boldsymbol\delta)\le\frac{(n-1)p}{n(n-p)}F_{p,n-p}(\alpha)\)</span> and <span class="math inline">\(100(1-\alpha)\%\)</span> <strong>simultaneous confidence intervals</strong> for the individual mean differences <span class="math inline">\(\delta_i\)</span> are given by <span class="math inline">\(\Biggl(\overline{d_i}-\sqrt{\frac{(n-1)p}{(n-p)}F_{p,n-p}(\alpha)}\sqrt{\frac{s_{ii}}{n}},\quad \overline{d_i}+\sqrt{\frac{(n-1)p}{(n-p)}F_{p,n-p}(\alpha)}\sqrt{\frac{s_{ii}}{n}}\Biggr)\)</span><br />
and the <strong>Bonferroni simultaneous confidence intervals</strong> for the individual mean differences are <span class="math inline">\(\Biggl(\overline{d_i}-t_{n-1}(\frac{\alpha}{2p})\sqrt{\frac{s_{ii}}{n}},\quad \overline{d_i}+t_{n-1}(\frac{\alpha}{2p})\sqrt{\frac{s_{ii}}{n}}\Biggr)\)</span></p></li>
<li><p><em>Repeated Measures Design</em> and many to one Comparisons of univariate variables:<br />
For univariate variables, <span class="math inline">\(q\)</span> treatments and <span class="math inline">\(n\)</span> observations for each treatment, <span class="math display">\[\mathbf X_j=\begin{bmatrix}
X_j1\\
X_j2\\
\vdots\\
X_jq\\
\end{bmatrix}\quad j=1,2,\cdots,n
\]</span>
and the <span class="math inline">\(q-1\)</span> treatments are compared with respect to a single treatment, the contrasts of the components of <span class="math inline">\(\boldsymbol\mu\)</span> is <span class="math display">\[\underset{(q-1)\times 1}{\underbrace{\begin{bmatrix}
\mu_1-\mu_2\\
\mu_1-\mu_3\\
\vdots\\
\mu_1-\mu_q\\
\end{bmatrix}}}=\underset{(q-1)\times q}{\underbrace{\begin{bmatrix}
1&amp;-1&amp;0&amp;\cdots&amp;0\\
1&amp;0&amp;-1&amp;\cdots&amp;0\\
\vdots&amp;\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\
1&amp;0&amp;0&amp;\cdots&amp;-1\\
\end{bmatrix}}}\underset{q\times 1}{\underbrace{\begin{bmatrix}
\mu_1\\
\mu_2\\
\vdots\\
\mu_q\\
\end{bmatrix}}}=\mathbf C_1\boldsymbol\mu\]</span> <span class="math inline">\(\mathbf C_1\)</span> is called contrast matrice. The hypothesis that there are no differences in treatments (equal treatment means) becomes <span class="math inline">\(\mathbf C\boldsymbol\mu=\mathbf 0\)</span> for any choice of the contrast matrix <span class="math inline">\(\mathbf C\)</span>. The contrasts of the observations <span class="math inline">\(\mathbf C\mathbf x_j\)</span> have means <span class="math inline">\(\mathbf C\overline{\mathbf x}\)</span> with <span class="math inline">\((q-1)\)</span> d.f. and covariance matrix <span class="math inline">\(\mathbf C\mathbf S\mathbf C^T\)</span> with <span class="math inline">\((n-q+1)\)</span> d.f., An <span class="math inline">\(\alpha\)</span>-level test of <span class="math inline">\(H_0:\mathbf C\boldsymbol\mu=\mathbf 0\)</span> versus <span class="math inline">\(H_1:\mathbf C\boldsymbol\mu\ne\mathbf 0\)</span> can use <span class="math inline">\(T^2\)</span>-statistic. Reject <span class="math inline">\(H_0\)</span> if: <span class="math inline">\(T^2=n(\mathbf C\overline{\mathbf x})^T(\mathbf C\mathbf S\mathbf C^T)^{-1}(\mathbf C\overline{\mathbf x})&gt;\displaystyle\frac{(n-1)(q-1)}{n-q+1}F_{q-1,n-q+1}(\alpha)\)</span> where <span class="math inline">\(\overline{\mathbf x}=\displaystyle\frac{1}{n}\displaystyle\sum_{j=1}^{n}\mathbf x_j\)</span> and <span class="math inline">\(\mathbf S=\displaystyle\frac{1}{n-1}\displaystyle\sum_{j=1}^{n}(\mathbf x_j-\overline{\mathbf x})(\mathbf x_j-\overline{\mathbf x})^T\)</span>
A <span class="math inline">\(100(1-\alpha)\%\)</span> <strong>confidence region</strong> for contrasts <span class="math inline">\(\mathbf C\boldsymbol\mu\)</span> is determined by the set of all <span class="math inline">\(\mathbf C\boldsymbol\mu\)</span> such that:<span class="math inline">\(n(\mathbf C\overline{\mathbf x}-\mathbf C\boldsymbol\mu)^T(\mathbf C\mathbf S\mathbf C^T)^{-1}(\mathbf C\overline{\mathbf x}-\mathbf C\boldsymbol\mu)\le\displaystyle\frac{(n-1)(q-1)}{n-q+1}F_{q-1,n-q+1}(\alpha)\)</span> and <span class="math inline">\(100(1-\alpha)\%\)</span> <strong>simultaneous confidence intervals</strong> for the individual contrasts <span class="math inline">\(\mathbf c^T\boldsymbol\mu\)</span> are given by <span class="math inline">\(\Biggl(\mathbf c^T\overline{\mathbf x}-\sqrt{\frac{(n-1)(q-1)}{n-q+1}F_{q-1,n-q+1}(\alpha)}\sqrt{\frac{\mathbf c^T\mathbf S\mathbf c}{n}},\quad \mathbf c^T\overline{\mathbf x}+\sqrt{\frac{(n-1)(q-1)}{n-q+1}F_{q-1,n-q+1}(\alpha)}\sqrt{\frac{\mathbf c^T\mathbf S\mathbf c}{n}}\Biggr)\)</span></p></li>
<li><p><span class="math inline">\(p\)</span>-variate two independent population mean vectors comparison:<br />
population <span class="math inline">\(1\)</span>: <span class="math inline">\(\mathbf X_{11},\mathbf X_{12},\cdots,\mathbf X_{1n_1}\)</span> with size <span class="math inline">\(n1\)</span>, mean vector <span class="math inline">\(\boldsymbol\mu_1\)</span> and covariance matrix <span class="math inline">\(\mathbf\Sigma_1\)</span>;<br />
population <span class="math inline">\(2\)</span>: <span class="math inline">\(\mathbf X_{21},\mathbf X_{22},\cdots,\mathbf X_{2n_2}\)</span> with size <span class="math inline">\(n2\)</span>, mean vector <span class="math inline">\(\boldsymbol\mu_2\)</span> and covariance matrix <span class="math inline">\(\mathbf\Sigma_2\)</span></p></li>
<li><p>When <span class="math inline">\(\mathbf\Sigma_1=\mathbf\Sigma_2=\mathbf\Sigma\)</span>, and both populations are multivariate normal, <span class="math inline">\(\displaystyle\sum_{j=1}^{n_1}(\mathbf X_{1j}-\overline{\mathbf X}_{1})(\mathbf X_{1j}-\overline{\mathbf X}_{1})^T\)</span> is an estimate of <span class="math inline">\((n_1-1)\mathbf\Sigma\)</span> and <span class="math inline">\(\displaystyle\sum_{j=1}^{n_2}(\mathbf X_{2j}-\overline{\mathbf X}_{2})(\mathbf X_{2j}-\overline{\mathbf X}_{2})^T\)</span> is an estimate of <span class="math inline">\((n_2-1)\mathbf\Sigma\)</span>
The common covariance <span class="math inline">\(\mathbf\Sigma\)</span> can be estimated using both samples <span class="math display">\[\begin{align}
\mathbf S_{pooled}&amp;=\displaystyle\frac{\displaystyle\sum_{j=1}^{n_1}(\mathbf X_{1j}-\overline{\mathbf X}_{1})(\mathbf X_{1j}-\overline{\mathbf X}_{1})^T+\displaystyle\sum_{j=1}^{n_2}(\mathbf X_{2j}-\overline{\mathbf X}_{2})(\mathbf X_{2j}-\overline{\mathbf X}_{2})^T}{n_1+n_2-2}\\
&amp;=\displaystyle\frac{(n_1-1)\mathbf S_1+(n_2-1)\mathbf S_2}{n_1+n_2-2}\\
&amp;=\displaystyle\frac{\mathbf W_{n_1-1}(\mathbf\Sigma)+\mathbf W_{n_2-1}(\mathbf\Sigma)}{n_1+n_2-2}\\
&amp;=\displaystyle\frac{\mathbf W_{n_1+n_2-2}(\mathbf\Sigma)}{n_1+n_2-2}
\end{align}\]</span>Because <span class="math inline">\(E(\overline{\mathbf X}_{1}-\overline{\mathbf X}_{2})=E(\overline{\mathbf X}_{1})-E(\overline{\mathbf X}_{2})=\boldsymbol\mu_1-\boldsymbol\mu_2\)</span> and <span class="math inline">\(Cov(\overline{\mathbf X}_{1}-\overline{\mathbf X}_{2})=Cov(\overline{\mathbf X}_{1})+Cov(\overline{\mathbf X}_{2})=(\frac{1}{n_1}+\frac{1}{n_2})\mathbf\Sigma\)</span> and <span class="math inline">\(\mathbf S_{pooled}\)</span> is an estimate of <span class="math inline">\(\mathbf\Sigma\)</span>, <span class="math inline">\(T^2\)</span> statistical <span class="math display">\[\begin{align}
T^2&amp;=\Bigl[(\overline{\mathbf X}_{1}-\overline{\mathbf X}_{2})-(\boldsymbol\mu_1-\boldsymbol\mu_2)\Bigr]^T\Bigl[(\frac{1}{n_1}+\frac{1}{n_2})\mathbf S_{pooled}\Bigr]^{-1}\Bigl[(\overline{\mathbf X}_{1}-\overline{\mathbf X}_{2})-(\boldsymbol\mu_1-\boldsymbol\mu_2)\Bigr]\\
&amp;=\Bigl(\frac{1}{n_1}+\frac{1}{n_2}\Bigr)^{-1/2}\Bigl[(\overline{\mathbf X}_{1}-\overline{\mathbf X}_{2})-(\boldsymbol\mu_1-\boldsymbol\mu_2)\Bigr]^T\mathbf S_{pooled}^{-1}\Bigl(\frac{1}{n_1}+\frac{1}{n_2}\Bigr)^{-1/2}\Bigl[(\overline{\mathbf X}_{1}-\overline{\mathbf X}_{2})-(\boldsymbol\mu_1-\boldsymbol\mu_2)\Bigr]\\
&amp;=\Bigl(\text{multivariate normal vector}\Bigr)^T\Bigl(\frac{\text{Wishart random matrix}}{d.f.}\Bigr)^{-1}\Bigl(\text{multivariate normal vector}\Bigr)\\
&amp;=N_p(\mathbf 0, \mathbf\Sigma)^T\Bigl(\frac{\mathbf W_{n_1+n_2-2}(\mathbf\Sigma)}{n_1+n_2-2}\Bigr)^{-1}N_p(\mathbf 0, \mathbf\Sigma)
\end{align}\]</span>is distributed as<span class="math inline">\(\displaystyle\frac{(n_1+n_2-2)p}{n_1+n_2-p-1}F_{p,n_1+n_2-p-1}\)</span> and <span class="math inline">\(P\Biggl[\Bigl[(\overline{\mathbf X}_{1}-\overline{\mathbf X}_{2})-(\boldsymbol\mu_1-\boldsymbol\mu_2)\Bigr]^T\Bigl[(\frac{1}{n_1}+\frac{1}{n_2})\mathbf S_{pooled}\Bigr]^{-1}\Bigl[(\overline{\mathbf X}_{1}-\overline{\mathbf X}_{2})-(\boldsymbol\mu_1-\boldsymbol\mu_2)\Bigr]\le\displaystyle\frac{(n_1+n_2-2)p}{n_1+n_2-p-1}F_{p,n_1+n_2-p-1}(\alpha)\Biggl]=1-\alpha\)</span></p></li>
<li><p>The contrasts of sample means <span class="math inline">\(\mathbf a^T(\overline{\mathbf X}_{1}-\overline{\mathbf X}_{2})\)</span> has <span class="math inline">\(E(\mathbf a^T(\overline{\mathbf X}_{1}-\overline{\mathbf X}_{2}))=\mathbf a^T(\boldsymbol\mu_1-\boldsymbol\mu_2)\)</span> and <span class="math inline">\(Cov(\mathbf a^T(\overline{\mathbf X}_{1}-\overline{\mathbf X}_{2}))=\mathbf a^T(\frac{n_1-1}{n_1+n_2-2}\mathbf S_1+\frac{n_2-1}{n_1+n_2-2}\mathbf S_2)\mathbf a=\mathbf a^T\mathbf S_{pooled}\mathbf a\)</span> and then <span class="math inline">\(t^2=\frac{\Bigl[\mathbf a^T(\overline{\mathbf X}_{1}-\overline{\mathbf X}_{2})-\mathbf a^T(\boldsymbol\mu_1-\boldsymbol\mu_2)\Bigr]^2}{\Bigl(\displaystyle\frac{1}{n_1}+\displaystyle\frac{1}{n_2}\Bigr)\mathbf a^T\mathbf S_{pooled}\mathbf a}=\frac{\Bigl[\mathbf a^T(\overline{\mathbf X}_{1}-\overline{\mathbf X}_{2}-(\boldsymbol\mu_1-\boldsymbol\mu_2)\Bigr]^2}{\Bigl(\displaystyle\frac{1}{n_1}+\displaystyle\frac{1}{n_2}\Bigr)\mathbf a^T\mathbf S_{pooled}\mathbf a}\le\Bigl[(\overline{\mathbf X}_{1}-\overline{\mathbf X}_{2})-(\boldsymbol\mu_1-\boldsymbol\mu_2)\Bigr]^T\Bigl[(\frac{1}{n_1}+\frac{1}{n_2})\mathbf S_{pooled}\Bigr]^{-1}\Bigl[(\overline{\mathbf X}_{1}-\overline{\mathbf X}_{2})-(\boldsymbol\mu_1-\boldsymbol\mu_2)\Bigr]=T^2\)</span> So, <span class="math inline">\((1-\alpha)=P\Bigl[T^2\le\displaystyle\frac{(n_1+n_2-2)p}{n_1+n_2-p-1}F_{p,n_1+n_2-p-1}(\alpha)\Bigr]\)</span> and the <span class="math inline">\(100(1-\alpha)\%\)</span> <strong>simultaneous confidence intervals</strong> for the contrasts <span class="math inline">\(\mathbf a^T(\boldsymbol\mu_1-\boldsymbol\mu_2)\)</span> are given by <span class="math inline">\(\Biggl(\mathbf a^T(\overline{\mathbf X}_{1}-\overline{\mathbf X}_{2})\pm\sqrt{\displaystyle\frac{(n_1+n_2-2)p}{n_1+n_2-p-1}F_{p,n_1+n_2-p-1}(\alpha)}\sqrt{\mathbf a^T\Bigl(\frac{1}{n_1}+\frac{1}{n_2}\Bigr)\mathbf S_{pooled}\mathbf a}\Biggr)\)</span> and the <strong>Bonferroni <span class="math inline">\(100(1-\alpha)\%\)</span> simultaneous confidence intervals</strong> for the individual mean differences are <span class="math inline">\(\mu_{1i}-\mu_{2i}:(\overline{x}_{1i}-\overline{x}_{2i})\pm t_{n_1+n_2-2}(\frac{\alpha}{2p})\sqrt{(\frac{1}{n_1}+\frac{1}{n_2})s_{ii,pooled}}\)</span></p></li>
</ul>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
          </li>
          <li>
          </li>
        </ul>
      </footer>

    </div>
    

    
<script src="../../../../js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

