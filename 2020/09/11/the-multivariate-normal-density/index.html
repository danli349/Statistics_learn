<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.75.1" />


<title>The Multivariate Normal Density - A Hugo website</title>
<meta property="og:title" content="The Multivariate Normal Density - A Hugo website">


  <link href='../../../../favicon.ico' rel='icon' type='image/x-icon'/>



  







<link rel="stylesheet" href="../../../../css/fonts.css" media="all">
<link rel="stylesheet" href="../../../../css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="../../../../" class="nav-logo">
    <img src="../../../../images/logo.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="../../../../vitae/">CV</a></li>
    
    <li><a href="https://github.com/danli349">GitHub</a></li>
    
    <li><a href="https://scholar.google.com/citations?user=mNjLK8EAAAAJ&amp;hl=en">Googlr Scholar</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">6 min read</span>
    

    <h1 class="article-title">The Multivariate Normal Density</h1>

    
    <span class="article-date">2020-09-11</span>
    

    <div class="article-content">
      
<script src="../../../../rmarkdown-libs/header-attrs/header-attrs.js"></script>


<p>The univariate normal pdf is:
<span class="math display">\[f_X(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{1}{2}(\frac{x-\mu}{\sigma})^2}, \quad -\infty&lt;x&lt;+\infty\]</span> The term <span class="math inline">\((\frac{x-\mu}{\sigma})^2=(x-\mu)(\sigma^2)^{-1}(x-\mu)\)</span> measures the square of
the <strong>univariate distance</strong> from <span class="math inline">\(x\)</span> to <span class="math inline">\(\mu\)</span> in standard deviation units. This can be generalized to a <span class="math inline">\(p\times 1\)</span> vector <span class="math inline">\(\mathbf x\)</span> of observations on several variables as <span class="math inline">\((\mathbf X-\boldsymbol \mu)^T(\mathbf \Sigma)^{-1}(\mathbf X-\boldsymbol \mu)\)</span>, which is the square of the <strong>multivariate generalized distance</strong> from <span class="math inline">\(\mathbf X\)</span> to <span class="math inline">\(\boldsymbol \mu\)</span>, the <span class="math inline">\(p\times p\)</span> matrix <span class="math inline">\(\mathbf \Sigma\)</span> is the variance–covariance matrix of <span class="math inline">\(\mathbf X\)</span>. Because the volume under the surface of the multivariate density function unity for any <span class="math inline">\(p\)</span> is <span class="math inline">\((2\pi)^{-p/2}|\boldsymbol\Sigma|^{-1/2}\)</span>, then a <span class="math inline">\(p\)</span>-dimensional normal density for the random vector <span class="math inline">\(\mathbf X^T=[X_1,X_2,\cdots,X_p]\)</span> has the form <span class="math display">\[
f_X(\mathbf x)=\frac{1}{(2\pi)^{p/2}|\mathbf\Sigma|^{1/2}}e^{-\frac{1}{2}(\mathbf x-\boldsymbol \mu)^T(\mathbf\Sigma)^{-1}(\mathbf x-\boldsymbol \mu)}, \quad -\infty&lt;x_i&lt;+\infty, \quad i=1,2,\cdots,p
\]</span>, which can be denoted by <span class="math inline">\(N_p(\boldsymbol \mu, \mathbf\Sigma)\)</span>.</p>
<p>For the <span style="color: red;"><strong>bivariate normal distribution</strong></span>, <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are random variables with joint pdf <span class="math display">\[\begin{align}
f_{X_1,X_2}(x_1, x_2)&amp;=\frac{1}{2\pi\sqrt{\sigma_{11}\sigma_{22}}\sqrt{1-\rho_{12}^2}}exp\Biggl[-\frac{1}{2}\frac{1}{1-\rho_{12}^2}\Bigl[(\frac{x_1 − \mu_1}{\sqrt{\sigma_{11}}})^2-2\rho_{12}(\frac{x_1 − \mu_1}{\sqrt{\sigma_{11}}})(\frac{x_2 − \mu_2}{\sqrt{\sigma_{22}}}) +(\frac{x_2 − \mu_2}{\sqrt{\sigma_{22}}})^2\Bigr]\Biggr]
\end{align}\]</span> and <span class="math inline">\(\rho_{12}=\frac{Cov(X_1,X_2)}{\sqrt{\sigma_{11}}\sqrt{\sigma_{22}}}=\frac{\sigma_{12}}{\sqrt{\sigma_{11}}\sqrt{\sigma_{22}}}\)</span> is the correlation coefficient between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. The inverse of the covariance matrix <span class="math display">\[\mathbf \Sigma=\begin{bmatrix}
\sigma_{11}&amp;\sigma_{12}\\
\sigma_{12}&amp;\sigma_{22}
\end{bmatrix}
\]</span> is <span class="math display">\[\mathbf \Sigma^{-1}=\frac{1}{\sigma_{11}\sigma_{22}-\sigma_{12}^2}\begin{bmatrix}
\sigma_{22}&amp;-\sigma_{12}\\
-\sigma_{12}&amp;\sigma_{11}
\end{bmatrix}
\]</span>, because <span class="math inline">\(\sigma_{11}\sigma_{22}-\sigma_{12}^2=\sigma_{11}\sigma_{22}(1-\rho_{12}^2)\)</span>, the <strong>squared distance</strong> becomes <span class="math display">\[\begin{align}
(\mathbf x-\boldsymbol \mu)^T(\mathbf \Sigma)^{-1}(\mathbf x-\boldsymbol \mu)&amp;=\begin{bmatrix}
x_1-\mu_1&amp;x_2-\mu_2
\end{bmatrix}\frac{1}{\sigma_{11}\sigma_{22}(1-\rho_{12}^2)}\begin{bmatrix}
\sigma_{22}&amp;-\sigma_{12}\\
-\sigma_{12}&amp;\sigma_{11}
\end{bmatrix}\begin{bmatrix}
x_1-\mu_1\\
x_2-\mu_2
\end{bmatrix}\\
&amp;=\begin{bmatrix}
x_1-\mu_1&amp;x_2-\mu_2
\end{bmatrix}\frac{1}{\sigma_{11}\sigma_{22}(1-\rho_{12}^2)}\begin{bmatrix}
\sigma_{22}&amp;-\rho_{12}\sqrt{\sigma_{11}}\sqrt{\sigma_{22}}\\
-\rho_{12}\sqrt{\sigma_{11}}\sqrt{\sigma_{22}}&amp;\sigma_{11}
\end{bmatrix}\begin{bmatrix}
x_1-\mu_1\\
x_2-\mu_2
\end{bmatrix}\\
&amp;=\frac{\sigma_{22}(x_1-\mu_1)^2+\sigma_{11}(x_2-\mu_2)^2-2\rho_{12}\sqrt{\sigma_{11}}\sqrt{\sigma_{22}}(x_1-\mu_1)(x_2-\mu_2)}{\sigma_{11}\sigma_{22}(1-\rho_{12}^2)}\\
&amp;=\frac{1}{(1-\rho_{12}^2)}\Biggl[\Biggl(\frac{x_1-\mu_1}{\sqrt{\sigma_{11}}}\Biggr)^2+\Biggl(\frac{x_2-\mu_2}{\sqrt{\sigma_{22}}}\Biggr)^2-2\rho_{12}\Biggl(\frac{x_1-\mu_1}{\sqrt{\sigma_{11}}}\Biggr)\Biggl(\frac{x_2-\mu_2}{\sqrt{\sigma_{22}}}\Biggr)\Biggr]
\end{align}\]</span> since <span class="math inline">\(|\mathbf \Sigma|=\sigma_{11}\sigma_{22}-\sigma_{12}^2=\sigma_{11}\sigma_{22}(1-\rho^2)\)</span>, then the compact general form of <strong>bivariate normal distribution</strong> is <span class="math display">\[f_{X_1,X_2}(x_1, x_2)=f(\mathbf x)=\frac{1}{2\pi|\mathbf\Sigma|^{1/2}}e^{-\frac{1}{2}(\mathbf x-\boldsymbol \mu)^T(\mathbf\Sigma)^{-1}(\mathbf x-\boldsymbol \mu)}\]</span></p>
<p><span class="math inline">\(\{ \text{all } \mathbf x \text{ that } (\mathbf x-\boldsymbol \mu)^T(\mathbf \Sigma)^{-1}(\mathbf x-\boldsymbol \mu)=c^2 \}\)</span> is called <span style="color: red;"><strong>Constant probability density contour</strong></span>.</p>
<p>If <span class="math inline">\((\lambda, \mathbf e),\mathbf e\ne0\)</span> is an eigenvalue–eigenvector pair for positive definite matrix <span class="math inline">\(\mathbf \Sigma\)</span>, then <span class="math inline">\(0&lt;\mathbf e^T\mathbf\Sigma\mathbf e=\mathbf e^T\lambda\mathbf e=\lambda\mathbf e^T\mathbf e=\lambda\)</span>, and <span class="math inline">\(\mathbf e=\mathbf \Sigma^{-1}\mathbf \Sigma\mathbf e=\mathbf \Sigma^{-1}\lambda\mathbf e\Rightarrow\frac{1}{\lambda}\mathbf e=\Sigma^{-1}\mathbf e\)</span>, which shows <span class="math inline">\((\frac{1}{\lambda}, \mathbf e)\)</span> is an eigenvalue–eigenvector pair for matrix <span class="math inline">\(\mathbf \Sigma^{-1}\)</span>, which is also positive definite, because <span class="math display">\[\begin{align}
\mathbf x^T\mathbf \Sigma^{-1}\mathbf x&amp;=\mathbf x^T\Biggl(\displaystyle\sum_{i=1}^{p}\frac{1}{\lambda_i}\mathbf e_i\mathbf e_i^T\Biggr)\mathbf x\\
&amp;=\displaystyle\sum_{i=1}^{p}\frac{1}{\lambda_i}\mathbf x^T(\mathbf e_i\mathbf e_i^T)\mathbf x\\
&amp;=\displaystyle\sum_{i=1}^{p}\frac{1}{\lambda_i}(\mathbf x^T\mathbf e_i)^2\ge0
\end{align}\]</span>
Then <span class="math inline">\((\mathbf x-\boldsymbol \mu)^T\mathbf \Sigma^{-1}(\mathbf x-\boldsymbol \mu)=c^2\)</span> are ellipsoids centered at <span class="math inline">\(\boldsymbol \mu\)</span> and have axes <span class="math inline">\(\pm c\sqrt{\lambda_i}\mathbf e_i\)</span>.</p>
<ul>
<li><p>If <span class="math inline">\(\mathbf X\)</span> is distributed as <span class="math inline">\(N_p(\boldsymbol \mu, \mathbf \Sigma)\)</span> with <span class="math inline">\(|\mathbf\Sigma|&gt;0\)</span>, then <span class="math inline">\((\mathbf X-\boldsymbol \mu)^T\mathbf \Sigma^{-1}(\mathbf X-\boldsymbol \mu)\)</span> is distributed as <span class="math inline">\(\chi_p^2\)</span>. Because <span class="math display">\[\begin{align}
(\mathbf X-\boldsymbol \mu)^T\mathbf \Sigma^{-1}(\mathbf X-\boldsymbol \mu)&amp;=(\mathbf X-\boldsymbol \mu)^T\sum_{i=1}^{p}\frac{1}{\lambda_i}\mathbf e_i\mathbf e_i^T(\mathbf X-\boldsymbol \mu)\\
&amp;=\sum_{i=1}^{p}\frac{1}{\lambda_i}(\mathbf X-\boldsymbol \mu)^T\mathbf e_i\mathbf e_i^T(\mathbf X-\boldsymbol \mu)\\
&amp;=\sum_{i=1}^{p}\frac{1}{\lambda_i}(\mathbf e_i^T(\mathbf X-\boldsymbol \mu))^2\\
&amp;=\sum_{i=1}^{p}(\frac{1}{\sqrt{\lambda_i}}\mathbf e_i^T(\mathbf X-\boldsymbol \mu))^2\\
&amp;=\sum_{i=1}^{p}\mathbf Z_i^2
\end{align}\]</span> We can denote <span class="math inline">\(\mathbf Z=\mathbf A(\mathbf X-\boldsymbol \mu)=\begin{bmatrix} \frac{1}{\sqrt{\lambda_1}}\mathbf e_1^T\\ \frac{1}{\sqrt{\lambda_2}}\mathbf e_2^T\\ \vdots\\ \frac{1}{\sqrt{\lambda_p}}\mathbf e_p^T\\ \end{bmatrix}(\mathbf X-\boldsymbol \mu)\)</span>, then <span class="math inline">\(\mathbf Z\)</span> is distributed as <span class="math inline">\(N_p(\mathbf 0, \mathbf A\mathbf \Sigma\mathbf A^T)\)</span>, where <span class="math inline">\(\mathbf A\mathbf \Sigma\mathbf A^T=\begin{bmatrix} \frac{1}{\sqrt{\lambda_1}}\mathbf e_1^T\\ \frac{1}{\sqrt{\lambda_2}}\mathbf e_2^T\\ \vdots\\ \frac{1}{\sqrt{\lambda_p}}\mathbf e_p^T\\ \end{bmatrix}\begin{bmatrix} \displaystyle\sum_{i=1}^{p}\lambda_i\mathbf e_i\mathbf e_i^T \end{bmatrix}\begin{bmatrix} \frac{1}{\sqrt{\lambda_1}}\mathbf e_1^T&amp; \frac{1}{\sqrt{\lambda_2}}\mathbf e_2^T&amp; \cdots&amp; \frac{1}{\sqrt{\lambda_p}}\mathbf e_p^T \end{bmatrix}=\mathbf I\)</span>, so <span class="math inline">\(Z_i\)</span> are <strong>independent standard normal</strong> variables.</p></li>
<li><p>When <span class="math inline">\(\mathbf X\)</span> is distributed as <span class="math inline">\(N_p(\boldsymbol \mu, \mathbf \Sigma)\)</span>, <span class="math inline">\((\mathbf X-\boldsymbol \mu)^T\mathbf \Sigma^{-1}(\mathbf X-\boldsymbol \mu)\)</span> is the squared statistical distance from <span class="math inline">\(\mathbf X\)</span> to <span class="math inline">\(\boldsymbol \mu\)</span>.</p></li>
<li><p>If <span class="math inline">\(\mathbf X\)</span> is distributed as <span class="math inline">\(N_p(\boldsymbol \mu, \mathbf \Sigma)\)</span>, any linear combination of the components of <span class="math inline">\(\mathbf X\)</span>, <span class="math inline">\(\mathbf a^T\mathbf X=a_1X_1+a_2X_2+\cdots+a_pX_p\)</span> is also normally distributed as <span class="math inline">\(N_p(\mathbf a^T\boldsymbol \mu, \mathbf a^T\mathbf \Sigma\mathbf a)\)</span>. <span class="math display">\[\begin{align}
\mathbf a^T\mathbf \Sigma\mathbf a&amp;=\begin{bmatrix}
a_{11}&amp;a_{12}&amp;\cdots&amp;a_{1p}
\end{bmatrix}\begin{bmatrix}
\sigma_{11}&amp;\sigma_{12}&amp;\cdots&amp;\sigma_{1p}\\
\sigma_{12}&amp;\sigma_{22}&amp;\cdots&amp;\sigma_{2p}\\
\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\
\sigma_{1p}&amp;\sigma_{2p}&amp;\cdots&amp;\sigma_{pp}\\
\end{bmatrix}\begin{bmatrix}
a_{11}\\
a_{12}\\
\vdots\\
a_{1p}
\end{bmatrix}\\
\end{align}\]</span></p></li>
<li><p>If <span class="math inline">\(\mathbf X\)</span> is distributed as <span class="math inline">\(N_p(\boldsymbol \mu, \mathbf \Sigma)\)</span>, the <span class="math inline">\(q\)</span> linear combination of the components of <span class="math inline">\(\mathbf X\)</span>, <span class="math display">\[\underset{(q\times p)}{\mathbf A}\underset{(p\times 1)}{\mathbf X}=\begin{bmatrix}
a_{11}X_1+a_{12}X_2+\cdots+a_{1p}X_p\\
a_{21}X_1+a_{22}X_2+\cdots+a_{2p}X_p\\
\vdots\\
a_{q1}X_1+a_{q2}X_2+\cdots+a_{qp}X_p\\
\end{bmatrix}\]</span> are also normally distributed as <span class="math inline">\(N_q(\underset{q\times p}{\mathbf A}\underset{p\times 1}{\boldsymbol \mu}, \underset{q\times p}{\mathbf A}\underset{p\times p}{\mathbf \Sigma}\underset{p\times q}{\mathbf A^T})\)</span>.</p></li>
<li><p>The marginal distribution of any component <span class="math inline">\(X_i, i\in \{1,\cdots,p\}\)</span> of <span class="math inline">\(\mathbf X\)</span> is <span class="math inline">\(N_p(\mu_i, \sigma_{ii})\)</span>.</p></li>
<li><p>The conditional density of <span class="math inline">\(X_1\)</span> given that <span class="math inline">\(X_2=x_2\)</span> for any bivariate distribution is <span class="math display">\[\begin{align}
f(X_1|x_2)&amp;=\frac{f(x_1, x_2)}{f(x_2)}\\
&amp;=\frac{\frac{1}{2\pi\sqrt{\sigma_{11}\sigma_{22}}\sqrt{1-\rho_{12}^2}}exp\Biggl[-\frac{1}{2}\frac{1}{1-\rho_{12}^2}\Bigl[(\frac{x_1 − \mu_1}{\sqrt{\sigma_{11}}})^2-2\rho_{12}(\frac{x_1 − \mu_1}{\sqrt{\sigma_{11}}})(\frac{x_2 − \mu_2}{\sqrt{\sigma_{22}}}) +(\frac{x_2 − \mu_2}{\sqrt{\sigma_{22}}})^2\Bigr]\Biggr]}{\frac{1}{\sqrt{2\pi}\sqrt{\sigma_{22}}}e^{-\frac{1}{2}\frac{(x_2-\mu_2)^2}{\sigma_{22}}}}\\
&amp;=\frac{\frac{1}{2\pi\sqrt{\sigma_{11}\sigma_{22}}\sqrt{1-\rho_{12}^2}}exp\Biggl[-\frac{1}{2}\frac{1}{\sigma_{11}(1-\rho_{12}^2)}\Bigl[(x_1 − \mu_1)^2-2\rho_{12}\frac{(x_1 − \mu_1)(x_2 − \mu_2)\sqrt{\sigma_{11}}}{\sqrt{\sigma_{22}}}+\frac{(x_2 − \mu_2)^2\sigma_{11}}{\sigma_{22}}\Bigr]\Biggr]}{\frac{1}{\sqrt{2\pi}\sqrt{\sigma_{22}}}e^{-\frac{1}{2}\frac{(x_2-\mu_2)^2}{\sigma_{22}}}}\\
&amp;=\frac{\frac{1}{2\pi\sqrt{\sigma_{11}\sigma_{22}}\sqrt{1-\rho_{12}^2}}exp\Biggl[-\frac{1}{2}\frac{1}{\sigma_{11}(1-\rho_{12}^2)}\Bigl[\Bigl((x_1 − \mu_1)-\rho_{12}\frac{\sqrt{\sigma_{11}}}{\sqrt{\sigma_{22}}}(x_2 − \mu_2)\Bigr)^2-\rho_{12}^2\frac{\sigma_{11}}{\sigma_{22}}(x_2 − \mu_2)^2+\frac{(x_2 − \mu_2)^2\sigma_{11}}{\sigma_{22}}\Bigr]\Biggr]}{\frac{1}{\sqrt{2\pi}\sqrt{\sigma_{22}}}e^{-\frac{1}{2}\frac{(x_2-\mu_2)^2}{\sigma_{22}}}}\\
&amp;=\frac{\frac{1}{2\pi\sqrt{\sigma_{11}\sigma_{22}}\sqrt{1-\rho_{12}^2}}exp\Biggl[-\frac{1}{2}\frac{1}{\sigma_{11}(1-\rho_{12}^2)}\Bigl[\Bigl((x_1 − \mu_1)-\rho_{12}\frac{\sqrt{\sigma_{11}}}{\sqrt{\sigma_{22}}}(x_2 − \mu_2)\Bigr)^2+(1-\rho_{12}^2)\frac{\sigma_{11}}{\sigma_{22}}(x_2 − \mu_2)^2\Bigr]\Biggr]}{\frac{1}{\sqrt{2\pi}\sqrt{\sigma_{22}}}e^{-\frac{1}{2}\frac{(x_2-\mu_2)^2}{\sigma_{22}}}}\\
&amp;=\frac{\frac{1}{2\pi\sqrt{\sigma_{11}\sigma_{22}}\sqrt{1-\rho_{12}^2}}exp\Biggl[-\frac{1}{2}\frac{1}{\sigma_{11}(1-\rho_{12}^2)}\Bigl[\Bigl(x_1 − \mu_1-\frac{\sigma_{11}}{\sigma_{22}}(x_2 − \mu_2)\Bigr)^2+(1-\rho_{12}^2)\frac{\sigma_{11}}{\sigma_{22}}(x_2 − \mu_2)^2\Bigr]\Biggr]}{\frac{1}{\sqrt{2\pi}\sqrt{\sigma_{22}}}e^{-\frac{1}{2}\frac{(x_2-\mu_2)^2}{\sigma_{22}}}}\\
&amp;=\frac{\frac{1}{2\pi\sqrt{\sigma_{11}\sigma_{22}}\sqrt{1-\rho_{12}^2}}exp\Biggl[-\frac{1}{2}\frac{1}{\sigma_{11}(1-\rho_{12}^2)}\Bigl(x_1−\mu_1-\frac{\sigma_{11}}{\sigma_{22}}(x_2−\mu_2)\Bigr)^2-\frac{1}{2}\frac{1}{\sigma_{22}}(x_2−\mu_2)^2\Biggr]}{\frac{1}{\sqrt{2\pi}\sqrt{\sigma_{22}}}e^{-\frac{1}{2}\frac{(x_2-\mu_2)^2}{\sigma_{22}}}}\\
&amp;=\frac{1}{\sqrt{2\pi}\sqrt{\sigma_{11}}\sqrt{1-\rho_{12}^2}}exp\Biggl[-\frac{1}{2}\frac{1}{\sigma_{11}(1-\rho_{12}^2)}\Bigl(x_1−\mu_1-\frac{\sigma_{11}}{\sigma_{22}}(x_2−\mu_2)\Bigr)^2\Biggr]
\end{align}\]</span> which is a normal distribution <span class="math inline">\(N(\mu_1+\frac{\sigma_{11}}{\sigma_{22}}(x_2−\mu_2),\sigma_{11}(1-\rho_{12}^2))\)</span>, and <span class="math inline">\(\mu_1+\frac{\sigma_{11}}{\sigma_{22}}(x_2−\mu_2)=\mu_1+\mathbf \Sigma_{12}\mathbf \Sigma_{22}^{-1}(x_2−\mu_2)\)</span>, <span class="math inline">\(\sigma_{11}(1-\rho_{12}^2)=\sigma_{11}-\sigma_{11}\rho_{12}^2=\sigma_{11}-\sigma_{12}^2/\sigma_{22}=\mathbf \Sigma_{11}-\mathbf \Sigma_{12}\mathbf \Sigma_{22}^{-1}\mathbf \Sigma_{21}\)</span></p></li>
<li><p>The above result can be generalized to:
if <span class="math inline">\(\mathbf X=\begin{bmatrix} \mathbf X_1\\ \hdashline \mathbf X_2\\ \end{bmatrix}\)</span> is distributed as <span class="math inline">\(N_p(\boldsymbol\mu, \mathbf\Sigma)\)</span> with <span class="math inline">\(\boldsymbol\mu=\begin{bmatrix} \boldsymbol\mu_1\\ \hdashline \boldsymbol\mu_2\\ \end{bmatrix}\)</span>, <span class="math inline">\(\mathbf\Sigma=\left[\begin{array}{c:c} \mathbf\Sigma_{11}&amp;\mathbf\Sigma_{12}\\ \hdashline \mathbf\Sigma_{21}&amp;\mathbf\Sigma_{22}\\ \end{array} \right]\)</span> and <span class="math inline">\(|\mathbf\Sigma_{22}|&gt;0\)</span>, then the conditional distribution of <span class="math inline">\(\mathbf X_1\)</span> given that <span class="math inline">\(\mathbf X_2=\mathbf x_2\)</span>, is a normal distribution with <span class="math inline">\(\boldsymbol\mu=\boldsymbol\mu_1+\mathbf \Sigma_{12}\mathbf \Sigma_{22}^{-1}(\mathbf x_2−\boldsymbol\mu_2)\)</span> and <span class="math inline">\(\mathbf\Sigma=\mathbf \Sigma_{11}-\mathbf \Sigma_{12}\mathbf \Sigma_{22}^{-1}\mathbf \Sigma_{21}\)</span>, which does not depend on the values of the conditioning variables.</p></li>
<li><p>Because <span class="math inline">\((\mathbf X-\boldsymbol \mu)^T\mathbf \Sigma^{-1}(\mathbf X-\boldsymbol \mu)\)</span> is a scalar, so <span class="math inline">\((\mathbf X-\boldsymbol \mu)^T\mathbf \Sigma^{-1}(\mathbf X-\boldsymbol \mu)=tr[(\mathbf X-\boldsymbol \mu)^T\mathbf \Sigma^{-1}(\mathbf X-\boldsymbol \mu)]=tr[\mathbf \Sigma^{-1}(\mathbf X-\boldsymbol \mu)(\mathbf X-\boldsymbol \mu)^T]\)</span> then <span class="math display">\[\begin{align}
\displaystyle\sum_{j=1}^{n}(\mathbf X_j-\boldsymbol \mu)^T\mathbf \Sigma^{-1}(\mathbf X_j-\boldsymbol\mu)&amp;=\displaystyle\sum_{i=1}^{n}tr\Bigl[\mathbf \Sigma^{-1}(\mathbf X_j-\boldsymbol\mu)(\mathbf X_j-\boldsymbol \mu)^T\Bigr]\\
&amp;=tr\Bigl[\mathbf \Sigma^{-1}\sum_{j=1}^{n}(\mathbf X_j-\boldsymbol\mu)(\mathbf X_j-\boldsymbol \mu)^T\Bigr]\\
&amp;=tr\Biggl[\mathbf \Sigma^{-1}\sum_{j=1}^{n}(\mathbf X_j-\overline{\mathbf X}+\overline{\mathbf X}-\boldsymbol\mu)(\mathbf X_j-\overline{\mathbf X}+\overline{\mathbf X}-\boldsymbol \mu)^T\Biggr]\\
&amp;=tr\Biggl[\mathbf\Sigma^{-1}\Biggl(\sum_{j=1}^{n}(\mathbf X_j-\overline{\mathbf X})(\mathbf X_j-\overline{\mathbf X})^T+\sum_{j=1}^{n}(\overline{\mathbf X}-\boldsymbol\mu)(\overline{\mathbf X}-\boldsymbol \mu)^T\Biggr)\Biggr]\\
&amp;=tr\Biggl[\mathbf\Sigma^{-1}\Biggl(\sum_{j=1}^{n}(\mathbf X_j-\overline{\mathbf X})(\mathbf X_j-\overline{\mathbf X})^T+n(\overline{\mathbf X}-\boldsymbol\mu)(\overline{\mathbf X}-\boldsymbol \mu)^T\Biggr)\Biggr]\\
&amp;=tr\Biggl[\mathbf\Sigma^{-1}\sum_{j=1}^{n}(\mathbf X_j-\overline{\mathbf X})(\mathbf X_j-\overline{\mathbf X})^T\Biggr]+n\cdot tr\Biggl[\mathbf\Sigma^{-1}(\overline{\mathbf X}-\boldsymbol\mu)(\overline{\mathbf X}-\boldsymbol \mu)^T\Biggr]\\
&amp;=tr\Biggl[\mathbf\Sigma^{-1}\sum_{j=1}^{n}(\mathbf X_j-\overline{\mathbf X})(\mathbf X_j-\overline{\mathbf X})^T\Biggr]+n\cdot tr\Biggl[(\overline{\mathbf X}-\boldsymbol \mu)^T\mathbf\Sigma^{-1}(\overline{\mathbf X}-\boldsymbol\mu)\Biggr]\\
&amp;=tr\Biggl[\mathbf\Sigma^{-1}\sum_{j=1}^{n}(\mathbf X_j-\overline{\mathbf X})(\mathbf X_j-\overline{\mathbf X})^T\Biggr]+n\Biggl[(\overline{\mathbf X}-\boldsymbol \mu)^T\mathbf\Sigma^{-1}(\overline{\mathbf X}-\boldsymbol\mu)\Biggr]\\
\end{align}\]</span> Because <span class="math inline">\(\mathbf\Sigma^{-1}\)</span> is positive definite, so <span class="math inline">\((\overline{\mathbf X}-\boldsymbol \mu)^T\mathbf\Sigma^{-1}(\overline{\mathbf X}-\boldsymbol\mu)\ge0\)</span> and <span class="math inline">\((\overline{\mathbf X}-\boldsymbol \mu)^T\mathbf\Sigma^{-1}(\overline{\mathbf X}-\boldsymbol\mu)=0\)</span> when <span class="math inline">\(\hat{\boldsymbol \mu}=\overline{\mathbf X}\)</span></p></li>
<li><p>For <span class="math inline">\(p\times p\)</span> symmetric positive definite matrix <span class="math inline">\(\mathbf A\)</span> and a scalar <span class="math inline">\(a&gt;0\)</span> and all positive definite <span class="math inline">\(\underset{(p\times p)}{\mathbf \Sigma}\)</span>, let <span class="math inline">\(\lambda_i\)</span> are the eigenvalues of <span class="math inline">\(\mathbf A^{1/2}\mathbf\Sigma^{-1}\mathbf A^{1/2}\)</span>, then <span class="math display">\[\begin{align}
\frac{1}{|\mathbf \Sigma|^a}e^{-\frac{1}{2}tr(\mathbf\Sigma^{-1}\mathbf A)}&amp;=\frac{1}{|\mathbf \Sigma|^a}e^{-\frac{1}{2}tr(\mathbf\Sigma^{-1}\mathbf A^{1/2}\mathbf A^{1/2})}\\
&amp;=\frac{1}{|\mathbf \Sigma|^a}e^{-\frac{1}{2}tr(\mathbf\Sigma^{-1}\mathbf A^{1/2}\mathbf A^{1/2})}\\
&amp;=\frac{1}{|\mathbf \Sigma|^a}e^{-\frac{1}{2}tr(\mathbf A^{1/2}\mathbf\Sigma^{-1}\mathbf A^{1/2})}\\
&amp;=\frac{1}{|\mathbf \Sigma|^a}e^{-\frac{1}{2}tr(\displaystyle\sum_{i=1}^{p}\lambda_i)}\\
\end{align}\]</span> and <span class="math display">\[\begin{align}
\prod_{i=1}^{p}\lambda_i=|\mathbf A^{1/2}\mathbf\Sigma^{-1}\mathbf A^{1/2}|&amp;=|\mathbf A^{1/2}||\mathbf\Sigma^{-1}||\mathbf A^{1/2}|\\
&amp;=|\mathbf\Sigma^{-1}||\mathbf A^{1/2}||\mathbf A^{1/2}|\\
&amp;=|\mathbf\Sigma^{-1}||\mathbf A|\\
&amp;=\frac{1}{|\mathbf\Sigma|}|\mathbf A|\\
\end{align}\]</span> then <span class="math inline">\(\frac{1}{|\mathbf\Sigma|}=\frac{\displaystyle\prod_{i=1}^{p}\lambda_i}{|\mathbf A|}\)</span> and <span class="math display">\[\begin{align}
\frac{1}{|\mathbf \Sigma|^a}e^{-\frac{1}{2}tr(\mathbf\Sigma^{-1}\mathbf A)}&amp;=\Biggl(\frac{\displaystyle\prod_{i=1}^{p}\lambda_i}{|\mathbf A|}\Biggr)^ae^{-\frac{1}{2}\sum_{i=1}^{p}\lambda_i}\\
&amp;=\frac{1}{|\mathbf A|^a}\displaystyle\prod_{i=1}^{p}\lambda_i^ae^{-\frac{1}{2}\lambda_i}
\end{align}\]</span> Because <span class="math inline">\(\lambda_i^ae^{-\frac{1}{2}\lambda_i}\)</span> has a maximum <span class="math inline">\((2a)^ae^{-a}\)</span> when <span class="math inline">\(\lambda_i=2a\)</span>, so <span class="math inline">\(\frac{1}{|\mathbf \Sigma|^a}e^{-\frac{1}{2}tr(\mathbf\Sigma^{-1}\mathbf A)}\le\frac{1}{|\mathbf A|^a}(2a)^{ap}e^{-ap}\)</span>, when <span class="math inline">\(\lambda_i=2a\)</span>, <span class="math inline">\(\frac{1}{|\mathbf\Sigma|}=\frac{\displaystyle\prod_{i=1}^{p}\lambda_i}{|\mathbf A|}=\frac{(2a)^p}{|\mathbf A|}\)</span> and <span class="math inline">\(tr(\mathbf\Sigma^{-1}\mathbf A)=2ap\)</span> and <span class="math inline">\(\mathbf\Sigma=\frac{1}{2a}\mathbf A\)</span></p></li>
<li><p>Let <span class="math inline">\(\mathbf X_1, \mathbf X_2, \cdots, \mathbf X_n\)</span> be a random sample from a normal population with mean <span class="math inline">\(\boldsymbol \mu\)</span> and covariance <span class="math inline">\(\mathbf\Sigma\)</span>, the likelihood function is <span class="math display">\[\begin{align}
L(\boldsymbol \mu,\mathbf\Sigma)&amp;=\prod_{j=1}^{n}\Biggl[\frac{1}{(2\pi)^{p/2}|\mathbf\Sigma|^{1/2}}e^{-\frac{1}{2}(\mathbf x_j-\boldsymbol \mu)^T\mathbf\Sigma^{-1}(\mathbf x_j-\boldsymbol \mu)}\Biggr]\\
&amp;=\frac{1}{(2\pi)^{\frac{np}{2}}|\mathbf\Sigma|^{n/2}}e^{-\frac{1}{2}\sum_{j=1}^{n}(\mathbf x_j-\boldsymbol \mu)^T\mathbf\Sigma^{-1}(\mathbf x_j-\boldsymbol \mu)}\\
&amp;=\frac{1}{(2\pi)^{\frac{np}{2}}|\mathbf\Sigma|^{n/2}}e^{-\frac{1}{2}tr\Biggl[\mathbf\Sigma^{-1}\sum_{j=1}^{n}(\mathbf x_j-\boldsymbol \mu)^T(\mathbf x_j-\boldsymbol\mu)\Biggr]}\\
&amp;=\frac{1}{(2\pi)^{\frac{np}{2}}|\mathbf\Sigma|^{n/2}}e^{-\frac{1}{2}tr\Biggl[\mathbf\Sigma^{-1}\Biggl(\sum_{j=1}^{n}(\mathbf x_j-\overline{\mathbf x})(\mathbf x_j-\overline{\mathbf x})^T+n(\overline{\mathbf x}-\boldsymbol\mu)(\overline{\mathbf x}-\boldsymbol\mu)^T\Biggr)\Biggr]}\\
\end{align}\]</span> the likelihood function maximized with respect to <span class="math inline">\(\hat{\boldsymbol \mu}=\overline{\mathbf x}\)</span> <span class="math inline">\(L(\boldsymbol \mu,\mathbf\Sigma)=\frac{1}{(2\pi)^{\frac{np}{2}}|\mathbf\Sigma|^{n/2}}e^{-\frac{1}{2}tr\Biggl[\mathbf\Sigma^{-1}\Biggl(\sum_{j=1}^{n}(\mathbf x_j-\overline{\mathbf x})(\mathbf x_j-\overline{\mathbf x})^T\Biggr)\Biggr]}\)</span> and maximized with respect to <span class="math inline">\(\hat{\mathbf\Sigma}=\frac{1}{2n/2}\displaystyle\sum_{j=1}^{n}(\mathbf x_j-\overline{\mathbf x})(\mathbf x_j-\overline{\mathbf x})^T=\frac{1}{n}\displaystyle\sum_{j=1}^{n}(\mathbf x_j-\overline{\mathbf x})(\mathbf x_j-\overline{\mathbf x})^T=\frac{n-1}{n}\mathbf S\)</span>, the maximized likelihood function is <span class="math inline">\(L(\hat{\boldsymbol\mu},\hat{\mathbf\Sigma})=\frac{1}{(2\pi)^{np/2}}\frac{1}{|\hat{\mathbf\Sigma}|^{n/2}}e^{-np/2}\)</span></p></li>
<li><p>For the sample variance <span class="math inline">\(s^2\)</span> of the univariate normal random variables <span class="math inline">\(s^2=\frac{1}{n-1}\sum_{j=1}^{n}(X_j-\overline X)^2=\frac{\sigma^2}{n-1}\sum_{j=1}^{n}(\frac{X_j-\overline X}{\sigma})^2=\frac{\sigma^2}{n-1}\chi_{n-1}^2\)</span>. The sampling distribution of the sample covariance matrix of multivariate normal random variables <span class="math inline">\(N_p(\boldsymbol\mu,\mathbf\Sigma)\)</span> is <span class="math inline">\(\mathbf S=\frac{1}{n-1}\sum_{j=1}^{n}\mathbf Z_j\mathbf Z_j^T\)</span> and <span class="math inline">\(\sum_{j=1}^{n}\mathbf Z_j\mathbf Z_j^T\)</span> is called the <strong>Wishart distribution</strong> with <span class="math inline">\(n\)</span> df.</p></li>
<li><p><span class="math inline">\(\overline {\mathbf X}\)</span> is distributed as <span class="math inline">\(N_p(\boldsymbol\mu,\frac{1}{n}\mathbf\Sigma)\)</span> then <span class="math inline">\(\sqrt{n}(\overline {\mathbf X}-\boldsymbol\mu)\)</span> is distributed as <span class="math inline">\(N_p(0,\mathbf\Sigma)\)</span> and <span class="math inline">\(n(\overline {\mathbf X}-\boldsymbol\mu)^T\mathbf\Sigma^{-1}(\overline {\mathbf X}-\boldsymbol\mu)\)</span> is distributed as <span class="math inline">\(\chi_p^2\)</span></p></li>
</ul>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
          </li>
          <li>
          </li>
        </ul>
      </footer>

    </div>
    

    
<script src="../../../../js/math-code.js"></script>
<script async src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>


    
  </body>
</html>

